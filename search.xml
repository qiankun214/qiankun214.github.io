<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>网络学习笔记2——信号与系统</title>
      <link href="2020/11/09/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%E2%80%94%E2%80%94%E7%89%A9%E7%90%86%E5%B1%82%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%EF%BC%89/"/>
      <url>2020/11/09/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%E2%80%94%E2%80%94%E7%89%A9%E7%90%86%E5%B1%82%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="1-信号相关概念"><a href="#1-信号相关概念" class="headerlink" title="1.信号相关概念"></a>1.信号相关概念</h1><ul><li>信号：信号与系统范畴内，信号被描述为以时间为唯一自变量的函数，一般连续信号使用<code>x(t)</code>表示，离散信号使用<code>x[n]</code>表示</li><li>信号的功率与能量：描述信号能量的物理量，如下表中所示。当范围分别趋向于正无穷和负无穷时，为无限范围的能量。</li></ul><div class="table-container"><table><thead><tr><th>定义</th><th>公式</th></tr></thead><tbody><tr><td>信号在一定时间范围内的能量</td><td>$\int^{T1}<em>{T2}\vert x(t)\vert ^2dt$（连续）、$\sum\limits^{T1}</em>{n=T2}\vert x[n]^2$（离散）</td></tr><tr><td>信号在一定时间范围内的功率</td><td>$\frac{1}{T1-T2}\int^{T1}<em>{T2}\vert x(t)\vert^2dt$（连续）、$\frac{1}{T1-T2}\sum\limits^{T1}</em>{n=T2}\vert x[n]\vert^2$（离散）</td></tr></tbody></table></div><ul><li>自变量变换：对于一个信号$x(t)$进行自变量的线性变换$x(\alpha \times t + \beta)$，不同的变换组合如下表所示：</li></ul><div class="table-container"><table><thead><tr><th>变换</th><th>参数变换</th><th>举例</th></tr></thead><tbody><tr><td>时移</td><td>$\alpha = 0,\beta \neq 0$</td><td>时间移动，当$\beta &gt; 0$，信号向时间轴右侧移动，反之左侧</td></tr><tr><td>反转</td><td>$\alpha = -1,\beta=0$</td><td>时间反转，将信号按时间倒转，类似于磁带倒放</td></tr><tr><td>尺度变换</td><td>$\alpha \neq 0,1,-1,\beta=0$</td><td>时间尺度伸缩，$\alpha&gt;0$时间加速，类似于音乐加速播放，反之为减速</td></tr></tbody></table></div><ul><li>周期信号：对于连续信号而言，对于任意t均满足$x(t) = x(t+T)$的信号为周期信号，否则为非周期信号，最小的T为基波周期；对于离散信号而言，对于任意的n均满足$x[n] = x[n + N]$的信号为周期信号，否则为非周期信号，最小的N为基波周期。</li><li>奇信号与偶信号：奇信号和偶信号的概念如下所示，任意一个信号$x(t)$都能被分解为一个奇信号$\frac{x(t) - x(t)}{2}$和一个偶信号$\frac{x(t)+x(-t)}{2}$的和</li></ul><div class="table-container"><table><thead><tr><th>概念</th><th>定义</th></tr></thead><tbody><tr><td>奇信号</td><td>对任意的t或n，满足$x(t) = -x(-t)$或$x[n] = -x[-n]$</td></tr><tr><td>偶信号</td><td>对任意的t或n，满足$x(t) = x(-t)$或$x[n] = x[-n]$</td></tr></tbody></table></div><h2 id="1-1-指数信号和正弦信号"><a href="#1-1-指数信号和正弦信号" class="headerlink" title="1.1.指数信号和正弦信号"></a>1.1.指数信号和正弦信号</h2><h2 id="1-2-阶跃信号和冲激信号"><a href="#1-2-阶跃信号和冲激信号" class="headerlink" title="1.2.阶跃信号和冲激信号"></a>1.2.阶跃信号和冲激信号</h2>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络学习笔记1——协议分层</title>
      <link href="2020/11/06/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%E2%80%94%E2%80%94%E5%8D%8F%E8%AE%AE%E5%88%86%E5%B1%82/"/>
      <url>2020/11/06/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%E2%80%94%E2%80%94%E5%8D%8F%E8%AE%AE%E5%88%86%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="分层概念"><a href="#分层概念" class="headerlink" title="分层概念"></a>分层概念</h1><p>网络协议是分层的，分层的概念类似于函数封装，不断提供更高级更抽象的接口，最后提供给客户使用。对于分层协议而言，整个协议共同完成一件事情，每个层次基于本层或低层接口完成本层次的功能并对更高级的层次提供接口，即对于每个层次而言，有以下两个主要功能：</p><ul><li>对高级提供接口：将本层次的功能封装，供高层调用</li><li>实现本层功能：在本层中实现功能，一般通过调用低层提供的接口实现（最底层除外）</li></ul><p>举一个例子，若要实现计算器计算的功能，我们实现一个计算器协议，其分为以下几个层次：</p><ol><li>用户输入层：最高层，为用于提供数据输入方式和结果输出方式，实现用户输入与逻辑语言的相互转换</li><li>逻辑编译层：中间层，将逻辑语言转换为硬件可以实现的代码，实现计算，将结果转为逻辑语言</li><li>硬件层：最底层，实现代码的计算和结果的输出</li></ol><p>假设厂商基于计算器协议构建了一个手写计算器，当用户需要进行<code>1+1</code>的运算时，以手写的方式输入计算需求，即一张手写图片，随后用户输入层将这个手写图片转换为逻辑语言<code>R=1+1</code>，调用逻辑编译层进行实现；逻辑编译层将其转换为汇编代码<code>ADD R 1 1</code>，调用硬件层进行实现；硬件层运行汇编代码得出结果R为2，并将结果反馈给逻辑编译层；逻辑编译层接收硬件层的结果并将其返回给用户输入层；用户输入层将结果转为手写数字2反馈给用户。</p><p>这种分层协议的好处在于分层之间相互独立，仅有接口上的联系，可以进行方便的替换。以上述计算器协议为例，用户输入层可以使用触屏，也可以使用键盘，只需要将输入（触屏输入或键盘输入）转为统一格式的逻辑语言即可；在逻辑编译层也可以使用不同的编译软件，只需要输入和输出格式接口相同即可；硬件层亦然，可以使用AMD的cpu也可以使用Intel的cpu，只需要提供给逻辑编译层相同的接口即可。层与层之间相互独立，层层抽象。</p><h1 id="TCP-IP分层"><a href="#TCP-IP分层" class="headerlink" title="TCP/IP分层"></a>TCP/IP分层</h1><p>TCP/IP分层脱胎于OSI分层，以上两个分层如下图所示：</p><p>OSI分层共分为7层，TCP/IP模型共分为5层，首先考虑OSI分层，并以联机对战中的一个操作为例，即控制某个人物向指定的方向释放出一个指定的技能（实际游戏会不同）：</p><ul><li>应用层：为应用程序提供服务并规定应用程序中通信相关的细节。在例子中，用户A按下技能快捷键，并点击鼠标，向某个方向释放出一个技能，在应用层，这一操作被打包为一个json数据包，组成为技能编号和释放方位。</li><li>表示层：主要负责数据格式的转换。将应用处理的信息转换为适合网络传输的格式，或将来自下一层的数据转换为上层能够处理的格式。例子中，将应用层产生的json包编码为一个byte流。</li><li>会话层：负责确定何事建立和断开通信连接（数据流动的逻辑通路），以及数据的分割等数据传输相关的管理。例子中，会话层接收到表示层产生的byte流，调用低层的接口建立与用户B会话层的通信连接，将byte流传递给用户B，但是若用户A的技能处于无法释放的状态，则会话层负责等待到技能可以释放时，再建立连接发送数据。</li><li>传输层：实际进行建立的层次，同时起着可靠传输的作用。当会话层决定建立连接时，传输层负责建立连接的具体事务，其建立连接并确保有效传输。例子中，若网络传输过程中byte流发生数据缺失，用户B的传输层会通知用户A的传输层再发送一次数据。</li><li>网络层：将数据传输到目标地址。例子中，即将byte流从用户A的主机发送到用户B的主机。</li><li>数据链路层：负责物理层面上互连的、节点之间的通信传输。例子中，即将负责将数据从一个节点发送到另一个节点。</li><li>物理层：负责0、1比特流（0、1序列）与电压的高低、光的闪灭之间的互换。例子中，若两个节点之间使用光纤通信，则负责光电信号的转换。</li></ul><p>对于TCP/IP的分层，将OSI中的应用层、表示层和会话层统一为应用层，因此5层分组和对应的协议举例有：</p><ul><li>应用层：HTTPS、HTTP、FTP、SSH等</li><li>传输层：TCP、UDP等</li><li>网络层：IPv4、IPv6等</li><li>数据链路层和物理层：以太网、IEEE 802.11等</li></ul><p>对于数据链路层和物理层，其功能为将数据从一个节点发送到一个相邻的节点；对于网络层，其功能为将数据从一个主机发送到另一个主机（可能跨越很多个节点，不关心是否出错）；对于传输层，要保证数据无错误的从一个主机发送到另一个主机，传输层协议一次传输可能调用网络层传输多次；应用层位用户最终接触到的协议，实现具体功能，例如HTTPS实现网页访问，FTP实现数据传输，如下图所示：</p>]]></content>
      
      
      <categories>
          
          <category> 网络协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高级综合工具StratusHLS学习笔记(4)</title>
      <link href="2020/09/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(4)/"/>
      <url>2020/09/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(4)/</url>
      
        <content type="html"><![CDATA[<h1 id="HLS中使用浮点数"><a href="#HLS中使用浮点数" class="headerlink" title="HLS中使用浮点数"></a>HLS中使用浮点数</h1><p>学习目标：</p><ul><li>使用浮点数</li><li>换用自己的库进行高级综合</li></ul><h2 id="HLS中的浮点数"><a href="#HLS中的浮点数" class="headerlink" title="HLS中的浮点数"></a>HLS中的浮点数</h2><p>stratus HLS提供内置的浮点数，可以实现常规的加减乘操作，类型为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cynw_cm_float&lt;e,f,accurcy,rounding mode,NaN handle&gt;</span><br></pre></td></tr></table></figure><p>该类型共有5个模板参数，分别如下所示：</p><ul><li>e：指数位宽，为浮点数的指数位数</li><li>f：尾数位宽，为浮点数的尾数位数</li><li>accuracy：精确度，这一参数可以设置是否需要实现完整的IEEE标准浮点数。若需要实现则可以提高计算精度，若不实现则可以缩小面积提升性能。</li><li>rounding mode：取整模式，推测为浮点数尾数处理中如何取整，具有多种模式</li><li>NaN handle：用于选择如何处理NaN</li></ul><p>对于指数位宽和尾数位宽，为每一个浮点数都具有的参数，不用过多解释；对于精确度，具有多种选项，每种选项具有不同的精度-代价折中，如下表所示：</p><div class="table-container"><table><thead><tr><th>标号</th><th>说明</th></tr></thead><tbody><tr><td>CYNW_REDUCED_ACCURACY</td><td>默认情况，使用低精度低代价实现方法</td></tr><tr><td>CYNW_BEST_ACCURACY</td><td>使用IEEE标准的浮点数</td></tr><tr><td>CYNW_NATIVE_ACCURACY</td><td>使用C++中的浮点数，不可综合</td></tr><tr><td>CYNW_EXCEPTION_ACCURACY</td><td>使用IEEE标准带异常的浮点数精度</td></tr></tbody></table></div><p>对于取整模式rounding，可选择的如下表所示：</p><div class="table-container"><table><thead><tr><th>标号</th><th>说明</th></tr></thead><tbody><tr><td>CYNW_NEAREST</td><td>默认情况，向最接近的偶数取整</td></tr><tr><td>CYNW_POSINF</td><td>向上取整</td></tr><tr><td>CYNW_NEGINF</td><td>向下取整</td></tr><tr><td>CYNW_RNDZERO</td><td>向零取整</td></tr><tr><td>CYNW_NEAREST_AWAY</td><td>四舍五入</td></tr></tbody></table></div><p>对于NaN处理，有下表所示：</p><div class="table-container"><table><thead><tr><th>标号</th><th>说明</th></tr></thead><tbody><tr><td>0</td><td>返回恒定的NaN</td></tr><tr><td>1</td><td>默认情况，标准IEEE的NaN处理方法，左操作数优先</td></tr><tr><td>2</td><td>标准IEEE的NaN处理方法，右操作数优先</td></tr></tbody></table></div><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>在设计中，需要添加头文件<code>cynw_cm_float.h</code>即可使用以上浮点数类型，使用时如同常规数据类型直接使用，可实现加减乘等操作，如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_cm_float.h&quot;</span></span></span><br><span class="line"><span class="keyword">typedef</span> cynw_cm_float&lt;<span class="number">5</span>,<span class="number">10</span>&gt; DT;</span><br><span class="line"><span class="comment">// DT a,b,c;c = a+b 可实现</span></span><br></pre></td></tr></table></figure><p>在<code>project.tcl</code>中，需要在添加库的同时添加使用浮点库，如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use_hls_lib <span class="string">&quot;cynw_cm_float&quot;</span></span><br></pre></td></tr></table></figure><p>随后进行常规的仿真流程即可，下图为CYNW_REDUCED_ACCURACY的float16加法器的仿真和综合结果，使用的库是自带的55nm库：</p><img src="/2020/09/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(4)/1.png" class=""><h1 id="时序相关"><a href="#时序相关" class="headerlink" title="时序相关"></a>时序相关</h1><h2 id="时序设置"><a href="#时序设置" class="headerlink" title="时序设置"></a>时序设置</h2><p>对于时序而言，在HLS有多个参数可以设置，包括：</p><ul><li>时钟频率（必须）</li><li>时钟非理想因素</li><li>输入与输出延迟</li></ul><p>这些因素在常规流程中使用SDC进行设置，在HLS流程中在代码或<code>project.tcl</code>中设置。首先考虑时钟非理想因素。即uncertainty，在HLS中使用<code>cycle_slack</code>在<code>project.tcl</code>中设置，如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set_attr clock_period <span class="number">10.0</span></span><br><span class="line">set_attr cycle_slack <span class="number">1.5</span></span><br></pre></td></tr></table></figure><p>上述设置时钟周期为10ns，非理想因素为1.5ns，等效时钟周期为8.5ns。输入与输出延迟在代码中直接设置，使用<code>HLS_SET_INPUT_DELAY</code>或<code>HLS_SET_DEFAULT_INPUT_DELAY</code>设置输入延迟，其中：</p><ul><li><code>HLS_SET_INPUT_DELAY( port, float delay, &quot;char* name&quot; )</code>：用于设置特定端口</li><li><code>HLS_SET_DEFAULT_INPUT_DELAY( float delay, &quot;char* name&quot; );</code>：用于设置所有未被特定设置的端口</li></ul><p>对于输出而言，同理有：</p><ul><li><code>HLS_SET_OUTPUT_DELAY(signal_id, delay );</code>：用于设置特定端口</li><li><code>HLS_SET_DEFAULT_OUTPUT_DELAY( delay);</code>：用于设置所有未被特定设置的端口</li></ul><p>stratus HLS一般使用寄存器输出，因此除非输出端口，输出延迟可以不进行设置。设置端口延迟如下所示，以下例子中，设置了w_in端口的输入延迟为0.5ns，其他端口（x_in和data_valid）均为0.3ns。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dut_template::t</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    HLS_SET_INPUT_DELAY(w_in,<span class="number">0.5</span>,<span class="string">&quot;data0_delay&quot;</span>);</span><br><span class="line">    HLS_SET_DEFAULT_INPUT_DELAY(<span class="number">0.3</span>,<span class="string">&quot;data1_delay&quot;</span>);</span><br><span class="line">    &#123;</span><br><span class="line">        HLS_DEFINE_PROTOCOL(<span class="string">&quot;reset&quot;</span>);</span><br><span class="line">        w_in.reset();</span><br><span class="line">        x_in.reset();</span><br><span class="line">        y_out.reset();</span><br><span class="line">        data_valid.write(<span class="number">0</span>);</span><br><span class="line">        wait();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        HLS_PIPELINE_LOOP(SOFT_STALL, <span class="number">1</span>, <span class="string">&quot;main_loop&quot;</span>);</span><br><span class="line">        DT x_val = x_in.get();</span><br><span class="line">        DT w_val = w_in.get();</span><br><span class="line">        DT out_val = x_val + w_val;</span><br><span class="line">        y_out.put(out_val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="时序违例"><a href="#时序违例" class="headerlink" title="时序违例"></a>时序违例</h2><p>HLS一般不会出现时序违例，因为可以自动进行流水线的插入操作，经过试验，即使float计算ip也可以在时序不满足时自动进行流水线插入以避免时序违例，同时stratus HLS将时序违例看做“错误”，当出现时序违例时，软件会抛出错误Error并打印时序违例的信息，一般时序违例来源于人工指定过多时序等，例如强制要求某段代码在指定的时钟周期内完成。</p><h1 id="使用自己的库"><a href="#使用自己的库" class="headerlink" title="使用自己的库"></a>使用自己的库</h1><p>stratus HLS中内置一个55nm的库，在具体工艺中，需要使用自己的库进行评估，在<code>project.tcl</code>中，使用如下命令：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use_tech_lib <span class="string">&quot;path.lib&quot;</span></span><br></pre></td></tr></table></figure><p>注意需要使用的是.lib库而不是.db库。随后重新生成makefile，即可使用自己的库进行评估。</p>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高级综合 </tag>
            
            <tag> StratusHLS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高级综合工具StratusHLS学习笔记(3)</title>
      <link href="2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/"/>
      <url>2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/</url>
      
        <content type="html"><![CDATA[<p>学习目标：</p><ul><li>学习如何使用Stratus IDE生成存储器模型</li><li>学习如何在代码中使用存储器模型</li></ul><h1 id="1-存储器生成"><a href="#1-存储器生成" class="headerlink" title="1.存储器生成"></a>1.存储器生成</h1><p>存储器生成使用Stratus IDE内置的存储器模型生成器，首先使用Stratus IDE打开工程，在左侧边栏中打开project选项卡，打开libraries，右键Memories，选择<code>New Memory Library</code>新建存储器库，新建后可以在工程下发现同名文件夹</p><img src="/2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/1.png" class=""><p>随后，右击新建的库memlib选择新建存储器，可以打开如下的界面进行配置：</p><ul><li>Memory name：存储器名称，使用存储器时使用该名称进行调用</li><li>Word size：数据位宽，即每个地址存储多少个bit</li><li>Number of words：地址数量，即有多少个word，存储容量为$Word size \times Number of words$bit</li><li>Latency：从地址输入到数据输出消耗的时钟周期数量</li><li>Setup time：通常意义的建立时间加保持时间，即控制信号需要在时钟沿附近保持的长度，不要写0。</li><li>Output delay：输出延迟，即从时钟沿或数据输入到数据输出的延迟时间，不要写0。</li><li>Area：面积，HLS将在综合报告中使用该面积（如果填写）</li></ul><p>中间的Option部分可以选择时序的方式，时序有以下几种：</p><ul><li>Allow chaining：使用左侧的Setup time和Output delay计入延迟估算，在必要时插入寄存器</li><li>Disallow chaining：不计入延迟估算，等效于Setup time和Output delay都填写0</li><li>Registers at memories：强制插入寄存器</li></ul><img src="/2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/2.png" class=""><p>在这个页面填写常规信息后，点击上方的Port端口添加或编辑端口信息，该界面如下所示。可以通过编辑端口数量、选择端口类型和编辑端口名称，这些端口名称将在波形中体现。</p><img src="/2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/3.png" class=""><p>随后点击OK即可生成存储器模型，生成的存储器模型文件结构如下所示：</p><img src="/2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/4.png" class=""><p>在调用存储器模型的文件中，需要引用头文件<code>memlib.h</code></p><h1 id="2-存储器使用"><a href="#2-存储器使用" class="headerlink" title="2.存储器使用"></a>2.存储器使用</h1><p>在高级综合中使用存储器通过wrapper和port构成：</p><ul><li>wrapper：存储器模块，通过调用该模块生成存储器</li><li>port：访问接口，在一个模块中声明一个存储器的port并将该port和wrapper指针连接即可进行存储器访问</li></ul><p>对于wrapper，其声明方式为<code>&lt;memory name&gt;::wrapper&lt;ioConfig&gt; * point</code>，例如声明一个名称为RAM的wrapper，命名为m_mem如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RAM::wrapper&lt;ioConfig&gt; * m_mem;</span><br></pre></td></tr></table></figure><p>定义后需要在构造函数（SC_CTOR）中对其进行实例化和绑定clk和rst端口，如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">m_mem = <span class="keyword">new</span> RAM::wrapper&lt;ioConfig&gt;(<span class="string">&quot;ram_wrapper&quot;</span>);</span><br><span class="line">m_mem-&gt;clk_rst(clk,rst);</span><br></pre></td></tr></table></figure><p>对于port，声明方式为<code>&lt;memory name&gt;::port&lt;ioConfig&gt; port</code>，例如声明一个名称为RAM的port，命名为ram_port如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RAM::port&lt;ioConfig&gt; ram_port;</span><br></pre></td></tr></table></figure><p>同样的，需要在构造函数中绑定clk和rst端口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ram_port.clk_rst(clk, rst);</span><br></pre></td></tr></table></figure><p>并且需要在顶层将wrapper绑定到端口上，如下所示（m_dut为ram_port所属的模块）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">m_dut-&gt;ram_port(*m_mem);</span><br></pre></td></tr></table></figure><p>随后可以使用类似数组的方式对存储进行访问，访问方式如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read_data = ram_port[i] <span class="comment">// 从i地址读取数据</span></span><br><span class="line">ram_port[i] = write_data <span class="comment">// 将数据写入i地址</span></span><br></pre></td></tr></table></figure><p>最后，需要在project.tcl中添加存储器库，使用<code>use_hls_lib</code>指令，写法如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">use_hls_lib <span class="string">&quot;./memlib&quot;</span></span><br></pre></td></tr></table></figure><p>另外，对于一个存储器模型，具有以下的参数可以方便代码的编写：</p><div class="table-container"><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>\<memory name>::SIZE</td><td>存储器word数量（Number of words）</td></tr><tr><td>\<memory name>::address_width</td><td>存储器地址位宽</td></tr><tr><td>\<memory name>::data_width</td><td>存储器数据位宽</td></tr></tbody></table></div><h1 id="3-实际工程"><a href="#3-实际工程" class="headerlink" title="3.实际工程"></a>3.实际工程</h1><p>这里实现了一个将memory集成的加法器功能，功能为输入一个数据i，从存储器的地址i获取数据并与i相加，加法部分模块如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __DUT_TEMPLATE__H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __DUT_TEMPLATE__H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_p2p.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_fifo.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;defines.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;memlib.h&quot;</span></span></span><br><span class="line">SC_MODULE(dut_template) &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    cynw_p2p&lt;DT, ioConfig&gt;::in x_in;</span><br><span class="line">    cynw_p2p&lt;DT, ioConfig&gt;::out y_out;</span><br><span class="line">    RAM::port&lt;ioConfig&gt; ram_port;  <span class="comment">// 存储器访问接口</span></span><br><span class="line">    </span><br><span class="line">    sc_in_clk clk;</span><br><span class="line">    sc_in&lt;<span class="keyword">bool</span>&gt; rst;</span><br><span class="line"></span><br><span class="line">    SC_CTOR(dut_template):</span><br><span class="line">        x_in(<span class="string">&quot;x_in&quot;</span>),</span><br><span class="line">        y_out(<span class="string">&quot;y_out&quot;</span>), </span><br><span class="line">        clk(<span class="string">&quot;clk&quot;</span>), rst(<span class="string">&quot;rst&quot;</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        SC_CTHREAD(t, clk.pos());</span><br><span class="line">        reset_signal_is(rst, <span class="number">0</span>);</span><br><span class="line">        x_in.clk_rst(clk, rst);</span><br><span class="line">        y_out.clk_rst(clk, rst);</span><br><span class="line">        ram_port.clk_rst(clk, rst);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">t</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;dut_template.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dut_template::t</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#123;</span><br><span class="line">        HLS_DEFINE_PROTOCOL(<span class="string">&quot;reset&quot;</span>);</span><br><span class="line">        x_in.reset();</span><br><span class="line">        y_out.reset();</span><br><span class="line">        ram_port.reset();</span><br><span class="line">        wait();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; RAM::SIZE; ++i) <span class="comment">// 存储器初始化过程</span></span><br><span class="line">    &#123;</span><br><span class="line">        ram_port[i] = i; <span class="comment">// 写入存储器</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        HLS_PIPELINE_LOOP(SOFT_STALL, <span class="number">1</span>, <span class="string">&quot;main_loop&quot;</span>); <span class="comment">// 使用流水线</span></span><br><span class="line">        DT x_val = x_in.get();</span><br><span class="line">        sc_uint&lt;RAM::address_width&gt; addr = x_val;  </span><br><span class="line">        sc_uint&lt;RAM::data_width&gt; ram_data = ram_port[addr];  <span class="comment">// 从存储器中读取数据</span></span><br><span class="line">        DT out_val = x_val + ram_data;</span><br><span class="line">        y_out.put(out_val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>顶层模块如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _DUI_MEM</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _DUI_MEM</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_p2p.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_fifo.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;defines.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;memlib.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;dut_template_wrap.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">SC_MODULE(memory_acc_test) &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    cynw_p2p&lt;DT, ioConfig&gt;::base_in x_in;</span><br><span class="line">    cynw_p2p&lt;DT, ioConfig&gt;::base_out y_out;</span><br><span class="line">    </span><br><span class="line">    RAM::wrapper&lt;ioConfig&gt; * m_mem;  <span class="comment">// 定义RAM的wrapper</span></span><br><span class="line">    dut_template_wrapper *m_dut;</span><br><span class="line">    </span><br><span class="line">    sc_in_clk clk;</span><br><span class="line">    sc_in&lt;<span class="keyword">bool</span>&gt; rst;</span><br><span class="line"></span><br><span class="line">    SC_CTOR(memory_acc_test):</span><br><span class="line">        x_in(<span class="string">&quot;x_in&quot;</span>),</span><br><span class="line">        y_out(<span class="string">&quot;y_out&quot;</span>), </span><br><span class="line">        clk(<span class="string">&quot;clk&quot;</span>), rst(<span class="string">&quot;rst&quot;</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        m_mem = <span class="keyword">new</span> RAM::wrapper&lt;ioConfig&gt;(<span class="string">&quot;ram_wrapper&quot;</span>); <span class="comment">// 实例化</span></span><br><span class="line">        m_mem-&gt;clk_rst(clk,rst); <span class="comment">// 绑定端口</span></span><br><span class="line"></span><br><span class="line">        m_dut = <span class="keyword">new</span> dut_template_wrapper(<span class="string">&quot;m_dut&quot;</span>);</span><br><span class="line">        m_dut-&gt;clk(clk);</span><br><span class="line">        m_dut-&gt;rst(rst);</span><br><span class="line">        m_dut-&gt;x_in(x_in);</span><br><span class="line">        m_dut-&gt;y_out(y_out);</span><br><span class="line">        m_dut-&gt;ram_port(*m_mem); <span class="comment">// 将wrapper绑定到port上</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>对于以上工程，project.tcl中的库部分如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> LIB_PATH <span class="string">&quot;[get_install_path]/share/stratus/techlibs/GPDK045/gsclib045_svt_v4.4/gsclib045/timing&quot;</span></span><br><span class="line"><span class="keyword">set</span> LIB_LEAF <span class="string">&quot;slow_vdd1v2_basicCells.lib&quot;</span></span><br><span class="line"></span><br><span class="line">use_tech_lib<span class="string">&quot;$LIB_PATH/$LIB_LEAF&quot;</span></span><br><span class="line">use_hls_lib <span class="string">&quot;./memlib&quot;</span></span><br></pre></td></tr></table></figure><p>除此之外，基本与之前的工程相同，进行仿真，不带流水线的结果如下所示：</p><img src="/2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/5.png" class=""><p>带流水线的结果如下所示：</p><img src="/2020/07/29/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)/6.png" class=""><p>可以发现流水线有三级，分别是输入地址、获取输出和计算和。</p>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高级综合 </tag>
            
            <tag> StratusHLS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高级综合工具StratusHLS学习笔记(2)</title>
      <link href="2020/07/19/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)/"/>
      <url>2020/07/19/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)/</url>
      
        <content type="html"><![CDATA[<p>学习目标为：</p><ul><li>如何使用高级综合生成流水线</li><li>如何使用Stratus进行层次化设计</li></ul><h1 id="1-生成流水线"><a href="#1-生成流水线" class="headerlink" title="1.生成流水线"></a>1.生成流水线</h1><p>Stratus允许指定一个主循环（<code>while(1)</code>）中的内容为流水线方式实现，即每个时钟周期均可以进入数据执行，需要在主循环开始时添加如下语句指定使用流水线实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HLS_PIPELINE_LOOP(&lt;STALL_TYPE&gt;, &lt;cycle&gt;, &lt;name&gt;);</span><br></pre></td></tr></table></figure><p>上述指定该loop为流水线实现，具有三个参数，分别如下所示：</p><ul><li>STALL_TYPE：实现类型，包括<code>HARD_STALL</code>和<code>SOFT_STALL</code>两种</li><li>cycle：数据进入间隔，即“每隔多少个时钟周期可进入一个数据”，当cycle=1时表示每个周期均可进入数据</li><li>name：流水线配置名称，每个循环流水线名称不同即可</li></ul><p>对于STALL_TYPE中的两种，具有以下的区别：</p><ul><li><code>HARD_STALL</code>：当流水线的某一级阻塞时，整条流水线停止运行</li><li><code>SOFT_STALL</code>：当流水线的某一级阻塞时，仅阻塞级之前的流水线停止运行，阻塞级之后的流水线继续运行</li></ul><p>对于要生成流水线的代码片（循环体），Stratus有以下的要求：</p><ul><li>循环展开（Nested Loops）：循环体中仅可以嵌套次数指定的循环，且被指定生成流水线的循环要么为无限循环，要么为指定次数循环</li><li>数据依赖（Data Dependencies）：需要保证每一级需要的数据在运行这一级之前已经生成，即数据流向固定向前，不存在反向数据流（产生数据冲突），若发生这种情况Stratus会报错：<code>Unable to satisfy HLS_HLS_PIPELINE_LOOP directive &quot;main_pipeline&quot;,possibly because of a statement in this line.</code></li><li>端口访问（Port Access Conflicts）：对于端口的访问需要谨慎，需要避免连续两个周期访问一个端口的写法，因为会产生对端口的访问冲突（前一次进入loop和后一次loop在同一周期需要访问同一个接口），这种情况会报出Warning：<code>Pipelining forces multiple assignments to output data_out</code></li><li>非平衡流水线（Unbalanced Protocol Blocks）：避免在展开为流水线的循环中使用消耗时钟周期不同的条件判断。即若在循环中使用if-else语句，两个代码块消耗的时钟周期必须一致。</li><li>循环跳出（Conditional Exits in Pipelined Loops）：允许使用break语句跳出循环，但用于判断是否跳出循环的逻辑消耗的时间必须少于数据进入间隔时钟周期</li></ul><p>学习过程使用上一次使用的+1功能电路，将其执行线程改为以下按流水线展开：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dut_template::t</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#123;</span><br><span class="line">        HLS_DEFINE_PROTOCOL(<span class="string">&quot;reset&quot;</span>);</span><br><span class="line">        x_in.reset();</span><br><span class="line">        y_out.reset();</span><br><span class="line">        wait();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// HLS_PIPELINE_LOOP(HARD_STALL, 1, &quot;main_loop&quot;);</span></span><br><span class="line">        HLS_PIPELINE_LOOP(SOFT_STALL, <span class="number">1</span>, <span class="string">&quot;main_loop&quot;</span>);</span><br><span class="line">        DT x_val = x_in.get();</span><br><span class="line">        DT out_val = x_val + <span class="number">1</span>;</span><br><span class="line">        y_out.put(out_val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用了输入间隔为1个周期（每个周期均可输入）的SOFT_STALL形式的流水线。</p><h1 id="2-层次化设计"><a href="#2-层次化设计" class="headerlink" title="2.层次化设计"></a>2.层次化设计</h1><p>为了观察流水线功能，这次将两个+1功能模块<code>dut_template</code>连在一起进行仿真，顶层为<code>pipeline_test</code>，代码如下所所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _DUT_PIPE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _DUT_PIPE</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_p2p.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_fifo.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;defines.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;dut_template_wrap.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">SC_MODULE(pipeline_test) &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">cynw_p2p&lt;DT, ioConfig&gt;::base_in x_in;</span><br><span class="line">cynw_p2p&lt;DT, ioConfig&gt;::base_out y_out;</span><br><span class="line">cynw_p2p&lt;DT, ioConfig&gt; tmp;</span><br><span class="line">sc_in_clk clk;</span><br><span class="line">sc_in&lt;<span class="keyword">bool</span>&gt; rst;</span><br><span class="line"></span><br><span class="line">dut_template_wrapper *ut0;</span><br><span class="line">dut_template_wrapper *ut1;</span><br><span class="line"></span><br><span class="line">SC_CTOR(pipeline_test):</span><br><span class="line">x_in(<span class="string">&quot;x_in&quot;</span>),y_out(<span class="string">&quot;y_out&quot;</span>),tmp(<span class="string">&quot;tmp&quot;</span>),</span><br><span class="line">clk(<span class="string">&quot;clk&quot;</span>),rst(<span class="string">&quot;rst&quot;</span>) &#123;</span><br><span class="line"></span><br><span class="line">ut0 = <span class="keyword">new</span> dut_template_wrapper(<span class="string">&quot;ut0&quot;</span>);</span><br><span class="line">ut0-&gt;clk(clk);</span><br><span class="line">ut0-&gt;rst(rst);</span><br><span class="line">ut0-&gt;x_in(x_in);</span><br><span class="line">ut0-&gt;y_out(tmp);</span><br><span class="line"></span><br><span class="line">ut1 = <span class="keyword">new</span> dut_template_wrapper(<span class="string">&quot;ut1&quot;</span>);</span><br><span class="line">ut1-&gt;clk(clk);</span><br><span class="line">ut1-&gt;rst(rst);</span><br><span class="line">ut1-&gt;x_in(tmp);</span><br><span class="line">ut1-&gt;y_out(y_out);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// void t();  不可调用函数进行连线！！！</span></span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>首先关注使用的p2p接口如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cynw_p2p&lt;DT, ioConfig&gt;::base_in x_in;</span><br><span class="line">cynw_p2p&lt;DT, ioConfig&gt;::base_out y_out;</span><br></pre></td></tr></table></figure><p>需要注意的是本次使用了<code>base_in</code>和<code>base_out</code>而不是<code>in</code>和<code>out</code>（参考笔记1），因为这两个端口的目的仅仅为连接使用，相当于连线，因此不需要使用<code>in</code>和<code>out</code>，也不需要指定时钟与复位信号。随后关注调用部分：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dut_template_wrapper *ut0;</span><br><span class="line">dut_template_wrapper *ut1;</span><br></pre></td></tr></table></figure><p>这里的调用方式为调用<code>dut_template_wrapper</code>而不是<code>dut_template</code>，这是Stratus的区别，若要在高级综合中保留层次结构，则需要在这里调用<code>wrapper</code>而不是本身，对应的，也需要在tcl中指定子模块<code>dut_template</code>为待综合模块。最后一点需要注意的是，<code>SC_CTOR</code>中连线部分需要在本函数中编写，不可像system中一样调用函数进行连线，否则会在仿真过程中产生问题。该设计对应的project.tcl如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">use_tech_lib<span class="string">&quot;$LIB_PATH/$LIB_LEAF&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set_attr clock_period           <span class="number">10.0</span></span><br><span class="line">set_attr message_detail         <span class="number">3</span></span><br><span class="line">set_attr default_input_delay    <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">set_attr cc_options             <span class="string">&quot;  -g --std=c++0x&quot;</span></span><br><span class="line">enable_waveform_logging -vcd</span><br><span class="line">set_attr end_of_sim_command <span class="string">&quot;make saySimPassed&quot;</span></span><br><span class="line"></span><br><span class="line">define_system_module basic_ut/main.cpp</span><br><span class="line">define_system_module basic_ut/system.cpp</span><br><span class="line">define_system_module basic_ut/tb.cpp</span><br><span class="line"></span><br><span class="line">define_hls_module pipeline_test dut_module/pipeline_test.cpp </span><br><span class="line">define_hls_module dut_template dut_module/dut_template.cpp # 子模块也需要指定为待综合模块</span><br><span class="line"></span><br><span class="line">define_io_config * TLM</span><br><span class="line">define_io_config * PIN</span><br><span class="line"></span><br><span class="line">define_hls_config pipeline_test BASIC</span><br><span class="line">define_hls_config dut_template BASIC # 子模块也需要指定综合等级</span><br><span class="line"></span><br><span class="line">define_sim_config T -io_config TLM</span><br><span class="line">define_sim_config B -io_config PIN</span><br><span class="line"></span><br><span class="line">define_sim_config H &#123;pipeline_test RTL_V BASIC&#125;</span><br></pre></td></tr></table></figure><h1 id="3-仿真结果"><a href="#3-仿真结果" class="headerlink" title="3.仿真结果"></a>3.仿真结果</h1><p>仿真结束后使用verdi查看波形，未添加流水线的波形如下所示：</p><img src="/2020/07/19/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)/1.png" class=""><p>可以发现这种情况下每两个周期才能输入一个数据，添加了流水线的波形如下所示：</p><img src="/2020/07/19/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)/2.png" class=""><p>添加了流水线展开后，可以发现每个时钟周期均可输入新的数据。</p>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高级综合 </tag>
            
            <tag> StratusHLS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高级综合工具StratusHLS学习笔记(1)</title>
      <link href="2020/07/09/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)/"/>
      <url>2020/07/09/%E9%AB%98%E7%BA%A7%E7%BB%BC%E5%90%88%E5%B7%A5%E5%85%B7StratusHLS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)/</url>
      
        <content type="html"><![CDATA[<p>本次学习参考Stratus内置的学习例程（simple_p2p），学习内容主要如下所示：</p><ul><li>Stratus HLS软件运行需要的必要文件及其写法</li><li>Stratus HLS软件操作方式</li><li>Stratus HLS内置的p2p端口的基本使用（非流水线）</li><li>Stratus HLS自定义数据类型</li></ul><h1 id="1-Stratus-HLS必要文件与写法"><a href="#1-Stratus-HLS必要文件与写法" class="headerlink" title="1.Stratus HLS必要文件与写法"></a>1.Stratus HLS必要文件与写法</h1><p>Stratus工程所需要的文件如下图所示：</p><div class="table-container"><table><thead><tr><th>文件</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>设计文件</td><td>cpp+h</td><td>描述设计的头文件和cpp文件</td></tr><tr><td>TestBench</td><td>cpp+h</td><td>描述测试平台的头文件和cpp文件</td></tr><tr><td>System</td><td>cpp+h</td><td>连接设计文件和TestBench的头文件和cpp文件</td></tr><tr><td>main.cpp</td><td>cpp</td><td>整个仿真平台的顶层文件</td></tr><tr><td>project.tcl</td><td>tcl</td><td>指定工程配置（仿真选项和综合选项）的tcl文件</td></tr><tr><td>Makefile</td><td>makefile</td><td>由project.tcl生成的makefile文件</td></tr></tbody></table></div><h2 id="1-1-设计文件"><a href="#1-1-设计文件" class="headerlink" title="1.1.设计文件"></a>1.1.设计文件</h2><p>设计文件的头文件如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __NEW1__H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __NEW1__H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_p2p.h&quot;</span>  <span class="comment">// p2p端口的头文件，如需使用cynw_p2p则需要引用该头文件</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1_input_type.h&quot;</span> <span class="comment">// 类型new1_INPUT_DT的头文件</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1_output_type.h&quot;</span> <span class="comment">// 类型new1_OUTPUT_DT的头文件</span></span></span><br><span class="line"></span><br><span class="line">SC_MODULE(new1) &#123;  <span class="comment">// 定义模块new1</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    cynw_p2p &lt; new1_INPUT_DT  &gt;::in     inputs;  <span class="comment">// 一个p2p输入端口</span></span><br><span class="line">    cynw_p2p &lt; new1_OUTPUT_DT &gt;::out    outputs; <span class="comment">// 一个p2p输出端口</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Declaration of clock and reset parameters</span></span><br><span class="line">    sc_in_clk               clk;                 <span class="comment">// 时钟端口，类型为sc_in_clk</span></span><br><span class="line">    sc_in &lt; <span class="keyword">bool</span> &gt;          rst;                 <span class="comment">// 复位端口</span></span><br><span class="line">    SC_CTOR(new1):inputs(<span class="string">&quot;inputs&quot;</span>), outputs(<span class="string">&quot;outputs&quot;</span>), clk(<span class="string">&quot;clk&quot;</span>), rst(<span class="string">&quot;rst&quot;</span>) &#123;<span class="comment">// 构造函数</span></span><br><span class="line">        SC_CTHREAD(thread1, clk.pos());          <span class="comment">// 定义线程thread1，绑定时钟上升沿</span></span><br><span class="line">        reset_signal_is(rst,<span class="number">0</span>);                  <span class="comment">// 定义复位为0时有效</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Connect the clk and rst signals to the metaports</span></span><br><span class="line">        inputs.clk_rst(clk, rst);                <span class="comment">// 绑定输入端口的时钟和复位</span></span><br><span class="line">        outputs.clk_rst(clk, rst);               <span class="comment">// 绑定输出端口的时钟和复位</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">thread1</span><span class="params">()</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function">new1_OUTPUT_DT <span class="title">my_function</span><span class="params">(new1_INPUT_DT)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>在设计头文件中，定义了一个模块new1，具有一个p2p输入端口和一个p2p输出端口以及时钟和复位端口，并声明函数thread1为线程，为其绑定了时钟和复位，thread1的实现在cpp文件中如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// The thread function for the design</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">new1::thread1</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// Reset the interfaces</span></span><br><span class="line">    &#123; <span class="comment">// 复位行为部分</span></span><br><span class="line">        CYN_PROTOCOL(<span class="string">&quot;reset&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        inputs.reset();  <span class="comment">// 输入端口复位</span></span><br><span class="line">        outputs.reset(); <span class="comment">// 输出端口复位</span></span><br><span class="line">        </span><br><span class="line">        wait();          <span class="comment">// 复位行为以wait结束</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Main execution loop</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)&#123;  <span class="comment">// 模块行为被包括在该无限循环中</span></span><br><span class="line">        new1_INPUT_DT  input_val = inputs.get();   <span class="comment">// get为阻塞的从input端口中获取一个数据     </span></span><br><span class="line">        new1_OUTPUT_DT output_val = my_function(input_val); <span class="comment">// 执行数据处理</span></span><br><span class="line">        outputs.put(output_val);   <span class="comment">// put为阻塞的发送一个数据</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  User&#x27;s computation function</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="function">new1_OUTPUT_DT <span class="title">new1::my_function</span><span class="params">(new1_INPUT_DT var)</span></span>&#123; <span class="comment">// 进行数据处理，处理方式为+1</span></span><br><span class="line">    new1_OUTPUT_DT my_outputs;</span><br><span class="line">    my_outputs.out1 = var.in1 + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> (my_outputs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-2-TB文件"><a href="#1-2-TB文件" class="headerlink" title="1.2.TB文件"></a>1.2.TB文件</h2><p>TestBench的头文件如下所示，其定义了一个模块tb，其他部分预设计文件类似</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __TB__H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __TB__H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_p2p.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1_input_type.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1_output_type.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">SC_MODULE(tb)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    cynw_p2p &lt; new1_OUTPUT_DT &gt;::base_in    inputs;</span><br><span class="line">    cynw_p2p &lt; new1_INPUT_DT &gt;::base_out    outputs;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Declaration of clock and reset parameters</span></span><br><span class="line">    sc_in_clk                   clk;</span><br><span class="line">    sc_out &lt; <span class="keyword">bool</span> &gt;             rst;</span><br><span class="line">    sc_in &lt; <span class="keyword">bool</span> &gt;              rst_in; <span class="comment">// sampling version of &quot;rst&quot;</span></span><br><span class="line">    </span><br><span class="line">    SC_CTOR(tb)</span><br><span class="line">    &#123;</span><br><span class="line">        SC_CTHREAD(source, clk.pos());</span><br><span class="line">        SC_CTHREAD(sink, clk.pos());</span><br><span class="line">        reset_signal_is(rst_in,<span class="number">0</span>);</span><br><span class="line">        rst_in(rst);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">source</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sink</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>tb定义了source和sink两个线程，线程描述如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;tb.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Source thread</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tb::source</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// Reset the output metaport and cycle the design&#x27;s reset</span></span><br><span class="line">    outputs.reset();    <span class="comment">// 输出端口复位</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 端口复位，拉低rst两个时钟周期后拉高</span></span><br><span class="line">    rst = <span class="number">0</span>;</span><br><span class="line">    wait(<span class="number">2</span>);</span><br><span class="line">    rst = <span class="number">1</span>;</span><br><span class="line">    wait();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 输入激励，这里的激励是从0发到9</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">        <span class="comment">// Write values to the DUT</span></span><br><span class="line">        new1_INPUT_DT tmp;</span><br><span class="line">        tmp.in1 = i;</span><br><span class="line">        outputs.put(tmp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Read all the expected values from the design</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">tb::sink</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    inputs.reset();      <span class="comment">// 复位行为</span></span><br><span class="line">    wait();                     <span class="comment">// to synchronize with reset</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 接收10个输出后结束</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">        <span class="comment">// Read values from the DUT</span></span><br><span class="line">        new1_OUTPUT_DT input_val = inputs.get();</span><br><span class="line">        <span class="comment">// printf(&quot;%d\n&quot;, input_val);</span></span><br><span class="line">        <span class="built_in">cerr</span> &lt;&lt; <span class="string">&quot;Read &quot;</span> &lt;&lt; input_val.out1 &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    esc_stop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现TB的行为没有按设计文件编写，因为TB并需要综合，所以可以用更符合C的方式编写。</p><h2 id="1-3-system文件"><a href="#1-3-system文件" class="headerlink" title="1.3.system文件"></a>1.3.system文件</h2><p>system文件用于连接TB和设计，头文件如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SYSTEM_H_INCLUDED</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SYSTEM_H_INCLUDED</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;systemc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;esc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cynw_p2p.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;tb.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1_input_type.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1_output_type.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;new1_wrap.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">SC_MODULE(TOP)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// cynw_p2p channels</span></span><br><span class="line">    cynw_p2p &lt; new1_INPUT_DT &gt;      inputs_chan;</span><br><span class="line">    cynw_p2p &lt; new1_OUTPUT_DT &gt;     outputs_chan;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// clock and reset signals</span></span><br><span class="line">    sc_clock            clk;</span><br><span class="line">    sc_signal &lt; <span class="keyword">bool</span> &gt;  rst;</span><br><span class="line">    <span class="comment">// The testbench and DUT modules.</span></span><br><span class="line">    new1_wrapper *m_dut;  <span class="comment">// 声明指向设计的指针</span></span><br><span class="line">    tb   *m_tb;           <span class="comment">// 声明指向tb的指针</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">initInstances</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">deleteInstances</span><span class="params">()</span></span>;</span><br><span class="line">    </span><br><span class="line">    SC_CTOR(TOP): clk(<span class="string">&quot;clk&quot;</span>, <span class="number">5</span>, SC_NS, <span class="number">0.5</span>, <span class="number">0</span>, SC_NS, <span class="literal">true</span>),  <span class="comment">// 定义时钟</span></span><br><span class="line">        inputs_chan(<span class="string">&quot;inputs_chan&quot;</span>),</span><br><span class="line">        outputs_chan(<span class="string">&quot;outputs_chan&quot;</span>),</span><br><span class="line">        rst(<span class="string">&quot;rst&quot;</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        initInstances();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~TOP()</span><br><span class="line">    &#123;</span><br><span class="line">        deleteInstances();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// SYSTEM_H_INCLUDED</span></span></span><br></pre></td></tr></table></figure><p>system定义了模块TOP，即整个仿真系统的顶层，使用指针的方式声明子模块，需要注意的是，Stratus会自动为设计的模块添加wrapper，因此设计指针的类型为<code>new1_wrapper</code>而不是<code>new</code>，连线的部分在cpp文件中如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;system.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TOP::initInstances</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    m_dut = <span class="keyword">new</span> new1_wrapper(<span class="string">&quot;new1_wrapper&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Connect the design module</span></span><br><span class="line">    m_dut-&gt;clk(clk);</span><br><span class="line">    m_dut-&gt;rst(rst);</span><br><span class="line">    m_dut-&gt;inputs(inputs_chan);</span><br><span class="line">    m_dut-&gt;outputs(outputs_chan);</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Connect the testbench</span></span><br><span class="line">    m_tb = <span class="keyword">new</span> tb(<span class="string">&quot;tb&quot;</span>);</span><br><span class="line">    m_tb-&gt;clk(clk);</span><br><span class="line">    m_tb-&gt;rst(rst);</span><br><span class="line">    m_tb-&gt;outputs(inputs_chan);</span><br><span class="line">    m_tb-&gt;inputs(outputs_chan);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TOP::deleteInstances</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">delete</span> m_tb;</span><br><span class="line">    <span class="keyword">delete</span> m_dut;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-4-main"><a href="#1-4-main" class="headerlink" title="1.4.main"></a>1.4.main</h2><p>main文件用于启动仿真、连接设计和连接联合仿真等功能，一般不需要修改，main.cpp文件如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;system.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">TOP *top = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span> <span class="title">esc_elaborate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    top = <span class="keyword">new</span> TOP(<span class="string">&quot;top&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="keyword">void</span>  <span class="title">esc_cleanup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">delete</span> top;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sc_main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    esc_initialize(argc, argv);</span><br><span class="line">    esc_elaborate();</span><br><span class="line">    sc_start();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-5-project-tcl"><a href="#1-5-project-tcl" class="headerlink" title="1.5.project.tcl"></a>1.5.project.tcl</h2><p>project.tcl用于指定综合信息和仿真信息，其主体主要需要执行以下步骤：</p><ul><li>指定库信息</li><li>指定时钟信息</li><li>设置仿真信息，包括仿真工具信息和仿真平台信息</li><li>设置高级综合信息</li><li>设置物理综合信息（如果需要）</li></ul><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置物理库信息，这里的写法可以照抄，调用的是Stratus内置的一个库</span></span><br><span class="line"><span class="keyword">set</span> LIB_PATH <span class="string">&quot;[get_install_path]/share/stratus/techlibs/GPDK045/gsclib045_svt_v4.4/gsclib045/timing&quot;</span></span><br><span class="line"><span class="keyword">set</span> LIB_LEAF <span class="string">&quot;slow_vdd1v2_basicCells.lib&quot;</span></span><br><span class="line">use_tech_lib<span class="string">&quot;$LIB_PATH/$LIB_LEAF&quot;</span> # 设置物理库</span><br><span class="line"></span><br><span class="line"><span class="comment"># set clock：设置时钟库</span></span><br><span class="line">set_attr clock_period <span class="number">5.0</span> # 设置时钟周期为<span class="number">5</span>ns</span><br><span class="line">set_attr default_input_delay <span class="number">0.1</span> # 设置输入delay为<span class="number">0.1</span>ns</span><br><span class="line"></span><br><span class="line"><span class="comment"># message level</span></span><br><span class="line">set_attr message_detail <span class="number">2</span> # 设置信息等级为<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set dump setting：设置仿真工具信息</span></span><br><span class="line">use_verilog_simulator incisive # 使用仿真器incisive（Stratus内置，其实为ncverilog）</span><br><span class="line">set_attr cc_options             <span class="string">&quot; -g&quot;</span>  # 仿真后选项，可直接照抄</span><br><span class="line">enable_waveform_logging -vcd  # 设置输出波形文件为vcd，还可以选择fsdb</span><br><span class="line">set_attr end_of_sim_command <span class="string">&quot;make saySimPassed&quot;</span> # 仿真后执行的命令</span><br><span class="line"></span><br><span class="line"><span class="comment"># system config：设置仿真平台信息，这一步需要设置所有描述不需要进行综合部分的文件为system_module</span></span><br><span class="line">define_system_module main.cpp  # 设置main为system_module</span><br><span class="line">define_system_module system.cpp # 设置system部分为system_module</span><br><span class="line">define_system_module tb.cpp # 设置仿真平台tb为system_module</span><br><span class="line"></span><br><span class="line"><span class="comment"># hls config：设置高级综合信息</span></span><br><span class="line">define_hls_module new1 new1.cpp # 设置hls_module为new1</span><br><span class="line">define_hls_config new1 BASIC    # 设置hls_config为BASIC</span><br><span class="line"><span class="comment"># define_hls_config new1 DPA --dpopt_auto=op,expr</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置仿真信息</span></span><br><span class="line">define_sim_config B <span class="string">&quot;new1 RTL_V BASIC&quot;</span> # 定义仿真目标，仿真目标为RTL_V级</span><br></pre></td></tr></table></figure><p>设置物理库到设置仿真平台信息都比较容易理解，比较复杂的是设置高级综合信息这个部分。高级综合信息的设置分为两个部分，分别是设置待综合的模块和综合等级，分别对应<code>define_hls_module</code>和<code>define_hls_config</code>命令。<code>define_hls_module</code>用于指定高级综合的对象，即指定待综合的模块和描述该模块的文件指令如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">define_hls_module 模块名 文件名</span><br></pre></td></tr></table></figure><p>一个例子如下所示，指定需要对<code>new1.cpp</code>的中包含的<code>new1</code>模块进行高级综合：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">define_hls_module new1 new1.cpp</span><br></pre></td></tr></table></figure><p>第二个部分为指定高级综合等级，高级综合具有多个等级，对应不同的性能和面积的折中，这里使用BASIC，指定指令如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">define_hls_config 模块名 综合等级</span><br><span class="line">define_hls_config new1 BASIC # 指定模块new1高级综合等级为BASIC</span><br></pre></td></tr></table></figure><p>随后需要设置仿真信息，只能对一个高级综合对象进行仿真，每次进行高级综合，生成3个模型，RTL_V是其中的一种，设置仿真信息需要指定对哪一个高级综合等级的哪一个高级综合对象中的哪一个模型进行仿真，仿真指令如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">define_sim_config 配置名称 <span class="string">&quot;模块名称 模型类型 综合等级&quot;</span></span><br><span class="line">define_sim_config B <span class="string">&quot;new1 RTL_V BASIC&quot;</span> # 定义仿真目标，仿真目标为RTL_V级</span><br></pre></td></tr></table></figure><h2 id="1-6-Makefile"><a href="#1-6-Makefile" class="headerlink" title="1.6.Makefile"></a>1.6.Makefile</h2><p>Makefile由project.tcl直接生成，不需要手动编写</p><h1 id="2-操作方式"><a href="#2-操作方式" class="headerlink" title="2.操作方式"></a>2.操作方式</h1><h2 id="2-1-makefile生成"><a href="#2-1-makefile生成" class="headerlink" title="2.1.makefile生成"></a>2.1.makefile生成</h2><p>Makefile通过project.tcl自动生成，指令如下所指示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bdw_makegen project.tcl</span><br></pre></td></tr></table></figure><h2 id="2-2-进行高级综合"><a href="#2-2-进行高级综合" class="headerlink" title="2.2.进行高级综合"></a>2.2.进行高级综合</h2><p>高级综合指令如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make hls_配置名称</span><br></pre></td></tr></table></figure><p>例如上述脚本，高级综合指令为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make hls_B</span><br></pre></td></tr></table></figure><p>生成的文件位于<code>bdw_work/modules</code>文件夹下</p><h2 id="2-3-进行仿真"><a href="#2-3-进行仿真" class="headerlink" title="2.3.进行仿真"></a>2.3.进行仿真</h2><p>进行仿真指令的命令如下所示：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make sim_配置名称</span><br></pre></td></tr></table></figure><p>例如上述脚本，进行仿真指令为：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make sim_B</span><br></pre></td></tr></table></figure><p>生成的波形文件位于<code>bdw_work/sim</code>文件夹下</p><h1 id="3-debug"><a href="#3-debug" class="headerlink" title="3.debug"></a>3.debug</h1><p>当dump fsdb波形时，会发生fsdb连接的错误，此时解决方法为：</p><ul><li>进行<code>make clean</code>操作</li><li>将dump的波形类型改为vcd并重新生成Makefile</li><li>进行仿真</li><li>将dump类型的模型改为fsdb并重新生成Makefile</li><li>进行仿真即可</li></ul>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高级综合 </tag>
            
            <tag> StratusHLS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>存储器体系结构学习笔记</title>
      <link href="2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="存储器性能评价指标"><a href="#存储器性能评价指标" class="headerlink" title="存储器性能评价指标"></a>存储器性能评价指标</h1><h2 id="存储器停顿周期数"><a href="#存储器停顿周期数" class="headerlink" title="存储器停顿周期数"></a>存储器停顿周期数</h2><p>存储器的性能直接影响到CPU的性能评价，定义存储器停顿周期数为CPU等待存储器访问而停顿的时钟周期数，由此有CPU执行时间有：</p><script type="math/tex; mode=display">CPU执行时间=(CPU时钟周期数+存储器停顿时钟周期数) \times 时钟周期时间</script><p>因此需要存储器停顿时钟周期数越小越好，对于这一变量有公式如下：</p><script type="math/tex; mode=display">存储器停顿周期数 = 缺失数量 \times 缺失代价 = 指令数 \times \frac{产生缺失指令数量}{指令数} \times 缺失代价 \\ = 指令数 \times \frac{存储器访问指令数}{指令总数} \times 缺失率 \times 缺失代价</script><p>其中，缺失率表示存储器访问指令中会产生cache缺失的百分比；缺失代价表示发生cache缺失后为了解决缺失需要消耗的平均时钟周期数。另一种度量指标与时钟周期无关，即为每条指令的平均缺失数：</p><script type="math/tex; mode=display">平均缺失数=\frac{产生访存缺失的指令数}{指令总数} = 缺失率 \times \frac{存储器访问指令数}{指令总数}</script><p>上述公式与缺失代价无关，缺失率的定义与上文相同</p><h2 id="存储器平均访问时间"><a href="#存储器平均访问时间" class="headerlink" title="存储器平均访问时间"></a>存储器平均访问时间</h2><p>缓存性能比较好的度量为存储器平均访问时间，即对于每次存储器访问而言需要的平均时间，公式如下：</p><script type="math/tex; mode=display">存储器平均访问时间 = 命中时间 + 缺失时间 \times 缺失代价</script><p>需要注意的是这一指标仅针对存储器访问指令，因此这是一个间接度量，考虑以下情况：</p><div class="table-container"><table><thead><tr><th>参数</th><th>数据</th></tr></thead><tbody><tr><td>16KB指令缓存缺失数（每千条指令）</td><td>3.82</td></tr><tr><td>16KB数据缓存缺失数（每千条指令）</td><td>40.9</td></tr><tr><td>32KB统一缓存缺失数（每千条指令）</td><td>43.3</td></tr><tr><td>统一缓存数据访问额外需要时钟周期数</td><td>1</td></tr><tr><td>存储器访问中指令引用占比</td><td>74%</td></tr><tr><td>命中周期数/缺失代价</td><td>1/100</td></tr><tr><td>指令中数据传输指令占比</td><td>36%</td></tr></tbody></table></div><p>需要注意的是，缺失数指的是对于所有指令而言产生存储器缺失的次数，而缺失率为相对于所有存储器访问产生缺失的比例。对于16KB的指令缓存，每条指令都会产生一次指令访问，缺失率为：</p><script type="math/tex; mode=display">缺失率_{指令} = \frac{3.82}{1000 \times 1} = 0.004</script><p>对于16KB的数据缓存，有36%的指令会产生一次存储器访问，因此有：</p><script type="math/tex; mode=display">缺失率_{数据} = \frac{40.9 }{0.36 \times 1000} = 0.114</script><p>有74%的存储器访问为指令访问，因此总体的缺失率为：</p><script type="math/tex; mode=display">缺失率_{分裂} = 0.74 \times 0.004 + 0.26 \times 0.114 = 0.0326</script><p>考虑存储器平均访问时间，有：</p><script type="math/tex; mode=display">存储器平均访问时间_{分裂} = 0.74 \times (1+0.004 \times 200) + 0.26 \times (1 + 0.114\times 200) = 7.52</script><p>对于32KB统一缓存而言，1000条指令一共产生1000次指令访存，其中36%的指令会产生数据访存，如下所示：</p><script type="math/tex; mode=display">缺失率_{统一} = \frac{43.3}{1000 + 1000 \times 0.36} = 0.0318</script><p>对于统一缓存而言，数据访存指令会产生两种存储器访问，一次指令访问和一次数据访问，而统一缓存仅有端口，因此数据访问需要等待一个时钟周期，因此存储器平均访问时间：</p><script type="math/tex; mode=display">存储器平均访问时间_{统一} = 0.74 \times (1+0.0318 \times 200) + 0.26 \times (1 + 1 + 0.0318 \times 200) = 7.62</script><h2 id="对CPU性能影响"><a href="#对CPU性能影响" class="headerlink" title="对CPU性能影响"></a>对CPU性能影响</h2><p>对于CPU性能而言，有以下公式：</p><script type="math/tex; mode=display">CPU执行时间=(CPU时钟周期数+存储器停顿时钟周期数) \times 时钟周期时间</script><p>一般认为缓存命中时间作为CPU执行时钟周期数的一个部分，考虑一个以下参数的缓存：</p><div class="table-container"><table><thead><tr><th>参数</th><th>数值</th></tr></thead><tbody><tr><td>CPU执行周期数</td><td>1</td></tr><tr><td>缺失代价</td><td>200</td></tr><tr><td>平均缺失率</td><td>2%</td></tr><tr><td>每条指令的存储器引用数</td><td>1.5</td></tr><tr><td>平均缓存缺失数（千条指令）</td><td>30</td></tr></tbody></table></div><p>对于以上参数，每千条指令产生的存储访问数为$1000 \times 1.5 = 150$，存储器访问的缺失率为2%，即千条指令产生的存储器缺失数量为$150 \times 2\%=30$，与给出的平均缓存缺失数一致。使用缺失数计算CPU执行时间：</p><script type="math/tex; mode=display">CPU执行时间 = IC \times (1 + \frac{存储器停顿周期数}{IC}) \times 时钟周期 \\= IC \times (1 + \frac{停顿数}{IC} \times 缺失代价) \times 时钟周期 = IC \times (1+\frac{30}{1000} \times 200) \times 时钟周期 \\ = 7 \times IC \times 时钟周期</script><p>上述分析均对于顺序存储器而言，其每次存储器缺失都会暴露为缺失代价。对于乱序处理器而言，其存储器缺失可能被乱序执行的其他指令掩盖，即有：</p><script type="math/tex; mode=display">存储器停顿周期 = 缺失数 \times (总缺失代价 - 重叠缺失延迟)</script><p>对于乱序执行的CPU而言，分析比较复杂，若一个时钟周期该CPU没有提交最大可能数目的指令，则认为该CPU发生的了存储器访问缺失。</p><h1 id="存储器层次结构"><a href="#存储器层次结构" class="headerlink" title="存储器层次结构"></a>存储器层次结构</h1><p>存储器之间的关于存储器层次结构，需要解决以下四个问题：</p><ul><li>块的放置：一个块可以放在这一级的什么位置</li><li>块的识别：如何找到放置在这一级中的一个块</li><li>块的替换：在缺失时应当替换哪个块</li><li>块的写入：写入时发生什么</li></ul><h2 id="块的放置"><a href="#块的放置" class="headerlink" title="块的放置"></a>块的放置</h2><p>首先定义<strong>组</strong>的概念，一个组是存储器中的一段连续空间，可以容纳多个（整数个）块。取一个存储器中组的数量为m，每个组可以容纳的块的数量为n，有以下关系：</p><script type="math/tex; mode=display">存储器容量 = m \times n \times 块大小</script><p>任何来自某个地址的块只能被放置在一个特定的组中，这种方法被称为组相联，一个组中可以容纳n个块，即为n-路组相联。块首先被映射到组，组编号为：</p><script type="math/tex; mode=display">组编号 = 块地址 \% m</script><p>随后，这个块可以被放置在这个组中的任意块地址位置。即对于一个块地址为A的块而言，对应的组编号为$G = A\%m$，其可以被放置在这个编号为G的组中的任意有效的块起始地址位置。如下图所示：</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ch2_cache_group.png" class=""><p>对于组相联，有两种特殊情况：</p><ul><li>直接映射：每个块只能存储在一个固定的位置，有$存储地址=块地址 \% m$，可认为时n=1的1-组相联</li><li>全相联：一个块可以放置在任意位置，可认为时m=1的n-路组相联（缓存中仅有一个组）</li></ul><h2 id="块的识别"><a href="#块的识别" class="headerlink" title="块的识别"></a>块的识别</h2><p>块的识别通过标签识别实现，每个存储器中的块对应一个标签，标签中包括一部分地址信息和有效性信号。对于一个块中的一个数据而言，其地址分为以下几个部分：</p><ul><li>标志部分：地址的高位部分，判断块时需要比对的部分</li><li>索引部分：地址的中间部分，标记这个块若存在于存储器中，应当存在于哪个组中，这个部分不用于判断</li><li>块偏移：地址的低位部分，标记这个数据相对于块起始地址的偏移量</li></ul><p>识别块时，首先根据索引部分查找到对应的组，再对比组内所有块的标志部分和要查找的块的标签部分是否相同，同时判断有效性。若标志部分相同且有效，则这个块为待识别的块，否则无识别的块，过程如下所示：</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ch2_cache_hit.png" class=""><p>首先提供查找地址，根据其中的索引查找到可能保存这个块的组，随后比对组内的所有标志和有效位，当有有效位置高且标志匹配的块，则命中，查找到该块。对于要查找的数据，根据偏移量从块中获取数据。</p><h2 id="块的替换"><a href="#块的替换" class="headerlink" title="块的替换"></a>块的替换</h2><p>当块发生缺失且对应的组中没有空闲的位置时，需要从已有的块中选择一个丢弃，块的替换算法决定丢弃哪个块，替换算法有以下几种：</p><ul><li>随机：随机选择一个块丢弃</li><li>最近最少使用（LRU）：丢弃掉未使用时间最久的块</li><li>先入先出（FIFO）：丢弃掉进入存储器最久的块</li></ul><p>最近最少使用算法的记录比较困难，常见的替换方法为伪LRU算法，为每一个块设置一个bit。每次对一个块的访问会使这个bit置位为1，当一次访问后所有的bit均为高时，所有bit拉低，仅当前访问的块对应的bit拉高。当需要替换块时，随机从该bit为低的块中选择一个替换</p><h2 id="块的写入"><a href="#块的写入" class="headerlink" title="块的写入"></a>块的写入</h2><p> 块的写入和读取最大的差别在于读取操作可以“任意进行”，因为对任何空间的读取不会对该该空间中的数据产生影响，而写入操作必须“精准执行”，因为写入操作对存储空间中的数据产生影响。对于这一级存储器中任何一个块的写入会产生一致性问题，即当前级的数据与上一级的数据不同，为了解决这一问题，有两种解决方法：</p><ul><li>直写：写入这一级存储的同时写入上一级存储</li><li>写回：仅写入这一级存储，当被写入的块被替换时写回上一级存储器</li></ul><p>直写策略容易实现，能保证数据的一致性，这上一级存储器中的数据永远时清洁的（即一致的），缺点是时间消耗大。而写回策略延迟低，但是实现复杂。当写回上一级存储器时，往往先将块放入写入缓冲器以减小延迟。另外，当需要对一个地址进行写入时，可能这个地址对应的块不在这一级存储器中，有两种策略：</p><ul><li>写入分派：首先执行命中操作，将块调入缓存，再进行写入</li><li>无写入分派：不将对应块调入，直接写入上一级存储器，直写策略下常常使用</li></ul><h2 id="举例：Opteron缓存"><a href="#举例：Opteron缓存" class="headerlink" title="举例：Opteron缓存"></a>举例：Opteron缓存</h2><p>AMD的Opteron处理器缓存组织方式如下图所示</p><p> <img src="存储器体系结构学习笔记/opteron_cache.png" alt=""></p><p>进入缓存的地址位宽为40bit，该缓存的容量为64KB，块大小为64B，使用两路组相联缓存。即由上可知，组内偏移量为6bit，缓存内共$\frac{64KB}{64}=1024$个块，使用两路组相联即有$\frac{1024}{2} = 512$个组，由此组索引位宽为9bit，地址位宽40bit，因此标志位宽为$48-9-6=25$bit。</p><p>该缓存使用最少替代（LRU）策略和写回/写入分派策略，对于一次缓存访问过程，过程如下：</p><ol><li>CPU给出40bit物理地址，分为标记、索引和偏移量三个部分（对应图中标号1）</li><li>根据索引部分找到可能存放这个块的组，读取组中两个块中的标记部分（对应图中标号2）</li><li>将两个标记与地址的标志部分比较，同时检查有效位是否为拉高：若有一个标记有效且与地址的标记相同，则缓存命中，使用二选一选择器将对应的数据数据输出；否则缓存未命中，需要进行访问低级存储器获取这个块（对应图中标志3）</li><li>若缓存未命中，则根据最少替代策略选择一个块，并将这个块送入牺牲块缓冲区，再由牺牲块缓冲区写回低级存储器，同时从低级存储器调入需要访问的块（对应图中标志4）</li></ol><p>由于这一缓存使用LRU和写回策略，因此对于每一个块，除了有效位以外，还需要设置LRU位和脏位设置标记，脏位用于表示该块是否与低级存储器中的块相同。当每次访问（无论读写）这个块时，都需要根据LRU算法对LRU位进行设置；当写一个块时，就将脏位拉高，因为只要块被写入，就认为其与低级缓存不同。</p><h1 id="缓存性能优化"><a href="#缓存性能优化" class="headerlink" title="缓存性能优化"></a>缓存性能优化</h1><h2 id="缺失模型"><a href="#缺失模型" class="headerlink" title="缺失模型"></a>缺失模型</h2><p>对于缓存优化，首先根据缺失类型将其分为3类：</p><ul><li>强制缺失：第一次访问一个块时，这个块一定不在内存中，产生缺失成为强制缺失</li><li>容量缺失：缓存无法容纳所有的块，当缓存容量满后，再载入块时必然放弃原有的块，再次访问由于容量不足被放弃的块产生的缺失为容量缺失</li><li>冲突缺失：对于组相联结构，每个组中的块有限，当一个组满且另一个属于这个组的块被调入时，组中的某个块必然被放弃，再次访问由于块内冲突被放弃的块产生的缺失为冲突缺失</li></ul><h2 id="优化原理"><a href="#优化原理" class="headerlink" title="优化原理"></a>优化原理</h2><p>优化目标为缩短存储器平均访问时间，有公式：</p><script type="math/tex; mode=display">存储器平均访问时间 = 命中时间+缺失率\times 缺失代价</script><p>因此缩短存储器平均访问时间，有以下几种优化方法：</p><ul><li>缩短命中时间：索引时避免地址转换、提前读取</li><li>降低缺失率：使用较大的块、较大的缓存和较高的关联度</li><li>降低缺失代价：多级缓存、使读取操作设定高于写入操作</li></ul><h2 id="基础优化方法"><a href="#基础优化方法" class="headerlink" title="基础优化方法"></a>基础优化方法</h2><p>下图是优化方法及其影响的汇总表</p><div class="table-container"><table><thead><tr><th>名称</th><th>命中时间</th><th>缺失代价</th><th>缺失率</th><th>硬件复杂度</th><th>备注</th></tr></thead><tbody><tr><td>增大块大小</td><td>无影响</td><td>增大</td><td>降低</td><td>无影响</td><td>需要合理设计大小</td></tr><tr><td>较大缓存大小</td><td>延长</td><td>无影响</td><td>降低</td><td>增加</td><td>广泛应用</td></tr><tr><td>提高组相联度</td><td>延长</td><td>无影响</td><td>降低</td><td>增加</td><td>广泛应用</td></tr><tr><td>多级缓存</td><td>无影响</td><td>降低</td><td>无影响</td><td>大幅度增加</td><td>广泛应用</td></tr><tr><td>提高读取缺失优先级</td><td>无影响</td><td>降低</td><td>无影响</td><td>增加</td><td>广泛应用</td></tr><tr><td>使用虚拟地址</td><td>降低</td><td>无影响</td><td>无影响</td><td>增加</td><td>广泛应用</td></tr></tbody></table></div><h3 id="增加块大小"><a href="#增加块大小" class="headerlink" title="增加块大小"></a>增加块大小</h3><p>由于空间局域性原理（一个被用到的数据附近的数据可能被用到），增大块大小可以减少强制缺失，由此降低缺失率。但是较大的块会增加缺失代价，即一个块的尺寸变大，产生访问缺失时，需要花费更多的时钟周期从低级存储器中获取这个较大的块。因此选取块的大小需要综合考虑这两个因素。对于一个16K存储器，缺失率、缺失代价与块大小有以下表所示的关系：</p><div class="table-container"><table><thead><tr><th>块大小</th><th>缺失率</th><th>缺失代价</th></tr></thead><tbody><tr><td>32</td><td>1.35%</td><td>$80+32 \times \frac{2}{16} = 84$</td></tr><tr><td>64</td><td>1.06%</td><td>$80 + 64 \times \frac{2}{16} = 88$</td></tr><tr><td>128</td><td>1.02%</td><td>$80 + 128 \times \frac{2}{16} = 96$</td></tr></tbody></table></div><p>缺失代价为无论块大小，都首先消耗80个时钟周期，随后每2个时钟周期载入16个数据。由存储器平均访问时间的公式，假设命中时间为1个时钟周期，有：</p><script type="math/tex; mode=display">存储器平均访问时间_{32} = 1 + 0.0135 \times 84 = 2.134 \\存储器平均访问时间_{64} = 1 + 0.0106 \times 88 = 1.933 \\存储器平均访问时间_{128} = 1+0.0102 \times 96 = 1.979</script><p>由上，尺寸为64的块最适合该系统。选取块的大小需要考虑低级存储器的带宽，这一参数决定缺失代价相对于块大小的上升速度。对于高带宽的系统而言，可以选择较大的块，因为此时缺失代价的上升速度低于缺失率的下降速度。</p><h3 id="增大缓存大小"><a href="#增大缓存大小" class="headerlink" title="增大缓存大小"></a>增大缓存大小</h3><p>增大缓存大小可以减小容量缺失进而降低缺失率，但对应的可能增加命中时间和硬件复杂度</p><h3 id="提高组相联度"><a href="#提高组相联度" class="headerlink" title="提高组相联度"></a>提高组相联度</h3><p>提高组相联度可以降低冲突缺失进而降低缺失率，对于组相联度有以下两条经验公式：</p><ul><li>对于降低冲突缺失率而言，八路组相联的效果基本等同于全相联</li><li>2:1经验规律：大小为N的直接映射缓存与大小为N/2的2路组相联缓存大致具有相同的缺失率</li></ul><p>对应的，提高组相联度会使硬件的命中部分变得复杂，提高了命中时间。</p><h3 id="使用多级缓存"><a href="#使用多级缓存" class="headerlink" title="使用多级缓存"></a>使用多级缓存</h3><p>多级缓存降低了缺失代价，二级缓存（L2）指再一级缓存（L1）和主存储器之间的缓存。当一级缓存发生缺失时，访问二级缓存查找数据；若二级缓存缺失，则由二级缓存到主存中找到数据。使用二级缓存后有：</p><script type="math/tex; mode=display">缺失代价_{L1} = 存储器平局访问时间_{L2} = 命中时间_{L2} + 缺失率_{L2} \times 缺失代价_{L2}</script><p>代入一级缓存的存储器平均访问时间公式有：</p><script type="math/tex; mode=display">存储器平局访问时间_{L1} = 命中时间_{L1} + 缺失率_{L1} \times (命中时间_{L2} + 缺失率_{L2} \times 缺失代价_{L2})</script><p>由于使用了二级缓存，对缺失率的定义细化如下：</p><ul><li>局部缺失率：$\frac{缓存中的产生的缺失数}{对该缓存进行存储器访问的总数}$，即对于L1缓存为$缺失率<em>{L1}$，对L2缓存为$缺失率</em>{L2}$</li><li>全局缺失率：$\frac{该缓存中产生的缺失数}{处理访问缓存总数}$，对于L1缓存为$缺失率<em>{L1}$，对L2缓存为$缺失率</em>{L1} \times 缺失率_{L2}$</li></ul><p>对于二级缓存，停顿周期参数如下所示：</p><script type="math/tex; mode=display">每条指令平均存储器停顿周期 = 缺失数_{L1} \times 缺失代价_{L1} + 缺失数_{L2} \times 缺失代价_{L2}</script><p>即对于一条指令而言，若产生缺失，则要么这一数据在L2缓存中，要么这一数据在L2缓存也缺失。对于第一种情况，这一指令的缺失仅计入$缺失数<em>{L1}$中；对于第二种情况，这一指令的缺失同时计入$缺失数</em>{L1}$和$缺失数_{L2}$。现在考虑一个以下参数的缓存系统：</p><div class="table-container"><table><thead><tr><th>参数</th><th>数据</th></tr></thead><tbody><tr><td>第一级缓存缺失（千次引用）</td><td>40</td></tr><tr><td>第二级缓存缺失（千次引用）</td><td>20</td></tr><tr><td>每条指令存储引用数</td><td>1.5</td></tr><tr><td>L1命中时间</td><td>1</td></tr><tr><td>L2命中时间</td><td>10</td></tr><tr><td>L2缺失代价</td><td>200</td></tr></tbody></table></div><p>有缺失率如下所示：</p><script type="math/tex; mode=display">全局缺失率_{L1} = 局部缺失率_{L1} = \frac{40}{1000} = 4\% \\局部缺失率_{L2} = \frac{20}{40} = 50\% \\全局缺失率_{L2} = \frac{20}{1000} = 2\%</script><p>由此计算存储器平均访问时间：</p><script type="math/tex; mode=display">存储器平局访问时间 = 1 + 0.04 \times (10 + 0.5 \times 200) = 5.4个时钟周期</script><p>若要计算每条指令的平均停顿时间，首先要计算缺失数：</p><script type="math/tex; mode=display">缺失数_{L1} = \frac{40}{\frac{1000}{1.5}} = 0.06 \\缺失数_{L2} = \frac{20}{\frac{1000}{1.5}} = 0.03</script><p>随后根据缺失代价和缺失数计算每条指令的平均停顿时间：</p><script type="math/tex; mode=display">每条指令平均停顿时间 = 缺失数_{L1} \times 缺失代价_{L1} + 缺失数_{L2} \times 缺失代价_{L2} \\= 0.06 \times 10 + 0.03 \times 200 = 6.6</script><p>对于两个指标，有如下关系：</p><script type="math/tex; mode=display">(存储器平均访问时间 - 命中时间) \times 每条指令存储访问数量 = (5.4- 1)\times 1.5 = 6.6 = 每条指令平均停顿时间</script><p>对于二级缓存的设计，有两个需要注意的点：</p><ul><li>第二级缓存如果足够大（远大于一级缓存），则二级缓存的局部缺失率与全局缺失率非常相似</li><li>二级缓存的主要评价指标是缓存全局缺失率</li></ul><p>对于二级缓存而言，首先需要考虑的是容量问题，一般来说二级缓存的容量应当略大于一级缓存；随后二级缓存使用组相联可以有效提高缺失代价；最后需要根据实际情况选择多级包含和多级互斥的策略：</p><ul><li>多级包含：二级缓存需要包含一级缓存中包含的所有块，实现简单，但是需要在多级之间使用相同的块大小，可能降低缓存的性能</li><li>多级互斥：一级缓存中的块一定不会出现在二级缓存中，一级缓存从二级缓存中调入块的过程复杂化为一二级缓存块的交换，优点是仅需要二级缓存略大于一级缓存</li></ul><h3 id="提高读取缺失优先级"><a href="#提高读取缺失优先级" class="headerlink" title="提高读取缺失优先级"></a>提高读取缺失优先级</h3><p>考虑缓存向存储器写入的情况，一般使用一个写缓冲区，当进行写入时，首先将数据写入写缓冲区中，此时认为写入完成，之后再由写缓冲区将数据写回主存。此时会有一个问题，即写缓冲块中可能有某次读请求需要的数据的最新副本（已经执行写入指令但尚未写入到主存中），具有两种解决方法：</p><ul><li>等待：每次读请求都等待写缓冲区清空再读取，实现简单，效率很低</li><li>访问：每次读请求首先从写缓冲区查找数据，再执行缓存命中，为目前的通用方法</li></ul><p>为了降低产生缺失的缺失代价，可以设置读取优先级高于写入优先级。若读取优先级未高于写入优先级，若当写缓冲区正在写入主存时产生读取缺失，首先需要等待写入完成再进行块读取，即：</p><script type="math/tex; mode=display">缺失代价 = 写入时间 + 块读取时间</script><p>若读缺失优先级高于写入缺失，无论写缓冲区是否执行写入，读缺失都会立刻处理（若有写操作则打断），缺失代价即直接为块读取时间。</p><h3 id="使用虚拟地址"><a href="#使用虚拟地址" class="headerlink" title="使用虚拟地址"></a>使用虚拟地址</h3><p>虚拟地址为操作系统分配个每个进程的存储空间的地址。对于使用物理地址的缓存，则首先需要将CPU给出的虚拟地址转换为物理地址，然后使用物理地址对缓存进行命中。这样操作的缓存设计简单，但命中过程中涉及虚拟和物理地址的转换，因此延长了命中时间，即：</p><script type="math/tex; mode=display">虚拟地址命中时间 = 地址转换时间 + 物理地址命中时间</script><p>为了降低命中时间，可以使用基于虚拟地址的缓存，即缓存中使用虚拟地址。但使用虚拟地址会产生一系列问题：</p><ul><li>保护问题：虚拟地址转为物理地址时需要检查页级保护，解决方法为在缺失时从主存中复制保护信息保存到缓存中，每次访问都进行检查</li><li>切换进程：每个进程都有自己的虚拟地址空间，可能出现两个进程的相同虚拟地址对应不同的物理地址，因此每次切换进程是需要刷新缓存，产生大量的强制缺失。解决方法是在标签中添加PID（进程识别标识符）字段，标记这个缓存的块属于哪一个进程，命中时进行检查。</li><li>别名地址：对于一个进程，可能给一个物理地址赋予多个不同的虚拟地址，因此可能出现一个物理块在缓存中有多个副本，若对一个副本进行写入，则会出现多个块不一致的问题。解决方法是别名消去，即要求每个缓存块必须拥有一个独一无二的物理地址。其中一种方案是检查所有块，例如一个两路组相联的64KB缓存（地址位宽16bit），块尺寸为4KB（偏移量地址12bit），标签位宽为3bit（16-12-1），则当发生缺失时，检查所有可能的块地址共八个，若有匹配，则使其无效。</li><li>I/O交换：I/O一般使用物理地址，映射到虚拟地址涉及地址转换</li></ul><p>一种折中的方案是仍然使用物理地址，但是当命中开始时直接使用块内偏移地址进行数据访问，同时并行的执行虚拟地址向物理地址的转换（虚拟地址和物理地址的块内偏移量相同），匹配使用物理地址匹配；即使用数据访问和地址转换并行掩盖地址转换时间。</p><h2 id="高级优化方法"><a href="#高级优化方法" class="headerlink" title="高级优化方法"></a>高级优化方法</h2><div class="table-container"><table><thead><tr><th>名称</th><th>命中时间</th><th>带宽</th><th>缺失代价</th><th>缺失率</th><th>硬件复杂度</th></tr></thead><tbody><tr><td>使用小而简单的L1缓存</td><td>降低</td><td>-</td><td>-</td><td>增大</td><td>-</td></tr><tr><td>路预测</td><td>降低</td><td>-</td><td>-</td><td>-</td><td>略微增加</td></tr><tr><td>缓存访问流水化</td><td>延长</td><td>增大</td><td>-</td><td>-</td><td>略微增加</td></tr><tr><td>无阻塞缓存</td><td>-</td><td>增大</td><td>降低</td><td>-</td><td>大幅度增加</td></tr><tr><td>分组缓存</td><td>-</td><td>增大</td><td>-</td><td>-</td><td>略微增加</td></tr><tr><td>关键字优先与提前启动</td><td>-</td><td>-</td><td>降低</td><td>-</td><td>增加</td></tr><tr><td>合并写缓冲区</td><td>-</td><td>-</td><td>降低</td><td>-</td><td>略微增加</td></tr><tr><td>编译器优化</td><td>-</td><td>-</td><td>-</td><td>降低</td><td>-</td></tr><tr><td></td><td>-</td><td>-</td><td>降低</td><td>降低</td><td>大幅度增加</td></tr></tbody></table></div><h3 id="使用小而简单的L1缓存"><a href="#使用小而简单的L1缓存" class="headerlink" title="使用小而简单的L1缓存"></a>使用小而简单的L1缓存</h3><p>使用小而简单的L1缓存主要用于降低命中时间，命中时间包括以下三个部分：</p><ul><li>使用地址中的索引字段确定组地址</li><li>读取组中的多个标记与地址中的标记字段进行比较</li><li>设置多路选择器选择正确的数据项</li></ul><p>若增大L1缓存的大小，则会增长第一个部分的时间，因此不会考虑大量增加L1缓存的大小。但是会考虑增加L1缓存的组相联度，原因如下所示：</p><ul><li>很多处理器访问缓存需要两个时钟周期，因此对命中时间不敏感</li><li>引入多线程后，冲突缺失增加，提高组相联度对于降低冲突缺失更友好</li></ul><h3 id="路预测"><a href="#路预测" class="headerlink" title="路预测"></a>路预测</h3><p>路预测也是降低命中时间的一种方法，其在缓存中保存一些额外的位，用于预测下一次缓存访问这个组时可能调用的块，即将设置多路选择器和比较标记并行执行。若预测结果与比较结果相同，则节省了设置多路器的时间；若预测结果与比较结果不同，则重新设置多路选择器，无性能损失。</p><h3 id="缓存访问流水化"><a href="#缓存访问流水化" class="headerlink" title="缓存访问流水化"></a>缓存访问流水化</h3><p>该方法也为了降低命中时间，其将命中时间分散到多个时钟周期中，缩短了时钟周期并提高了带宽（时钟周期提高），但是增加了发出载入指令到获取到数据的时钟周期数，增加了分支预测错误代价。</p><h3 id="无阻塞缓存"><a href="#无阻塞缓存" class="headerlink" title="无阻塞缓存"></a>无阻塞缓存</h3><p>无阻塞缓存指在产生缓存缺失后仍然允许进行缓存命中操作。对于阻塞缓存而言，若访问地址A产生缺失，则需要等待缺失处理完成并获取到对应数据DA后才能进行地址B的访问；对于无阻塞缓存，访问地址A产生缺失后，仍可以立刻对地址B进行访问，若地址B未缺失，可以立刻提供对应数据DB。这种方式可以将缺失代价用后续缓存访问掩盖，降低了缺失代价。</p><h3 id="多组缓存"><a href="#多组缓存" class="headerlink" title="多组缓存"></a>多组缓存</h3><p>将一整块缓存分为多组，不同组之间可以并行访问，提高了缓存的带宽</p><h3 id="关键字优先与提前启动"><a href="#关键字优先与提前启动" class="headerlink" title="关键字优先与提前启动"></a>关键字优先与提前启动</h3><p>这种优化用于降低缺失代价，即对于某个地址的访问缺失后，传统的流程是将这个地址所属的块整个调入缓存后再提供数据，这两种优化方法的操作方式如下所示：</p><ul><li>关键字优先：从需要提取的地址开始将块载入，当提取到CPU请求的数据后立刻将其返回给CPU，随后块中剩下的数据以回卷的方式读入缓存</li><li>提前启动：仍然从块的起始地址开始载入块，当提取到CPU请求的数据后立刻将其返回给CPU，随后继续载入块</li></ul><p>这两种方法的核心思想都是通过尽快获取CPU请求的数据，随后再考虑块的载入的方法降低缺失代价</p><h3 id="合并写缓冲区"><a href="#合并写缓冲区" class="headerlink" title="合并写缓冲区"></a>合并写缓冲区</h3><p>合并写缓冲区用于降低写操作产生的缺失代价，对于写操作而言，一般通过写缓冲区进行，当进行块的写回操作时，将数据写回写缓冲区，此时缓存认为写操作已经完成。若写缓冲区满，则写操作必须等待写缓冲区非满时才继续进行，此时产生写操作的时间代价。</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/write_op.PNG" class=""><p>合并写缓冲区指在将数据写回写缓冲区时，查询写缓冲区已有的数据，若有相同地址的数据，直接覆盖；若有连续地址，可以将其合并为一个写操作，充分利用写带宽资源。如上图所示，上方为未执行写合并时的情况，连续的四个写访问将写缓冲区填满，引起写操作阻塞；下方为写合并的情况，将四个连续地址的写入合并，不仅充分利用了写缓冲区空间，还充分利用了写带宽。需要注意的是，对于某些对IO访问，不可使用写合并（写连续的控制和数据流），需要使用标记标明其不可合并。</p><h3 id="编译器优化"><a href="#编译器优化" class="headerlink" title="编译器优化"></a>编译器优化</h3><p>不改变硬件而通过软件的优化充分利用数据的局部性以降低缺失率，其核心思想为尽量将连续访问的数据人工的置于一个数据块中，常见的优化有以下两种：</p><ul><li>循环交换：假设对于一个数组<code>a[100][200]</code>，按先y后x的顺序访问（<code>a[0][0]</code>，<code>a[1][0]</code>,….）下为每次步幅为200的访问，此时每次访问都可能产生依次缓存缺失。若按先x后y的顺序访问（<code>a[0][0]</code>，<code>a[0][1]</code>,…）则为每次步幅为1的访问，此时访问块开头的数据产生缓存缺失，块内的数据均不产生缺失，充分利用了数据局部性降低了缺失率</li><li>分块：对于大型矩阵，将其分为若干个小矩阵（可以放进一个块中）循环处理可以降低缺失率，因为每次访问一个小矩阵仅产生依次缓存缺失</li></ul><h3 id="预取数据"><a href="#预取数据" class="headerlink" title="预取数据"></a>预取数据</h3><p>根据数据的局部性，一个数据被用到后，其附近的数据也很有可能被用到。以此为原理，可以使用数据预取的方式降低缺失率，数据预取有两种分类：</p><ul><li>硬件预取：使用硬件预取数据，额外设置一个数据读入缓冲区。当发生缺失需要调入一个块时，缺失的块调入缓存，将下一个块（缺失的块紧邻的下一个块）调入读入缓冲区。若下次发生缺失且缺失的就是读入缓冲区的块，则直接从读入缓冲区将其调入缓存；若不是读入缓冲区的块，则将读入缓冲区中的块置无效，重新从主存中读取块（也使用读缓冲区预取下一个块）</li><li>软件预取：通过软件控制预取的过程（编译器在指令中将数据读入指令提前），此时需要编译器小心设计预取的时间，保证预取产生优化</li></ul><h1 id="虚拟存储器"><a href="#虚拟存储器" class="headerlink" title="虚拟存储器"></a>虚拟存储器</h1><p>虚拟存储器方案将物理存储器划分为块，分配给不同的进程，每个进程仅能访问属于自己的块，虚拟存储器用于自动的处理主存储器（内存）和辅助存储器（硬盘）两级存储结构。虚拟存储器提供虚拟地址，一个进程执行需要连续的虚拟地址空间，但这个连续的虚拟地址空间对应的物理地址可能是非连续的，甚至部分可能不在主存上，虚拟存储器用于自动的处理这些问题。虚拟地址和物理地址的对应关系如下所示：</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/vaddr.PNG" class=""><p>虚拟存储器系统可根据划分方法分为三类：</p><ul><li>页式：使用大小固定的块</li><li>段式：使用大小不固定的块</li><li>段页式：一个段由多个大小固定的页组成，一个段包括的页数不固定（一定是整数）</li></ul><p>页和段的优缺点如下表所示：</p><div class="table-container"><table><thead><tr><th>指标</th><th>页</th><th>段</th></tr></thead><tbody><tr><td>信息长度</td><td>1（地址）</td><td>2（地址、长度）</td></tr><tr><td>可见性</td><td>不可见</td><td>可见</td></tr><tr><td>替换块</td><td>容易</td><td>复杂（需要查找一个可容纳该段的空余地址）</td></tr><tr><td>磁盘通信</td><td>高效（每次长度相同）</td><td>不一定（小的段可能仅几个字节）</td></tr></tbody></table></div><h2 id="层次结构"><a href="#层次结构" class="headerlink" title="层次结构"></a>层次结构</h2><p>对于虚拟存储器，也需要考虑类似缓存的四个问题：放置、识别、替换和写入。需要注意的是，由于虚拟存储器管理的低级存储器为硬盘（磁盘或SSD），单位为页，因此缺失代价很大。所以在考虑上述问题时，优先考虑降低缺失率以提高性能：</p><ul><li>放置：为了降低缺失率，一般使用全相联的方式，即一个页或段可以放置在主存的任意位置</li><li>识别：识别用页表或段表实现，即在主存中划分一部分区域，用于存储虚拟地址页号-物理起始地址的表。需要查找一个块时，需要访问两次主存：第一次访问页表获得其物理地址，第二次根据物理地址访问数据</li><li>替换：为了将缺失率降低，因此采用替换最近最少使用块（LRU）的方式</li><li>写入：考虑写入一个块需要消耗很多时钟周期，因此广泛使用写回的方式</li></ul><h2 id="快速地址变换（优化）"><a href="#快速地址变换（优化）" class="headerlink" title="快速地址变换（优化）"></a>快速地址变换（优化）</h2><p>对于使用虚拟地址的系统而言，使用虚拟地址获取数据需要执行两次内存访问：第一次访问分页表获得对应的物理地址；第二次访问物理地址获取数据。为了加速这一类似缓存命中的过程，使用快速地址变换技术，即引入变换旁视缓冲区（TLB）。TLB的组织方式类似缓存，区别在于数据局域不是一个数据块而是一个物理地址。TLB结构如下图所示：</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ch2_tlb.PNG" class=""><p>虚拟地址包括虚拟页号和页偏移量，与缓存中的数据块偏移量相同，虚拟地址和物理地址的偏移量相同，因此这个部分不需要包含在页表或TLB中。TLB中以虚拟页号为标记（key为虚拟页号），存储一些状态位和物理地址（value为物理地址）。执行变换时，首先将虚拟页号发给TLB的每一个表项，若标记匹配（虚拟页号与标记字段相同且有效位拉高），则TLB命中，将对应表项存储的物理地址和偏移量组合为物理地址。若不匹配，则根据页偏移量访问页表，将对应的物理地址调入TLB中在执行命中操作。</p><h2 id="保护"><a href="#保护" class="headerlink" title="保护"></a>保护</h2><p>虚拟存储器一个功能是保护数据，即只让一个进程访问其对应的地址空间而不能访问其他地址空间，尤其是需要受保护的地址空间。首先每个进程具有其独有的分页表，使其仅能获取属于自己的页对应的物理地址，其次还有以下方式对内存进行保护：</p><ul><li>界限检查：在分页表或分段表中标明偏移量的上界，即提供的偏移量不可超过这个固定的值，阻止其访问超过上界的地址空间</li><li>划分共享与保护空间：将地址空间划分为共享和独享两个部分，并使用不同的分页表，分页表中标记页的等级，仅有访问等级高于页的等级的访问才能进行</li><li>调用门：在分页表中提供特殊的表项，其数据域中为物理地址而不为基地址，访问提供的偏移量被忽略。即强制对指定页的访问落到指定地址，即只能访问页中的指定地址。</li></ul><h2 id="虚拟存储器与缓存"><a href="#虚拟存储器与缓存" class="headerlink" title="虚拟存储器与缓存"></a>虚拟存储器与缓存</h2><p>对于同时具有虚拟存储器和缓存的系统，缓存具有多种选择方式，包括：</p><ul><li>逻辑索引+逻辑标记：按逻辑地址查找组，比对的标记（地址高位）为逻辑地址高位</li><li>逻辑索引+物理标记：按逻辑地址查找组，比对的标记为物理地址高位</li><li>物理索引+物理标记：按物理地址查找组，比对的标记位物理地址高位</li></ul><p>对于逻辑索引+逻辑标记这种组合，直接使用逻辑地址进行命中操作，若命中则直接获取数据，不存在物理地址变换步骤。对于物理索引+物理标记的组合，首先使用TLB进行地址变换操作，随后执行缓存命中操作。对于逻辑索引+物理标记的组合，访问的方式如下所示：</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/cache_with_tlb.PNG" class=""><p>上图为一个TLB+二级缓存的系统，一级缓存为逻辑索引+物理地址，二级缓存为物理地址+物理缓存。访问过程首先CPU给出虚拟地址，以下两个步骤并行执行：</p><ul><li>缓存：根据逻辑地址中的索引字段（L1缓存索引）在L1缓存中查找到对应的组</li><li>TLB：使用虚拟页编号进行地址变换，将其转为物理地址</li></ul><p>随后，使用TLB提供的物理地址与缓存对应组中的标志（物理标志）进行比较，若匹配，则缓存命中，向CPU提供数据。若不匹配，则L1缓存缺失，使用物理地址访问L2缓存进行命中操作。</p><h2 id="举例：Opteron存储器管理"><a href="#举例：Opteron存储器管理" class="headerlink" title="举例：Opteron存储器管理"></a>举例：Opteron存储器管理</h2><p>Opteron虚拟存储器部分使用AMD64的虚拟存储器结构。AMD64中，64位虚拟地址被映射到52位物理地址，剩下的12位用于提供保护和使用信息。在Opteron中，使用48位虚拟地址和40位物理地址，AMD64中虚拟地址的高16位（16+48=64）为符号位扩展。AMD64为了管理64位页表使用了4级页表，Opteron中每个页表9位，偏移量12位，即有48=9+9+9+9+12，高一级页表中存储的是低一级页表的地址，如下所示：</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/tlb_example.PNG" class=""><p>对于虚拟地址，首先根据高9位查询页映射表L4，获得对应页目录指针表的起始地址，再以38~30位为偏移量查询页目录指针表获取页目录表地址，依次类推查找到页表，获取对应的物理地址，和页偏移量组合产生物理地址。每个表中的表项中的数据都分为以下两个字段：</p><ul><li>数据：下一级表的物理地址</li><li>保护和使用信息：数据的保护信息</li></ul><p>由于有四级页表，每个页表都有保护和使用信息，执行时服从最低级页表的保护和使用信息。为了实现快速地址变换，Opteron使用了4个TLB，两个用于指令访问两个用于数据访问。</p><h1 id="举例：Cortex-A8与I7"><a href="#举例：Cortex-A8与I7" class="headerlink" title="举例：Cortex-A8与I7"></a>举例：Cortex-A8与I7</h1><h2 id="Cortex-A8缓存结构"><a href="#Cortex-A8缓存结构" class="headerlink" title="Cortex A8缓存结构"></a>Cortex A8缓存结构</h2><p>Cortex A8存储结构为一个两级缓存的结构：</p><ul><li>第一级缓存为缓存对（指令缓存和数据缓存分离），使用虚拟索引和物理标记。大小为16KB或32KB，块大小为64B，组织形式为四路组相联，使用路预测和随即替代算法。</li><li>第二级缓存使用物理索引和物理标记，为8路组相联，大小为128KB~1MB，块大小为64B。</li></ul><p>虚拟地址和物理地址的转换使用TLB管理，TLB的容量为32项全相联，支持页面大小可变，替换算法为一种轮询算法，当发生TLB缺失时，使用硬件轮询主存页表进行处理。其整体操作方式与[虚拟存储器与缓存]中所述相同。</p><h2 id="I7缓存结构"><a href="#I7缓存结构" class="headerlink" title="I7缓存结构"></a>I7缓存结构</h2><p>i7的缓存结构要远远比A8复杂，其具有三级缓存和两级TLB，三级缓存的信息如下所示：</p><div class="table-container"><table><thead><tr><th>特性</th><th>L1 I-cache</th><th>L1 D-cache</th><th>L2缓存</th><th>L3缓存</th></tr></thead><tbody><tr><td>大小</td><td>32KB</td><td>32KB</td><td>256KB</td><td>每个核心2MB</td></tr><tr><td>相联度</td><td>四路</td><td>八路</td><td>八路</td><td>十六路</td></tr><tr><td>访问延迟</td><td>4个周期（流水）</td><td>4个周期（流水）</td><td>10个周期</td><td>35个周期</td></tr><tr><td>替代方法</td><td>伪LRU</td><td>伪LRU</td><td>伪LRU</td><td>带有序选择算法的伪LRU</td></tr><tr><td>索引</td><td>虚拟索引</td><td>虚拟索引</td><td>物理索引</td><td>物理索引</td></tr><tr><td></td><td>物理标记</td><td>物理标记</td><td>物理标记</td><td>物理标记</td></tr></tbody></table></div><p>同时使用两级TLB，第一级TLB指令与数据分离，如下所示：</p><div class="table-container"><table><thead><tr><th>特性</th><th>I-TLB</th><th>D-TLB</th><th>TLB</th></tr></thead><tbody><tr><td>大小</td><td>128</td><td>64</td><td>512</td></tr><tr><td>相联度</td><td>四路</td><td>四路</td><td>四路</td></tr><tr><td>替换算法</td><td>伪LRU</td><td>伪LRU</td><td>伪LRU</td></tr><tr><td>访问延迟</td><td>1个周期</td><td>1个周期</td><td>6个周期</td></tr><tr><td></td><td>7个周期</td><td>7个周期</td><td>访问页表，不确定</td></tr></tbody></table></div><p>存储器的整体结构如下图所示：</p><img src="/2020/01/05/%E5%AD%98%E5%82%A8%E5%99%A8%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/i7_memory.PNG" class="">]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机体系结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EIE结构与算法映射</title>
      <link href="2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/"/>
      <url>2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/</url>
      
        <content type="html"><![CDATA[<h1 id="算法基础"><a href="#算法基础" class="headerlink" title="算法基础"></a>算法基础</h1><p>EIE（Efficient Inference Engine）的算法基础是一种被称为Deep Compression的神经网络压缩算法。EIE可以说是为Deep Compression量身定制的硬件，Deep Compression的算法流程如下所示：</p><ol><li>剪枝：将小于某个阈值的权值直接置为0，这一操作引入权值的稀疏性</li><li>量化：这里的量化是一种非线性量化，通过k近邻类聚算法确定量化中心和量化间隔</li><li>编码：原文中使用霍夫曼编码压缩权值的存储，EIE中使用CSC压缩存储方式</li></ol><h2 id="Deep-Compression压缩"><a href="#Deep-Compression压缩" class="headerlink" title="Deep Compression压缩"></a>Deep Compression压缩</h2><p>Deep Compression压缩分为剪枝、量化和编码操作。其中剪枝为对所有权值做以下操作：</p><script type="math/tex; mode=display">pruning(x) = \begin{cases}x & x > T \\ 0  & x \leq T\end{cases}</script><p>其中T为剪枝阈值，该步骤将所有小于剪枝阈值T的权值置为0，引入了权值的稀疏性。原文中对于VGG结构的剪枝后，卷积层的非零参数量一般还剩原参数量的30%~60%中，全连接层的非零参数量一般仅剩5%以下，由于全连接层参数占参数的主要部分，因此全网络的非零参数量仅剩下原有的7.5%。考虑VGG是比较容易产生冗余的网络，因此对其他网络的剪枝效果可能差于VGG网络。剪枝阈值T在剪枝过程中为超参数，需要综合考虑剪枝效果和剪枝后网络的性能表现多次试验确定。</p><p>量化操作为对于<strong>每个层</strong>，使用k-近邻类聚算法类聚。类聚算法产生指定数量的类聚中心，所有属于某一类的权值都被直接赋予类聚中心的值。随后使用修改过的优化算法运行一定轮数的训练，调整类聚中心的值（权值从属关系不改变），具体过程参见Deep Compression论文，这里仅考虑结果，进行完量化后，每一层的权值张量变为一个同形状的标号张量和一个解码表。标号张量标记每个位置的元素属于的类别，一般仅有2~5bit（即分为4~32类）；解码表标记每个类别的数据，如下图所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/quantize.png" class=""><p>现在考虑量化对实现的影响。原有的高精度权值张量（取$D_H$bit）的非零参数量为M，则需要的存储空间为$M \times D_H$bit。量化后权值张量改为标号张量，标号的位数一般远远低于权值数据，取为$D_L$，需要存储空间为$M \times D_L$；另考虑编码表，编码表需要的bit数为$2^{D_L} \times D_H$。则量化后权值需要的存储空间占原有比例为：</p><script type="math/tex; mode=display">R_w = \frac{M \times D_L + 2^{D_L} \times D_H}{M \times D_H} = \frac{D_L}{D_H} + \frac{2^{D_L}}{M}</script><p>$D_L$一般来说仅有5bit（VGG网络），因此有$M &gt;&gt; 2^{D_L}$，则可以发现将权值的存储空间降低到$\frac{5}{32} = 15.625\%$，有效的缓解了存储瓶颈。但是权值使用时，需要根据标号张量中的标号从编码表中查询权值，再将其与输入进行运算，比原有矩阵直接运算多一步查询，需要通过硬件查询。</p><p>Deep Compression论文中为了进一步压缩权值的存储，在量化后使用霍夫曼编码压缩矩阵的存储。EIE为了方便的硬件实现，使用CSC方法压缩稀疏权值矩阵。</p><h2 id="CSC稀疏矩阵表示"><a href="#CSC稀疏矩阵表示" class="headerlink" title="CSC稀疏矩阵表示"></a>CSC稀疏矩阵表示</h2><p>CSC（compressed sparse column）为一种稀疏矩阵的表示方法，其将一个稀疏矩阵压缩表示为三个向量。首先考虑向量的压缩方法，每个稀疏向量被压缩为两个非稀疏向量，如下所示的向量：</p><script type="math/tex; mode=display">[0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3]</script><p>将其压缩为两个长度相等的向量，第一个向量为按顺序排列的所有的非稀疏元素，第二个向量为对应位置的非稀疏元素与前面一个非稀疏元素中间的0数量，上述向量压缩完成如下所示：</p><script type="math/tex; mode=display">v = [1, 2, 0, 3] \\z = [2, 0, 15, 2]</script><p>u为非零元素，z为两个非零元素之间0的数量。例如$v[0]=1,z[0]=2$表示第一个非0元素为1，该元素之前有2个零；$v[1]=2,z[1]=0$表示第二个非0元素为2，该元素之前没有0（原向量中为$[0,0,1,2,…$）。由于这里的z向量使用的为int4类型数据，因此第三个非零数据3之前的18个零超出了表示范围，因此在v中添加一个0元素，即其中$v[2]=0,z[2]=15$表示第三个数据为0，之前有15个0。这个数据并不是非零数据，是为了能使用int4表示18而额外补充的数据。之后的$v[3]=3,z[3]=2$为要表示的数据3，之前有2个零，和前一条一起表示间隔18个零的情况，如下图所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/csc_vector.png" class=""><p>随后考虑矩阵的表示方法，CSC稀疏表示将矩阵的每一列视为一个向量进行压缩，每一列都产生一个v向量和一个z向量，第i列产生的向量$v_i$和$z_i$向量的长度和其他列均可能不同。将每一列的v向量按列号依次连接，z向量按列号依次连接，获得矩阵的v和z向量，为了区分不同列，额外引入u向量，u向量长度为列数加1，表示每一列的v或z向量在矩阵v和z向量中的位置，即第i列的v和z向量在矩阵的v和z向量的第$u[i]$个到第$u[i+1] - 1$元素之间，u[0]固定为0。如下图所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/csc_matrix.png" class=""><p>最终，一个稀疏矩阵将被压缩到三个向量U、V和Z中，该方式仅保存非零数据（为了表示超过Z限制额外引入的0除外），同时Z和U向量使用的数据类型一般比U小，因此可以有效的压缩稀疏矩阵。</p><h1 id="EIE结构"><a href="#EIE结构" class="headerlink" title="EIE结构"></a>EIE结构</h1><h2 id="PE结构"><a href="#PE结构" class="headerlink" title="PE结构"></a>PE结构</h2><p>EIE（Efficient Inference Engine）作为一种Engine，主要作为加速器系统组件使用，因此论文中并未提出明确的系统架构，而是重点描述了其PE的结构，PE结构图如下：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/eie_structure.png" class=""><p>PE按功能为以下几个部分：</p><ul><li>蓝色底色部分为缓存部分，分布缓存了CSC格式表示矩阵方法下的U、V和Z向量以及Deep Compression产生的解码表和产生的部分和输出数据。</li><li>紫色底色部分为标号处理部分，标号累加为一个累加器，通过累加一个向量CSC表示中之前的元素的z部分产生该元素在向量中的实际绝对位置；列地址生成从矩阵从U向量中获取某一列的数据在V和Z向量中的起始和结束位置。</li><li>橙色底色部分为算数运算部分，输入数据和解码后的权值相乘并和之前的结构相加，结果保存在输出缓存中，当运算完成时，通过ReLu单元激活后输出。</li></ul><p>该PE如何映射运算将在后续章节[算法映射]中表述。</p><h2 id="CSC编码器"><a href="#CSC编码器" class="headerlink" title="CSC编码器"></a>CSC编码器</h2><p>PE运算产生的结果并不是CSC方法表示。一般来说，在ReLU函数之前的输出数据并不具有稀疏性，但是ReLU函数将所有负数输出置为0，引入了输入\输出数据的稀疏性，因此需要将输出数据进行CSC编码，CSC编码器结构如下所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/nzd_structure.png" class=""><p>论文中PE以4个一组，每个PE输出一个输出数据及其绝对标号，非零数据检测器从PE0的输出数据开始依次检测，若发现非0数据，则通过绝对标号计算CSC格式的相对标号，同时输出器数据和相对标号，实现CSC编码。</p><h1 id="算法映射"><a href="#算法映射" class="headerlink" title="算法映射"></a>算法映射</h1><h2 id="矩阵-向量乘法"><a href="#矩阵-向量乘法" class="headerlink" title="矩阵-向量乘法"></a>矩阵-向量乘法</h2><p>原论文中以4个PE为一组，计算矩阵乘法。输入权值和输入数据以下图为例：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/eie_weight_data.png" class=""><p>矩阵乘法计算的目标为：</p><script type="math/tex; mode=display">Y = W \times X,W \in R^{a \times b}，X \in R^b</script><p>上图中，有a=8、b=8。权值矩阵的第i行数据保存在标号为$i \% 4$的PE中并由该PE负责计算。第i个PE的所有权值行向量顺序堆叠组成一个新权值矩阵$W_i,W \in R^{(a//4) \times b}$，这里新权值矩阵为2行。标号为i的PE中存储的是新权值矩阵$W_i$的CSC表示。</p><p>EIE映射算法的原理如下图所示，综合考虑输入数据和权值的稀疏性，将矩阵-向量乘法分解为多个向量相乘，当且仅当对应位置上的元素均不为0时才进行计算，因此可以减少很多0之间的运算。</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/eie_source.png" class=""><p>EIE的PE输入为一个CSC格式压缩的稀疏向量，将每个元素的数据和标号（v和z）依次输入数据队列和标号队列。处理一个数据时，从数据队列中取出数据D并从标号队列中取出标号$I_z$，标号$I_z$通过标号累加器变为向量的绝对坐标I。以上图中所述第一个数据X0为例，其相z元素为0，即之前没有0，因此X0的绝对位置为0。输入向量CSC格式累加过程如下所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/eie_index_acc.png" class=""><p>随后通过$I//2$查询奇数U缓存，$I // 2 + I \%2$查询偶数缓存。分别从偶数U缓存和奇数U缓存中获取地址各一个：</p><ul><li>若I为奇数，则从奇数缓存中读取的数据为起始地址$U_s$，从偶数缓存中读取的数据为结束地址$U_e$</li><li>若I为偶数，则从偶数缓存中读取的数据为起始地址$U_s$，从奇数缓存中读取的数据为结束地址$U_e$</li></ul><p>对于X0而言，对应绝对位置为0，读出起始地址为0，结束地址为1；对于X2，读出起始地址为1，结束地址为2；对于X5，读取起始地址为3，读取终止地址为4。对于$U<em>s = U_e$的情况，说明该输入数据对应的列无非0数据，可直接跳过该输入数据的处理过程。随后使用$U_s$和$U_e$之间的值（不包括$U_e$，即$[U_s,U_e)$）从V缓存和Z缓存中读取权值。对于X0，读出权值$W</em>{0,0}$和相对位置0，对于X2，读取权值$W<em>{0,2}$和相对位置0；对于X5，读取权值$W</em>{4,5}$和相对位置1。根据这些权值从编码表中查询真实权值。相对位置进行与输入相同的权值累加计算真实权值WI，计算结果分别为0、0和1。</p><p>随后输入数据与读出的真实权值依次相乘，相乘的结果与输出缓存中位置为WI的数据累加，过程如下所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/eie_acc.png" class=""><p>累加完成后，输出缓存每个地址存储的就是对应绝对位置的输出结果，完成矩阵-向量乘法映射。</p><h2 id="卷积映射"><a href="#卷积映射" class="headerlink" title="卷积映射"></a>卷积映射</h2><p>卷积映射在原论文中没有提到，一下为基于结构对映射卷积方式的猜测，其映射卷积的方式可能为将卷积拆分为多个矩阵乘法实现，如下图所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/eie_conv.png" class=""><p>PE的输入为广播输入，因此所有PE的输入数据必须相同，而所有权值均为本地存储，因此权值应当不在PE之间交换，由上推测出卷积的映射方法应当将一个$K \times K$的卷积变为$K \times K$个$1 \times 1$卷积实现。上图举出了一种$2 \times 2$卷积在EIE上实现的可能方案。每个PE计算一个输出通道为CO+1，输入通道为CI+1的$1 \times 1$卷积，所有PE计算完成后，将结果错位相加即可获得$2 \times 2$卷积的计算结果，错位相加过程如下所示：</p><img src="/2019/07/22/EIE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E6%98%A0%E5%B0%84/eie_conv_add.png" class="">]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基2FFT原理</title>
      <link href="2019/07/09/%E5%9F%BA2FFT%E5%8E%9F%E7%90%86/"/>
      <url>2019/07/09/%E5%9F%BA2FFT%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="FFT前置知识"><a href="#FFT前置知识" class="headerlink" title="FFT前置知识"></a>FFT前置知识</h1><h2 id="FT和DFT"><a href="#FT和DFT" class="headerlink" title="FT和DFT"></a>FT和DFT</h2><p>傅里叶变换FT（fourier transform）用于将时域信号$x(t)$和频域信号$X(f)$之间变换，公式如下所示：</p><script type="math/tex; mode=display">X(f) = \int^{\infty}_{-\infty}x(t)e^{-j2\pi ft}dt \\x(t) = \int^{\infty}_{-\infty}X(f)e^{j2\pi ft}df</script><p>对于计算机系统中，无法处理连续的过程，因此离散化为离散傅里叶变换DFT（Discrete Fourier Transform）：</p><script type="math/tex; mode=display">X[k] = \frac{1}{N}\sum\limits^{N-1}_{n=0} x[n] \times e^{-\frac{2\pi k}{N}j\times n} \\x[n] = \frac{1}{N}\sum\limits^{N-1}_{k=0} X[k]\times e^{-\frac{2\pi n}{N}j\times k}</script><p>取$W_N  = e^{-\frac{2\pi}{N}j}$，可将DFT改写为以下公式：</p><script type="math/tex; mode=display">X[k] = \frac{1}{N}\sum\limits^{N-1}_{n=0} x[n] \times W_N^{kn} \\x[n] = \frac{1}{N}\sum\limits^{N-1}_{k=0} X[k]\times W_N^{-kn}</script><h2 id="DFT改进（削减计算量）"><a href="#DFT改进（削减计算量）" class="headerlink" title="DFT改进（削减计算量）"></a>DFT改进（削减计算量）</h2><p>首先分析原始公式的计算量，取一个8点DFT算法，对于一个点：</p><ul><li>需要复数乘法N次，每次复数乘法由四次实数乘法和两次实数加法实现</li><li>需要复数加法N-1次，每次复数加法由两次实数加法构成</li></ul><p>因此，对于一个点，需要实数乘法共4N次，实数加法共（2N-2+2N）=4N-2次。削减计算量的主要重点在$W_N$上，使用欧拉公式有：</p><script type="math/tex; mode=display">W_N^{k} = e^{-\frac{2\pi}{N}jk} = \cos\frac{2\pi k}{N} - j\sin\frac{2\pi k}{N}</script><p>考虑$W_N^{k+\frac{N}{2}}$的情况，有以下公式：</p><script type="math/tex; mode=display">W_N^{k+\frac{N}{2}} = e^{-\frac{2\pi}{N}j(k+\frac{N}{2})} = \cos\frac{2\pi (k+\frac{N}{2})}{N} - j\sin\frac{2\pi (k+\frac{N}{2})}{N} \\= \cos(\frac{2\pi k}{N}+\pi) - j\sin(\frac{2\pi k}{N}+\pi) = -\cos\frac{2\pi k}{N} + j\sin\frac{2\pi k}{N} = -W_N^{k}</script><p>同理有$W_N^{k+N} = W_N$，因此以一个4点DFT为例，有以下公式：</p><script type="math/tex; mode=display">X[1] = x(0)W_4^0 + x(1)W_4^1 +x(2)W_4^2+x(3)W_4^3 =[x(0) - x(2)]W^0_4 + [x(1)-x(3)]W_4^2</script><p>可减少所需要的复数乘法的次数，进而减少对应的实数乘法和加法的数量</p><h1 id="FFT"><a href="#FFT" class="headerlink" title="FFT"></a>FFT</h1><h2 id="基2FFT"><a href="#基2FFT" class="headerlink" title="基2FFT"></a>基2FFT</h2><p>基2FFT指点数为$2^n$的FFT变换，取$N = 2^n$的FFT变换如下所示：</p><script type="math/tex; mode=display">X[k] = \sum\limits^{N-1}_{n=0}x(n)W_N^{kn} = \sum\limits^{\frac{N}{2}-1}_{n=0}x(2n)W_N^{2kn} + \sum\limits^{\frac{N}{2}-1}_{n=0}x(2n+1)W_N^{(2n+1)k}</script><p>将一个N点的FFT分解为两个FFT，一个为奇数项的FFT，另一个为偶数项的FFT。对于$W_N^{nk}$而言，考虑以下变化：</p><script type="math/tex; mode=display">W_N^{2nk} = e^{-\frac{2\pi \times 2nk}{N}j} = e^{-\frac{2\pi \times nk}{\frac{N}{2}}j} = W_{\frac{N}{2}}^{nk}</script><p>带入上式，有以下：</p><script type="math/tex; mode=display">X[k] =\sum\limits^{\frac{N}{2}-1}_{n=0}x(2n)W_N^{2kn} + W_N^k\sum\limits^{\frac{N}{2}-1}_{n=0}x(2n+1)W_N^{2nk} = \sum\limits^{\frac{N}{2}-1}_{n=0}x(2n)W_{\frac{N}{2}}^{kn} +W_N^k \sum\limits^{\frac{N}{2}-1}_{n=0}x(2n+1)W_{\frac{N}{2}}^{nk}</script><p>取$FFT<em>1(k) = \sum\limits^{\frac{N}{2}-1}</em>{n=0}x(2n)W<em>{\frac{N}{2}}^{kn} $和$FFT_2(k) = \sum\limits^{\frac{N}{2}-1}</em>{n=0}x(2n+1)W_{\frac{N}{2}}^{nk}$分别是两个长度为$\frac{N}{2}$的FFT运算，有：</p><script type="math/tex; mode=display">X[k] = FFT_1(k) +W_N^k\times FFT_2(k)</script><p>上述有$n &lt; \frac{N}{2}$，考虑后半段结果，有：</p><script type="math/tex; mode=display">FFT_1(k+\frac{N}{2}) =\sum\limits^{\frac{N}{2}-1}_{n=0}x(2n)W_{\frac{N}{2}}^{n(k+\frac{N}{2})} = \sum\limits^{\frac{N}{2}-1}_{n=0}x(2n)W_{\frac{N}{2}}^{nk+\frac{Nk}{2}} = \sum\limits^{\frac{N}{2}-1}_{n=0}x(2n)W_{\frac{N}{2}}^{kn} = FFT_1(k)</script><p>同理有$FFT_2(k+\frac{N}{2}) = FFT_2(k)$，因此当$n \geq \frac{N}{2}$时，考虑$W_N$的周期性，有：</p><script type="math/tex; mode=display">X[k] = FFT_1(k) + W_N^{k+\frac{N}{2}}\times FFT_2(k) =FFT_1(k) - W_N^k\times FFT_2(k)</script><p>综上所述对于一个N点的FFT运算，有</p><script type="math/tex; mode=display">X[k] = \begin{cases} FFT_1(k) +W_N^k\times FFT_2(k) & k < \frac{N}{2} \\ FFT_1(k-\frac{N}{2}) -W_N^k\times FFT_2(k-\frac{N}{2}) & k \geq \frac{N}{2} \end{cases}</script><p>其中，$FFT_1$为对偶数序列的$\frac{N}{2}$点FFT；$FFT_2$为对应奇数序列的$\frac{N}{2}$点FFT。该操作将一个N点FFT分解为两个$\frac{N}{2}$点的FFT。</p><h2 id="蝶形运算"><a href="#蝶形运算" class="headerlink" title="蝶形运算"></a>蝶形运算</h2><p>蝶形运算为一个二输入二输出的运算，公式如下所示：</p><script type="math/tex; mode=display">Y_1 = X_1 + W \times X_2 \\Y_2 = X_1 - W \times X_2</script><p>其中$X_1,X_2$为两个输入；$Y_1,Y_2$为两个输出；W为权值，均为复数。蝶形运算可以用于映射基2FFT，首先考虑2点FFT，两点FFT公式如下所示：</p><script type="math/tex; mode=display">X[0] = x(0)\times W_2^0 + x(1) \times W_2^0 = x(0) + W_2^0 \times x(1) \\X[1] = x(0)\times W_2^0 + x(1) \times W_2^1 = x(0) - W_2^0 \times x(1)</script><p>因此可以使用一个蝶形运算实现，权值为$W_2^k$，现考虑一个4点FFT，首先将其分解为2个两点FFT，分解的公式为</p><script type="math/tex; mode=display">X[k] = \begin{cases} FFT_1(k) +W_N^k\times FFT_2(k) & k < \frac{N}{2} \\ FFT_1(k-\frac{N}{2}) -W_N^k\times FFT_2(k-\frac{N}{2}) & k \geq \frac{N}{2} \end{cases}</script><p>分解步骤也可以用蝶形运算实现，因此整体运算如下图所示：</p><img src="/2019/07/09/%E5%9F%BA2FFT%E5%8E%9F%E7%90%86/fft4.png" class=""><p>更多点数的FFT可以类似的进行，即不断分解为长度为一半的奇偶序列的FFT变换分层实现。</p>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浮点数处理</title>
      <link href="2019/05/28/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%A4%84%E7%90%86/"/>
      <url>2019/05/28/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="浮点数表达"><a href="#浮点数表达" class="headerlink" title="浮点数表达"></a>浮点数表达</h1><p>IEEE754标准是用于规范浮点数运算的IEEE标准，用于解决浮点数标准混乱的问题。其被认证后不久，几乎所有的处理器生产商都采用这一标准，极大的推动了软件的发展。浮点数存储的格式如下：</p><img src="/2019/05/28/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%A4%84%E7%90%86/float.png" class=""><p>浮点数由符号位，指数位和尾数三个部分组成，表达公式如下式：</p><script type="math/tex; mode=display">X = (-1)^{s} \times f \times 2^{e}</script><p>在IEEE754标准中，主要规定了单精度浮点（float）和双精度浮点（double）两种浮点数：</p><div class="table-container"><table><thead><tr><th>类型</th><th>符号位数</th><th>指数位数</th><th>尾数位数</th></tr></thead><tbody><tr><td>单精度浮点（float）</td><td>1</td><td>8</td><td>23</td></tr><tr><td>双精度浮点（double）</td><td>1</td><td>11</td><td>52</td></tr></tbody></table></div><p>首先考虑符号位，当该符号位为0时，表示该数为正数，符号位为1时，表示该数为负数。指数可以为负数，一般使用移码表示，移码表示为：</p><script type="math/tex; mode=display">E = e- bias</script><p>E为真实的指数，e为浮点数中存储的尾数，bias为移位，有$bias = 2^{len(e) - 1} - 1$。以单精度浮点为例，指数位数$len(e) = 8$，则有bias=127，真实指数和存储的关系为$E = e - 127$，表示范围为-126~127（e=0和e=255用于表示特殊字符）。尾数为规格化的尾数，即尾数的二进制表示$f_b$前有一个隐藏的二进制1，即如下表示：</p><script type="math/tex; mode=display">X = (-1)^{s} \times 1.f_b \times 2^{e-bias}</script><p>当e=0时，该浮点数为非规格化数，表示的数如下所示：</p><script type="math/tex; mode=display">X = (-1)^s \times 0.f_b \times 2^{-126}</script><p>该标准内还定义了几个特殊值：</p><div class="table-container"><table><thead><tr><th>特殊值</th><th>说明</th></tr></thead><tbody><tr><td>0</td><td>指数部分和尾数部分均为1</td></tr><tr><td>无穷大</td><td>指数部分为$2^{len(e)} - 1$（指数最大值），尾数部分为0</td></tr><tr><td>NaN</td><td>指数部分为$2^{len(e)} - 1$（指数最大值），尾数部分不为0</td></tr></tbody></table></div><h1 id="浮点数计算"><a href="#浮点数计算" class="headerlink" title="浮点数计算"></a>浮点数计算</h1><h2 id="浮点数乘法"><a href="#浮点数乘法" class="headerlink" title="浮点数乘法"></a>浮点数乘法</h2><p>浮点数的乘法分为以下几个步骤：</p><ul><li>计算符号位：通过异或操作计算符号位，若两个操作数符号位相同，则结果符号位为0，否则结果符号为1</li><li>计算原始尾数：两个操作数的尾数相乘，得到原始尾数</li><li>计算原始指数：将两个操作数的指数相加，得到原始指数</li><li>规格化与舍入：对原始尾数和原始指数进行规格化，获得结果的指数，再对尾数进行舍入，获得结果的尾数</li></ul><img src="/2019/05/28/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%A4%84%E7%90%86/mul_flow.png" class=""><p>对于科学计数法表示的乘法，有：</p><script type="math/tex; mode=display">[(-1)^{s_1} \times 1.f_1 \times 2^{e_1}] \times [(-1)^{s_2} \times 1.f_2 \times 2^{e_2}] = (-1)^{s_1 \ XOR \ s_2} \times (1.f_1\times 1.f_2) \times 2^{e_1+e_2}</script><p>现考虑32位的单精度浮点数（float），其指数为8位，尾数为23位，获得原始指数和原始尾数为：</p><ul><li>原始指数：原始指数为两个8位的指数相加，共9位</li><li>原始尾数：原始尾数为两个23位的尾数相乘，共46位</li></ul><p>获得原始指数和尾数后进行规格化，若原始指数小于-126，则小于表示范围，将原始尾数右移，每右移一位，原始指数+1，直到原始指数到达-126，此时形成非规格化数。若原始尾数不小于-126，进行正常的标准化：</p><ul><li>两个规格化数相乘：$1.f_1 \times 1.f_2$，结果在1~4之间，即最高2位有以下几种可能性：<ul><li>最高2位为<code>01</code>：原始尾数向左移位2位（包括移除隐含的1），原始指数直接为获得规格化的指数，小数部分还剩44位，在舍入部分处理。若原始指数-2后为-127，则在移位后尾数前添加1，使用非规格化表示</li><li>最高2位为<code>10</code>或<code>11</code>：原始尾数向左移位1位（移除隐含的1），原始指数+1获得规格化的指数，小数部分还剩45位，在舍入部分处理。</li></ul></li><li>非规格数和规格化相乘：$1.f_1 \times 0.f_2$，结果在0~2之间，操作方式与上述类似</li><li>非规格化数和非规格化数相乘：原始指数为-252，尾数部分仅有46位，无论如何都不可能使指数规格化到-126，直接为0</li></ul><p>进行规格化后，原始指数被修正为指数$e_3$，此时若尾数的位数超过23位，还需要进行舍入操作。将规格化后的尾数使用$sf$表示，$sf[h:h-23]$表示高23位的指数，$sf[h-24:0]$表示24位以后尾数。舍入使用“四舍六入”的方式，舍入规则如下所示：</p><ul><li>若$sf[h-24:0] &lt; 1000…0$：抛弃，舍入结果为$sf[h:h-23]$（四舍）</li><li>若$sf[h-24:0] &gt; 1000…0$：进位，舍入结果为$sf[h:h-23]+1$（六入）</li><li>若$sf[h-24:0] == 1000…0$：舍向偶数，即使$sf[h:h-23]$变为偶数（$sf[h:h-23]$为奇数时进位，否则抛弃）</li></ul><p>进行舍入后，原始尾数被修正为尾数$f_3$，乘法计算完成。</p><h2 id="浮点数加法"><a href="#浮点数加法" class="headerlink" title="浮点数加法"></a>浮点数加法</h2><p>浮点数的加法分为以下几个步骤：</p><ul><li>对阶：将指数较小的浮点数进行尾数向右移位，指数同步增大，直到两个操作数的指数等</li><li>求和：对尾数进行求和</li><li>规格化：对指数和尾数做规格化，并对尾数进行舍入</li></ul><img src="/2019/05/28/%E6%B5%AE%E7%82%B9%E6%95%B0%E5%A4%84%E7%90%86/add_flow.png" class=""><p>对于科学计数法表示的加法，有：</p><script type="math/tex; mode=display">[(-1)^{s_1} \times 1.f_1 \times 2^{e_1}] + [(-1)^{s_2} \times 1.f_2 \times 2^{e_2}] = [(-1)^{s_1} \times 1.f_1 \times 2^{e_1-e_2}+ (-1)^{s_2} \times 1.f_2] \times 2^{e_2}</script><p>第一步为对阶，即将指数变为相同以实现加法，规定小阶向大阶对阶，即原始指数$e=\max{e_1,e_2}$，对于指数较小的操作数，需要将尾数向右移位，每移动一位，指数加1，移位直到阶数相等即完成对阶，对阶过程可表示为：</p><script type="math/tex; mode=display">\begin{cases}(-1)^{s_1} \times 1.f_1 \times 2^{e_1} \\ (-1)^{s_2} \times 1.f_2 \times 2^{e_2}\end{cases} \to \begin{cases}[(-1)^{s_1} \times 1.f_1 \times 2^{e_1 - \max\{e_1,e_2\}}] \times 2^{\max\{e_1,e_2\}} \\ [(-1)^{s_2} \times 1.f_2 \times 2^{e_2 - \max\{e_1,e_2\}}] \times 2^{\max\{e_1,e_2\}}\end{cases}</script><p>第二步为求和，即对阶完成后，两个尾数可以直接求和获得原始尾数，求和过程如下所示：</p><script type="math/tex; mode=display">\begin{cases}[(-1)^{s_1} \times 1.f_1 \times 2^{e_1 - \max\{e_1,e_2\}}] \times 2^{\max\{e_1,e_2\}} \\ [(-1)^{s_2} \times 1.f_2 \times 2^{e_2 - \max\{e_1,e_2\}}] \times 2^{\max\{e_1,e_2\}}\end{cases} \to \\ [(-1)^{s_1} \times 1.f_1 \times 2^{e_1 - \max\{e_1,e_2\}} + (-1)^{s_2} \times 1.f_2 \times 2^{e_2 - \max\{e_1,e_2\}}] \times 2^{\max\{e_1,e_2\}}</script><p>第三步为规格化和舍入，原始尾数$f = (-1)^{s_1} \times 1.f_1 \times 2^{e_1 - \max{e_1,e_2}} + (-1)^{s_2} \times 1.f_2 \times 2^{e_2 - \max{e_1,e_2}}$，原始指数$e=\max{e_1,e_2}$，对其进行规格化和舍入操作，获得新的指数$e_3$和尾数$f_3$，操作方式与乘法相同，即完成浮点数的加法。</p>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> float32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>异步FIFO设计</title>
      <link href="2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/"/>
      <url>2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-设计目标"><a href="#1-设计目标" class="headerlink" title="1.设计目标"></a>1.设计目标</h1><p>设计一个参数可配置的异步FIFO，要求：</p><ul><li>FIFO深度从4开始在2的幂次方连续可配（4、8、16、……）</li><li>读写时钟域相位差、频率差任意（同步器参数可配）</li></ul><h1 id="2-参数列表"><a href="#2-参数列表" class="headerlink" title="2.参数列表"></a>2.参数列表</h1><div class="table-container"><table><thead><tr><th>名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>DEPTH_LOG</td><td>4</td><td>FIFO容量为$2^{DEPTH_LOG}$</td></tr><tr><td>DATA_WIDTH</td><td>8</td><td>数据位宽</td></tr></tbody></table></div><h1 id="3-端口"><a href="#3-端口" class="headerlink" title="3.端口"></a>3.端口</h1><h2 id="3-1-端口列表"><a href="#3-1-端口列表" class="headerlink" title="3.1.端口列表"></a>3.1.端口列表</h2><h3 id="3-1-1-系统端口"><a href="#3-1-1-系统端口" class="headerlink" title="3.1.1.系统端口"></a>3.1.1.系统端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>read_clk</td><td>input</td><td>1</td><td>读时钟域时钟</td></tr><tr><td>write_clk</td><td>input</td><td>1</td><td>写时钟域时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位端口，低有效</td></tr></tbody></table></div><h3 id="3-1-2-读端口"><a href="#3-1-2-读端口" class="headerlink" title="3.1.2.读端口"></a>3.1.2.读端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>read_req</td><td>input</td><td>1</td><td>读完成信号</td></tr><tr><td>read_valid</td><td>output</td><td>1</td><td>读数据有效信号</td></tr><tr><td>read_data</td><td>output</td><td>DEPTH_LOG</td><td>读数据</td></tr><tr><td>fifo_empty</td><td>output</td><td>1</td><td>FIFO空信号</td></tr></tbody></table></div><h3 id="3-1-3-写端口"><a href="#3-1-3-写端口" class="headerlink" title="3.1.3.写端口"></a>3.1.3.写端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>write_req</td><td>input</td><td>1</td><td>写请求信号</td></tr><tr><td>write_data</td><td>input</td><td>DEPTH_LOG</td><td>写数据</td></tr><tr><td>fifo_full</td><td>output</td><td>1</td><td>FIFO满信号</td></tr></tbody></table></div><h2 id="3-2-端口时序"><a href="#3-2-端口时序" class="headerlink" title="3.2.端口时序"></a>3.2.端口时序</h2><h3 id="3-2-1-读端口时序"><a href="#3-2-1-读端口时序" class="headerlink" title="3.2.1.读端口时序"></a>3.2.1.读端口时序</h3><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/read_port.png" class=""><p><code>read_req</code>信号拉高表示请求读数据，若此时FIFO非空（<code>fifo_empty</code>为低），FIFO将会将数据置于<code>read_data</code>上，同时拉高<code>read_valid</code>信号。即当<code>read_valid</code>有效时，对应的<code>read_data</code>上的数据有效。<code>fifo_empty</code>拉高表示FIFO已空，当前数据输出端口上的数据无意义， 再拉高<code>read_req</code>将不会改变<code>read_data</code>上的数据。</p><h3 id="3-2-2-写端口时序"><a href="#3-2-2-写端口时序" class="headerlink" title="3.2.2.写端口时序"></a>3.2.2.写端口时序</h3><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/write_port.png" class=""><p>写端口如上所示，当且仅当<code>write_req</code>信号高且<code>fifo_full</code>信号低时将<code>write_data</code>端口上的数据写入FIFO。</p><h1 id="4-系统结构"><a href="#4-系统结构" class="headerlink" title="4.系统结构"></a>4.系统结构</h1><h2 id="4-1-结构框图"><a href="#4-1-结构框图" class="headerlink" title="4.1.结构框图"></a>4.1.结构框图</h2><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/structure.png" class=""><p>系统整体结构如上所示，分为两个时钟域——读时钟域和写时钟域。每个时钟域结构相互镜像：</p><ul><li>读/写指针：二进制的读写指针，用于SRAM的读/写地址</li><li>二进制到格雷码转换器：将读/写指针从二进制转为格雷码，用于传递到下一个时钟域或生产空\满信号</li><li>空/满信号生成：比对读指针和写指针的格雷码，生成空和满信号</li></ul><p>其他还有跨时钟域的组件，分别为：</p><ul><li>双口SRAM：一个端口使用写时钟和写时钟域下的信号，另一个使用读时钟和读时钟域的信号</li><li>同步器：两个同步器，分别将读指针同步到写时钟域和将写时钟同步到读时钟域</li></ul><h2 id="4-2-系统方法"><a href="#4-2-系统方法" class="headerlink" title="4.2.系统方法"></a>4.2.系统方法</h2><h3 id="4-2-1-二进制转格雷码"><a href="#4-2-1-二进制转格雷码" class="headerlink" title="4.2.1.二进制转格雷码"></a>4.2.1.二进制转格雷码</h3><p>假设二进制码为每位为$bin[n]$，对应的格雷码每位为$gray[n]$，共N位，转换算法为：</p><script type="math/tex; mode=display">\begin{cases}gray[N-1] = bin[N - 1]  \\gray[i] = bin[i] \ NOR \ bin[i+1] & i < N-1\end{cases}</script><p>例如二进制码<code>011</code>，共3位，则格雷码第2位为<code>0</code>，其他几位为<code>10</code>，对应格雷码为<code>010</code>，在具体实现时，可以参考下图的实现方法：</p><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/bin2gray.png" class=""><h3 id="4-2-2-格雷码判空判满"><a href="#4-2-2-格雷码判空判满" class="headerlink" title="4.2.2.格雷码判空判满"></a>4.2.2.格雷码判空判满</h3><p>对读指针和写指针有以下含义：</p><ul><li>读指针：指向当前正在读的地址</li><li>写指针：指向下一次写入操作需要写入的地址</li></ul><p>二进制下，对于地址位宽为N的SRAM，可以使用位宽为N+1的地址——低N位为地址，MSB为标志位，用于标记满和空：</p><ul><li>当低N位相等，MSB不相等时：FIFO满（写指针领先读指针“一圈”）</li><li>当低N为相等，MSB相等时：FIFO空（读指针“追上”写指针）</li></ul><p>转换到格雷码域，做相同判断，判空条件为两个指针相等，相等的二进制码对应格雷码相等，条件不变。对于判满，需要两个二进制仅有最高位不同，参考二进制转格雷码条件，判满条件如下：</p><ul><li>最高位不相等（格雷码MSB与二进制MSB相同）</li><li>次高位不相等（次高位由二进制码的最高位和次高位异或，两指针二进制下最高位不同，次高位相同）</li><li>其他位均相等（异或操作依赖的位数均相等）</li></ul><p>由于同步器的同步需要消耗时钟周期，因此：</p><ul><li>判满：在写时钟域下生成满信号，读指针通过同步器，为若干个时钟周期之前的读指针。若在FIFO满的情况下，读操作发生，读指针的变化延迟传递到写时钟域，在传递的若干个周期内状态为“假满”</li><li>判空：在读时钟域下生成空信号，写指针通过同步器，为若干个时钟周期之前的写指针。若在FIFO空的情况下，写操作发生，写指针的变化延迟传递到读时钟域，在传递的若干个周期内状态为“假空”</li></ul><p>“假满”和“假空”状态均不影响异步FIFO的正常工作，仅为略微降低FIFO的工作效率</p><h3 id="4-2-3-同步器"><a href="#4-2-3-同步器" class="headerlink" title="4.2.3.同步器"></a>4.2.3.同步器</h3><p>同步器是一种跨时钟域数据传输的方法，二级同步器结构如下所示：</p><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/synchronizer.png" class=""><p>从源时钟域下的源信号开始，依次通过多个时钟为目标时钟域时钟下的寄存器，即构成了多级同步器，寄存器的数量就是同步器的级数。一般的信号仅需要二级同步器，高速信号一般使用三级同步器。</p><h1 id="5-实现细节"><a href="#5-实现细节" class="headerlink" title="5.实现细节"></a>5.实现细节</h1><h2 id="5-1-写FIFO部分"><a href="#5-1-写FIFO部分" class="headerlink" title="5.1.写FIFO部分"></a>5.1.写FIFO部分</h2><p>写FIFO部分包括以下几个组件：</p><ul><li>同步器：将读指针从读时钟域同步到写时钟域，使用两级同步器</li><li>写指针：指示写入地址的指针，当满信号拉低且写请求拉高时加1</li><li>写指针二进制转格雷码：将写指针从二进制转为格雷码，送到判满部分判满和向读时钟域的同步器</li><li>满信号生成：当满足[4.2.2]的判满条件成立时，拉高满信号</li></ul><h3 id="5-1-1-需求"><a href="#5-1-1-需求" class="headerlink" title="5.1.1.需求"></a>5.1.1.需求</h3><p>写FIFO部分的需求如下：</p><ul><li>产生写SRAM的相关信号，包括写请求信号，写地址信号和写数据信号</li><li>同步内部读指针，配合写指针生成满信号。将写指针传递到读部分。</li></ul><h3 id="5-1-2-端口"><a href="#5-1-2-端口" class="headerlink" title="5.1.2.端口"></a>5.1.2.端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>写部分时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位</td></tr><tr><td>write_req</td><td>input</td><td>1</td><td>写FIFO请求</td></tr><tr><td>fifo_full</td><td>output</td><td>1</td><td>FIFO满信号</td></tr><tr><td>write_addr</td><td>output</td><td>DEPTH_LOG</td><td>写存储器地址</td></tr><tr><td>read_point_gray</td><td>input</td><td>DEPTH_LOG+1</td><td>读指针格雷码，未同步</td></tr><tr><td>write_point_gray</td><td>output</td><td>DEPTH_LOG+1</td><td>写指针格雷码</td></tr></tbody></table></div><h3 id="5-1-3-实现"><a href="#5-1-3-实现" class="headerlink" title="5.1.3.实现"></a>5.1.3.实现</h3><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/write_control.png" class=""><p>上图为<code>fifo_full</code>生成部分的结构图，为了保证保证<code>fifo_full</code>拉高的及时性，设置<code>next_write_point_gray</code>寄存器，指示下一个格雷码的写地址。当一次<code>is_write</code>拉高时，每个部件的功能如下所示：</p><ul><li><code>write_point</code>：自增1</li><li><code>write_point_gray</code>：从<code>next_write_point_gray</code>获取与<code>write_point</code>同步的格雷码</li><li><code>next_write_point_gray</code>：取现在write_point加2后对应的格雷码，获得与<code>write_point+1</code>同步的格雷码</li></ul><p>写产生FIFO满的波形如下所示：</p><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/full_gen.png" class=""><p>当一次写请求使FIFO满时，由于写请求发生，因此使用<code>next_write_point_gray</code>进行判满操作，此时该信号与<code>read_point_gray</code>相等，因此在下一个时钟周期<code>fifo_full</code>拉高（图中a,b-&gt;c），同时，<code>write_point</code>和<code>write_point_gray</code>均完成更新。下一个时钟周期，无写请求发生，因此使用<code>write_point_gray</code>进行判满操作，此时<code>write_point_gray</code>更新后与<code>read_point_gray</code>相等，保持fifo满状态（图中e,d-&gt;f）。</p><p>对于数据部分，如下图所示：</p><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/write_data.png" class=""><p>该部分不包括在写控制模块中，系统输入的<code>write_data</code>端口直接连接到SRAM的写数据端口，写请求端口为<code>write_req</code>和<code>fifo_full</code>的组合逻辑与信号（<code>write_req &amp;&amp; !fifo_full</code>）</p><h2 id="5-2-读FIFO部分"><a href="#5-2-读FIFO部分" class="headerlink" title="5.2.读FIFO部分"></a>5.2.读FIFO部分</h2><p>读FIFO部分包括以下几个组件：</p><ul><li>同步器：将写指针从写时钟域同步到读时钟域，使用两级同步器</li><li>读指针：指示读取地址的指针，当空信号拉低且读请求拉高时加1</li><li>读指针二进制转格雷码：将读指针从二进制转为格雷码，送到判空部分判空和向写时钟域的同步器</li><li>空信号生成：当满足[4.2.2]的判空条件成立时，拉高空信号</li></ul><h3 id="5-2-1-需求"><a href="#5-2-1-需求" class="headerlink" title="5.2.1.需求"></a>5.2.1.需求</h3><p>读FIFO部分需要满足以下几个需求：</p><ul><li>产生读SRAM的相关信号，包括地址信号，数据有效信号</li><li>同步内部写指针，配合读指针生成空信号。将读指针传递到读部分。</li></ul><h3 id="5-2-2-端口"><a href="#5-2-2-端口" class="headerlink" title="5.2.2.端口"></a>5.2.2.端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>读时钟信号</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位信号，低有效</td></tr><tr><td>read_req</td><td>input</td><td>1</td><td>读请求信号</td></tr><tr><td>fifo_empty</td><td>output</td><td>1</td><td>FIFO空信号</td></tr><tr><td>memory_read_addr</td><td>output</td><td>DEPTH_LOG</td><td>SRAM的读地址信号</td></tr><tr><td>read_point_gray</td><td>output</td><td>DEPTH_LOG+1</td><td>读指针格雷码</td></tr><tr><td>write_point_gray</td><td>input</td><td>DEPTH_LOG+1</td><td>写指针格雷码，未同步</td></tr><tr><td>read_valid</td><td>output</td><td>1</td><td>读数据有效信号</td></tr></tbody></table></div><h3 id="5-2-3-实现"><a href="#5-2-3-实现" class="headerlink" title="5.2.3.实现"></a>5.2.3.实现</h3><p>实现的方式与写部分类似，<code>fifo_empty</code>信号和读指针生成如下所示：</p><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/read_control.png" class=""><p>主要部件的功能如下所示：</p><ul><li>read_point：读指针，产生读地址，每当读请求成立时自增1</li><li>read_point_gray：读指针的格雷码，用于产生空逻辑和向写时钟域传递</li><li>next_read_point_gray：下一个读指针的格雷码，用于空信号的及时性</li></ul><img src="/2019/05/06/%E5%BC%82%E6%AD%A5FIFO%E8%AE%BE%E8%AE%A1/read_data.png" class=""><p>读数据部分如上图所示，read_valid信号在<code>read_req &amp;&amp; !fifo_empty</code>为真时拉高，表示当前<code>read_data</code>上的数据有效。<code>read_data</code>为输出数据端口直接连接到SRAM的输出端口（SRAM输出端口自带寄存器）。</p>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> FIFO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Octave卷积学习笔记</title>
      <link href="2019/05/05/Octave%E5%8D%B7%E7%A7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2019/05/05/Octave%E5%8D%B7%E7%A7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Octave卷积"><a href="#Octave卷积" class="headerlink" title="Octave卷积"></a>Octave卷积</h1><p>Octave卷积的主题思想来自于图片的分频思想，首先认为图像可进行分频：</p><ul><li>低频部分：图像低频部分保存图像的大体信息，信息数据量较少</li><li>高频部分：图像高频部分保留图像的细节信息，信息数据量较大</li></ul><p>由此，认为卷积神经网络中的feature map也可以进行分频，可按channel分为高频部分和低频部分，如图所示：</p><img src="/2019/05/05/Octave%E5%8D%B7%E7%A7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/feature_map.png" class=""><p>对于一个feature map，将其按通道分为两个部分，分别为低频通道和高频通道。随后将低频通道的长宽各缩减一半，则将一个feature map分为了高频和低频两个部分，即为Octave卷积处理的基本feature map，使用X表示，该类型X可表示为$X = [X^H,X^L]$，其中$X^H$为高频部分，$X^L$为低频部分。</p><p>为了处理这种结构的feature map，其使用了如下所示的Octave卷积操作：</p><img src="/2019/05/05/Octave%E5%8D%B7%E7%A7%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/octave_conv.png" class=""><p>首先考虑低频部分输入$X^L$，该部分进行两个部分的操作：</p><ul><li>$X^L \to X^H$：从低频到高频，首先使用指定卷积核$W^{L \to H}$进行卷积，随后进行Upample操作生成与高频部分长宽相同的Tensor，最终产生$Y^{L\to H} = Upsample(Conv(X^L,W^{L \to H}),2)$</li><li>$X^L \to X^L$：从低频到低频，这个部分为直接进行卷积操作$Y^{L \to L} = Conv(X^L,W^{L \to L})$</li></ul><p>随后考虑高频部分，与低频部分类似有两个部分的操作：</p><ul><li>$X^H \to X^H$：从高频到高频，直接进行卷积操作$Y^{H \to H} = Conv(X^H,W^{H \to H})$</li><li>$X^H \to X^L$：从高频到低频，首先进行stride和kernel均为2的平均值池化，再进行卷积操作，生成与$Y^L$通道数相同的feature map，最终产生$Y^{H \to L} = conv(avgpool(X^H,2),W^{H \to L}))$</li></ul><p>最终，有$Y^L = Y^{H \to L} + Y^{L \to L}$和$Y^H = Y^{H \to H} +Y^{L \to H}$，因此可以总结如下公式：</p><script type="math/tex; mode=display">Y^L = Y^{H \to L} + Y^{L \to L}  = Y^{H \to L} = conv(avgpool(X^H,2),W^{H \to L})) + Conv(X^L,W^{L \to L}) \\Y^H = Y^{H \to H} +Y^{L \to H} = Conv(X^H,W^{H \to H}) +  Upsample(Conv(X^L,W^{L \to H}),2)</script><p>因此有四个部分的权值：</p><div class="table-container"><table><thead><tr><th>来源/去向</th><th>$\to H$</th><th>$\to L$</th></tr></thead><tbody><tr><td>H</td><td>$W^{H \to H}$</td><td>$W^{H \to L}$</td></tr><tr><td>L</td><td>$W^{L \to H}$</td><td>$W^{L \to L}$</td></tr></tbody></table></div><p>另外进行使用时，在网络的输入和输出需要将两个频率上的Tensor聚合，做法如下：</p><ul><li>输入部分，取$X = [X,0]$，即有$X^H = X$，$X^L = 0$，仅进行$H \to L$和$H \to H$操作，输出输出的低频仅有X生成，即$Y^H = Y^{H \to H}$和$Y^L = Y^{H \to L}$</li><li>输出部分，取$X = [X^H,X^L]$，$\alpha = 0$。即仅进行$L \to H$和$H \to H$的操作，最终输出为$Y = Y^{L \to H} + Y^{H \to H}$</li></ul><h1 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h1><p>以下计算均取原Tensor尺寸为$CI \times W \times H$，卷积尺寸为$CO \times CI \times K \times K$，输出Tensor尺寸为$CO \times W \times H$（stride=1，padding设置使feature map尺寸不变）。</p><h2 id="计算量分析"><a href="#计算量分析" class="headerlink" title="计算量分析"></a>计算量分析</h2><p>Octave卷积的最大优势在于减小计算量，取参数$\alpha$为低频通道占总通道的比例。首先考虑直接卷积的计算量，对于输出feature map中的每个数据，需要进行$CI \times K \times K$次乘加计算，因此总的计算量为：</p><script type="math/tex; mode=display">C_{conv} = (CO \times W \times H) \times (CI \times K \times K)</script><p>现考虑Octave卷积，有四个卷积操作：</p><ul><li>$L \to L$卷积：$C<em>{L \to L} = \alpha^2 \times (CO \times \frac{W}{2} \times \frac{H}{2}) \times (CI \times K \times K) = \frac{\alpha^2}{4} \times C</em>{conv}$</li><li>$L \to H$卷积：$C<em>{L \to H} = ((1 - \alpha) \times CO \times \frac{W}{2} \times \frac{H}{2}) \times ( \alpha \times CI \times K \times K) = \frac{\alpha(1-\alpha)}{4} \times C</em>{conv}$</li><li>$H \to L$卷积：$C<em>{H \to L} = (\alpha  \times CO \times \frac{W}{2} \times \frac{H}{2}) \times ((1 - \alpha) \times CI \times K \times K) = \frac{\alpha(1-\alpha)}{4} \times C</em>{conv}$</li><li>$H \to H$卷积：$C<em>{H \to H} = ((1 - \alpha) \times CO \times W \times H) \times  ((1 - \alpha) \times CI \times K \times K) = (1 - \alpha)^2 \times C</em>{conv}$</li></ul><p>总上，可以得出计算量有：</p><script type="math/tex; mode=display">\frac{C_{octave}}{C_{conv}} = \frac{\alpha^2 + 2\alpha(1-\alpha) + 4 (1 - \alpha)^2}{4} = 1 - \frac{3}{4}\alpha(2- \alpha)</script><p>在$\alpha \in [0,1]$中单调递减，当取$\alpha = 1$时，有$\frac{C<em>{octave}}{C</em>{conv}} = \frac{1}{4}$。</p><h2 id="参数量分析"><a href="#参数量分析" class="headerlink" title="参数量分析"></a>参数量分析</h2><p>原卷积的参数量为：</p><script type="math/tex; mode=display">W_{conv} = CO \times CI \times K \times K</script><p>Octave卷积将该部分分为四个，对于每个卷积有：</p><ul><li>$L \to L$卷积：$W<em>{L \to L} =(\alpha\times  CO) \times (\alpha \times CI) \times K \times K = \alpha^2 \times W</em>{conv}$</li><li>$L \to H$卷积：$W<em>{L \to H} =((1-\alpha) \times  CO) \times (\alpha \times CI) \times K \times K = \alpha(1 - \alpha) \times W</em>{conv}$</li><li>$H \to L$卷积：$W<em>{H \to L} =(\alpha \times  CO) \times ((1-\alpha) \times CI) \times K \times K = \alpha(1 - \alpha) \times W</em>{conv}$</li><li>$H \to H$卷积：$W<em>{H \to L} =((1-\alpha) \times  CO) \times ((1-\alpha) \times CI) \times K \times K = (1 - \alpha)^2 \times W</em>{conv}$</li></ul><p>因此共有参数量：</p><script type="math/tex; mode=display">C_{octave} = (\alpha^2 + 2\alpha(1 - \alpha) +  (1 - \alpha)^2) \times C_{conv} = C_{conv}</script><p>由此，参数量没有发生变化，该方法无法减少参数量。</p><h1 id="Octave卷积实现"><a href="#Octave卷积实现" class="headerlink" title="Octave卷积实现"></a>Octave卷积实现</h1><h2 id="Octave卷积模块"><a href="#Octave卷积模块" class="headerlink" title="Octave卷积模块"></a>Octave卷积模块</h2><p>以下实现了一个兼容普通卷积的Octave卷积模块，针对不同的高频低频feature map的通道数，分为以下几种情况：</p><ul><li><code>Lout_channel != 0 and Lin_channel != 0</code>：通用Octave卷积，需要四个卷积参数</li><li><code>Lout_channel == 0 and Lin_channel != 0</code>：输出Octave卷积，输入有低频部分，输出无低频部分，仅需要两个卷积参数</li><li><code>Lout_channel != 0 and Lin_channel == 0</code>：输入Octave卷积，输入无低频部分，输出有低频部分，仅需要两个卷积参数</li><li><code>Lout_channel == 0 and Lin_channel == 0</code>：退化为普通卷积，输入输出均无低频部分，仅有一个卷积参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OctaveConv</span>(<span class="params">pt.nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,Lin_channel,Hin_channel,Lout_channel,Hout_channel,</span></span></span><br><span class="line"><span class="function"><span class="params">kernel,stride,padding</span>):</span></span><br><span class="line"><span class="built_in">super</span>(OctaveConv, self).__init__()</span><br><span class="line"><span class="keyword">if</span> Lout_channel != <span class="number">0</span> <span class="keyword">and</span> Lin_channel != <span class="number">0</span>:</span><br><span class="line">self.convL2L = pt.nn.Conv2d(Lin_channel,Lout_channel, kernel,stride,padding)</span><br><span class="line">self.convH2L = pt.nn.Conv2d(Hin_channel,Lout_channel, kernel,stride,padding)</span><br><span class="line">self.convL2H = pt.nn.Conv2d(Lin_channel,Hout_channel, kernel,stride,padding)</span><br><span class="line">self.convH2H = pt.nn.Conv2d(Hin_channel,Hout_channel, kernel,stride,padding)</span><br><span class="line"><span class="keyword">elif</span> Lout_channel == <span class="number">0</span> <span class="keyword">and</span> Lin_channel != <span class="number">0</span>:</span><br><span class="line">self.convL2L = <span class="literal">None</span></span><br><span class="line">self.convH2L = <span class="literal">None</span></span><br><span class="line">self.convL2H = pt.nn.Conv2d(Lin_channel,Hout_channel, kernel,stride,padding)</span><br><span class="line">self.convH2H = pt.nn.Conv2d(Hin_channel,Hout_channel, kernel,stride,padding)</span><br><span class="line"><span class="keyword">elif</span> Lout_channel != <span class="number">0</span> <span class="keyword">and</span> Lin_channel == <span class="number">0</span>:</span><br><span class="line">self.convL2L = <span class="literal">None</span></span><br><span class="line">self.convH2L = pt.nn.Conv2d(Hin_channel,Lout_channel, kernel,stride,padding)</span><br><span class="line">self.convL2H = <span class="literal">None</span></span><br><span class="line">self.convH2H = pt.nn.Conv2d(Hin_channel,Hout_channel, kernel,stride,padding)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">self.convL2L = <span class="literal">None</span></span><br><span class="line">self.convH2L = <span class="literal">None</span></span><br><span class="line">self.convL2H = <span class="literal">None</span></span><br><span class="line">self.convH2H = pt.nn.Conv2d(Hin_channel,Hout_channel, kernel,stride,padding)</span><br><span class="line">self.upsample = pt.nn.Upsample(scale_factor=<span class="number">2</span>)</span><br><span class="line">self.pool = pt.nn.AvgPool2d(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,Lx,Hx</span>):</span></span><br><span class="line"><span class="keyword">if</span> self.convL2L <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">L2Ly = self.convL2L(Lx)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">L2Ly = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> self.convL2H <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">L2Hy = self.upsample(self.convL2H(Lx))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">L2Hy = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> self.convH2L <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">H2Ly = self.convH2L(self.pool(Hx))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">H2Ly = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> self.convH2H <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">H2Hy = self.convH2H(Hx)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">H2Hy = <span class="number">0</span></span><br><span class="line"><span class="keyword">return</span> L2Ly+H2Ly,L2Hy+H2Hy</span><br></pre></td></tr></table></figure><p>在前项传播的过程中，根据是否有对应的卷积操作参数判断是否进行卷积，若不进行卷积，将输出置为0。前向传播时，输入为低频和高频两个feature map，输出为低频和高频两个feature map，输入情况和参数配置应与通道数的配置匹配。</p><h2 id="其他部分"><a href="#其他部分" class="headerlink" title="其他部分"></a>其他部分</h2><p>使用MNIST数据集，构建了一个三层卷积+两层全连接层的神经网络，使用Adam优化器训练，代价函数使用交叉熵函数，训练3轮，最后在测试集上进行测试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> pt</span><br><span class="line"><span class="keyword">import</span> torchvision <span class="keyword">as</span> ptv</span><br><span class="line"><span class="comment"># download dataset</span></span><br><span class="line">train_dataset = ptv.datasets.MNIST(<span class="string">&quot;./&quot;</span>,train=<span class="literal">True</span>,download=<span class="literal">True</span>,transform=ptv.transforms.ToTensor())</span><br><span class="line">test_dataset = ptv.datasets.MNIST(<span class="string">&quot;./&quot;</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,transform=ptv.transforms.ToTensor())</span><br><span class="line">train_loader = pt.utils.data.DataLoader(train_dataset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = pt.utils.data.DataLoader(test_dataset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build network</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mnist_model</span>(<span class="params">pt.nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="built_in">super</span>(mnist_model, self).__init__()</span><br><span class="line">self.conv1 = OctaveConv(<span class="number">0</span>,<span class="number">1</span>,<span class="number">8</span>,<span class="number">8</span>,kernel=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">self.conv2 = OctaveConv(<span class="number">8</span>,<span class="number">8</span>,<span class="number">16</span>,<span class="number">16</span>,kernel=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">self.conv3 = OctaveConv(<span class="number">16</span>,<span class="number">16</span>,<span class="number">0</span>,<span class="number">64</span>,kernel=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">self.pool =  pt.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">self.relu = pt.nn.ReLU()</span><br><span class="line">self.fc1 = pt.nn.Linear(<span class="number">64</span>*<span class="number">7</span>*<span class="number">7</span>,<span class="number">256</span>)</span><br><span class="line">self.fc2 = pt.nn.Linear(<span class="number">256</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">out = [self.pool(self.relu(i)) <span class="keyword">for</span> i <span class="keyword">in</span> self.conv1(<span class="number">0</span>,x)]</span><br><span class="line">out = self.conv2(*out)</span><br><span class="line">_,out = self.conv3(*out)</span><br><span class="line">out = self.fc1(self.pool(self.relu(out)).view(-<span class="number">1</span>,<span class="number">64</span>*<span class="number">7</span>*<span class="number">7</span>))</span><br><span class="line"><span class="keyword">return</span> self.fc2(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = mnist_model().cuda()</span><br><span class="line"><span class="comment"># print(net)</span></span><br><span class="line"><span class="comment"># prepare training</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acc</span>(<span class="params">outputs,label</span>):</span></span><br><span class="line">    _,data = pt.<span class="built_in">max</span>(outputs,dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> pt.mean((data.<span class="built_in">float</span>()==label.<span class="built_in">float</span>()).<span class="built_in">float</span>()).item()</span><br><span class="line"></span><br><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br><span class="line">optimizer = pt.optim.Adam(net.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line"><span class="keyword">for</span> i,(data,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader) :</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"><span class="comment"># print(i,data,label)</span></span><br><span class="line">data,label = data.cuda(),label.cuda()</span><br><span class="line">outputs = net(data)</span><br><span class="line">loss = lossfunc(outputs,label)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">optimizer.step()</span><br><span class="line"><span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">print(i,loss.cpu().data.item(),acc(outputs,label))</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line">acc_list = []</span><br><span class="line"><span class="keyword">for</span> i,(data,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">data,label = data.cuda(),label.cuda()</span><br><span class="line">outputs = net(data)</span><br><span class="line">acc_list.append(acc(outputs,label))</span><br><span class="line">print(<span class="string">&quot;Test:&quot;</span>,<span class="built_in">sum</span>(acc_list)/<span class="built_in">len</span>(acc_list))</span><br><span class="line"></span><br><span class="line"><span class="comment"># save</span></span><br><span class="line">pt.save(net,<span class="string">&quot;./model.pth&quot;</span>)</span><br></pre></td></tr></table></figure><p>最终获得模型的准确率为0.988</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>转置型FIR设计</title>
      <link href="2019/04/24/%E8%BD%AC%E7%BD%AE%E5%9E%8BFIR%E8%AE%BE%E8%AE%A1/"/>
      <url>2019/04/24/%E8%BD%AC%E7%BD%AE%E5%9E%8BFIR%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-设计目标"><a href="#1-设计目标" class="headerlink" title="1.设计目标"></a>1.设计目标</h1><p>设计基于单口SRAM的转置型FIR，半并行实现，要求满足：</p><ul><li>并行程度与串行程度参数可配置</li><li>数据位宽可配置，支持负数，负数为补码类型</li></ul><h1 id="2-参数表"><a href="#2-参数表" class="headerlink" title="2.参数表"></a>2.参数表</h1><div class="table-container"><table><thead><tr><th>名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>PALL_PAM</td><td>4</td><td>并行阶数</td></tr><tr><td>PALL_PAM_LOG</td><td>2</td><td>并行阶数LOG值</td></tr><tr><td>SERI_PAM</td><td>4</td><td>串行阶数</td></tr><tr><td>SERI_PAM_LOG</td><td>2</td><td>串行阶数LOG值</td></tr><tr><td>DATA_WIDTH</td><td>16</td><td>数据位宽</td></tr></tbody></table></div><h1 id="3-端口列表"><a href="#3-端口列表" class="headerlink" title="3.端口列表"></a>3.端口列表</h1><h2 id="3-1-系统端口"><a href="#3-1-系统端口" class="headerlink" title="3.1.系统端口"></a>3.1.系统端口</h2><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>系统时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位信号，低有效</td></tr></tbody></table></div><h2 id="3-2-配置端口"><a href="#3-2-配置端口" class="headerlink" title="3.2.配置端口"></a>3.2.配置端口</h2><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>cfg_valid</td><td>input</td><td>1</td><td>配置有效信号</td></tr><tr><td>cfg_addr</td><td>input</td><td>PALL_PAM_LOG*SERI_PAM_LOG</td><td>配置地址</td></tr><tr><td>cfg_data</td><td>input</td><td>DATA_WIDTH</td><td>配置数据</td></tr></tbody></table></div><h2 id="3-3-数据端口"><a href="#3-3-数据端口" class="headerlink" title="3.3.数据端口"></a>3.3.数据端口</h2><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>din_valid</td><td>input</td><td>1</td><td>输入有效信号</td></tr><tr><td>din_busy</td><td>output</td><td>1</td><td>输入忙信号</td></tr><tr><td>din_data</td><td>input</td><td>DATA_WIDTH</td><td>输入数据</td></tr><tr><td>dout_valid</td><td>output</td><td>1</td><td>输出有效信号</td></tr><tr><td>dout_busy</td><td>input</td><td>1</td><td>输出忙信号</td></tr><tr><td>dout_data</td><td>output</td><td>DATA_WIDTH</td><td>输出数据</td></tr></tbody></table></div><h1 id="4-系统结构"><a href="#4-系统结构" class="headerlink" title="4.系统结构"></a>4.系统结构</h1><h2 id="4-1-结构框图"><a href="#4-1-结构框图" class="headerlink" title="4.1.结构框图"></a>4.1.结构框图</h2><img src="/2019/04/24/%E8%BD%AC%E7%BD%AE%E5%9E%8BFIR%E8%AE%BE%E8%AE%A1/structure.png" class=""><p>该FIR共分为四个部分：</p><ul><li>输入部分：输入寄存器和单口RAM，用于控制输入端口信号，实现数据输入</li><li>计算部分：由多个串行单元组成，每个串行单元 串行计算，多个串行单元之间并行计算</li><li>输出部分：输出寄存器，用于控制输出端口信号实现结果输出功能</li><li>控制部分：产生时序控制信号，控制输入部分、计算部分和输出部分的运行</li></ul><h2 id="4-2-系统算法"><a href="#4-2-系统算法" class="headerlink" title="4.2.系统算法"></a>4.2.系统算法</h2><p>以一个六阶的FIR为例，并行度为2，串行度为3（每个串行处理单元串行处理3个乘加操作），整体有以下数据流：</p><script type="math/tex; mode=display">\begin{matrix}cycle &0 &1 &2 &3 &4 &5 &6 &7\\input & x(0) &x(2) &x(4) &x(1) &x(3) &x(5) &x(2) &x(4)\\PE1 & h(5)x(0) & h(3)x(2) & h(1)x(4) & h(5)x(1) & h(3)x(3) & h(1)x(5)& h(5)x(2) & h(3)x(4) \\PE2 & h(4)x(0) & h(2)x(2) & h(0)x(4) & h(4)x(1) & h(2)x(3) & h(0)x(5) &h(4)x(2) & h(2)x(4)\end{matrix}</script><p>可以发现，对于：</p><script type="math/tex; mode=display">y(0) = [h(5)x(0) + h(3)x(2) + h(1)x(4)] + [h(4)x(1) + h(2)x(3) + h(0)x(5)]</script><p>而言，前一部分的部分和在PE0的第0~2cycle中计算，后一部分的部分和在PE1的3~5cycle中计算，同时，PE0在第3~5个周期中计算$y(1)$的部分和。因此对于$m \times n$阶的FIR（并行度为m，串行度为n），每个串行单元负责一个FIR结果的n个乘法的计算。对于第i个串行单元，负责$h(j \times m + i),j= 0,1,…,n$和对应输入数据的乘法。现在考虑第k个输出$y(k)$，相关伪代码如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">k_result = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; m;i++) &#123; <span class="comment">// 不同PE分时并行实现</span></span><br><span class="line">    <span class="keyword">float</span> this_result;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; n;j++) &#123; <span class="comment">// 串行实现</span></span><br><span class="line">    <span class="keyword">if</span>(j == <span class="number">0</span>) &#123;</span><br><span class="line">            this_result = x(k+j*m+i) * h((n-j)*m-i) + k_result;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            this_result = x(k+j*m+i) * h((n-j)*m-i) + this_result;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    k_result = this_result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于第i个PE（PE的标号计算从1开始），在第j个周期（周期标号从0开始），输出的权值为$h[(n-j) \times m - i]$，每个PE的标号i是固定的，因此ROM对应的地址仅与当前串行周期数有关。对于第z个周期的输入（z计数从0开始，输出$x(k)$的周期为第0周期），对应的输入数据应为$x[k+m\times (z\%n) + z //n]$，因此对于数据RAM取数据的地址除了与周期数z有关外，还与k有关。</p><h1 id="5-子模块设计"><a href="#5-子模块设计" class="headerlink" title="5.子模块设计"></a>5.子模块设计</h1><h2 id="5-1-输入模块"><a href="#5-1-输入模块" class="headerlink" title="5.1.输入模块"></a>5.1.输入模块</h2><h3 id="5-1-1-需求"><a href="#5-1-1-需求" class="headerlink" title="5.1.1.需求"></a>5.1.1.需求</h3><p>输入模块包括输入数据寄存器和数据RAM，需要实现以下功能：</p><ul><li>输入寄存器使用P2P接口，当且仅当P2P端口valid信号高且busy信号低时，输入有效</li><li>数据寄存器中的数据在控制模块的控制下将数据输入到RAM中保存</li></ul><h3 id="5-1-2-端口"><a href="#5-1-2-端口" class="headerlink" title="5.1.2.端口"></a>5.1.2.端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>系统时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位信号，低有效</td></tr><tr><td>din_valid</td><td>input</td><td>1</td><td>输入P2P接口有效信号</td></tr><tr><td>din_busy</td><td>input</td><td>1</td><td>输入P2P接口忙信号，控制器生成</td></tr><tr><td>din_data</td><td>input</td><td>DATA_WIDTH</td><td>输入P2P数据信号</td></tr><tr><td>control_ram_addr</td><td>input</td><td>SERL_PRAM_LOG+PALL_PRAM_LOG</td><td>读写数据ram的地址</td></tr><tr><td>control_ram_write</td><td>input</td><td>1</td><td>写ram请求信号</td></tr><tr><td>unit_din</td><td>output</td><td>DATA_WIDTH</td><td>ram输出数据</td></tr></tbody></table></div><h3 id="5-1-3-实现"><a href="#5-1-3-实现" class="headerlink" title="5.1.3.实现"></a>5.1.3.实现</h3><img src="/2019/04/24/%E8%BD%AC%E7%BD%AE%E5%9E%8BFIR%E8%AE%BE%E8%AE%A1/din_structure.png" class=""><p>该部分设计如上图，共两个部分，如下所示：</p><ul><li>输入寄存器：P2P接口的输入寄存器，P2P接口的busy信号由控制器产生，该寄存器接收valid和busy信号，当valid为高且busy为低时，将输入数据data锁存到输入寄存器中</li><li>RAM：数据单口先读后写RAM，接收控制器的控制信号，写数据从输入寄存器获得，数据输出到内部端口</li></ul><p>该部分不包括控制流部分，仅实现输入的数据流，控制流由控制器生成。输出端口的数据来源为RAM或输入寄存器。当执行RAM写入操作时，内部输出数据来源于输入寄存器，否则来源于数据RAM。</p><h2 id="5-2-串行处理单元"><a href="#5-2-串行处理单元" class="headerlink" title="5.2.串行处理单元"></a>5.2.串行处理单元</h2><h3 id="5-2-1-需求"><a href="#5-2-1-需求" class="headerlink" title="5.2.1.需求"></a>5.2.1.需求</h3><p>串行处理单元，实现串并行处理的串行部分，多个串行处理单元并行实现并行部分，单个单元的需求为：</p><ul><li>实现串行的相乘相加，一个操作数来自ROM，一个操作数来自输入模块的输出</li><li>实现可选择的累加，选择控制信号由控制模块生成</li></ul><h3 id="5-2-2-端口"><a href="#5-2-2-端口" class="headerlink" title="5.2.2.端口"></a>5.2.2.端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>系统时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位信号，低有效</td></tr><tr><td>cfg_valid</td><td>input</td><td>1</td><td>配置有效信号，高有效</td></tr><tr><td>cfg_addr</td><td>input</td><td>PALL_PAM_LOG+SERI_PAM_LOG</td><td>配置目标地址</td></tr><tr><td>cfg_data</td><td>input</td><td>DATA_WIDTH</td><td>配置数据</td></tr><tr><td>unit_din</td><td>input</td><td>DATA_WIDTH</td><td>乘法操作数，来自输入模块</td></tr><tr><td>unit_partsum_din</td><td>input</td><td>DATA_WIDTH*2</td><td>部分和累加操作数，来自上一个串行单元</td></tr><tr><td>unit_partsum_dout</td><td>output</td><td>DATA_WIDTH*2</td><td>部分和，输出到下一个串行单元</td></tr><tr><td>control_rom_addr</td><td>input</td><td>SERI_PAM_LOG</td><td>参数ROM地址，产生ROM的乘法操作数</td></tr><tr><td>control_mux_controller</td><td>input</td><td>2</td><td>控制信号，控制累加器功能</td></tr></tbody></table></div><h3 id="5-2-3-实现"><a href="#5-2-3-实现" class="headerlink" title="5.2.3.实现"></a>5.2.3.实现</h3><img src="/2019/04/24/%E8%BD%AC%E7%BD%AE%E5%9E%8BFIR%E8%AE%BE%E8%AE%A1/serial_structure.png" class=""><p>串行处理单元如上图所示，该部分仅包括数据流，控制流由控制器统一产生。分为以下几个部分：</p><ul><li>ROM：存储当前单元的相关数据，可使用<code>cfg_*</code>接口进行参数配置。非配置时根据控制器提供的地址输出乘法操作数</li><li>乘法器：带符号数乘法器，将ROM的数据输出和数据输入<code>unit_din</code>进行相乘</li><li>累加部分：包括累加寄存器、加法器和Mux，可选择不执行操作、乘法结果与部分和输入相加和乘法结果累加三种操作</li></ul><p>对于一次操作，数据输入和ROM地址对应的数据输出到乘法器完成乘法，根据控制信号加法器将乘法结果与部分和输入或累加结果进行相加，累加寄存器的值输出到部分和输出端口。其中的reg用于保证数据对齐。</p><h2 id="5-3-控制器"><a href="#5-3-控制器" class="headerlink" title="5.3.控制器"></a>5.3.控制器</h2><h3 id="5-3-1-需求"><a href="#5-3-1-需求" class="headerlink" title="5.3.1.需求"></a>5.3.1.需求</h3><p>该设计使用中央控制的方式进行控制，所有控制信号均由控制器生成，包括：</p><ul><li>控制输入部分的busy信号和数据RAM的地址</li><li>控制串行处理单元的ROM地址和操作方式</li><li>控制输出部分的valid信号</li></ul><h3 id="5-3-2-端口"><a href="#5-3-2-端口" class="headerlink" title="5.3.2.端口"></a>5.3.2.端口</h3><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>系统时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位，低有效</td></tr><tr><td>din_valid</td><td>input</td><td>1</td><td>输入数据P2P端口有效信号</td></tr><tr><td>din_busy</td><td>output</td><td>1</td><td>输入数据P2P端口忙信号</td></tr><tr><td>control_ram_addr</td><td>output</td><td>SERL_PRAM_LOG+PALL_PRAM_LOG</td><td>读写数据ram的地址</td></tr><tr><td>control_ram_write</td><td>output</td><td>1</td><td>写数据ram请求信号</td></tr><tr><td>control_rom_addr</td><td>output</td><td>SERI_PAM_LOG</td><td>参数ROM地址，产生ROM的乘法操作数</td></tr><tr><td>control_mux_controller</td><td>output</td><td>2</td><td>控制信号，控制累加器功能</td></tr><tr><td>dout_busy</td><td>input</td><td>1</td><td>输出数据P2P端口忙信号</td></tr><tr><td>dout_valid</td><td>output</td><td>1</td><td>输出数据P2P端口有效信号</td></tr></tbody></table></div><h3 id="5-3-3-实现"><a href="#5-3-3-实现" class="headerlink" title="5.3.3.实现"></a>5.3.3.实现</h3><p>该部分的核心是一个状态机，该状态机控制所有部件的运行，状态机的流程图如下所示：</p><img src="/2019/04/24/%E8%BD%AC%E7%BD%AE%E5%9E%8BFIR%E8%AE%BE%E8%AE%A1/controller_fsm.png" class=""><p>该状态机有四个状态：</p><ul><li>INIT：初始待机状态，等待输入数据</li><li>READ：读取数据状态，当输入P2P传输发生时从INIT进入，下一时钟周期进入COMP状态</li><li>COMP：计算状态，从READ状态进入，SERI_PAM个时钟周期后进入WRITE状态</li><li>WRITE：输出状态，从COMP状态进入，3个时钟周期（等待计算全部完成）后控制P2P输出端口输出数据</li></ul><h4 id="5-3-3-1-输入端口控制实现"><a href="#5-3-3-1-输入端口控制实现" class="headerlink" title="5.3.3.1.输入端口控制实现"></a>5.3.3.1.输入端口控制实现</h4><p>输入P2P端口需要控制的信号是<code>din_busy</code>信号，该信号仅在状态机状态为INIT时为低，否则为高。</p><p>输入部分RAM地址的控制信号为$k+i\times PALL_PAM,i&lt;SERI_PAM$，其中：</p><ul><li>k为基地址寄存器，每次WRITE状态结束时加1，范围为0~(PALL_PAM+SERI_PAM + 1)</li><li>i为偏移量，在COMP状态中每时钟周期加1，范围为0~SERI_PAM</li></ul><p>输入部分RAM写请求信号在COMP的最后一个周期拉高，将数据写入RAM，同时将输入寄存器的值作为数据输出</p><h4 id="5-3-3-2-串行处理单元控制实现"><a href="#5-3-3-2-串行处理单元控制实现" class="headerlink" title="5.3.3.2.串行处理单元控制实现"></a>5.3.3.2.串行处理单元控制实现</h4><p>串行处理单元的ROM地址信号在COMP状态从SERI_PAM-1到0递减，每时钟周期减1</p><p>串行处理单元的MUX控制信号如下所示：</p><ul><li>在非COMP状态下为0，即加法器不工作</li><li>在COMP的第一个时钟周期为1，为加法器实现乘法结果与部分和输入相加</li><li>在COMP的其他时钟周期为3，为加法器实现乘法结果的累加操作</li></ul><h4 id="5-3-3-3-输出端口控制实现"><a href="#5-3-3-3-输出端口控制实现" class="headerlink" title="5.3.3.3.输出端口控制实现"></a>5.3.3.3.输出端口控制实现</h4><p>输出部分控制信号为<code>dout_valid</code>，在进入WRITE状态3个时钟周期后将该信号拉高，退出WRITE状态时拉低</p>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SystemC入门笔记</title>
      <link href="2019/01/22/SystemC%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"/>
      <url>2019/01/22/SystemC%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="变量说明"><a href="#变量说明" class="headerlink" title="变量说明"></a>变量说明</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>SystemC为<strong>C++</strong>的一个库，因此C++的特性在SystemC中均可以使用，数据类型同理，除了C++中的数据类型外，SystemC也有一些自己的数据类型，如下所示：</p><ul><li>二值变量：<code>sc_bit</code>和<code>sc_bv&lt;n&gt;</code>（n为宽度）分别为二值（0、1）变量和任意位宽二值向量。</li><li>四值变量：<code>sc_logic</code>和<code>sc_lv&lt;n&gt;</code>（n为宽度）分别为四值（0、1、x、z）变量和任意位宽四值向量</li><li>int型变量：<code>sc_int&lt;n&gt;</code>和<code>sc_uint&lt;n&gt;</code>（n为宽度）分别为有符号和无符号的不超过64位宽的整型变量</li><li>bigint变量：<code>sc_bigint&lt;n&gt;</code>和<code>sc_bituing</code>（n为宽度）分别为有符号和无符号任意位宽的整型变量</li></ul><h2 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h2><p>信号使用<code>sc_signal&lt;type&gt;</code>声明，一般用于连接端口和进程通信（功能进程之间连接信号）</p><h2 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h2><p>SystemC中端口类型主要有<code>sc_in&lt;type&gt;</code>、<code>sc_out&lt;type&gt;</code>和<code>sc_inout&lt;type&gt;</code>，type中为端口的类型，可以使用C++自带的一些类型，也可以使用SystemC中的数据类型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc_out&lt;sc_int&lt;WIDTH * <span class="number">2</span>&gt; &gt; vec_o;</span><br></pre></td></tr></table></figure><p>例如上面为一个输出端口例子，该输出端口名称为vec_o，类型为SystemC的数据类型<code>sc_int&lt;W&gt;</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc_in&lt;sc_int&lt;WIDTH&gt; &gt; vec1[VEC_WIDTH];</span><br></pre></td></tr></table></figure><p>可以声明端口数组，如上所示，声明了一个宽度为<code>VEC_WIDTH</code>的端口数组，每个端口的类型是<code>sc_int&lt;W&gt;</code>。</p><h1 id="模块设计——矩阵-向量乘法器"><a href="#模块设计——矩阵-向量乘法器" class="headerlink" title="模块设计——矩阵-向量乘法器"></a>模块设计——矩阵-向量乘法器</h1><p>设计一个矩阵-向量乘法器用于熟悉语法，需要注意的是若要使用SystemC特性，需要使用<code>#include &quot;systemc.h&quot;</code></p><h2 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h2><img src="/2019/01/22/SystemC%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/structure.png" class=""><p>该系统用于实现矩阵-向量乘法的行为级建模，包括以下几个部分：</p><ul><li>乘法器：实现矩阵-向量乘法功能，由多个向量-向量乘法器构成</li><li>测试平台：激励生成器，用于产生指定尺寸的矩阵和向量以及时钟复位等控制信号</li></ul><h2 id="子模块设计"><a href="#子模块设计" class="headerlink" title="子模块设计"></a>子模块设计</h2><p>每个子模块在SystemC使用一个类描述，这个类使用宏<code>SC_MODULE(&lt;module name&gt;)</code>声明，这里的子模块是向量-向量乘法器，这一部分代码如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">SC_MODULE(vector_mul) &#123;</span><br><span class="line"></span><br><span class="line">sc_in&lt;<span class="keyword">bool</span>&gt; clk,rst_n;</span><br><span class="line">sc_in&lt;sc_int&lt;WIDTH&gt; &gt; vec1[VEC_WIDTH],vec2[VEC_WIDTH];</span><br><span class="line">sc_out&lt;sc_int&lt;WIDTH * <span class="number">2</span>&gt; &gt; vec_o;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">compute_vector_mul</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (rst_n.read() == <span class="literal">false</span>) &#123;</span><br><span class="line">vec_o.write(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">temp = temp + vec1[i].read() * vec2[i].read();</span><br><span class="line">&#125;</span><br><span class="line">vec_o.write(temp);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">SC_CTOR(vector_mul) &#123;</span><br><span class="line">SC_METHOD(compute_vector_mul);</span><br><span class="line">sensitive_pos &lt;&lt; clk;</span><br><span class="line">sensitive_neg &lt;&lt; rst_n;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>一个子模块包括三个部分：端口定义、功能描述与构造函数。端口定义使用上述的端口定义，如下所示，该乘法器定义了两个类型为<code>bool</code>的控制端口：<code>clk</code>和<code>rst_n</code>。分别是时钟和复位端口；还定义了两个输入端口数组，分别是<code>vec1</code>和<code>vec2</code>，数组宽度为<code>VEC_WIDTH</code>（宏定义），类型为有符号整数类型<code>sc_int&lt;WIDTH&gt;</code>；此外还定义了一个输出端口<code>vec_o</code>，类型为指定位宽的整数类型<code>sc_int&lt;WIDTH * 2&gt;</code>。定义端口后，该部分框图如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sc_in&lt;<span class="keyword">bool</span>&gt; clk,rst_n;</span><br><span class="line">sc_in&lt;sc_int&lt;WIDTH&gt; &gt; vec1[VEC_WIDTH],vec2[VEC_WIDTH];</span><br><span class="line">sc_out&lt;sc_int&lt;WIDTH * <span class="number">2</span>&gt; &gt; vec_o;</span><br></pre></td></tr></table></figure><img src="/2019/01/22/SystemC%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/port.png" class=""><p>功能描述使用一个无输入参数无输出参数的方法描述，建议使用<code>.read()</code>读取输入端口的数据并使用<code>.write()</code>向输出端口写入数据。一个模块可以有多个功能描述，这里的功能描述功能类似于Verilog中的<code>always</code>块。SystemC中的赋值基本都是阻塞的，可以在这一函数中使用任意的C++特性和库等。定义了这一方法后，该部分框图如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">compute_vector_mul</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">int</span> temp = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (rst_n.read() == <span class="literal">false</span>) &#123;</span><br><span class="line">vec_o.write(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">temp = temp + vec1[i].read() * vec2[i].read();</span><br><span class="line">&#125;</span><br><span class="line">vec_o.write(temp);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><img src="/2019/01/22/SystemC%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/func.png" class=""><p>最后一个部分是构造函数，这一部分是为了注册功能，描述连接关系和敏感列表等。无参数化的构造函数使用<code>SC_CTOR(&lt;module name&gt;)</code>定义，这里的<code>module name</code>必须与这个类的名称一致。一个类可能有很多方法，只有如下所示的方式定义为<code>METHOD</code>（或<code>THREAD</code>等）的方法才作为模块的一个功能，定义后需要立刻定义敏感列表，只有敏感列表中的变量发生改变时，功能才运行：<code>sensitive &lt;&lt;</code>表示事件（电平）敏感，一般用于组合逻辑建模；<code>sensitive_pos &lt;&lt;</code>和<code>sensitive_neg &lt;&lt;</code>分别为正跳变敏感和负跳变敏感，一般用于时序逻辑建模。完成以上所有部分的定义后，完成对一个子模块的构建。</p><p><code>METHOD</code>是一种阻塞式的功能进程，当这个进程被敏感列表触发之后，获取仿真控制权开始运行，直到运行完成，将控制权返回SystemC仿真内核。使用<code>METHOD</code>注册的功能函数不能含有无限循环，这会导致仿真卡死在这个任务中，控制权无法返回仿真内核。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SC_CTOR(vector_mul) &#123;</span><br><span class="line">SC_METHOD(compute_vector_mul);<span class="comment">// 注册为METHOD</span></span><br><span class="line">sensitive_pos &lt;&lt; clk;<span class="comment">// clk为正跳变敏感信号</span></span><br><span class="line">sensitive_neg &lt;&lt; rst_n;<span class="comment">// rst_n为负跳变敏感信号</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><img src="/2019/01/22/SystemC%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/final.png" class=""><h2 id="顶层模块"><a href="#顶层模块" class="headerlink" title="顶层模块"></a>顶层模块</h2><p>顶层模块用于实现子模块的连接，代码实现如下所示。除了声明端口以外，还需要在构造函数中定义连接关系。连接关系的定义分为三个部分：模块指针声明、模块实例化和端口连接。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">SC_MODULE(matrix_vector_mul) &#123;</span><br><span class="line"></span><br><span class="line">sc_in&lt;<span class="keyword">bool</span>&gt; clk,rst_n;</span><br><span class="line">sc_in&lt;sc_int&lt;WIDTH&gt; &gt; matrix[VEC_NUM][VEC_WIDTH];</span><br><span class="line">sc_in&lt;sc_int&lt;WIDTH&gt; &gt; vector_in[VEC_WIDTH];</span><br><span class="line">sc_out&lt;sc_int&lt;WIDTH * <span class="number">2</span>&gt; &gt; vector_out[VEC_NUM];</span><br><span class="line"></span><br><span class="line">vector_mul *pe[VEC_NUM];</span><br><span class="line"></span><br><span class="line">SC_CTOR(matrix_vector_mul) &#123;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">ostringstream</span> pe_name;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">pe_name &lt;&lt; <span class="string">&quot;pe&quot;</span> &lt;&lt; i;</span><br><span class="line">pe[i] = <span class="keyword">new</span> vector_mul(pe_name.str().c_str());</span><br><span class="line">pe[i]-&gt;clk(clk);</span><br><span class="line">pe[i]-&gt;rst_n(rst_n);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_WIDTH; ++j) &#123;</span><br><span class="line">pe[i]-&gt;vec1[j](matrix[i][j]);</span><br><span class="line">pe[i]-&gt;vec2[j](vector_in[j]);</span><br><span class="line">&#125;</span><br><span class="line">pe[i]-&gt;vec_o(vector_out[i]);</span><br><span class="line">pe_name.str(<span class="string">&quot;&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>模块指针声明如下所示，这里声明了VEC_NUM个子模块指针作为顶层模块的成员变量。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector_mul *pe[VEC_NUM];</span><br></pre></td></tr></table></figure><p>模块实例化如下所示，若使用<code>SC_CTOR</code>宏定义构造函数的子模块，需要使用一个唯一的字符串作为实例名。由于C++没有格式化字符串的功能，因此使用<code>std::ostringstream</code>生成唯一不重复的实例名，再用<code>c_str()</code>转为构造函数指定的类型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pe[i] = <span class="keyword">new</span> vector_mul(pe_name.str().c_str());</span><br></pre></td></tr></table></figure><p>信号连接额部分使用如下所示的方式完成：<code>&lt;point&gt;-&gt;&lt;port name&gt;(&lt;signal name&gt;)</code>。需要注意的是若声明的是端口数组，则需要将每个数组中的每个端口拆分出来依次连接。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pe[i]-&gt;clk(clk);<span class="comment">// clk端口与clk信号连接</span></span><br><span class="line">pe[i]-&gt;rst_n(rst_n);<span class="comment">// rst_n端口与rst_n信号连接</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_WIDTH; ++j) &#123;</span><br><span class="line">pe[i]-&gt;vec1[j](matrix[i][j]);<span class="comment">// vec1[j]端口与matrix[i][j]信号连接</span></span><br><span class="line">pe[i]-&gt;vec2[j](vector_in[j]);<span class="comment">// vec2[j]端口与vector_in[j]信号连接</span></span><br><span class="line">&#125;</span><br><span class="line">pe[i]-&gt;vec_o(vector_out[i]);<span class="comment">// vec_o端口与vector_out[i]信号连接</span></span><br></pre></td></tr></table></figure><h1 id="测试平台设计"><a href="#测试平台设计" class="headerlink" title="测试平台设计"></a>测试平台设计</h1><h2 id="平台组件"><a href="#平台组件" class="headerlink" title="平台组件"></a>平台组件</h2><p>这里实现的组件仅有激励生成器，该模块与上述模块没有太大的差别，该模块用于生成复位信号和数据信号。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">SC_MODULE(driver)</span><br><span class="line">&#123;</span><br><span class="line">    sc_in &lt;<span class="keyword">bool</span>&gt; clk;</span><br><span class="line">    sc_out&lt;<span class="keyword">bool</span>&gt; rst_n;</span><br><span class="line">    sc_out&lt;sc_int&lt;WIDTH&gt; &gt; mat[VEC_NUM][VEC_WIDTH];</span><br><span class="line">    sc_out&lt;sc_int&lt;WIDTH&gt; &gt; vec[VEC_WIDTH];</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">generate_input</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_NUM; ++j) &#123;</span><br><span class="line">        mat[j][i].write(rand() % ((<span class="keyword">int</span>)<span class="built_in">pow</span>(<span class="number">2</span>,WIDTH) - <span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">            vec[i].write(rand() % ((<span class="keyword">int</span>)<span class="built_in">pow</span>(<span class="number">2</span>,WIDTH) - <span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">            wait();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_NUM; ++j) &#123;</span><br><span class="line">        mat[j][i].write(rand() % ((<span class="keyword">int</span>)<span class="built_in">pow</span>(<span class="number">2</span>,WIDTH) - <span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">            vec[i].write(rand() % ((<span class="keyword">int</span>)<span class="built_in">pow</span>(<span class="number">2</span>,WIDTH) - <span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">generate_reset</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">        rst_n.write(<span class="number">1</span>);</span><br><span class="line">        wait(<span class="number">1</span>,SC_NS);</span><br><span class="line">        rst_n.write(<span class="number">0</span>);</span><br><span class="line">        wait(<span class="number">1</span>,SC_NS);</span><br><span class="line">        rst_n.write(<span class="number">1</span>);</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    SC_CTOR(driver) &#123;</span><br><span class="line">        SC_THREAD(generate_input);</span><br><span class="line">        sensitive_neg &lt;&lt; clk;</span><br><span class="line">        SC_THREAD(generate_reset);</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>需要注意的是这里的功能描述和构造函数，如下所示。构造函数中功能成员<code>generate_input</code>和<code>generate_reset</code>均使用<code>THREAD</code>宏注册为功能，这一宏与<code>METHOD</code>的区别是这一种功能进程在仿真开始时运行，碰到<code>wait()</code>跳出，直到敏感列表中的信号再次触发这一进程，从上次跳出的<code>wait()</code>处继续运行，因此这种进程可以使用循环体包括<code>wait()</code>的无限循环。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SC_CTOR(driver) &#123;</span><br><span class="line">    SC_THREAD(generate_input);</span><br><span class="line">    sensitive_neg &lt;&lt; clk;</span><br><span class="line">    SC_THREAD(generate_reset);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>除了使用<code>wait()</code>阻塞运行外，还可以使用<code>wait(&lt;times&gt;,SC_NS);</code>将执行延迟指定的时钟周期，如<code>rst_n</code>信号的实现，使用多个<code>wait(&lt;times&gt;,SC_NS)</code>延迟执行。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">generate_reset</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    rst_n.write(<span class="number">1</span>);</span><br><span class="line">    wait(<span class="number">1</span>,SC_NS);<span class="comment">// 延迟1ns</span></span><br><span class="line">    rst_n.write(<span class="number">0</span>);</span><br><span class="line">    wait(<span class="number">1</span>,SC_NS);<span class="comment">// 延迟1ns</span></span><br><span class="line">    rst_n.write(<span class="number">1</span>);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="平台运行"><a href="#平台运行" class="headerlink" title="平台运行"></a>平台运行</h2><p>最终的平台运行集成在<code>main</code>函数中，如下所示，分为以下几个步骤：信号声明，模块声明和端口连接，波形追踪和仿真运行。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;systemc.h&quot;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sc_main</span><span class="params">(<span class="keyword">int</span> argc,<span class="keyword">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">sc_clock <span class="title">clk</span><span class="params">(<span class="string">&quot;clk&quot;</span>,<span class="number">10</span>,SC_NS)</span></span>;</span><br><span class="line">    sc_signal&lt;<span class="keyword">bool</span>&gt; rst_n;</span><br><span class="line">    sc_signal&lt;sc_int&lt;WIDTH&gt; &gt; mat[VEC_NUM][VEC_WIDTH],vec[VEC_WIDTH];</span><br><span class="line">    sc_signal&lt;sc_int&lt;WIDTH * <span class="number">2</span>&gt; &gt;vec_o[VEC_NUM];</span><br><span class="line"></span><br><span class="line">    sc_trace_file *fp;<span class="comment">// Create VCD file</span></span><br><span class="line">    fp=sc_create_vcd_trace_file(<span class="string">&quot;wave&quot;</span>);<span class="comment">// open(fp), create wave.vcd file</span></span><br><span class="line">    fp-&gt;set_time_unit(<span class="number">1</span>, SC_NS);<span class="comment">// set tracing resolution to ns</span></span><br><span class="line"></span><br><span class="line">    <span class="function">matrix_vector_mul <span class="title">dut</span><span class="params">(<span class="string">&quot;dut&quot;</span>)</span></span>;</span><br><span class="line">    dut.clk(clk);</span><br><span class="line">    dut.rst_n(rst_n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_WIDTH; ++j) &#123;</span><br><span class="line">    dut.matrix[i][j](mat[i][j]);</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">        dut.vector_in[i](vec[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">    dut.vector_out[i](vec_o[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">driver <span class="title">d</span><span class="params">(<span class="string">&quot;dri&quot;</span>)</span></span>;</span><br><span class="line">    d.clk(clk);</span><br><span class="line">    d.rst_n(rst_n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_NUM; ++j) &#123;</span><br><span class="line">        d.mat[j][i](mat[j][i]);</span><br><span class="line">        &#125;</span><br><span class="line">        d.vec[i](vec[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sc_trace(fp,clk,<span class="string">&quot;clk&quot;</span>);</span><br><span class="line">    sc_trace(fp,rst_n,<span class="string">&quot;rst_n&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_WIDTH; ++j) &#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">ostringstream</span> mat_name;</span><br><span class="line">    mat_name &lt;&lt; <span class="string">&quot;matrix(&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    sc_trace(fp,mat[i][j],mat_name.str());</span><br><span class="line">    mat_name.str(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">   <span class="built_in">std</span>::<span class="built_in">ostringstream</span> stream1;</span><br><span class="line">   stream1 &lt;&lt; <span class="string">&quot;vec(&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot;)&quot;</span>;</span><br><span class="line">   sc_trace(fp,vec[i],stream1.str());</span><br><span class="line">   stream1.str(<span class="string">&quot;&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">   <span class="built_in">std</span>::<span class="built_in">ostringstream</span> out_name;</span><br><span class="line">   out_name &lt;&lt; <span class="string">&quot;dout(&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot;)&quot;</span>;</span><br><span class="line">   sc_trace(fp,vec_o[i],out_name.str());</span><br><span class="line">   out_name.str(<span class="string">&quot;&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">    sc_start(<span class="number">1000</span>,SC_NS);</span><br><span class="line"></span><br><span class="line">    sc_close_vcd_trace_file(fp);<span class="comment">// close(fp)</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>第一个步骤是声明信号和模块，这一步用于声明连接需要的信号，这里的时钟信号使用SystemC的方法生成。用于连接的信号需要声明成<code>sc_signal&lt;&gt;</code>类型。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">sc_clock <span class="title">clk</span><span class="params">(<span class="string">&quot;clk&quot;</span>,<span class="number">10</span>,SC_NS)</span></span>;<span class="comment">// 时钟，周期为10ns</span></span><br><span class="line">sc_signal&lt;<span class="keyword">bool</span>&gt; rst_n;</span><br><span class="line">sc_signal&lt;sc_int&lt;WIDTH&gt; &gt; mat[VEC_NUM][VEC_WIDTH],vec[VEC_WIDTH];</span><br><span class="line">sc_signal&lt;sc_int&lt;WIDTH * <span class="number">2</span>&gt; &gt;vec_o[VEC_NUM];</span><br></pre></td></tr></table></figure><p>第二步是声明模块并连接信号，这里的连接和声明与顶层模块中类似，只是这里直接声明对象而不是指针。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">matrix_vector_mul <span class="title">dut</span><span class="params">(<span class="string">&quot;dut&quot;</span>)</span></span>;</span><br><span class="line">dut.clk(clk);</span><br><span class="line">dut.rst_n(rst_n);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_WIDTH; ++j) &#123;</span><br><span class="line">    dut.matrix[i][j](mat[i][j]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">    dut.vector_in[i](vec[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">    dut.vector_out[i](vec_o[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第三步是实现波形跟踪与保存，首先定义一个<code>sc_trace_file</code>类型的指针，使用对应方法打开指定的文件类型和波形名称（<code>fp=sc_create_vcd_trace_file(&quot;wave&quot;);</code>保存vcd格式的波形）并进行配置。随后使用<code>sc_trace(fp,signal,&lt;signal name&gt;);</code>将需要观察的信号添加到波形跟踪中，其中<code>&lt;signal name&gt;</code>为波形文件中这一信号的名称，因此需要保证对于每一个信号该名称唯一。当仿真完成后，需要使用<code>sc_close_vcd_trace_file(fp);</code>关闭仿真文件。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">sc_trace_file *fp;<span class="comment">// Create VCD file</span></span><br><span class="line">fp=sc_create_vcd_trace_file(<span class="string">&quot;wave&quot;</span>);<span class="comment">// open(fp), create wave.vcd file</span></span><br><span class="line">fp-&gt;set_time_unit(<span class="number">1</span>, SC_NS);<span class="comment">// set tracing resolution to ns</span></span><br><span class="line">......</span><br><span class="line">sc_trace(fp,clk,<span class="string">&quot;clk&quot;</span>);</span><br><span class="line">sc_trace(fp,rst_n,<span class="string">&quot;rst_n&quot;</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; VEC_WIDTH; ++j) &#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">ostringstream</span> mat_name;</span><br><span class="line">    mat_name &lt;&lt; <span class="string">&quot;matrix(&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    sc_trace(fp,mat[i][j],mat_name.str());</span><br><span class="line">    mat_name.str(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_WIDTH; ++i) &#123;</span><br><span class="line">   <span class="built_in">std</span>::<span class="built_in">ostringstream</span> stream1;</span><br><span class="line">   stream1 &lt;&lt; <span class="string">&quot;vec(&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot;)&quot;</span>;</span><br><span class="line">   sc_trace(fp,vec[i],stream1.str());</span><br><span class="line">   stream1.str(<span class="string">&quot;&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; VEC_NUM; ++i) &#123;</span><br><span class="line">   <span class="built_in">std</span>::<span class="built_in">ostringstream</span> out_name;</span><br><span class="line">   out_name &lt;&lt; <span class="string">&quot;dout(&quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot;)&quot;</span>;</span><br><span class="line">   sc_trace(fp,vec_o[i],out_name.str());</span><br><span class="line">   out_name.str(<span class="string">&quot;&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">......</span><br><span class="line">sc_close_vcd_trace_file(fp);<span class="comment">// close(fp)</span></span><br></pre></td></tr></table></figure><p>第四个部分是启动仿真，使用<code>sc_start()</code>运行指定的时间长度。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc_start(<span class="number">1000</span>,SC_NS); <span class="comment">// 运行1000ns</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SystemC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DianNao运算单元与体系结构分析</title>
      <link href="2018/12/24/DianNao%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"/>
      <url>2018/12/24/DianNao%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="运算单元"><a href="#运算单元" class="headerlink" title="运算单元"></a>运算单元</h1><h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><div class="table-container"><table><thead><tr><th>名称</th><th>参数</th></tr></thead><tbody><tr><td>数据输入位宽</td><td>$T_n \times DW$bit</td></tr><tr><td>权值输入位宽</td><td>$T_n \times T_n \times DW$bit</td></tr><tr><td>数据输出位宽</td><td>$T_n \times DW$bit</td></tr><tr><td>功能</td><td>矩阵乘法、最大值池化、平均值池化</td></tr><tr><td>乘法器数量</td><td>$T_n \times T_n \times T_n$</td></tr><tr><td>加法器数量</td><td>$T_n \times (T_n - 1)$</td></tr></tbody></table></div><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><img src="/2018/12/24/DianNao%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/strutrue.png" class=""><p>NFU的整体结构如上所示，该部分分为三个部分，分别是NFU-1、NFU-2和NFU-3三个部分，分别是乘法器阵列，加法或最大值树和非线性函数部分。NFU-1由一些乘法器阵列构成，如下图所示。一个单元具有一个输入数据$I<em>i$和$T_n$个输入权值，一个单元中共有$T_n$个乘法器，分别计算$I_i \times W</em>{ji}$的值，具有$T_n$个输出。</p><img src="/2018/12/24/DianNao%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/nfu1_unit.png" class=""><p>$T<em>n$个输入数据和$T_n \times T_n$输入权值经过NFU-1处理后，变为$T_n \times T_n$个部分积，第i个乘法器单元的第j个输出为$P</em>{ij} = I<em>i  \times W</em>{ji}$。所有部分积经过route分配给$T_n$NFU-2单元，分配规则如下所示，第i个NFU-2单元的输入是所有NFU-1单元的第i个输出。</p><script type="math/tex; mode=display">Input_i = \{P_{1,i},P_{2,i},P_{3,i},...,P_{T_n,i}\}</script><p>NFU-2单元为加法/平均值（加法树前添加位移单元）/最大值（加法树的加法器可配置为取最大值）树，用于计算$T_n$个输入的和/平均值或最大值，如下所示：</p><script type="math/tex; mode=display">Output_i = mux\{\sum\limits_{k=1}^{T_n}P_{k,i},\frac{1}{T_n}\sum\limits_{k=1}^{T_n}P_{k,i},\max\limits_{0 \leq k \leq T_n}\{P_{k,i}\}\}</script><p>NFU-2单元的输出为一个数据，整个NFU-2部分输出为$T_n$个部分操作数据。该输出可以流向NFU-3部分作为NFU-2的输出，也可以流向D-Reg作为部分和临时保存以节约带宽。NFU-3为一个加法器和一个非线性单元。非线性单元使用分段线性逼近非线性函数，分段线性逼近参数保存在RAM中，可通过更改该参数使该单元实现任意非线性函数。</p><h2 id="运算映射"><a href="#运算映射" class="headerlink" title="运算映射"></a>运算映射</h2><h3 id="矩阵乘法-卷积"><a href="#矩阵乘法-卷积" class="headerlink" title="矩阵乘法/卷积"></a>矩阵乘法/卷积</h3><p>映射以下矩阵乘法：</p><script type="math/tex; mode=display">W \times x = y,W \in R^{T_n \times T_n},x \in R^{T_n}\\y_{i} = \sum\limits_{j=0}^{T_n}{w_{ij}x_j}</script><p>有以下配置：</p><ul><li>数据输入：第i个NFU-1单元数据输入为$x_i$</li><li>权值输入：第i个NFU-1单元的第j个权值输入为$w_{ji}$，即第i个NFU-1单元输入的数据为W矩阵的第i列</li><li>NFU-2：配置和实现加法树功能</li></ul><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>映射以下最大值操作：</p><script type="math/tex; mode=display">y = Max(x),x \in R^{T_n}</script><p>有以下配置：</p><ul><li>数据输入：第i个NFU-1单元数据输入为$x_i$</li><li>权值输入：所有权值配置为1</li><li>NFU-2：配置实现最大值树功能（若为求平均值，配置为平均值树）</li></ul><p>对于x的维度小于$T_n$时，推测可以将权值部分设置为1部分设置为0作为掩码，同时计算多个最大值/平均值操作</p><h1 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h1><img src="/2018/12/24/DianNao%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/DianNao.png" class=""><p>系统结构如上所述，各部分：</p><ul><li>NFU：神经计算单元，已经加入compute_unit的pool中</li><li>分裂缓存：按功能分裂为三个的缓存，已经加入memory的pool中</li><li>控制模块CP：指令使控制，每个指令分为四个部分，分别是NBin指令，NBout指令，SB指令和NFU指令</li></ul><p>系统使用指令控制，每条指令可以实现一次矩阵-向量乘法运算，每个指令的四个部分被解耦后发送给四个部分，因此存储器的load指令不需要等待NFU运算完成，对于三个缓存，执行完当前步骤后立刻执行下一个指令中对应部分的指令，可以实现数据的预取，但是考虑计算正确性，NFU必须等待运算所需要的数据预存完成后才能执行。</p><h1 id="计算映射"><a href="#计算映射" class="headerlink" title="计算映射"></a>计算映射</h1><p>对于一个矩阵乘法：</p><script type="math/tex; mode=display">W \times x = y</script><p>首先进行矩阵分块，参数矩阵W分块为$C^{T_n \times T_n}$的矩阵，输入向量x分块为$C^{T_n}$，再进行计算，如下图所示：</p><img src="/2018/12/24/DianNao%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/mul.png" class=""><p>分块后，原论文给出的加速器参数为$T_n=16$，计算需要的权值矩阵有$W \in Q^{256 \times 8192}$，数据向量有$x \in Q^{8192}$，缓存载入的规则为：</p><ul><li>Nbin：数据向量分块为$\frac{8192 \times 2B}{2KB} = 8$块，每一块数据大小为2KB=$16 \times 2B \times 64$，每次载入一块。即每次载入的输入数据包括64个逻辑块。</li><li>SB：每次载入32768B=$16 \times 16 \times 2B \times 64$，即每次载入的数据包括64个逻辑块。</li></ul><p>映射一个矩阵乘法，步骤为：</p><ol><li>Nbin载入前四个逻辑块D1,D2,~,D64。SB载入与前四个输入逻辑块运算相关的64个数据块W11、W12、W13~W64,1（分块后W的前4列，前16行的块）。NFU计算对应乘法（例如$W<em>{11} \times D_1$，$W</em>{12} \times D<em>2$，…,$W</em>{1,64} \times D_{64}$），并将部分和存储在Nbout中</li><li>Nbin载入第二块输入数据，包括D65~D128，SB继续载入与D1~D64运算相关的权值块W2,1~W2,64。NFU继续计算D1~D64对应乘法。直到将D1~D64相关的乘法计算完成以后，才进行D65~D128相关的乘法。</li><li>…</li><li>当某个输出的计算完成后，Nbout将其输出到外部缓存中</li></ol><p>复用策略为仅复用输入，仅当这一块输入数据需要参与的所有运算完成后才开始进行下一块输入相关的计算。对于每一块输入映射过程如下图所示：</p><img src="/2018/12/24/DianNao%E8%BF%90%E7%AE%97%E5%8D%95%E5%85%83%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/map.png" class="">]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AXI学习笔记-1</title>
      <link href="2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/"/>
      <url>2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AXI总线结构"><a href="#1-AXI总线结构" class="headerlink" title="1.AXI总线结构"></a>1.AXI总线结构</h1><p>AXI总线由5个通道构成：</p><div class="table-container"><table><thead><tr><th>通道名称</th><th>通道功能</th><th>数据流向</th></tr></thead><tbody><tr><td>read address</td><td>读地址通道</td><td>主机-&gt;从机</td></tr><tr><td>read data</td><td>读数据通道（包括数据通道和读响应通道）</td><td>从机-&gt;主机</td></tr><tr><td>write address</td><td>写地址通道</td><td>主机-&gt;从机</td></tr><tr><td>write data</td><td>写数据通道（包括数据通道和每8bit一个byte的写数据有效信号）</td><td>主机-&gt;从机</td></tr><tr><td>write response</td><td>写响应通道</td><td>从机-&gt;主机</td></tr></tbody></table></div><h2 id="1-1-AXI通道"><a href="#1-1-AXI通道" class="headerlink" title="1.1.AXI通道"></a>1.1.AXI通道</h2><p>读操作的通道如下图所示</p><p>写操作的通道如下图所示</p><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/axi_write_channel.JPG" class=""><h2 id="1-2-AXI系统"><a href="#1-2-AXI系统" class="headerlink" title="1.2.AXI系统"></a>1.2.AXI系统</h2><p>常见的标准AXI系统如下图所示，通常包括：</p><ul><li>AXI master：AXI通信主机</li><li>AXI slave：AXI通信从机</li><li>AXI interconnect：AXI通信通路</li></ul><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/axi_typical_system.JPG" class=""><p>AXI接口协议可用于：</p><ul><li>AXI master - AXI interconnect的连接</li><li>AXI slave - AXI interconnect的连接</li><li>AXI master - AXI slave的连接</li></ul><h2 id="1-3-AXI接口"><a href="#1-3-AXI接口" class="headerlink" title="1.3.AXI接口"></a>1.3.AXI接口</h2><h3 id="1-3-1-全局信号"><a href="#1-3-1-全局信号" class="headerlink" title="1.3.1.全局信号"></a>1.3.1.全局信号</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>ACLK</td><td>system clock</td><td>全局时钟信号</td></tr><tr><td>ARESTn</td><td>system reset</td><td>全局复位信号，低有效</td></tr></tbody></table></div><h3 id="1-3-2-写地址通道"><a href="#1-3-2-写地址通道" class="headerlink" title="1.3.2.写地址通道"></a>1.3.2.写地址通道</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>AWID</td><td>master</td><td>写地址ID（用于区分该地址属于哪个写地址组）</td></tr><tr><td>AWADDR</td><td>master</td><td>写地址</td></tr><tr><td>AWLEN</td><td>master</td><td>突发长度</td></tr><tr><td>AWSIZE</td><td>master</td><td>突发尺寸（每次突发传输的最长byte数）</td></tr><tr><td>AWBURST</td><td>master</td><td>突发方式（FIXED，INCR，WRAP）</td></tr><tr><td>AWCACHE</td><td>master</td><td>存储类型（标记系统需要的传输类型）</td></tr><tr><td>AWPROT</td><td>master</td><td>保护模式</td></tr><tr><td>AWQOS</td><td>master</td><td>QoS标识符</td></tr><tr><td>AWREGION</td><td>master</td><td>region标识符（当slave有多种逻辑接口时标识使用的逻辑接口）</td></tr><tr><td>AWUSER</td><td>master</td><td>用户自定义信号</td></tr><tr><td>AWVALID</td><td>master</td><td>写地址有效信号（有效时表示AWADDR上地址有效）</td></tr><tr><td>AWREADY</td><td>master</td><td>写从机就绪信号（有效时表示从机准备好接收地址）</td></tr></tbody></table></div><h3 id="1-3-3-写数据通道"><a href="#1-3-3-写数据通道" class="headerlink" title="1.3.3.写数据通道"></a>1.3.3.写数据通道</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>WDATA</td><td>master</td><td>写数据</td></tr><tr><td>WSTRB</td><td>master</td><td>数据段有效（标记写数据中哪几个8位字段有效）</td></tr><tr><td>WLAST</td><td>master</td><td>last信号（有效时表示当前为突发传输最后一个数据）</td></tr><tr><td>WUSER</td><td>master</td><td>用户自定义信号</td></tr><tr><td>WVALID</td><td>master</td><td>写有效信号（有效时表示WDATA上数据有效）</td></tr><tr><td>WREADY</td><td>slave</td><td>写ready信号（有效时表示从机准备好接收数据）</td></tr></tbody></table></div><h3 id="1-3-4-写响应通道"><a href="#1-3-4-写响应通道" class="headerlink" title="1.3.4.写响应通道"></a>1.3.4.写响应通道</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>BID</td><td>slave</td><td>响应ID</td></tr><tr><td>BRESP</td><td>slave</td><td>写响应</td></tr><tr><td>BUSER</td><td>slave</td><td>用户自定义信号</td></tr><tr><td>BVALID</td><td>slave</td><td>写响应信号有效</td></tr><tr><td>BREADY</td><td>master</td><td>写响应ready（主机准备好接受写响应信号）</td></tr></tbody></table></div><h3 id="1-3-5-读地址通道"><a href="#1-3-5-读地址通道" class="headerlink" title="1.3.5.读地址通道"></a>1.3.5.读地址通道</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>ARID</td><td>master</td><td>读地址ID</td></tr><tr><td>ARADDR</td><td>master</td><td>读地址</td></tr><tr><td>ARLEN</td><td>master</td><td>突发长度</td></tr><tr><td>ARSIZE</td><td>master</td><td>突发尺寸（每次突发传输的byte数）</td></tr><tr><td>ARBURST</td><td>master</td><td>突发类型（FIXED，INCR，WRAP）</td></tr><tr><td>ARCACHE</td><td>master</td><td>存储类型</td></tr><tr><td>ARPROT</td><td>master</td><td>保护类型</td></tr><tr><td>ARQOS</td><td>master</td><td>QoS标识符</td></tr><tr><td>ARREGION</td><td>master</td><td>区域标识符</td></tr><tr><td>ARUSER</td><td>master</td><td>用户自定义</td></tr><tr><td>ARVALID</td><td>master</td><td>读地址有效（有效时表示ARADDR上地址有效）</td></tr><tr><td>ARREADY</td><td>slave</td><td>写有效信号（有效时表示从机准备好接收读地址）</td></tr></tbody></table></div><h3 id="1-3-6-读数据通道"><a href="#1-3-6-读数据通道" class="headerlink" title="1.3.6.读数据通道"></a>1.3.6.读数据通道</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>RID</td><td>slave</td><td>读ID标签</td></tr><tr><td>RDATA</td><td>slave</td><td>读数据</td></tr><tr><td>RRESP</td><td>slave</td><td>读响应</td></tr><tr><td>RLAST</td><td>slave</td><td>有效时表示为突发传输的最后一个</td></tr><tr><td>RUSER</td><td>slave</td><td>用户自定义</td></tr><tr><td>RVALID</td><td>slave</td><td>读数据有效信号</td></tr><tr><td>RREADY</td><td>master</td><td>主机就绪信号（有效时表示）</td></tr></tbody></table></div><h3 id="1-3-7-低功耗接口信号"><a href="#1-3-7-低功耗接口信号" class="headerlink" title="1.3.7.低功耗接口信号"></a>1.3.7.低功耗接口信号</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>CSYSREQ</td><td>Clock controller</td><td>该信号有效时，系统退出低功耗模式</td></tr><tr><td>CSYSACK</td><td>Peripheral device</td><td>退出低功耗模式应答信号</td></tr><tr><td>CACTIVE</td><td>Peripheral device</td><td>外设申请时钟信号</td></tr></tbody></table></div><h1 id="2-AXI接口时序"><a href="#2-AXI接口时序" class="headerlink" title="2.AXI接口时序"></a>2.AXI接口时序</h1><h2 id="2-1-复位"><a href="#2-1-复位" class="headerlink" title="2.1.复位"></a>2.1.复位</h2><p>复位信号可以异步复位，但必须<strong>同步释放</strong>，复位时，信号要求如下：</p><ul><li>主机驱动的所有VALID信号（ARVALID, AWVALID和WVALID）必须被拉低</li><li>从机驱动的所有VALID信号（RVALID和BVALID）必须被拉低</li><li>其他信号无要求</li></ul><h2 id="2-2-基本传输"><a href="#2-2-基本传输" class="headerlink" title="2.2.基本传输"></a>2.2.基本传输</h2><h3 id="2-2-1-握手信号"><a href="#2-2-1-握手信号" class="headerlink" title="2.2.1.握手信号"></a>2.2.1.握手信号</h3><p>握手信号包括VALID和READY信号，传输行为仅在VALID和READY同时有效时发生。其中：</p><ul><li>VALID信号表示地址/数据/应答信号总线上的信号是有效的，由传输发起方控制</li><li>READY信号表示传输接收方已经准备好接收，由传输接收方控制</li></ul><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/basic_handshake.png" class=""><p>VALID和READY的先后关系具有三种情况：</p><ul><li>VALID先有效，等待READY有效后完成传输（VALID一旦有效后在传输完成前不可取消）</li><li>READY先有效，等待VALID有效后完成传输（READY可以在VALID有效前撤销）</li><li>VALID和READY同时有效，立刻完成传输</li></ul><p>此外，需要注意的是允许READY信号等待VALID信号再有效，即即使从机准备好，也可以不提供READY信号，等到主机发送VALID信号再提供READY信号。对应的VALID信号不允许等待READY信号，即不允许VALID等待READY信号拉高后再拉高，否则容易产生死锁现象。</p><h4 id="2-2-1-1-命令通道握手（读地址，写地址，写响应）"><a href="#2-2-1-1-命令通道握手（读地址，写地址，写响应）" class="headerlink" title="2.2.1.1.命令通道握手（读地址，写地址，写响应）"></a>2.2.1.1.命令通道握手（读地址，写地址，写响应）</h4><ul><li>仅当地址等信息有效时，才拉高VALID，该VALID必须保持直到传输完成（READY置位）</li><li>READY默认状态不关心，仅当准备好接收时拉高READY</li></ul><h4 id="2-2-1-2数据通道握手（写数据和读地址）"><a href="#2-2-1-2数据通道握手（写数据和读地址）" class="headerlink" title="2.2.1.2数据通道握手（写数据和读地址）"></a>2.2.1.2数据通道握手（写数据和读地址）</h4><ul><li>突发读写模式下，仅数据信息有效时才拉高VALID，该VALID必须保持直到传输完成。当突发传输最后一个数据发送时拉高LAST信号</li><li>READY默认状态不关心，仅当准备好接收时拉高READY</li></ul><h3 id="2-2-2-通道顺序"><a href="#2-2-2-通道顺序" class="headerlink" title="2.2.2.通道顺序"></a>2.2.2.通道顺序</h3><p>传输中，通道传输的先后有以下规定</p><ul><li>写响应通道传输必须在写操作完成以后进行</li><li>读数据通道传输必须在读地址通道传输后进行</li><li>必须遵循一系列的状态依赖关系</li></ul><p>下文中会使用一些图描述依赖关系。图表中，单箭头表示可以等待有效再置位，双重箭头表示必须等待有效再置位</p><h4 id="2-2-2-1-读操作顺序"><a href="#2-2-2-1-读操作顺序" class="headerlink" title="2.2.2.1.读操作顺序"></a>2.2.2.1.读操作顺序</h4><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/read_depend.PNG" class=""><p>上图为读操作的依赖关系，ARREADY可以等待ARVALID信号，RVALID<strong>必须等待</strong>ARVALID和ARREADY同时有效后（一次地址传输发生）才能能有效</p><h4 id="2-2-2-2-写操作顺序"><a href="#2-2-2-2-写操作顺序" class="headerlink" title="2.2.2.2.写操作顺序"></a>2.2.2.2.写操作顺序</h4><p>AXI3中写操作中唯一的强依赖关系是写响应通道BVALID，仅当WVALID和WREADY信号同时有效（数据传输完成）且WLAST信号有效（突发传输的最后一个数据传输完成）后才会被置位。</p><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/axi4_write_depend.PNG" class=""><p>在AXI4中，定义了额外的依赖关系，即BVALID必须依赖AWVALID、AWREADY、WVALID和WREADY信号。</p><h1 id="3-数据结构"><a href="#3-数据结构" class="headerlink" title="3.数据结构"></a>3.数据结构</h1><h2 id="3-1-地址通道数据结构"><a href="#3-1-地址通道数据结构" class="headerlink" title="3.1.地址通道数据结构"></a>3.1.地址通道数据结构</h2><p>AXI总线是基于突发传输的总线，若主机要开始一次突发传输，需要传输一次地址和相关控制信号，之后从机自动计算地址，但一次突发传输的地址范围不能跨越4KB。</p><h3 id="3-1-1-突发传输信息"><a href="#3-1-1-突发传输信息" class="headerlink" title="3.1.1.突发传输信息"></a>3.1.1.突发传输信息</h3><h4 id="3-1-1-1-突发长度（AxLEN）"><a href="#3-1-1-1-突发长度（AxLEN）" class="headerlink" title="3.1.1.1.突发长度（AxLEN）"></a>3.1.1.1.突发长度（AxLEN）</h4><p>突发长度为每次突发传输的传输次数，范围限制1~16（AXI4增量模式1~256）且不能跨越4kb的地址空间，每次突发传输不允许提前终止（可以通过关闭所有数据字段的方式使一段传输数据无效，但传输行为必须完成）。每次传输的突发长度为AxLEN[3:0] + 1（AXI增量模式AxLEN[7:0] + 1）</p><ul><li>ARLEN[7:0]：读地址通道的突发长度接口</li><li>AWLEN[7:0]：写地址通道的突发长度接口</li></ul><p>对于回卷模式突发传输，突发长度仅能是2,4,8或16。</p><h4 id="3-1-1-2-突发尺寸（AxSIZE）"><a href="#3-1-1-2-突发尺寸（AxSIZE）" class="headerlink" title="3.1.1.2.突发尺寸（AxSIZE）"></a>3.1.1.2.突发尺寸（AxSIZE）</h4><p>突发尺寸为每次传输的byte数量，与突发传输的地址预测相关性很强。每次的突发尺寸不能超过数据通道的宽度；若突发尺寸小于数据通道宽度，需要指定哪些位数是有效的。突发尺寸为2^AxSIZE[2:0]^。</p><ul><li>ARSIZE[2:0]：读地址通道突发尺寸</li><li>AWSIZE[2:0]：写地址通道突发尺寸</li></ul><h4 id="3-1-1-3-突发类型（AxBURST）"><a href="#3-1-1-3-突发类型（AxBURST）" class="headerlink" title="3.1.1.3.突发类型（AxBURST）"></a>3.1.1.3.突发类型（AxBURST）</h4><p>AXI支持三种突发类型：</p><ul><li>FIXED（AxBURST[1:0]=0b00）：固定突发模式，每次突发传输的地址相同</li><li>INCR（AxBURST[1:0]=0b01）：增量突发模式，突发传输地址递增，递增量与突发尺寸相关</li><li>WRAP（AxBURST[1:0]=0b10）：回卷突发模式，突发传输地址可溢出性递增，突发长度仅支持2,4,8,16。地址空间被划分为长度【突发尺寸*突发长度】的块，传输地址不会超出起始地址所在的块，一旦递增超出，则回到该块的起始地址。</li></ul><h3 id="3-1-2-存储类型（AxCACHE）"><a href="#3-1-2-存储类型（AxCACHE）" class="headerlink" title="3.1.2.存储类型（AxCACHE）"></a>3.1.2.存储类型（AxCACHE）</h3><p>AXI4可支持不同的存储类型，AxCACHE[3:0]用于描述不同的存储类型，如下图所示</p><div class="table-container"><table><thead><tr><th>ARCACHE[3:0]</th><th>AWCACHE[3:0]</th><th>Memory type</th></tr></thead><tbody><tr><td>0000</td><td>0000</td><td>Device Non-bufferable</td></tr><tr><td>0001</td><td>0001</td><td>Device Bufferable</td></tr><tr><td>0010</td><td>0010</td><td>Normal Non-cacheable Non-bufferable</td></tr><tr><td>0011</td><td>0011</td><td>Normal Non-cacheable Bufferable</td></tr><tr><td>1010</td><td>0110</td><td>Write-through No-allocate</td></tr><tr><td>1110 (0110)</td><td>0110</td><td>Write-through Read-allocate</td></tr><tr><td>1010</td><td>1110 (1010)</td><td>Write-through Write-allocate</td></tr><tr><td>1110</td><td>1110</td><td>Write-through Read and Write-allocate</td></tr><tr><td>1011</td><td>0111</td><td>Write-back No-allocate</td></tr><tr><td>1111</td><td>(0111) 0111</td><td>Write-back Read-allocate</td></tr><tr><td>1011</td><td>1111 (1011)</td><td>Write-back Write-allocate</td></tr><tr><td>1111</td><td>1111</td><td>Write-back Read and Write-allocate</td></tr></tbody></table></div><h3 id="3-1-3-Qos标识符（AxQOS）"><a href="#3-1-3-Qos标识符（AxQOS）" class="headerlink" title="3.1.3.Qos标识符（AxQOS）"></a>3.1.3.Qos标识符（AxQOS）</h3><p>AXI4总线支持QoS，该标识符AxQOS[3:0]表示服务的优先级</p><h3 id="3-1-4-REGION标识符（AxREGION）"><a href="#3-1-4-REGION标识符（AxREGION）" class="headerlink" title="3.1.4.REGION标识符（AxREGION）"></a>3.1.4.REGION标识符（AxREGION）</h3><p>region标识符用于指定选用的高级逻辑接口类型，当使用该标识符AxREGION[3:0]时，表示有多个逻辑接口共享该物理接口</p><h3 id="3-1-5-权限标识符（AxPROT）"><a href="#3-1-5-权限标识符（AxPROT）" class="headerlink" title="3.1.5.权限标识符（AxPROT）"></a>3.1.5.权限标识符（AxPROT）</h3><p>权限标识符AxPROT[2:0]用于防止非法传输</p><h3 id="3-1-6-用户自定义（AxUSER）"><a href="#3-1-6-用户自定义（AxUSER）" class="headerlink" title="3.1.6.用户自定义（AxUSER）"></a>3.1.6.用户自定义（AxUSER）</h3><p>用户自定义数据</p><h2 id="3-2-数据通道数据结构"><a href="#3-2-数据通道数据结构" class="headerlink" title="3.2.数据通道数据结构"></a>3.2.数据通道数据结构</h2><h3 id="3-2-1-数据选通（WSTRB）"><a href="#3-2-1-数据选通（WSTRB）" class="headerlink" title="3.2.1.数据选通（WSTRB）"></a>3.2.1.数据选通（WSTRB）</h3><p>WSTRB的每一位对应数据中的8位（1字节），用于标志数据中的对应字节是否有效。即当WSTRB[n] = 1时，标志数据中WDATA[(8n)+7: (8n)]部分有效。</p><h3 id="3-2-2-数据（xDATA）"><a href="#3-2-2-数据（xDATA）" class="headerlink" title="3.2.2.数据（xDATA）"></a>3.2.2.数据（xDATA）</h3><h4 id="3-2-2-1-窄带传输（Narrow-transfers）"><a href="#3-2-2-1-窄带传输（Narrow-transfers）" class="headerlink" title="3.2.2.1.窄带传输（Narrow transfers）"></a>3.2.2.1.窄带传输（Narrow transfers）</h4><p>当传输的数据位宽小于xDATA总线带宽时，为窄带传输，每次使用的数据位数不同：</p><ul><li>固定地址的突发下，使用同一段数据信号线</li><li>在递增地址和包装地址的突发下，使用不同段信号线</li></ul><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/narrow.JPG" class=""><p>上图为地址递增突发下，在32位数据信号下使用8bit传输的窄带传输使用的位数图。第一次传输使用0~7位，第二次使用8~15位，依次递增；在第五次传输时回到开头使用0~7位</p><h4 id="3-2-2-2-不对齐传输（Unaligned-transfers）"><a href="#3-2-2-2-不对齐传输（Unaligned-transfers）" class="headerlink" title="3.2.2.2.不对齐传输（Unaligned transfers）"></a>3.2.2.2.不对齐传输（Unaligned transfers）</h4><p>当传输位宽超过1byte，起始地址不为数据总线硬件带宽（byte单位）整数倍时，为不对齐传输。不对齐传输的时候需要配合数据选通在第一次传输时将某几个byte置为无效，使第二次突发传输的起始地址（从机自动计算）为突发尺寸的整数倍。</p><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/Unaligned.JPG" class=""><p>如图，突发尺寸为4byte，若要对齐传输，起始地址要为4的整数倍。图中起始地址为0x07，因此为非对齐传输。第一次传输时，前3个数据为无效字段，可以使用数据选通WSTRB将前3个byte置为无效。</p><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/unaligned_narrow.PNG" class=""><p>上图是在窄带传输下的非对齐传输启动。传输带宽为32bit，每次传输使用16bit，由于是窄带传输，因此每次交替使用低字节和高字节。现在关注启动状态，由于启动地址为7，而硬件带宽为8bit，则必须由地址0启动，设置前7个字段为无效，那么下次传输从地址8开始，满足不对齐传输。</p><h3 id="3-2-3-用户自定义（-USER）"><a href="#3-2-3-用户自定义（-USER）" class="headerlink" title="3.2.3.用户自定义（*USER）"></a>3.2.3.用户自定义（*USER）</h3><p>用户自定义数据</p><h2 id="3-3-应答通道数据结构"><a href="#3-3-应答通道数据结构" class="headerlink" title="3.3.应答通道数据结构"></a>3.3.应答通道数据结构</h2><h3 id="3-3-1-响应信号（-RESP）"><a href="#3-3-1-响应信号（-RESP）" class="headerlink" title="3.3.1.响应信号（*RESP）"></a>3.3.1.响应信号（*RESP）</h3><p>针对读和写均有响应的响应信号：</p><ul><li>BRESP[1:0]写响应信号，每次突发传输完成后</li><li>RRESP[1:0]读响应信号（位于读数据通道）</li></ul><p>响应信号含义如下：</p><ul><li>OKAY（00）：正常访问正确/特权访问失败/不支持特权访问</li><li>EXOKAY（01）：特权访问成功</li><li>SLVERR（10）：从机错误，传输失败</li><li>DECERR（11）：互连解码错误，传输失败</li></ul><h3 id="3-3-2-用户自定义"><a href="#3-3-2-用户自定义" class="headerlink" title="3.3.2.用户自定义"></a>3.3.2.用户自定义</h3><p>用户自定义数据</p><h1 id="4-传输特性"><a href="#4-传输特性" class="headerlink" title="4.传输特性"></a>4.传输特性</h1><p>AXI从机分为两种：</p><ul><li>存储器从机（Memory Slave）：需要支持所有传输特性</li><li>外设从机（Peripheral Slave）：仅需要支持指定的操作，但是可以保证所有类型的传输完成（不要求非指定的操作响应正确）</li></ul><p>AxCACHE用于指定传输特性，传输特性用于标定传输如何在系统中进行和系统级缓存如何处理传输。</p><h2 id="4-1-存储器特性"><a href="#4-1-存储器特性" class="headerlink" title="4.1.存储器特性"></a>4.1.存储器特性</h2><p>存储器特性包括4个位，如下所示：</p><ul><li><p>AxCACHE[0]（Bufferable）：AxCACHE[0]表示传输过程中是否有缓存，当该位置为1时，表示表示传输路径上具有buffer（可延迟transaction到达最终点的时间）</p></li><li><p>AxCACHE[1]（Modifiable）：标记传输是否可以被修改/优化，当其置0时，每个传输将不会被更改，具体来说，AxADDR、AxSIZE、AxLEN、AxBURST、AxLOCK和AxPROT信号不会被修改（地址，突发传输信息，传输隐私信息不被修改）。但是AxCACHE[0]、ID和QoS可能被修改，同时，一个突发长度长于16的突发传输可能被切开，但是保证传输效果相同。当该位置1时，除了以上可能发生的改变，另外：</p><ul><li>多个传输可能被合并为一个传输，一个传输可能被切分为多个传输</li><li>读传输在从机端读出的数据可能多于主机的请求（多的数据被保存在cache中用于优化数据访问）</li><li>写传输可能访问到超过主机请求的地址范围，妥善使用WSTRB保证仅有需要的地址被覆盖</li></ul><p>另外，AxLOCK和AxPROT信号仍然不能被改变，同时需要注意的是：AxCACHE[0]=0，具有相同的AXI ID和指向相同的从机的一系列传输的顺序不能改变。</p></li><li><p>AxCACHE[2]（Read-allocate）和AxCACHE[3]（Write-allocate）：读写操作前是否检查缓存以优化传输</p></li></ul><h2 id="4-2-存储器类型"><a href="#4-2-存储器类型" class="headerlink" title="4.2.存储器类型"></a>4.2.存储器类型</h2><p>通过ARCACHE和AWCACHE的不同定义不同的存储器类型</p><img src="/2018/11/18/AXI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/mem_type.PNG" class="">]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> AMBA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>booth乘法器</title>
      <link href="2018/11/14/booth%E4%B9%98%E6%B3%95%E5%99%A8/"/>
      <url>2018/11/14/booth%E4%B9%98%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h1><p>Booth乘法器是一种使用移位实现的乘法器，实现过程如下，对于乘法：</p><script type="math/tex; mode=display">R = A \times B \\A = a_na_{n-1}...a_2a_1a_0</script><p>扩展A的位数为n+1位，添加$a_{-1}=0$，则A变为：</p><script type="math/tex; mode=display">A = a_na_{n-1}...a_2a_1a_0a_{-1}</script><p>从i=0开始，到i=n-1结束，依次考察$a<em>{i}a</em>{i-1}$的值，做如下操作：</p><ul><li>若$a<em>{i} = a</em>{i-1}$，不进行操作</li><li>若$a<em>{i}a</em>{i-1} = 01$，$R = R + B &lt;&lt; i$</li><li>若$a<em>ia</em>{i-1}=10$，$R = R - B &lt;&lt; i$</li></ul><p>最后，舍弃R的最右端1位，即获得$R = A \times B$</p><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>其原理比较容易理解，对于以上乘法，可以分解为：</p><script type="math/tex; mode=display">R = \sum\limits_{i=0}^n (a_i \times 2^i \times B)</script><p>以上是位移乘法器的原理，那么对于booth乘法器，添加了一条：</p><img src="/2018/11/14/booth%E4%B9%98%E6%B3%95%E5%99%A8/booth.png" class=""><p>即有：</p><script type="math/tex; mode=display">2^k + 2^{k-1} + ... + 2 ^{j+1} + 2^j = 2^{k+1} - 2^j</script><p>将移位乘法器原理式中$a_i$连续为1的部分使用两个减法代替，即形成booth乘法器</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>这次实现了一个基于P2P接口的booth乘法器，位宽可配置。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> booth_mul #(</span><br><span class="line"><span class="keyword">parameter</span> DIN_WIDTH_LOG = <span class="number">3</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> din_valid,</span><br><span class="line"><span class="keyword">output</span> din_busy,</span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> ** DIN_WIDTH_LOG-<span class="number">1</span>:<span class="number">0</span>] din_data_a,</span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> ** DIN_WIDTH_LOG-<span class="number">1</span>:<span class="number">0</span>] din_data_b,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> dout_valid,</span><br><span class="line"><span class="keyword">input</span> dout_busy,</span><br><span class="line"><span class="keyword">output</span> [<span class="number">2</span> ** (DIN_WIDTH_LOG + <span class="number">1</span>) - <span class="number">1</span>:<span class="number">0</span>]dout_data</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>首先定义控制流，控制流为一个状态机，分别为：</p><ul><li><code>INIT</code>：静默状态，等待输入，获得输入时，转向<code>WORK</code>状态</li><li><code>WORK</code>：工作状态，进行booth乘法，过程中<code>din_busy</code>信号被拉高，当运算完成后，转向<code>TRAN</code></li><li><code>TRAN</code>：传输状态，进行P2P输出，输出完成后转向<code>INIT</code>状态</li></ul><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">parameter</span> INIT = <span class="number">2&#x27;b00</span>;</span><br><span class="line"><span class="keyword">parameter</span> WORK = <span class="number">2&#x27;b01</span>;</span><br><span class="line"><span class="keyword">parameter</span> TRAN = <span class="number">2&#x27;b11</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [DIN_WIDTH_LOG-<span class="number">1</span>:<span class="number">0</span>]shifter_counter;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">1</span>:<span class="number">0</span>] status,next_status;</span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> : proc_status</span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">status &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">status &lt;= next_status;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">wire</span> is_computed = (shifter_counter == <span class="number">2</span> ** DIN_WIDTH_LOG - <span class="number">1</span>);</span><br><span class="line"><span class="keyword">wire</span> is_traned = dout_valid &amp;&amp; !dout_busy;</span><br><span class="line"><span class="keyword">always</span> @(*) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">case</span> (status)</span><br><span class="line">INIT:<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(din_valid) <span class="keyword">begin</span></span><br><span class="line">next_status = WORK;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">next_status = INIT;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">WORK:<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(is_computed) <span class="keyword">begin</span></span><br><span class="line">next_status = TRAN;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">next_status = WORK;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">TRAN:<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(is_traned) <span class="keyword">begin</span></span><br><span class="line">next_status = INIT;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">next_status = TRAN;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">default</span> : next_status = INIT;</span><br><span class="line"><span class="keyword">endcase</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">assign</span> din_busy = status[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">shifter_counter &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(status == WORK) <span class="keyword">begin</span></span><br><span class="line">shifter_counter &lt;= shifter_counter + <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">shifter_counter &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_computed) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_traned) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>下面是数据流的部分，该部分实现了上述的booth乘法操作</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">2</span> ** DIN_WIDTH_LOG:<span class="number">0</span>]a_data;</span><br><span class="line"><span class="keyword">wire</span> is_read = !din_busy &amp;&amp; din_valid;</span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> : proc_a_data</span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">a_data &lt;= <span class="number">0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_read) <span class="keyword">begin</span></span><br><span class="line">a_data &lt;= &#123;din_data_a,<span class="number">1&#x27;b0</span>&#125;;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(status == WORK) <span class="keyword">begin</span></span><br><span class="line">a_data &lt;= a_data &gt;&gt; <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">2</span> ** (DIN_WIDTH_LOG + <span class="number">1</span>) - <span class="number">1</span>:<span class="number">0</span>]b_data;</span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> : proc_b_data</span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">b_data &lt;= <span class="number">0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_read)<span class="keyword">begin</span></span><br><span class="line">b_data &lt;= &#123;(<span class="number">2</span> ** DIN_WIDTH_LOG)&#x27;(<span class="number">0</span>),din_data_b&#125;;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(status == WORK) <span class="keyword">begin</span></span><br><span class="line">b_data &lt;= b_data &lt;&lt; <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">2</span> ** (DIN_WIDTH_LOG + <span class="number">1</span>):<span class="number">0</span>]temp_data,result_data;</span><br><span class="line"><span class="keyword">always</span> @(*) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">case</span> (a_data[<span class="number">1</span>:<span class="number">0</span>])</span><br><span class="line"><span class="number">2&#x27;b01</span>:temp_data = dout_data + b_data;</span><br><span class="line"><span class="number">2&#x27;b10</span>:temp_data = dout_data - b_data;</span><br><span class="line"><span class="keyword">default</span>:temp_data = dout_data;</span><br><span class="line"><span class="keyword">endcase</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> : proc_dout_data</span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">result_data &lt;= <span class="number">0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_read) <span class="keyword">begin</span></span><br><span class="line">result_data &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(status == WORK) <span class="keyword">begin</span></span><br><span class="line">result_data &lt;= temp_data;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">assign</span> dout_data = result_data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSD目标检测系统</title>
      <link href="2018/11/04/SSD%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/"/>
      <url>2018/11/04/SSD%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h1><img src="/2018/11/04/SSD%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/system.png" class=""><p>SSD识别系统也是一种单步物体识别系统，即将提取物体位置和判断物体类别融合在一起进行，其最主要的特点是识别器用于判断物体的特征不仅仅来自于神经网络的输出，还来自于神经网络的中间结果。该系统分为以下几个部分：</p><ul><li>神经网络部分：用作特征提取器，提取图像特征</li><li>识别器：根据神经网络提取的特征，生成包含物品位置和类别信息的候选框（使用卷积实现）</li><li>后处理：对识别器提取出的候选框进行解码和筛选（NMS），输出最终的候选框</li></ul><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>该系统的网络结构如上图所示基本网络为VGG-16网络，VGG-16网络由一系列3x3卷积顺序连接构成，在conv5_3层卷积之前，共有4个stride=2的最大值池化，因此该层的输出的长和宽比原始输入缩小16倍，在SSD300网络中输入图像的尺寸被归一化到300x300，因此该层的输出长和宽为$[300/2^4] = [18.75] = 19$，channel为512，即基础网络VGG-16的输出尺寸为512x19x19。</p><p>在基础网络之后，还有如下的网络结构：</p><div class="table-container"><table><thead><tr><th>名称</th><th>输入</th><th>kernel尺寸</th><th>stride</th><th>padding</th><th>输出</th><th>是否输出</th></tr></thead><tbody><tr><td>conv6</td><td>512x19x19</td><td>1024x512x3x3</td><td>1</td><td>1</td><td>1024x19x19</td><td>N</td></tr><tr><td>conv7</td><td>1024x19x19</td><td>1024x1024x1x1</td><td>1</td><td>0</td><td>1024x19x19</td><td>Y</td></tr><tr><td>conv8_1</td><td>1024x10x10</td><td>256x1024x1x1</td><td>1</td><td>0</td><td>256x10x10</td><td>N</td></tr><tr><td>conv8_2</td><td>256x10x10</td><td>512x256x3x3</td><td>2</td><td>1</td><td>512x10x10</td><td>Y</td></tr><tr><td>conv9_1</td><td>512x10x10</td><td>128x512x1x1</td><td>1</td><td>0</td><td>128x10x10</td><td>N</td></tr><tr><td>conv9_2</td><td>128x10x10</td><td>256x128x3x3</td><td>2</td><td>1</td><td>256x5x5</td><td>Y</td></tr><tr><td>conv10_1</td><td>256x5x5</td><td>128x256x1x1</td><td>1</td><td>0</td><td>128x5x5</td><td>N</td></tr><tr><td>conv10_2</td><td>128x5x5</td><td>256x128x3x3</td><td>1</td><td>0</td><td>256x3x3</td><td>Y</td></tr><tr><td>conv11_1</td><td>256x3x3</td><td>128x256x1x1</td><td>1</td><td>0</td><td>128x3x3</td><td>N</td></tr><tr><td>conv11_2</td><td>128x3x3</td><td>256x128x3x3</td><td>1</td><td>0</td><td>256x1x1</td><td>Y</td></tr></tbody></table></div><p>其中，是否输出一栏标为Y的均将其输出送到识别器，即最终识别器接受不同大小的feature map共(5+1)=6个（5个额外的输出层和1个基础网络输出），分别为10x10，5x5，3x3，1x1和两个19x19，</p><h2 id="识别器"><a href="#识别器" class="headerlink" title="识别器"></a>识别器</h2><p>识别器使用卷积层构成，其卷积尺寸为$(box_num \times (4 + class_num) ) \times in_channel \times 3 \times 3$，其中box_num为feature map上一个格点所产生的识别框数量，class_num为类别数量（包括背景类），具体如下所示：</p><img src="/2018/11/04/SSD%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/default_box.PNG" class=""><p>图中是一个4x4的feature map，共$4 \times 4 = 16$个格点，每个格点上有3个候选框，即box_num=3，类别信息中共有p个数据，即共有p类物品以供判断（p中含有背景类），class_num=p。另外的4个数据为loc后的位置微调信息。一个$C \times W \times H$的feature map经过识别器处理后，变为$(box_num \times (4 + class_num) ) \times W \times H$的Tensor，共包含$W \times H \times box_num$个候选框。</p><h2 id="后处理"><a href="#后处理" class="headerlink" title="后处理"></a>后处理</h2><p>第一步后处理是解析候选框中的数据，每一个候选框由4+class_num个数据构成：4个位置信息x,y,w,h和class_num个类别信息。解析方式与anchor box几乎相同，如下所示：</p><script type="math/tex; mode=display">G_x = P_w \times \frac{P_x + sigmoid(x)}{F_x} \\G_y = P_h \times \frac{P_y + sigmoid(y)}{F_y} \\G_w =  P_w \times （D_w \times e^{sigmoid(w)}） \\G_h = P_h \times （D_h \times e^{sigmoid(h)}）</script><p>其中，$G_x,G_y,G_w,G_h$分别是识别出的物品的中心点的宽度坐标，高度坐标和物品的高度和宽度。$P_w,P_h$分别是输入图像的宽度和高度，$P_x,P_y$为候选框所在格点的坐标，取值范围分别为0~$F_x - 1$和0~$F_y-1$，如上图中有$P_x = 3,P_y=2$。$F_x,F_y$为候选框所在的feature map的宽度和高度，如上图有$F_x=F_y=4$。$D_w,D_h$分别是对应default box的默认<strong>归一化</strong>宽高。对于类别信息，取其中最大的即可：</p><script type="math/tex; mode=display">cls = argmax_{i \in class\_id}(class\_feature_i) \\conf = max(class\_feature_i)</script><p>第二步后处理是使用NMS（非极大值抑制）对候选框进行筛选：当两个候选框的IOU超过一个阈值时，丢弃置信度conf低的候选框。</p><h1 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h1><p>网络训练分为了两个部分：</p><ul><li>建立label：一般的物体检测的label为物体的位置信息，为了实现训练需要将label转移到default box上</li><li>代价函数：反向传播的起点，标记训练任务</li></ul><h2 id="标签建立"><a href="#标签建立" class="headerlink" title="标签建立"></a>标签建立</h2><h3 id="default-box生成"><a href="#default-box生成" class="headerlink" title="default box生成"></a>default box生成</h3><p>在每个feature map的格点上，default box的面积是一个定值，长宽比为几种可选的值，如下所示：</p><script type="math/tex; mode=display">s_k = s_{min} + \frac{k-1}{m-1} \times (s_{max} - s_{min}),k \in \{1,2,...m\}\\w_k^a = s_k \times \sqrt{a_r} \\h_k^a = \frac{s_k}{\sqrt{a_r}} \\a_r \in \{2,3,\frac{1}{2},\frac{1}{3}\}</script><p>其中，$s<em>k$为第k个feature map的归一化尺寸参数（实际尺寸与图片尺寸的比），$s</em>{min} = 0.2,s_{max} = 0.9$，即k=1时（$F_x ,F_y$最大的feature map），尺寸参数为图片尺寸的0.2倍，k=m时（$F_x ,F_y$最小的feature map），尺寸参数为图片尺寸的0.9倍。$w_k^a,h_k^a$分别为第k个feature map下不同长宽比的default box的默认归一化宽和高。除了以上所述4个default box之外，每个feature map的格点default box还有两个长宽比为1的框，其尺寸系数分别是：</p><script type="math/tex; mode=display">s_k' = \sqrt{s_{k-1}\times s_k} \\s_k'' = \sqrt{s_k \times s_{k+1}}</script><p>综上所述，每个feature map的格点共对应6个default box</p><h3 id="label匹配"><a href="#label匹配" class="headerlink" title="label匹配"></a>label匹配</h3><p>对一个default box进行label匹配时，遍历这张输入图片的物体信息label，若该物品和这个default box的IOU超过某个阈值时，认定这个default box用于识别这个物体，按如下建立label：</p><ul><li>对于位置信息：根据以上后处理所示的公式进行反处理，则可以获得位置信息的label</li><li>对于类别信息：将物品类别对应位置的置信度置1，其他置0</li></ul><p>按以上方法遍历所有default box，即生成了对于一张输入数据的label</p><h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>代价函数由两个部分构成，分别对于定位准度和分类精度：</p><script type="math/tex; mode=display">L(x,c,l,g) = \frac{1}{N}(L_{conf}(x,c) + \alpha L_{loc}(x,l,g))</script><p>其中x为标记信息，$x<em>{ij}^p={0,1}$，当第i个default box被标记为属于类别p的第j个物体时，$x</em>{ij}^p=1$，否则该标记为0。代价函数分为两个部分，第一个部分是分类精度，使用softmax损失函数，如下所示。$i \in Pos$指该default box的在label中不属于背景（p&gt;0），反之$i \in Neg$。c为网络输出中置信度有关的向量，$c_i^p$为SSD输出的第i个default box中属于类别p的置信度。</p><script type="math/tex; mode=display">L_{conf}(x,c) = - \sum\limits_{i\in Pos}^N x_{ij}^p log(c_i^p) - \sum\limits_{i \in Neg} log(c_i^0) \\c_i^p = \frac{exp(c_i^p)}{\sum_p exp(c_i^p)}</script><p>第二个部分为定位准确度，使用L1下的smooth函数作为代价函数：</p><script type="math/tex; mode=display">L_{loc}(x,l,g) = \sum\limits_{i\in Pos}^N \sum\limits_{m \in \{x,y,w,h\}} x_{ij}^ksmooth_{L1}(l^m_i-g^m_j)</script><h2 id="其他训练细节"><a href="#其他训练细节" class="headerlink" title="其他训练细节"></a>其他训练细节</h2><h3 id="正反例"><a href="#正反例" class="headerlink" title="正反例"></a>正反例</h3><p>保证正例：反例=1:3，由于一般正例远远少于反例，所以保留所有正例，并根据正例三倍的数量选择反例，选择的标准为置信度：即选择$c^0$高的反例。</p><h3 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h3><p>输入图片随机选择进行以下处理：</p><ul><li>输入原始图像</li><li>截取与物品IOU大于0.3,0.5,0.7或0.9的部分</li><li>随机截取图片部分</li></ul><p>进行完以上随机选择后，随机对处理后的图片做翻转处理</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLO的网络后处理</title>
      <link href="2018/10/22/YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E5%90%8E%E5%A4%84%E7%90%86/"/>
      <url>2018/10/22/YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E5%90%8E%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="理论分析"><a href="#理论分析" class="headerlink" title="理论分析"></a>理论分析</h1><img src="/2018/10/22/YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E5%90%8E%E5%A4%84%E7%90%86/system.png" class=""><p>YOLO从v2版本开始重新启用anchor box，YOLOv2网络的网络输出为尺寸为<code>[b,125,13,13]</code>的tensor，要将这个Tensor变为最终的输出结果，还需要以下的处理：</p><ul><li>解码：从Tensor中解析出所有框的位置信息和类别信息</li><li>NMS：筛选最能表现物品的识别框</li></ul><h2 id="解码过程"><a href="#解码过程" class="headerlink" title="解码过程"></a>解码过程</h2><p>解码之前，需要明确的是每个候选框需要5+class_num个数据，分别是相对位置x,y，相对宽度w,h，置信度c和class_num个分类结果，YOLOv2-voc中class_num=20，即每个格点对应5个候选框，每个候选框有5+20=25个参数，这就是为什么输出Tensor的最后一维为5*（20+5）=125。</p><img src="/2018/10/22/YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E5%90%8E%E5%A4%84%E7%90%86/tensor.png" class=""><p>上图为一个框所需要的所有数据构成，假设这个框是位于格点X,Y的，对应的anchor box大小为W,H，位置相关参数的处理方法如下所示，其中，$T_x,T_y​$分别是输出Tensor在长宽上的值，这里$T_x = 13,T_y = 13​$；$P_x,P_y​$分别为原图片的长和宽：</p><script type="math/tex; mode=display">x_r = \cfrac{sigmoid(x) + X}{T_x} \times P_x\\y_r = \cfrac{sigmoid(x) + Y}{T_y} \times P_y\\w_r = e^{w} \times W \\h_r = e^{h} \times H</script><p>置信度和类别信息处理方法如下所示：</p><script type="math/tex; mode=display">c_{r} = sigmoid(c) \times max\{softmax(class)\} \\class\_id = argmax(class)</script><p>当格点置信度大于某个阈值时，认为该格点有物体，物体类别为class_id对应的类别</p><h2 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h2><p>NMS为非最大值抑制，用在YOLO系统中的含义指从多个候选框标记同一个物品时，从中选择最合适的候选框。其基本思维很简单：使用置信度最高的候选框标记一个物体，若其他候选框与该候选框的IOU超过一个阈值，则认为其他候选框与该候选框标记的是同一个物体，丢弃其他候选框。</p><p>具体实现时，可以将所有候选框进行排序，置信度高的在前，置信度低的在后。从置信度高的候选框开始遍历所有候选框，对于某一个候选框，将之后所有的候选框与其计算IOU，若IOU高于一个阈值，则丢弃置信度低的候选框。算法流程图如下所示：</p><img src="/2018/10/22/YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E5%90%8E%E5%A4%84%E7%90%86/nms.png" class=""><h1 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h1><p>这里选择的是<a href="https://github.com/marvis">marvis</a>开源的基于Pytorch的YOLOv2代码，其优势在于所有的部分均使用Python实现，没有使用Cython，无需编译即可使用，且依赖较少，文件管理比较扁平。</p><h2 id="解码部分"><a href="#解码部分" class="headerlink" title="解码部分"></a>解码部分</h2><p>解码部分在<code>utils.py</code>文件中，由<code>get_region_boxes</code>函数实现。首先是准备部分，这里首先获取了输出的相关信息，yolo-voc网络下有b为batch，预测模式下一般为1，h=w=13。随后reshape了输出，其维度变为(25,13*13*5)，改变维度的目的是方便后面处理的索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_region_boxes</span>(<span class="params">output, conf_thresh, num_classes, anchors, num_anchors, only_objectness=<span class="number">1</span>, validation=<span class="literal">False</span></span>):</span>    </span><br><span class="line">    anchor_step = <span class="built_in">len</span>(anchors) / num_anchors</span><br><span class="line">    <span class="keyword">if</span> output.dim() == <span class="number">3</span>:</span><br><span class="line">        output = output.unsqueeze(<span class="number">0</span>)</span><br><span class="line">    batch = output.size(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">assert</span>(output.size(<span class="number">1</span>) == (<span class="number">5</span> + num_classes) * num_anchors)</span><br><span class="line">    h = output.size(<span class="number">2</span>)</span><br><span class="line">    w = output.size(<span class="number">3</span>)</span><br><span class="line">    output = output.view(batch * num_anchors, <span class="number">5</span> + num_classes, h * w).transpose(</span><br><span class="line">        <span class="number">0</span>, <span class="number">1</span>).contiguous().view(<span class="number">5</span> + num_classes, batch * num_anchors * h * w)</span><br><span class="line">    all_boxes = []</span><br></pre></td></tr></table></figure><p>随后是处理x，y的部分，xs和ys就是处理后的候选框中心点相对坐标，grid_x和grid_y与output[0]shape相同，分别表示对应output位置的候选框所属的格点坐标X与Y，这里的xs和ys实现了上述公式中的$xs = sigmoid(x) + X$和$ys = sigmoid(y) + Y$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">grid_x = torch.linspace(<span class="number">0</span>, w - <span class="number">1</span>, w).repeat(h, <span class="number">1</span>).repeat(batch *</span><br><span class="line">                                                         num_anchors, <span class="number">1</span>, <span class="number">1</span>).view(batch * num_anchors * h * w).cuda()</span><br><span class="line">grid_y = torch.linspace(<span class="number">0</span>, h - <span class="number">1</span>, h).repeat(w, <span class="number">1</span>).t().repeat(</span><br><span class="line">    batch * num_anchors, <span class="number">1</span>, <span class="number">1</span>).view(batch * num_anchors * h * w).cuda()</span><br><span class="line">print(<span class="string">&quot;outputs shape&quot;</span>, output.shape)</span><br><span class="line">xs = torch.sigmoid(output[<span class="number">0</span>]) + grid_x</span><br><span class="line">ys = torch.sigmoid(output[<span class="number">1</span>]) + grid_y</span><br></pre></td></tr></table></figure><p>之后为处理w,h的部分，与处理x,y的部分类似，最终ws和hs为修正后的物品尺寸信息，实现了$ws = e^w\cdot W$和$hs = e^{h} \cdot H$。其中W和H分别为当前anchor box的建议尺寸。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">anchor_w = torch.Tensor(anchors).view(</span><br><span class="line">    num_anchors, anchor_step).index_select(<span class="number">1</span>, torch.LongTensor([<span class="number">0</span>]))</span><br><span class="line">anchor_h = torch.Tensor(anchors).view(</span><br><span class="line">    num_anchors, anchor_step).index_select(<span class="number">1</span>, torch.LongTensor([<span class="number">1</span>]))</span><br><span class="line">anchor_w = anchor_w.repeat(batch, <span class="number">1</span>).repeat(</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, h * w).view(batch * num_anchors * h * w).cuda()</span><br><span class="line">anchor_h = anchor_h.repeat(batch, <span class="number">1</span>).repeat(</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, h * w).view(batch * num_anchors * h * w).cuda()</span><br><span class="line">ws = torch.exp(output[<span class="number">2</span>]) * anchor_w</span><br><span class="line">hs = torch.exp(output[<span class="number">3</span>]) * anchor_h</span><br></pre></td></tr></table></figure><p>接下来是获取置信度的部分和类别部分，获取该anchor box的置信度为<code>det_confs=sigmoid(c)</code>。随后处理类别信息，先对类别信息对应的数据做softmax操作，随后获取其最大值<code>cls_max_confs</code>和最大值所在的位置<code>cls_max_ids</code>，其中位置<code>cls_max_ids</code>对应每个anchor box框住的“物品”的类别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">det_confs = torch.sigmoid(output[<span class="number">4</span>])</span><br><span class="line">cls_confs = torch.nn.Softmax()(</span><br><span class="line">    Variable(output[<span class="number">5</span>:<span class="number">5</span> + num_classes].transpose(<span class="number">0</span>, <span class="number">1</span>))).data</span><br><span class="line">cls_max_confs, cls_max_ids = torch.<span class="built_in">max</span>(cls_confs, <span class="number">1</span>)</span><br><span class="line">cls_max_confs = cls_max_confs.view(-<span class="number">1</span>)</span><br><span class="line">cls_max_ids = cls_max_ids.view(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>随后是一些其他的处理过程，例如获取格点数量<code>sz_hw</code>，anchor box的数量<code>sz_hwa</code>等，函数<code>convert2cpu</code>是在CPU上复制一个该数据，注意这里是拷贝，并不是将数据从GPU转移到CPU上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sz_hw = h * w</span><br><span class="line">sz_hwa = sz_hw * num_anchors</span><br><span class="line">det_confs = convert2cpu(det_confs)</span><br><span class="line">cls_max_confs = convert2cpu(cls_max_confs)</span><br><span class="line">cls_max_ids = convert2cpu_long(cls_max_ids)</span><br><span class="line">xs = convert2cpu(xs)</span><br><span class="line">ys = convert2cpu(ys)</span><br><span class="line">ws = convert2cpu(ws)</span><br><span class="line">hs = convert2cpu(hs)</span><br><span class="line"><span class="keyword">if</span> validation:</span><br><span class="line">    cls_confs = convert2cpu(cls_confs.view(-<span class="number">1</span>, num_classes))</span><br></pre></td></tr></table></figure><p>随后是一个解码的大循环，分析见下面的注释</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(batch):</span><br><span class="line">    boxes = []</span><br><span class="line">    <span class="comment"># boxes为容纳所有候选框的list</span></span><br><span class="line">    <span class="keyword">for</span> cy <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">        <span class="keyword">for</span> cx <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_anchors):</span><br><span class="line">                <span class="comment"># 遍历每一个anchor box，这里访问位于格点cx,cy的第i个anchor box</span></span><br><span class="line">                ind = b * sz_hwa + i * sz_hw + cy * w + cx</span><br><span class="line">                <span class="comment"># 获取该anchor box在det_conf中对应的index</span></span><br><span class="line">                det_conf = det_confs[ind]</span><br><span class="line">                <span class="keyword">if</span> only_objectness:</span><br><span class="line">                    conf = det_confs[ind]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    conf = det_confs[ind] * cls_max_confs[ind]</span><br><span class="line">                <span class="comment"># 处理置信度</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> conf &gt; conf_thresh:</span><br><span class="line">                    <span class="comment"># 若置信度大于阈值，则认为该anchor box有效</span></span><br><span class="line">                    bcx = xs[ind]</span><br><span class="line">                    bcy = ys[ind]</span><br><span class="line">                    bw = ws[ind]</span><br><span class="line">                    bh = hs[ind]</span><br><span class="line">                    cls_max_conf = cls_max_confs[ind]</span><br><span class="line">                    cls_max_id = cls_max_ids[ind]</span><br><span class="line">                    <span class="comment"># 获取所有相关信息，包括长，宽，位置，置信度和类别</span></span><br><span class="line">                    box = [bcx / w, bcy / h, bw / w, bh / h,</span><br><span class="line">                           det_conf, cls_max_conf, cls_max_id]</span><br><span class="line">                    <span class="comment"># 处理数据，其中位置信息x,y,尺寸信息w,h均归一化，使其与输入图片尺寸解耦</span></span><br><span class="line">                    <span class="keyword">if</span> (<span class="keyword">not</span> only_objectness) <span class="keyword">and</span> validation:</span><br><span class="line">                        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">                            tmp_conf = cls_confs[ind][c]</span><br><span class="line">                            <span class="keyword">if</span> c != cls_max_id <span class="keyword">and</span> det_confs[ind] * tmp_conf &gt; conf_thresh:</span><br><span class="line">                                box.append(tmp_conf)</span><br><span class="line">                                box.append(c)</span><br><span class="line">                    boxes.append(box)</span><br><span class="line">                    <span class="comment"># 将处理好的anchor box信息保存在boxes中</span></span><br><span class="line">    all_boxes.append(boxes)</span><br><span class="line">    <span class="keyword">return</span> all_boxes</span><br></pre></td></tr></table></figure><h2 id="NMS部分"><a href="#NMS部分" class="headerlink" title="NMS部分"></a>NMS部分</h2><p>NMS也在<code>utils.py</code>中，函数名为<code>nms</code>。该函数中，首先实现对所有候选框的排序。这里使用<code>det_confs</code>获取了置信度从大到小的anchor box的坐标位置<code>sortIds</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nms</span>(<span class="params">boxes, nms_thresh</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(boxes) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> boxes</span><br><span class="line"></span><br><span class="line">    det_confs = torch.zeros(<span class="built_in">len</span>(boxes))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(boxes)):</span><br><span class="line">        det_confs[i] = <span class="number">1</span> - boxes[i][<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">    _, sortIds = torch.sort(det_confs)</span><br></pre></td></tr></table></figure><p>随后实现候选框的筛选，从高置信度的候选框开始遍历，对于每个候选框<code>boxes[sortIds[i]]</code>，遍历所有置信度低于该候选框且置信度不为0（置信度为0表示该候选框被抛弃）的候选框，若低置信度候选框与高置信度候选框的IOU大于阈值，则抛弃低置信度候选框。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">out_boxes = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(boxes)):</span><br><span class="line">    <span class="comment"># 按置信度从高到低遍历</span></span><br><span class="line">    box_i = boxes[sortIds[i]]</span><br><span class="line">    <span class="keyword">if</span> box_i[<span class="number">4</span>] &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 置信度大于0表示该候选框没有在之前的筛选中被抛弃</span></span><br><span class="line">        out_boxes.append(box_i)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(boxes)):</span><br><span class="line">            <span class="comment"># 遍历所有置信度低于该候选框的候选框</span></span><br><span class="line">            box_j = boxes[sortIds[j]]</span><br><span class="line">            <span class="keyword">if</span> bbox_iou(box_i, box_j, x1y1x2y2=<span class="literal">False</span>) &gt; nms_thresh:</span><br><span class="line">                <span class="comment"># 若置信度低的候选框与该候选框IOU大于一定值，抛弃低置信度候选框</span></span><br><span class="line">                box_j[<span class="number">4</span>] = <span class="number">0</span></span><br><span class="line"><span class="keyword">return</span> out_boxes</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络压缩实验-Deep-compression</title>
      <link href="2018/10/05/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%8B%E7%BC%A9%E5%AE%9E%E9%AA%8C-Deep-compression/"/>
      <url>2018/10/05/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%8B%E7%BC%A9%E5%AE%9E%E9%AA%8C-Deep-compression/</url>
      
        <content type="html"><![CDATA[<h1 id="实验准备"><a href="#实验准备" class="headerlink" title="实验准备"></a>实验准备</h1><h2 id="基础网络搭建"><a href="#基础网络搭建" class="headerlink" title="基础网络搭建"></a>基础网络搭建</h2><p>为了实现神经网络的deep compression，首先要训练一个深度神经网络，为了方便实现，这里实现一个两层卷积+两层MLP的神经网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">net</span>(<span class="params">pt.nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(net,self).__init__()</span><br><span class="line">        self.conv1 = pt.nn.Conv2d(in_channels=<span class="number">1</span>,out_channels=<span class="number">64</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.conv2 = pt.nn.Conv2d(in_channels=<span class="number">64</span>,out_channels=<span class="number">256</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.fc1 = pt.nn.Linear(in_features=<span class="number">7</span>*<span class="number">7</span>*<span class="number">256</span>,out_features=<span class="number">512</span>)</span><br><span class="line">        self.fc2 = pt.nn.Linear(in_features=<span class="number">512</span>,out_features=<span class="number">10</span>)</span><br><span class="line">        self.pool = pt.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.pool(pt.nn.functional.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(pt.nn.functional.relu(self.conv2(x)))</span><br><span class="line">        x = pt.nn.functional.relu(self.fc1(x.view((-<span class="number">1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">256</span>))))</span><br><span class="line">        <span class="keyword">return</span> self.fc2(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = net().cuda()</span><br><span class="line">print(model)</span><br><span class="line">print(model(pt.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>).cuda()))</span><br></pre></td></tr></table></figure><pre><code>net(  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  (conv2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  (fc1): Linear(in_features=12544, out_features=512, bias=True)  (fc2): Linear(in_features=512, out_features=10, bias=True)  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))tensor(1.00000e-02 *       [[-7.7157,  3.0435, -6.5732,  6.5343, -4.2159, -2.8651, -0.6792,          3.9223, -3.7523,  2.4532]], device=&#39;cuda:0&#39;)</code></pre><h2 id="基础网络训练"><a href="#基础网络训练" class="headerlink" title="基础网络训练"></a>基础网络训练</h2><h3 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = ptv.datasets.MNIST(<span class="string">&quot;./&quot;</span>,download=<span class="literal">True</span>,transform=ptv.transforms.ToTensor())</span><br><span class="line">test_dataset = ptv.datasets.MNIST(<span class="string">&quot;./&quot;</span>,train=<span class="literal">False</span>,transform=ptv.transforms.ToTensor())</span><br><span class="line">trainloader = pt.utils.data.DataLoader(train_dataset,shuffle=<span class="literal">True</span>,batch_size=<span class="number">128</span>)</span><br><span class="line">testloader = pt.utils.data.DataLoader(test_dataset,shuffle=<span class="literal">True</span>,batch_size=<span class="number">128</span>)</span><br></pre></td></tr></table></figure><h3 id="代价函数与优化器"><a href="#代价函数与优化器" class="headerlink" title="代价函数与优化器"></a>代价函数与优化器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br><span class="line">optimizer = pt.optim.Adam(model.parameters(),<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">acc</span>(<span class="params">outputs,label</span>):</span></span><br><span class="line">    _,data = pt.<span class="built_in">max</span>(outputs,dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> pt.mean((data.<span class="built_in">float</span>()==label.<span class="built_in">float</span>()).<span class="built_in">float</span>()).item()</span><br></pre></td></tr></table></figure><h3 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> i,(data,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">        data,label = data.cuda(),label.cuda()</span><br><span class="line">        model.zero_grad()</span><br><span class="line">        outputs = model(data)</span><br><span class="line">        loss = lossfunc(outputs,label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(i,acc(outputs,label))</span><br></pre></td></tr></table></figure><pre><code>0 0.1171875100 0.8984375200 0.953125300 0.984375400 0.96875</code></pre><h3 id="测试网络"><a href="#测试网络" class="headerlink" title="测试网络"></a>测试网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_model</span>(<span class="params">model,testloader</span>):</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> data,label <span class="keyword">in</span> testloader:</span><br><span class="line">        data,label = data.cuda(),label.cuda()</span><br><span class="line">        outputs = model(data)</span><br><span class="line">        result.append(acc(outputs,label))</span><br><span class="line">    result = <span class="built_in">sum</span>(result) / <span class="built_in">len</span>(result)</span><br><span class="line">    print(result)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">test_model(model,testloader)</span><br></pre></td></tr></table></figure><pre><code>0.96875</code></pre><h3 id="保存网络"><a href="#保存网络" class="headerlink" title="保存网络"></a>保存网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pt.save(model.state_dict(),<span class="string">&quot;./base.ptb&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="剪枝实验"><a href="#剪枝实验" class="headerlink" title="剪枝实验"></a>剪枝实验</h1><p>剪枝是deep compression的第一步，含义是将部分较小（小于某个阈值)的权值置位为0，表示这个连接被剪掉，且在之后的微调过程中，这个连接的梯度也将被置位为0，即不参加训练</p><h2 id="准备相关工具"><a href="#准备相关工具" class="headerlink" title="准备相关工具"></a>准备相关工具</h2><p>剪枝实验需要准备一些函数：剪枝函数，梯度剪枝函数和稀疏度评估函数</p><h3 id="剪枝函数"><a href="#剪枝函数" class="headerlink" title="剪枝函数"></a>剪枝函数</h3><p>剪枝函数输入模型和阈值，将所有绝对值小于阈值的权值置位为0</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">puring</span>(<span class="params">model,threshold</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> model.parameters():</span><br><span class="line">        i.data[pt.<span class="built_in">abs</span>(i) &lt; threshold] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h3 id="梯度剪枝函数"><a href="#梯度剪枝函数" class="headerlink" title="梯度剪枝函数"></a>梯度剪枝函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grad_puring</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> model.parameters():</span><br><span class="line">        mask = i.clone()</span><br><span class="line">        mask[mask != <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        i.grad.data.mul_(mask)</span><br></pre></td></tr></table></figure><h3 id="稀疏度评估函数"><a href="#稀疏度评估函数" class="headerlink" title="稀疏度评估函数"></a>稀疏度评估函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_sparse</span>(<span class="params">model</span>):</span></span><br><span class="line">    result = []</span><br><span class="line">    total_num = <span class="number">0</span></span><br><span class="line">    total_sparse = <span class="number">0</span></span><br><span class="line">    print(<span class="string">&quot;-----------------------------------&quot;</span>)</span><br><span class="line">    print(<span class="string">&quot;Layer sparse&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> name,f <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">        num = f.view(-<span class="number">1</span>).shape[<span class="number">0</span>]</span><br><span class="line">        total_num += num</span><br><span class="line">        sparse = pt.nonzero(f).shape[<span class="number">0</span>]</span><br><span class="line">        total_sparse+= sparse</span><br><span class="line">        print(<span class="string">&quot;\t&quot;</span>,name,(sparse)/num)</span><br><span class="line">        result.append((sparse)/num)</span><br><span class="line">    total = total_sparse/total_num</span><br><span class="line">    print(<span class="string">&quot;Total:&quot;</span>,total)</span><br><span class="line">    <span class="keyword">return</span> total</span><br></pre></td></tr></table></figure><h2 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h2><p>首先，查看原有网络的稀疏度情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = net().cuda()</span><br><span class="line">model.load_state_dict(pt.load(<span class="string">&quot;./base.ptb&quot;</span>))</span><br><span class="line">_ = test_model(model,testloader)</span><br></pre></td></tr></table></figure><pre><code>0.96875</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print_sparse(model)</span><br></pre></td></tr></table></figure><pre><code>-----------------------------------Layer sparse     conv1.weight 1.0     conv1.bias 1.0     conv2.weight 1.0     conv2.bias 1.0     fc1.weight 1.0     fc1.bias 1.0     fc2.weight 1.0     fc2.bias 1.0Total: 1.0</code></pre><p>可以发现，原有网络完全没有稀疏性，现在进行剪枝，使用阈值为0.01进行剪枝，小于0.01的连接将被剪掉。根据结果可以发现，在阈值0.01下，剪枝后仅剩8.3%参数，且<strong>准确率不受影响</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model1 = puring(model,<span class="number">0.01</span>)</span><br><span class="line">test_model(model1,testloader)</span><br><span class="line">print_sparse(model1)</span><br></pre></td></tr></table></figure><pre><code>0.9706289556962026-----------------------------------Layer sparse     conv1.weight 0.9739583333333334     conv1.bias 0.90625     conv2.weight 0.7641262478298612     conv2.bias 0.71875     fc1.weight 0.06729390669842156     fc1.bias 0.025390625     fc2.weight 0.7837890625     fc2.bias 0.9Total: 0.083586734751286470.08358673475128647</code></pre><p>现在调整阈值为0.1，准确率大幅度下降，现在仅剩很少的参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(pt.load(<span class="string">&quot;./base.ptb&quot;</span>))</span><br><span class="line">model2 = puring(model,<span class="number">0.1</span>)</span><br><span class="line">test_model(model2,testloader)</span><br><span class="line">print_sparse(model2)</span><br></pre></td></tr></table></figure><pre><code>0.09760680379746836-----------------------------------Layer sparse     conv1.weight 0.671875     conv1.bias 0.6875     conv2.weight 0.0     conv2.bias 0.0     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.0     fc2.bias 0.0Total: 6.553616029871108e-056.553616029871108e-05</code></pre><p>现在进行阈值的格点扫描，扫描的范围从0.1到0.01，步长为0.01</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sparse_list = []</span><br><span class="line">threshold_list = [x*<span class="number">0.01</span>+<span class="number">0.01</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">acc_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> threshold_list:</span><br><span class="line">    model.load_state_dict(pt.load(<span class="string">&quot;./base.ptb&quot;</span>))</span><br><span class="line">    model3 = puring(model,i)</span><br><span class="line">    acc_list.append(test_model(model3,testloader))</span><br><span class="line">    sparse_list.append(print_sparse(model3))</span><br><span class="line">    threshold_list.append</span><br></pre></td></tr></table></figure><pre><code>0.9706289556962026-----------------------------------Layer sparse     conv1.weight 0.9739583333333334     conv1.bias 0.90625     conv2.weight 0.7641262478298612     conv2.bias 0.71875     fc1.weight 0.06729390669842156     fc1.bias 0.025390625     fc2.weight 0.7837890625     fc2.bias 0.9Total: 0.083586734751286470.47735363924050633-----------------------------------Layer sparse     conv1.weight 0.9375     conv1.bias 0.890625     conv2.weight 0.5333726671006944     conv2.bias 0.4765625     fc1.weight 0.0015011222995057398     fc1.bias 0.0     fc2.weight 0.5765625     fc2.bias 0.7Total: 0.013984291392927750.09513449367088607-----------------------------------Layer sparse     conv1.weight 0.9045138888888888     conv1.bias 0.890625     conv2.weight 0.3156263563368056     conv2.bias 0.2578125     fc1.weight 1.5414490991709182e-05     fc1.bias 0.0     fc2.weight 0.371875     fc2.bias 0.4Total: 0.0074799415253229590.09612341772151899-----------------------------------Layer sparse     conv1.weight 0.8732638888888888     conv1.bias 0.875     conv2.weight 0.13545735677083334     conv2.bias 0.0546875     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.1615234375     fc2.bias 0.1Total: 0.0032501982050694880.09691455696202532-----------------------------------Layer sparse     conv1.weight 0.8402777777777778     conv1.bias 0.84375     conv2.weight 0.03839111328125     conv2.bias 0.00390625     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.016796875     fc2.bias 0.0Total: 0.00095582437038909010.1003757911392405-----------------------------------Layer sparse     conv1.weight 0.8142361111111112     conv1.bias 0.796875     conv2.weight 0.0084228515625     conv2.bias 0.0     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.0     fc2.bias 0.0Total: 0.000267922771337190060.09760680379746836-----------------------------------Layer sparse     conv1.weight 0.7760416666666666     conv1.bias 0.765625     conv2.weight 0.0014580620659722222     conv2.bias 0.0     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.0     fc2.bias 0.0Total: 0.000108111856084416660.09760680379746836-----------------------------------Layer sparse     conv1.weight 0.7447916666666666     conv1.bias 0.734375     conv2.weight 0.00014241536458333334     conv2.bias 0.0     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.0     fc2.bias 0.0Total: 7.55718600196274e-050.09968354430379747-----------------------------------Layer sparse     conv1.weight 0.7065972222222222     conv1.bias 0.71875     conv2.weight 0.0     conv2.bias 0.0     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.0     fc2.bias 0.0Total: 6.888139353901653e-050.09760680379746836-----------------------------------Layer sparse     conv1.weight 0.671875     conv1.bias 0.6875     conv2.weight 0.0     conv2.bias 0.0     fc1.weight 0.0     fc1.bias 0.0     fc2.weight 0.0     fc2.bias 0.0Total: 6.553616029871108e-05</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">3</span>))</span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">plt.plot(threshold_list,acc_list)</span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">plt.plot(threshold_list,acc_list)</span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">plt.plot(sparse_list,acc_list)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2018/10/05/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8E%8B%E7%BC%A9%E5%AE%9E%E9%AA%8C-Deep-compression/output_30_0.png" class=""><p>上图自左向右分别是阈值-准确率，阈值-稀疏度和稀疏度-准确率关系</p><h2 id="剪枝后微调"><a href="#剪枝后微调" class="headerlink" title="剪枝后微调"></a>剪枝后微调</h2><p>我们发现，阈值为大约0.02时，准确率仅为47%左右，考虑使用微调阈值的方式进行调整</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = net().cuda()</span><br><span class="line">model.load_state_dict(pt.load(<span class="string">&quot;./base.ptb&quot;</span>))</span><br><span class="line">model1 = puring(model,<span class="number">0.02</span>)</span><br><span class="line">test_model(model1,testloader)</span><br><span class="line">print_sparse(model1)</span><br></pre></td></tr></table></figure><pre><code>0.4759691455696203-----------------------------------Layer sparse     conv1.weight 0.9375     conv1.bias 0.890625     conv2.weight 0.5333726671006944     conv2.bias 0.4765625     fc1.weight 0.0015011222995057398     fc1.bias 0.0     fc2.weight 0.5765625     fc2.bias 0.7Total: 0.01398429139292775</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">optimizer = pt.optim.Adam(model1.parameters(),<span class="number">1e-5</span>)</span><br><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> i,(data,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">        data,label = data.cuda(),label.cuda()</span><br><span class="line">        outputs = model1(data)</span><br><span class="line">        loss = lossfunc(outputs,label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        grad_puring(model1)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(i,acc(outputs,label))</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>0 0.4375100 0.4375200 0.5625300 0.6015625400 0.68750 0.7265625100 0.6953125200 0.7890625300 0.8046875400 0.77343750 0.8125100 0.8046875200 0.890625300 0.8515625400 0.8750 0.859375100 0.8515625200 0.9140625300 0.890625400 0.9296875</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_model(model1,testloader)</span><br><span class="line">print_sparse(model1)</span><br><span class="line">pt.save(model1.state_dict(),<span class="string">&#x27;./puring.pt&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>0.9367088607594937-----------------------------------Layer sparse     conv1.weight 0.9375     conv1.bias 0.890625     conv2.weight 0.5333726671006944     conv2.bias 0.4765625     fc1.weight 0.0015011222995057398     fc1.bias 0.0     fc2.weight 0.5765625     fc2.bias 0.7Total: 0.01398429139292775</code></pre><p>由上发现，经过权值微调后，在保持原有的稀疏度的情况下将准确率提高到了90%以上</p><h1 id="量化实验"><a href="#量化实验" class="headerlink" title="量化实验"></a>量化实验</h1><p>量化过程比较复杂，分为量化和微调两个步骤，量化步骤使用sklearn的k-mean实现，微调使用pytorch本身实现</p><h2 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = net().cuda()</span><br><span class="line">model.load_state_dict(pt.load(<span class="string">&quot;./puring.pt&quot;</span>))</span><br><span class="line">test_model(model,testloader)</span><br></pre></td></tr></table></figure><pre><code>0.9367088607594937</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">kmean_list = []</span><br><span class="line">bit = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> name,i <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    data = i.data.clone().view(-<span class="number">1</span>).cpu().detach().numpy().reshape(-<span class="number">1</span>)</span><br><span class="line">    data = data[data != <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> data.size &lt; <span class="number">2</span> ** bit:</span><br><span class="line">        kmean_list.append(<span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    init = [x*(np.<span class="built_in">max</span>(data)+np.<span class="built_in">min</span>(data))/(<span class="number">2</span> ** bit) + np.<span class="built_in">min</span>(data) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** bit)]</span><br><span class="line">    kmn = KMeans(<span class="number">2</span> ** bit,init=np.array(init).reshape(<span class="number">2</span> ** bit,<span class="number">1</span>))</span><br><span class="line">    kmn.fit(data.reshape((-<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    kmean_list.append(kmn)</span><br><span class="line">    print(name,i.shape)</span><br></pre></td></tr></table></figure><pre><code>conv1.weight torch.Size([64, 1, 3, 3])conv1.bias torch.Size([64])conv2.weight torch.Size([256, 64, 3, 3])conv2.bias torch.Size([256])fc1.weight torch.Size([512, 12544])fc2.weight torch.Size([10, 512])fc2.bias torch.Size([10])c:\program files\python35\lib\site-packages\sklearn\cluster\k_means_.py:896: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10  return_n_iter=True)</code></pre><p>训练完量化器后，将每一层数据使用对应的量化器进行量化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i,(name,f) <span class="keyword">in</span> <span class="built_in">enumerate</span>(model.named_parameters()):</span><br><span class="line">    data = f.data.clone().view(-<span class="number">1</span>).cpu().detach().numpy().reshape(-<span class="number">1</span>)</span><br><span class="line">    data_nozero = data[data != <span class="number">0</span>].reshape((-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> data_nozero.size == <span class="number">0</span> <span class="keyword">or</span> data.size &lt; <span class="number">2</span> ** bit <span class="keyword">or</span> kmean_list[i] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        f.kmeans_result = <span class="literal">None</span></span><br><span class="line">        f.kmeans_label = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"><span class="comment">#     print(name)</span></span><br><span class="line"><span class="comment">#     print(data.size)</span></span><br><span class="line"></span><br><span class="line">    result = data.copy()</span><br><span class="line">    result[result == <span class="number">0</span>] = -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#     print(data_nozero)</span></span><br><span class="line"><span class="comment">#     print(kmean_list[i])</span></span><br><span class="line">    label = kmean_list[i].predict(data_nozero).reshape(-<span class="number">1</span>)</span><br><span class="line"><span class="comment">#     print(data_nozero)</span></span><br><span class="line"><span class="comment">#     print(label)</span></span><br><span class="line">    new_data = np.array([kmean_list[i].cluster_centers_[x] <span class="keyword">for</span> x <span class="keyword">in</span> label])</span><br><span class="line">    data[data != <span class="number">0</span>] = new_data.reshape(-<span class="number">1</span>)</span><br><span class="line"><span class="comment">#     print(data,new_data)</span></span><br><span class="line">    f.data = pt.from_numpy(data).view(f.data.shape).cuda()</span><br><span class="line">    result[result != -<span class="number">1</span>] = label</span><br><span class="line">    f.kmeans_result = pt.from_numpy(result).view(f.data.shape).cuda()</span><br><span class="line">    f.kmeans_label = pt.from_numpy(kmean_list[i].cluster_centers_).cuda()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_model(model,testloader)</span><br><span class="line">print_sparse(model)</span><br></pre></td></tr></table></figure><pre><code>0.8919106012658228-----------------------------------Layer sparse     conv1.weight 0.9375     conv1.bias 0.890625     conv2.weight 0.5333726671006944     conv2.bias 0.4765625     fc1.weight 0.0015011222995057398     fc1.bias 0.0     fc2.weight 0.5765625     fc2.bias 0.7Total: 0.013984291392927750.01398429139292775</code></pre><p>由上可以发现，对于这种玩具级的网络来说，2bit量化已经完全足够了，精度损失3个百分点</p><h2 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br><span class="line">lr = <span class="number">0.001</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> a,(data,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">        data,label = data.cuda(),label.cuda()</span><br><span class="line">        model.zero_grad()</span><br><span class="line">        outputs = model(data)</span><br><span class="line">        loss = lossfunc(outputs,label)</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> name,i <span class="keyword">in</span> model.named_parameters():</span><br><span class="line"><span class="comment">#             print(i.data)</span></span><br><span class="line"><span class="comment">#             break</span></span><br><span class="line">            <span class="keyword">if</span> i.kmeans_result <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** bit):</span><br><span class="line">                grad = pt.<span class="built_in">sum</span>(i.grad.detach()[i.kmeans_result == x])</span><br><span class="line"><span class="comment">#                 print(grad.item())</span></span><br><span class="line">                i.kmeans_label[x] += -lr * grad.item()</span><br><span class="line">                i.data[i.kmeans_result == x] = i.kmeans_label[x].item()</span><br><span class="line"><span class="comment">#                 print(i.data)</span></span><br><span class="line"><span class="comment">#                 break</span></span><br><span class="line"><span class="comment">#             print(name)</span></span><br><span class="line"><span class="comment">#             test_model(model,testloader)</span></span><br><span class="line"><span class="comment">#             break</span></span><br><span class="line">        <span class="keyword">if</span> a % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(a,acc(outputs,label))</span><br><span class="line"><span class="comment">#         break</span></span><br><span class="line"><span class="comment">#     break</span></span><br></pre></td></tr></table></figure><pre><code>0 0.8828125100 0.921875200 0.9296875300 0.9296875400 0.9140625</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_model(model,testloader)</span><br><span class="line">print_sparse(model)</span><br><span class="line">pt.save(model.state_dict(),<span class="string">&quot;quantization.pt&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>0.9384889240506329-----------------------------------Layer sparse     conv1.weight 0.9375     conv1.bias 0.890625     conv2.weight 0.5333726671006944     conv2.bias 0.4765625     fc1.weight 0.0015011222995057398     fc1.bias 0.0     fc2.weight 0.5765625     fc2.bias 0.7Total: 0.01398429139292775</code></pre><p>通过对量化中心的微调，2bit量化网络的准确率已经与非量化网络的准确率相当</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep-compression阅读笔记</title>
      <link href="2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
      <url>2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h1><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/pipeline.png" class=""><p>以上是Deep compression中所述的神经网络压缩方法，主要包括三个步骤：</p><ul><li>剪枝：将部分很小的（认为不重要的）权值设为0，使权值矩阵转为一个稀疏矩阵</li><li>量化：将剪枝后保留的权值进行量化，使剪枝后保留的权值共享一些的使用一些值，这样可以减小保存权值使用的空间，进一步压缩所需要的存储空间</li><li>霍夫曼编码（可选）：霍夫曼编码是一种编码形式，可以减小数据的保存需要的存储空间</li></ul><p>经过以上的步骤，神经网络的存储空间可以被压缩到一个很小的值，同时提高预测运行的速度，降低功耗，且并几乎不损失准确率。</p><h2 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h2><p>剪枝的实现非常方便，即设定一个阈值，绝对值大于这个阈值的权值被保留，其他权值被置0，公式如下所示：</p><script type="math/tex; mode=display">pruning(x) = \begin{cases} 0 & |x| \leq TH \\ x & |x| > TH\end{cases}</script><p>剪枝过后，权值矩阵由稠密矩阵转为稀疏矩阵（或由稀疏矩阵转为更稀疏的矩阵），由此权值矩阵可以使用存储稀疏矩阵的压缩存储方式存储，例如CSR(compressed sparse row) 或CSC(compressed sparse column)。该论文在CSR和CSC的基础上，将index上的值由绝对坐标转为偏移量，如下所示：</p><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/pruning.PNG" class=""><p>即原来的存储方式为：</p><div class="table-container"><table><thead><tr><th>idx</th><th>1</th><th>4</th><th>15</th></tr></thead><tbody><tr><td>value</td><td>3.4</td><td>0.9</td><td>1.7</td></tr></tbody></table></div><p>现在的存储方式为：</p><div class="table-container"><table><thead><tr><th>diff（3bit）</th><th>1</th><th>3</th><th>8</th><th>3</th></tr></thead><tbody><tr><td>value</td><td>3.4</td><td>0.9</td><td>0</td><td>1.7</td></tr></tbody></table></div><p>这样的好处是diff可以使用更少的bit为存储，若发生偏移量超过bit位可表示的范围时，插入额外的0以补齐偏移。</p><h2 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h2><p>量化是一种近似的过程，以适度的误差为代价，使无限精度（或很高精度）的数值可以使用较少的位数表示。这里的量化是指定一系列值，使所有的权值都从中进行选择，即完成所有权值的数值共享。该过程分为以下几个步骤：</p><ul><li>初始化k-means质心：因为量化过程通过k-means实现，k-means质心的初值对结果的影响很大，有三种方法：均匀量化，随机量化和按密度量化，论文中证明使用均匀量化的初始化效果较好，均匀量化的量化输出为在权值的最大值和最小值之间隔均匀的去量化输出，如下所示，其中n为量化的位数：</li></ul><script type="math/tex; mode=display">c_k^{init} = w_{min} + k \times \cfrac{w_{max} - w_{min}}{2^n}</script><ul><li>确定量化阈值：即确定对于每一个权值$w_{ij}$使用哪个量化输出$c_k$代替值，这一步通常使用一维的k-means确定，k-means的初值由上一步确定。一个簇内的权值均共享一个值（质心值）。需要注意的是，一旦某个权值指定了使用量化输出$c_k$的值量化，这一选择关系不再发生改变，即使下一步量化输出微调后单个权值的量化误差变大。</li><li>进行微调：对k-means的质心再进行微调，参考为反向权值，如下图所示：</li></ul><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/Quantization.PNG" class=""><p>微调过程中，首先进行正常的前向传播和反向传播，注意由于由于剪枝的作用，矩阵已经成为稀疏矩阵，权值矩阵中为0表示该连接被移除，因此这些位置的梯度被舍弃（置0）。微调的对象为<strong>类聚质心</strong>即量化后的输出。上一步完成后，每一个权值对应的簇已经确定，在图中的<code>cluster_index</code>表示量化类聚的结果，同时该结果在weights和gradient的图中以颜色标注，例如weights中的2.09（第一行第一列）和2.12（第二行第四列）为同一簇，量化后使用同一值表示。</p><p>当生成梯度矩阵后，对类聚质心进行微调，微调的方式是对属于同一簇的所有权值对应的梯度进行求和，乘以学习率，再从质心中减去，公式如下：</p><script type="math/tex; mode=display">c_k^n = c_k^{n-1} - lr \times \sum\limits_{w_{ij} \in C_k}{grad(w_{ij})}</script><p>其中$c_k^n$为第n次微调后的结果，lr为学习率，$C_k$为类聚属于k簇的所有权值构成的集合，$grad(w)$表示权值w对应的梯度。微调过程的初值$c_k^0$为k-means输出的类聚质心。</p><p>完成量化后，原来的稀疏矩阵变为一个稀疏矩阵加一个查找表，即原来的稀疏矩阵存储权值w的位置变为存储w所属簇编号k，簇编号k的位数小于权值w的位数，达到了压缩的目的。查找表索引为簇编号，值为该簇的类聚质心$c_k$（量化输出）。还原一个矩阵的过程变为首先从稀疏矩阵中读出对应的簇编号，再从查找表中查找该类对应的值。如上图的例子，存储结果为：</p><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/store.PNG" class=""><h2 id="霍夫曼编码"><a href="#霍夫曼编码" class="headerlink" title="霍夫曼编码"></a>霍夫曼编码</h2><p>霍夫曼编码是进一步压缩的方式，这种编码使用变长编码表进行编码，可以进一步压缩存储所需要的空间，在进行运算的过程中从霍夫曼编码的存储中解码出所需要的数据即可。</p><h1 id="相关分析"><a href="#相关分析" class="headerlink" title="相关分析"></a>相关分析</h1><h2 id="量化过程"><a href="#量化过程" class="headerlink" title="量化过程"></a>量化过程</h2><h3 id="压缩比"><a href="#压缩比" class="headerlink" title="压缩比"></a>压缩比</h3><p>这里的考虑的压缩比主要是量化带来的，因为剪枝的压缩比与权值的值情况密切相关，而量化的压缩比主要是由使用低bit的数表示高精度数带来的，公式如下：</p><script type="math/tex; mode=display">r = \cfrac{nb}{nlog_2(k)+kb}</script><p>其中n是权重的数量，b为未量化矩阵的位数，k为量化簇的数量。即每个权值量化后可以使用$log_2(k)$bit表示，这样所有的权值需要的bit数就是$n \times log_2(k)$，初次之外，还需要一张有k个值的查找表，存储需要的bit数为$k \times b$</p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>反向传播过程中微调的对象是类聚质心，因此考虑量化误差为：</p><script type="math/tex; mode=display">loss = \sum\limits_{i=1}^k\sum\limits_{w \in c_k}|w-ci|^2</script><p>这恰好与k-means相符，因此使用k-means进行量化可以尽量减小量化误差。进行微调时，需要考虑量化质心对结果的影响，即量化质心对网络代价函数的影响，梯度传播公式如下：</p><script type="math/tex; mode=display">\cfrac{\partial L}{\partial C_k} = \sum\limits_{i,j}\cfrac{\partial L}{\partial W_{ij}}\cfrac{\partial W_{ij}}{\partial C_k} = \sum\limits_{i,j}\cfrac{\partial L}{\partial W_{ij}}II(I_{ij} == k)</script><p>其中$II(\cdot)$为indicator函数（条件成立为1，否则为0），这一公式与量化的微调过程完全对应。</p><h2 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h2><h3 id="压缩率vs准确率"><a href="#压缩率vs准确率" class="headerlink" title="压缩率vs准确率"></a>压缩率vs准确率</h3><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/a_c.PNG" class=""><p>上图描述了压缩率和准确率的关系，在可以发现无论是单独使用量化与剪枝还是组合使用，都可以在一定的压缩率下达到不损失精度的压缩，同时效果均优于SVD</p><h3 id="量化位数vs准确率"><a href="#量化位数vs准确率" class="headerlink" title="量化位数vs准确率"></a>量化位数vs准确率</h3><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/q_a.PNG" class=""><p>上图表明了量化位数对准确率的影响，同时也表示剪枝过程对量化的影响。可以发现对于论文评估的这种网络，全连接层使用2bit量化，卷积网络使用5bit量化就可以达到很好的结果，同时剪枝对量化的影响很小，可以认为两个过程互不干扰。</p><h3 id="质心初始化方法"><a href="#质心初始化方法" class="headerlink" title="质心初始化方法"></a>质心初始化方法</h3><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/init.PNG" class=""><p>上图表示的是三种不同的初始化方式对压缩后的准确率的影响，可以发现线性量化的初始化方式比较优秀。论文中分析因为较大的权值对结果影响比较大，但是这种权值的数量较小，使用线性初始化的方式倾向于生成一些比较大的类聚质心。</p><h3 id="运行速度与功耗"><a href="#运行速度与功耗" class="headerlink" title="运行速度与功耗"></a>运行速度与功耗</h3><img src="/2018/09/16/Deep-compression%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/speed.PNG" class=""><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Deep compression的方法概括为剪枝+量化+霍夫曼编码，可以在不损失精度的情况将神经网络压缩，其中对于AlexNet可以压缩35倍，VGG-16可以压缩49倍，且推理时使存储的应用更有效。目前，剪枝/稀疏矩阵的运算已经广泛被各种框架支持，然而量化的支持很少，因此可以考虑重写CPU库或设计专用ASIC以实现量化网络的高效运算。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster-RCNN阅读笔记</title>
      <link href="2018/09/05/Faster-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
      <url>2018/09/05/Faster-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h1><img src="/2018/09/05/Faster-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/structure.png" class=""><p>Faster-RCNN是Fast-RCNN的后续版本，主要针对Fast-RCNN速度过慢进行优化。在Fast-RCNN中，速度的瓶颈主要是用于生成候选区域的Selective Search过程。在Faster-RCNN中，候选区域的生成使用RPN网络，且共享的使用了卷积产生的特性，由此将候选区域的生成方式纳入神经网络的范畴下。该系统有以下部分构成：</p><ul><li>卷积神经网络：对待测图片进行几层卷积，产生高级特征，这些高级特征用于RPN生成候选框和RoI池化输入</li><li>PRN网络：根据卷积产生的高级特性生成一系列不考虑物品类别的候选区域，即代替Selective Search方法</li><li>Fast-CNN：RoI pool层输入的Fast-RCNN网络，输入为高级特征和候选区域，生成该候选区域的类别信息和候选区域的调整因子</li></ul><h2 id="PRN网络"><a href="#PRN网络" class="headerlink" title="PRN网络"></a>PRN网络</h2><p>PRN网络用于产生类别无关的候选区域，即代替Selective Search的功能，其结构如下：</p><img src="/2018/09/05/Faster-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/prn_structure.png" class=""><p>其输入为从共享卷积部分的输出feature map，该部分再经过PRN网络的卷积部分，变为PRN feature，其长宽不变，通道数变为$(4+2)n$，其中n为每个点上生成候选框的数量。即每个候选框对应六个数据，分别为：</p><ul><li>位置信息x,y,w,h：包含位置信息，分别是位置和大小的调整系数。</li><li>评分信息a,b：对这个区域是否含有物体的打分，一个为物品的分数，另一个为是背景的分数。</li></ul><p>需要注意的是，位置信息均是调整系数，其和真实位置信息的关系为：</p><script type="math/tex; mode=display">t_x = \cfrac{x-x_a}{w_a} \\t_y = \cfrac{y-y_a}{h_a} \\t_w = log\cfrac{w}{w_a} \\t_h = log\cfrac{h}{h_a}</script><p>其中，$t_x,t_y,t_w,t_h$为网络的输出，$x_a,y_a,w_a,h_a$为anchor box提供的基础框大小，而x,y,w,h为最终预测的结果。这里的anchor box为一种预设为固定大小的框，其长度和宽度为超参数，在训练前指定，其x坐标和y坐标为PRN feature产生该预测框的点在原图中对应的点。例如输入原图大小为400*400，卷积网络使用了三次2*2的池化，feature map的尺寸为50*50，那么在PRN feature中坐标为(4,4)产生的所有anchor box的预设中心坐标$x_a,y_a$均为(32,32)。</p><p>anchor box的尺寸共n个，每个点共享n个anchor box尺寸，该尺寸一般通过类聚数据集上的物品尺寸产生，每个点都按指定的n个anchor box尺寸生成n个anchor box的调整系数和分数，调整后产生RoI的尺寸，注意RoI尺寸是原图上的尺寸，应用到Fast-RCNN上还需要进行缩放变换。</p><h2 id="Fast-RCNN网络"><a href="#Fast-RCNN网络" class="headerlink" title="Fast-RCNN网络"></a>Fast-RCNN网络</h2><img src="/2018/09/05/Faster-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/fast_rcnn_structure.png" class=""><p>这里的Fast-RCNN部分指RoI池化层之后的部分，输入为与PRN共享的卷积网络的输出，输出分为两个部分：</p><ul><li>类别信息：总物体类别加1，即类别+背景，用于判断候选框的物品类别</li><li>调整因子：用于微调PRN的输出结果，该部分输出的每个数据的功能与PRN的4个调整因子相同</li></ul><p>由上图所示，共享卷积层输出的结果与PRN输出的RoI结合通过RoI池化层，获得一个固定大小的RoI feature，该部分经过一个共享的处理（卷积层，全连接层等），获得后续的feature，该feature分别通过两个独立的全连接层，获得类别信息和调整因子。使用其中的调整因子调整PRN输出的RoI数据，获得最终的RoI位置和大小数据。</p><h1 id="系统训练"><a href="#系统训练" class="headerlink" title="系统训练"></a>系统训练</h1><h2 id="标签标注"><a href="#标签标注" class="headerlink" title="标签标注"></a>标签标注</h2><p>标记分为三种，分别是：</p><ul><li>标记为正例：相对于真实物体IoU高于0.7或相对于真实物体IoU在所有候选区域中最高</li><li>标记为反例：相对于真实物体的IoU低于0.3</li><li>不标记：不属于正例也不属于反例的候选区域，这些区域不影响训练过程</li></ul><h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><h3 id="PRN代价函数"><a href="#PRN代价函数" class="headerlink" title="PRN代价函数"></a>PRN代价函数</h3><script type="math/tex; mode=display">L(\{p_i\},\{t_i\}) = \cfrac{1}{N_{cls}}\sum\limits_i{L_{cls}(p_i,p_i^*)}+\lambda\cfrac{1}{N_{reg}}\sum\limits_ip_i^*L_{reg}(t_i,t_i^*)</script><p>PRN网络的代价函数如上所示，其中$i$是anchor box的标号；$p_i$为PRN判定的该anchor box有物体的概率；$p_i^<em>$为该anchor box的标记，若标记正例为1，反例则标记为0；$t_i$为PRN判定的调整因子；$t_i^</em>$为真实的调整因子。</p><p>代价函数分为两个部分，分别是：</p><ul><li>类别代价：$L_{cls}(p_i,p_i^*)$衡量类别判断错误产生的代价，为log代价函数（交叉熵）</li><li>回归代价：$L_{reg}(t_i,t_i^<em>)$衡量调整因子误差产生的代价，为$R(t_i-t_i^</em>)$</li></ul><p>其中，R函数的表达式如下所示：</p><script type="math/tex; mode=display">R(x)=\begin{cases}0.5x^2 & |x| <1 \\ |x|-0.5&otherwise\end{cases}</script><h3 id="Fast-RCNN代价函数"><a href="#Fast-RCNN代价函数" class="headerlink" title="Fast-RCNN代价函数"></a>Fast-RCNN代价函数</h3><p>Fast-RCNN代价函数分为两个部分，如下所示：</p><script type="math/tex; mode=display">L(p,u.t_u,v) = L_{cls}(p,u) + \lambda[u \geq 1]L_{loc}(t^u,v)</script><p>第一个部分$L_{cls}$为分类部分的代价函数，使用交叉熵函数，公式如下，其中u为该RoI区域的标记类别，p为神经网络输出的分类向量：</p><script type="math/tex; mode=display">L_{cls}(p,u) = -log(p_u)</script><p>第二个部分$L<em>{loc}$为调整因子的代价函数，$[u \geq 1]$表示仅当当前位置不是背景时才考虑该部分代价， 超参数$\lambda$表示两个部分之间的权重，论文中取1。$L</em>{loc}$如下所示，其中t为网络输出的调整因子，v为目标调整因子。</p><script type="math/tex; mode=display">L_{loc}(t^u,v) = \sum\limits_{i \in \{x,y,w,h\}}smooth_{L_1}(t^u_i-v_i) \\smooth_{L_1}=\begin{cases}0.5x^2 & |x| <1 \\ |x|-0.5&otherwise\end{cases}</script><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>训练过程包括PRN和Fast-RCNN网络的训练，其中，前段的卷积层还是共享权值的，训练方法如下所示：</p><ol><li>单独训练共享部分和PRN网络，使其能获得类别无关的候选区域</li><li>单独训练共享部分和Fast-RCNN网络，候选区域使用第一步中训练出的PRN获得，注意这里PRN和Fast-RCNN前端卷积（前向传播时共享权值的部分）并没有实现共享权值，PRN和Fast-RCNN是两个完全独立的网络</li><li>将PRN网络与第二步训练出的共享部分连接，并固定共享部分权值，单独微调训练PRN网络</li><li>使用第三步训练产生的PRN产生候选区域，固定共享部分权值，微调Fast-RCNN的ROI池化之后层的参数，注意这一步的PRN和Fast-RCNN网络的前端卷积的权值是共享的</li></ol><img src="/2018/09/05/Faster-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/train.png" class=""><p>Fast-RCNN和PRN的训练都是批处理的，每一批均是从一张图片中获取的anchor box，且要求正例和反例的数量相同，原论文中batch大小是256，由128个正例和128个反例组成。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>流水线式p2p接口的分析与实现</title>
      <link href="2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
      <url>2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="0-简介"><a href="#0-简介" class="headerlink" title="0.简介"></a>0.简介</h1><p>P2P接口是一种双向握手接口，传输的前级和后级各提供一个数据有效信号valid和忙信号busy信号，只有当两个信号达成某种指定情况时，握手完成，数据传输完成，否则数据传输均未完成。这可以看成一种分布式控制方式，每个模块的开发人员仅需要考虑上下级的握手信号即可。</p><h1 id="1-端口"><a href="#1-端口" class="headerlink" title="1.端口"></a>1.端口</h1><div class="table-container"><table><thead><tr><th>端口名</th><th>类型</th><th>位宽</th><th>功能</th></tr></thead><tbody><tr><td>din_valid</td><td>input</td><td>1</td><td>输入数据有效信号</td></tr><tr><td>din_busy</td><td>output</td><td>1</td><td>输入部分忙，不接受输入数据</td></tr><tr><td>dout_valid</td><td>output</td><td>1</td><td>输出有效信号</td></tr><tr><td>dout_busy</td><td>input</td><td>1</td><td>输出部分忙，下一级不接受输入</td></tr><tr><td>din</td><td>input</td><td>-</td><td>输入数据</td></tr><tr><td>dout</td><td>output</td><td>-</td><td>输出数据</td></tr></tbody></table></div><h1 id="2-状态分析"><a href="#2-状态分析" class="headerlink" title="2.状态分析"></a>2.状态分析</h1><h2 id="2-1-输入状态分析"><a href="#2-1-输入状态分析" class="headerlink" title="2.1.输入状态分析"></a>2.1.输入状态分析</h2><div class="table-container"><table><thead><tr><th>din_valid</th><th>din_busy</th><th>状态</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>静默，无数据传输</td></tr><tr><td>1</td><td>0</td><td>正常接收数据，无阻塞情况发生</td></tr><tr><td>0</td><td>1</td><td>输入忙，但无数据输入</td></tr><tr><td>1</td><td>1</td><td>输入数据被阻塞</td></tr></tbody></table></div><h2 id="2-2-输出状态分析"><a href="#2-2-输出状态分析" class="headerlink" title="2.2.输出状态分析"></a>2.2.输出状态分析</h2><div class="table-container"><table><thead><tr><th>dout_valid</th><th>dout_busy</th><th>状态</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>静默，无数据传输</td></tr><tr><td>1</td><td>0</td><td>正常发送数据，无阻塞情况发生</td></tr><tr><td>0</td><td>1</td><td>输出忙，但无数据输出</td></tr><tr><td>1</td><td>1</td><td>输出数据被阻塞</td></tr></tbody></table></div><h2 id="2-3-组合情况分析"><a href="#2-3-组合情况分析" class="headerlink" title="2.3.组合情况分析"></a>2.3.组合情况分析</h2><div class="table-container"><table><thead><tr><th>din_valid</th><th>din_busy</th><th>dout_valid</th><th>dout_busy</th><th>状态</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>1</td><td>全阻塞</td></tr><tr><td>1</td><td>0</td><td>1</td><td>1</td><td>接收在本级被阻塞的数据</td></tr><tr><td>1</td><td>1</td><td>1</td><td>0</td><td>释放被阻塞被本级的数据</td></tr></tbody></table></div><h1 id="3-结构框图"><a href="#3-结构框图" class="headerlink" title="3.结构框图"></a>3.结构框图</h1><h2 id="3-1-结构"><a href="#3-1-结构" class="headerlink" title="3.1.结构"></a>3.1.结构</h2><img src="/2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/p2p_structure.png" class=""><ul><li>Input：数据输入接口</li><li>Lock reg：输入锁存器，当阻塞时在本级存储被阻塞的数据</li><li>combinatiorial logic：处理逻辑，用于处理输入数据</li><li>output reg：输出寄存器</li></ul><h2 id="3-2-分析"><a href="#3-2-分析" class="headerlink" title="3.2.分析"></a>3.2.分析</h2><p>下图分析了一个在四级流水线中数据的传输过程，其中：</p><ul><li>白色的方块表示正常工作没有阻塞的模块</li><li>红色的方块表示阻塞的模块（dout_busy=1）</li><li>箭头上的数据表示在上一个模块输出的数据</li><li>方块中的数据表示被存储在模块中的数据</li></ul><img src="/2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/p2p_analysis.png" class=""><p>分析过程如下：</p><ol><li>最后一级dout_busy=1，din_busy=0，则刚遇到阻塞，将上一级输入存储在本级lock reg中</li><li>最后一级din_busy=1，即第三级dout_busy=1，此时数据B已经位于第三级output reg中，第三级将输入数据C存储在第三级的lock reg中</li><li>…</li><li>当最后一级dout_busy=1且din_busy=0时，下一级阻塞解除，第四级output reg中的数据已经被之后接收</li><li>最后一级din_busy=0即第三级dout_busy=0时，第四级阻塞解除，原先存储在第四级lock reg中的数据A已经被送到output reg中传送到下一级，同时接收存储在第三级output reg中的数据B</li><li>第三级din_busy=0即第二级dout_busy=0时，第三级阻塞解除，原先存储在第三级lock reg中的数据C被送到output reg中传送到下一级，同时接收存储在第二级output reg中的数据D</li><li>…</li></ol><h2 id="3-3-时序图分析"><a href="#3-3-时序图分析" class="headerlink" title="3.3.时序图分析"></a>3.3.时序图分析</h2><img src="/2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/p2p_noraml.png" class=""><p>上图为一个通常情况的可用于流水线的P2P接口时序图，当连续传递无阻塞时（d0和d1），busy信号复位，valid信号和数据相对于上一级延迟一个时钟周期。d2~d5表示的是在流水线过程中发送后级阻塞的处理方法：</p><ul><li>当后级流水线发生阻塞时，该阻塞在一个时钟周期后反馈到前级</li><li>由于前级反馈产生busy信号由后级busy信号寄存产生，而后级的输出由前级输出寄存（处理）产生，因此两个busy信号之间差了两个数据（前级卡在端口的数据为d5，而后级卡在端口的数据为上上个数据d3）</li><li>由于相差两个数据，则需要一个深度为1旁路缓存暂存中间的数据d4</li><li>当后级busy信号复位后，完成未完成传输d3后，立刻从旁路缓存中取出d4进行传输，此时前级的数据d5完成传输，在下一个时钟周期由后级转发</li></ul><img src="/2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/p2p_start_with_busy.png" class=""><p>上图是传输开始时就有后级busy信号的情况，可以发现，该情况与上一种情况相同，参照上一种情况可分析。</p><img src="/2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/p2p_one_cycle.png" class=""><p>上图是仅传输一个单独数据且遇到阻塞的情况，该情况最大的不同是<code>din_valid</code>信号仅置位一个时钟周期，而<code>dout_valid</code>要等发送数据d2完成发送后再复位，因此两个valid信号之间并不是简单的延迟一个周期的关系。</p><img src="/2018/08/19/%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%BC%8Fp2p%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E7%8E%B0/p2p_two_cycle.png" class=""><p>上图是最后一个典型情况——仅发送两个数据且遇到阻塞的情况：</p><ul><li>前级发送第一个数据d2时，后级阻塞，但是由于后级无传输行为，因此不阻塞该传输</li><li>后级接受到数据d2，并发生阻塞情况，同时后级的阻塞还未传输到前级，此时前级发送数据d3</li><li>后级发送数据d2未完成，但前级d3发送已经完成，因此d3被存入旁路缓存，等待发送，同时前级静默</li><li>后级发送d2完成时，从旁路缓存中取出数据d3进行发送</li></ul><h1 id="4-实现细节"><a href="#4-实现细节" class="headerlink" title="4.实现细节"></a>4.实现细节</h1><p>首先定义了一些用于简化判断的wire型变量：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">wire</span> busy_drop_buf = (!dout_busy)&amp;&amp; din_busy ;</span><br><span class="line"><span class="keyword">wire</span> is_din_busy = dout_busy &amp;&amp; dout_valid;</span><br><span class="line"><span class="keyword">wire</span> is_no_dout = (!lock_valid) &amp;&amp; (!(din_valid &amp;&amp; (!din_busy)))  ;</span><br><span class="line"><span class="keyword">wire</span> is_lock = is_din_busy &amp;&amp; (!din_busy) &amp;&amp; din_valid ;</span><br><span class="line"><span class="keyword">wire</span> is_unlock = busy_drop_buf &amp;&amp; lock_valid ;</span><br></pre></td></tr></table></figure><p><code>busy_drop_buf</code>表示dout_busy信号下降沿，该信号在后期判断中经常使用；<code>is_din_busy</code>表示后级发生阻塞行为，当后级的valid和busy同时置位时，表示后级有数据未完成传输，此时阻塞信号应传递到前级；<code>is_no_dout</code>表示没有数据需要发送，即旁路缓存中没有数据且上一级没有发送给这一级的数据；<code>is_lock</code>和<code>is_unlock</code>分别表示数据存入旁路缓存和数据从旁路缓存中取出，其中：</p><ul><li>is_lock：当后级发生阻塞（is_din_busy）且尚未传到前级完成一次数据传输（(!din_busy) &amp;&amp; din_valid）时有效，即后级发生第一个阻塞时将前级发送的数据放到旁路缓存中（该数据不做特殊处理会丢失）</li><li>is_unlock：当后级阻塞接触的第一个周期（busy_drop_buf）完成后，若缓存中有数据，则取出发送</li></ul><h2 id="4-1-旁路缓存"><a href="#4-1-旁路缓存" class="headerlink" title="4.1.旁路缓存"></a>4.1.旁路缓存</h2><p>旁路缓存用于在打断busy反馈的组合路径且不丢失数据，该部分分为两个信号：</p><ul><li>lock_data：缓存数据，用存储数据</li><li>lock_valid：缓存有效，用于标记lock_data中的数据是否有效</li></ul><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n)<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">lock_valid &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_lock) <span class="keyword">begin</span></span><br><span class="line">lock_valid &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_unlock) <span class="keyword">begin</span></span><br><span class="line">lock_valid &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n)<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">lock_data &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_lock) <span class="keyword">begin</span></span><br><span class="line">lock_data &lt;= din_data;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>这两个信号控制基本相同，通过<code>is_lock</code>和<code>is_unlock</code>分别进行进缓存和出缓存控制。</p><h2 id="4-2-dout-valid"><a href="#4-2-dout-valid" class="headerlink" title="4.2.dout_valid"></a>4.2.dout_valid</h2><p>由上分析，当上一级传输完成时，需要将上级传输来的数据转发给下一级，此时<code>dout_valid</code>信号置位；当当前传输完成且没有需要发送的数据时，后级没有需要发送的数据，<code>dout_valid</code>信号复位，代码如下所示：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(din_valid &amp;&amp; (!din_busy)) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(dout_valid &amp;&amp; (!dout_busy) &amp;&amp; is_no_dout) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2 id="4-2-din-busy"><a href="#4-2-din-busy" class="headerlink" title="4.2.din_busy"></a>4.2.din_busy</h2><p><code>din_busy</code>信号由寄存器产生，因此可以打断从最后一级向前传递的组合逻辑busy反馈路线，当后级发生阻塞时，前级不能继续发送数据，此时该信号置位；当后级busy信号复位后，无论是否发送数据，均可接收新数据（参考时序图分析），因此当后级busy信号复位后该信号复位。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_din_busy) <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(!dout_busy) <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2 id="4-3-dout-data"><a href="#4-3-dout-data" class="headerlink" title="4.3.dout_data"></a>4.3.dout_data</h2><p><code>dout_data</code>信号为转发数据，有三种情况：</p><ul><li>后级阻塞（is_din_busy）：阻塞情况下，输出数据不能改变</li><li>释放缓存（is_unlock）：达成缓存释放条件，此时从缓存中取出数据发送</li><li>其他情况：发送前级传递来的数据</li></ul><p>整体代码如下所示：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">dout_data &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_din_busy) <span class="keyword">begin</span></span><br><span class="line">dout_data &lt;= dout_data;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(is_unlock) <span class="keyword">begin</span></span><br><span class="line">        dout_data &lt;= lock_data;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">dout_data &lt;= din_data;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> pipeline </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>P2P接口串行FIR设计</title>
      <link href="2018/08/18/P2P%E6%8E%A5%E5%8F%A3%E4%B8%B2%E8%A1%8CFIR%E8%AE%BE%E8%AE%A1/"/>
      <url>2018/08/18/P2P%E6%8E%A5%E5%8F%A3%E4%B8%B2%E8%A1%8CFIR%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h1><p>设计一个仅使用一个乘法器单元的参数化串行FIR，要求：</p><ul><li>FIR参数可配置</li><li>具有双向P2P握手协议，可嵌入P2P流水线中</li><li>当流水线后续被阻塞时，要求完成当前运算再进入等待状态</li></ul><h1 id="结构框图"><a href="#结构框图" class="headerlink" title="结构框图"></a>结构框图</h1><img src="/2018/08/18/P2P%E6%8E%A5%E5%8F%A3%E4%B8%B2%E8%A1%8CFIR%E8%AE%BE%E8%AE%A1/structure.png" class=""><p>整体结构如上图所示，共分为4个模块：</p><ul><li>P2P输入模块：输入模块，接收P2P握手信号，将数据传递给FIR滤波器并控制整个系统运行，为控制流起点</li><li>FIR滤波器：功能模块，完成FIR滤波运算</li><li>P2P输出端口：将功能模块的输出通过P2P握手方式发送给P2P转发模块</li><li>P2P转发模块：隔离FIR滤波器和后向模块，使当后向模块阻塞时FIR滤波器仍能完成当前运算且不丢失数据</li></ul><h1 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h1><div class="table-container"><table><thead><tr><th>参数</th><th>默认值</th><th>功能</th></tr></thead><tbody><tr><td>ADDR_WIDTH</td><td>3</td><td>配置地址位宽，要求为最小为ceil(log2(COM_NUM))</td></tr><tr><td>DATA_WIDTH</td><td>8</td><td>输入数据位宽</td></tr><tr><td>COM_NUM</td><td>6</td><td>FIR级数</td></tr></tbody></table></div><h1 id="端口列表"><a href="#端口列表" class="headerlink" title="端口列表"></a>端口列表</h1><h2 id="系统端口"><a href="#系统端口" class="headerlink" title="系统端口"></a>系统端口</h2><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>功能</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>系统时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位信号</td></tr></tbody></table></div><h2 id="配置端口"><a href="#配置端口" class="headerlink" title="配置端口"></a>配置端口</h2><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>功能</th></tr></thead><tbody><tr><td>cfg_addr</td><td>input</td><td>ADDR_WIDTH</td><td>配置数据的地址</td></tr><tr><td>cfg_data</td><td>input</td><td>DATA_WIDTH</td><td>配置数据</td></tr><tr><td>cfg_valid</td><td>input</td><td>1</td><td>配置有效信号，高有效</td></tr></tbody></table></div><h2 id="输入端口"><a href="#输入端口" class="headerlink" title="输入端口"></a>输入端口</h2><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>功能</th></tr></thead><tbody><tr><td>din_data</td><td>input</td><td>DATA_WIDTH</td><td>输入数据</td></tr><tr><td>din_valid</td><td>input</td><td>1</td><td>输入有效信号</td></tr><tr><td>din_busy</td><td>output</td><td>1</td><td>输入忙信号</td></tr></tbody></table></div><h2 id="输出端口"><a href="#输出端口" class="headerlink" title="输出端口"></a>输出端口</h2><div class="table-container"><table><thead><tr><th>名称</th><th>类型</th><th>位宽</th><th>功能</th></tr></thead><tbody><tr><td>dout_data</td><td>output</td><td>DATA_WIDTH</td><td>输出数据</td></tr><tr><td>dout_valid</td><td>output</td><td>1</td><td>输出有效信号</td></tr><tr><td>dout_busy</td><td>input</td><td>1</td><td>输出忙信号</td></tr></tbody></table></div><h1 id="设计实现"><a href="#设计实现" class="headerlink" title="设计实现"></a>设计实现</h1><h2 id="配置接口"><a href="#配置接口" class="headerlink" title="配置接口"></a>配置接口</h2><p>配置接口使用寄存器组实现，掉电丢失，因此每次使用之前需要进行配置FIR参数，配置接口时序如下所示：</p><img src="/2018/08/18/P2P%E6%8E%A5%E5%8F%A3%E4%B8%B2%E8%A1%8CFIR%E8%AE%BE%E8%AE%A1/config_timing.png" class=""><p>配置地址，配置数据和配置有效信号同时有效即完成了一个位置的数据写入，要求配置地址的最大值小于COM_NUM，以防止配置数据超出限制地址。该部分的代码实现如下所示：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">integer</span> i;</span><br><span class="line"><span class="keyword">reg</span> [DATA_WIDTH-<span class="number">1</span>:<span class="number">0</span>]fir_params[COM_NUM-<span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; COM_NUM; i = i + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">fir_params[i] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(cfg_valid &amp;&amp; (cfg_addr &lt; COM_NUM)) <span class="keyword">begin</span></span><br><span class="line">fir_params[cfg_addr] &lt;= cfg_data;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>在复位信号有效时，所有位置的数据被清零，因此每次复位后需要重新写入配置数据。当配置有效信号有效且写入数据地址处于有效区间时，配置数据被写入对应位置。</p><h2 id="P2P输入接口"><a href="#P2P输入接口" class="headerlink" title="P2P输入接口"></a>P2P输入接口</h2><p>P2P输入接口是控制流和数据流的起点，主要信号为din_valid，din_busy和din_data信号，其中din_busy是唯一的输出信号，该信号有效表示后续处于处理状态，无法接收新的数据，因此该信号使用一个状态机实现：</p><ul><li>INIT状态：等待状态，复位后处于该状态，当din_valid信号有效时，转移到WORK状态。</li><li>WORK状态：工作状态，表示后续处于工作状态，当当前运算结果已经成功传递给后续模块时，转移到INIT状态，该状态下din_busy信号为高，否则din_busy信号为低。</li></ul><p>相关代码如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">case</span> (din_busy)</span><br><span class="line"><span class="number">1&#x27;b0</span>:<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(din_valid) <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="number">1&#x27;b1</span>:<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>((!inter_fir_busy) &amp;&amp; inter_fir_valid) <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">din_busy &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">default</span>:din_busy &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">endcase</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>由于din_busy信号的行为与状态高度契合，因此直接使用din_busy作为状态变量，该信号为0时，表示该接口准备就绪，可以接受数据输入，当有信号输入（din_valid==1）时，跳转到1；当该信号为1时，表示后续正在处理或被阻塞，当输出数据已经被传输给后端（(!inter_fir_busy) &amp;&amp; inter_fir_valid，其中inter_fir_valid和inter_fir_busy分别是FIR和转发模块之间的有效和忙信号）时，可以接收下一个输入，跳转到0。</p><h2 id="FIR滤波器"><a href="#FIR滤波器" class="headerlink" title="FIR滤波器"></a>FIR滤波器</h2><p>该部分使用一个乘法器构成串行FIR滤波器，结构图如下：</p><img src="/2018/08/18/P2P%E6%8E%A5%E5%8F%A3%E4%B8%B2%E8%A1%8CFIR%E8%AE%BE%E8%AE%A1/fir_structure.png" class=""><h3 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h3><p>自增计数器在FIR中充当控制器使用，其产生的结果用于选择参数，选择输入和决定累加寄存器的工作模式，代码如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">count &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(din_busy) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(count == COM_NUM) <span class="keyword">begin</span></span><br><span class="line">count &lt;= count;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">count &lt;= count + <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">count &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>该部分为一个0~COM_NUM的计数器，当din_busy==1时自增（工作状态自增）。其中0~COM_NUM-1为运算流程，count\==COM_NUM标记为运算部分终止，当达到该条件时，count将卡死并不再递增，直到该次运算结束清零（din_busy\==0）时。</p><h3 id="移位寄存器"><a href="#移位寄存器" class="headerlink" title="移位寄存器"></a>移位寄存器</h3><p>移位寄存器用于存储数据，共COM_NUM级，要求从P2P接口输入一个数据时整体后移一位，同时抛弃最后一个数据，代码如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [DATA_WIDTH-<span class="number">1</span>:<span class="number">0</span>]fir_data[COM_NUM-<span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; COM_NUM; i = i + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">fir_data[i] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(din_valid &amp;&amp; (!din_busy)) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">for</span> (i = COM_NUM-<span class="number">1</span>; i &gt; <span class="number">0</span>; i = i - <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">fir_data[i] = fir_data[i-<span class="number">1</span>];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">fir_data[<span class="number">0</span>] &lt;= din_data;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>复位时，所有寄存器清零，当P2P输入接口有数据输入（din_valid &amp;&amp; (!din_busy)）时，将数据整体后移一位并将输入数据放在最前一个寄存器中。注意寄存器的移位操作与din_busy置1同时完成，因此当din_busy==1时，移位寄存器数据稳定。</p><h3 id="乘法器"><a href="#乘法器" class="headerlink" title="乘法器"></a>乘法器</h3><p>乘法器根据count选择移位寄存器和参数，并完成单个乘法运算，代码如下所示：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">2</span>*DATA_WIDTH-<span class="number">1</span>:<span class="number">0</span>]one_cycle_result;</span><br><span class="line"><span class="keyword">reg</span> finish_count_buf;</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">one_cycle_result &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">finish_count_buf &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(count &lt;= COM_NUM-<span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">one_cycle_result &lt;= (<span class="number">2</span>*DATA_WIDTH)&#x27;(fir_data[COM_NUM - count - <span class="number">1</span>]) * fir_params[COM_NUM -  count - <span class="number">1</span>];</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">one_cycle_result &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">finish_count_buf &lt;= finish_count;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>当运算进行时，根据count选择数据相乘，当是数据超出限制，即已经完成后，持续输出0防止后级的累加器累加错误的数据，注意<code>(2*DATA_WIDTH)&#39;(fir_data[COM_NUM - count - 1])</code>为了显式表示输出数据的位数。同时该部分还缓存了运算结束信号<code>finish_count</code>，缓存后的信号<code>finish_count_buf</code>与乘法器结果<code>one_cycle_result</code>同步，即让控制流数据和数据流通过相同的延迟路径，以达到同步和简化功能。</p><h3 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h3><p>累加器用于累加乘法器的输出，要求运算过程中来累加，输出过程稳定，非计算过程清零以实现下一次运算，代码如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">2</span>*DATA_WIDTH-<span class="number">1</span>:<span class="number">0</span>]inter_fir_dout;</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">inter_fir_dout &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(din_busy) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(inter_fir_valid) <span class="keyword">begin</span></span><br><span class="line">inter_fir_dout &lt;= inter_fir_dout;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">inter_fir_dout &lt;= inter_fir_dout + one_cycle_result;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">inter_fir_dout &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>除了工作状态以外（din_busy==1），其他状态该累加器均清0。工作状态下，当运算完成向下一级输出时（下一级为转发模块），数据保持稳定，否则累加乘法器的输入。</p><h3 id="P2P输出接口"><a href="#P2P输出接口" class="headerlink" title="P2P输出接口"></a>P2P输出接口</h3><p>P2P输出接口用于FIR滤波器向转发模块发送数据，需要控制的为有效信号valid（data信号即为累加器输出），该部分代码如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">inter_fir_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(finish_count_buf)<span class="keyword">begin</span></span><br><span class="line">inter_fir_valid &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(!inter_fir_busy) <span class="keyword">begin</span></span><br><span class="line">inter_fir_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>当结束信号有效（finish_count_buf\==1）时，valid信号拉高，注意该信号相比finish_count_buf落后一个周期，与累加器输出同步（落后乘法器输出一个时钟周期），当传输完成时（inter_fir_busy\==0 且finish_count_buf !=0 ）时清零。</p><h2 id="转发模块"><a href="#转发模块" class="headerlink" title="转发模块"></a>转发模块</h2><p>该转发模块用于隔离FIR滤波器和后级输出：</p><ul><li>若没有该模块，当后级忙时，FIR将被卡在当前运算处无法接受下一个输入，知道后级可接受信号</li><li>若添加该模块，当后级忙时，FIR仍然可以完成当前运算并开始下一次计算，因此留给后一级的相应时间延长。</li></ul><p>该部分为一个简单的P2P直连接口，没有内部组合逻辑，其对FIR的接口部分需要控制busy信号，代码如下所示：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n)<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">inter_fir_busy &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">case</span> (inter_fir_busy)</span><br><span class="line"><span class="number">1&#x27;b0</span>:<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(inter_fir_valid) <span class="keyword">begin</span></span><br><span class="line">inter_fir_busy &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">inter_fir_busy &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="number">1&#x27;b1</span>:<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(dout_valid &amp;&amp; !dout_busy) <span class="keyword">begin</span></span><br><span class="line">inter_fir_busy &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">inter_fir_busy &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">default</span> :inter_fir_busy &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">endcase</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>该部分与P2P输入接口完全相同，具体说明可以参见【P2P输入接口】，其对下一级的输出部分代码如下所示：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">dout_data &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(inter_fir_valid &amp;&amp; !inter_fir_busy) <span class="keyword">begin</span></span><br><span class="line">dout_data &lt;= inter_fir_dout;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(inter_fir_valid &amp;&amp; !inter_fir_busy) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(dout_valid &amp;&amp; !dout_busy) <span class="keyword">begin</span></span><br><span class="line">dout_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><code>dout_data</code>为输出数据，当与FIR传输信号握手成功（inter_fir_valid &amp;&amp; !inter_fir_busy）时更新，否则一直保持。<code>dout_valid</code>为对下一级的输出valid信号，当有新数据传入时置1，当传输成功时置0，表示当前传输结束。</p>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fast-RCNN阅读笔记</title>
      <link href="2018/08/07/Fast-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
      <url>2018/08/07/Fast-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h1><img src="/2018/08/07/Fast-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/structure.png" class=""><p>由于RCNN存在流水线过长，检测速度慢的问题，Fast-RCNN几乎将整个过程置于深度学习的框架下，因此带来了准确率和速度的提升，该系统主要组成部分如上图所示，有：</p><ul><li>CNN特征提取器：与RCNN不同，该网络的输入为整张图片，输出为特征张量</li><li>候选框提取：与RCNN相同使用Selective Search提取候选框，只是候选框通过大小变换后作用于CNN提取出的特征张量中，而不直接作用于图片</li><li>RoI Pooling层：该层次用于将不同大小的候选框归一化到同一个大小上，然后通过全连接层计算出固定长度的特征向量</li><li>分类器：根据特征向量对物品进行分类，列表包括物品类别和背景</li><li>回归器：根据特征向量微调候选框位置和大小，最终生成针对候选框的调整因子</li></ul><p>该系统对于待识别图片，首先将其使用Selective Search处理获得一系列候选框，随后将其归一化到固定大小，送入CNN网络中提取特征。对于提取出的特征张量，假设其保留了原图片的空间位置信息，将候选框做对应变换后映射到特征张量上，提取出大小不同的候选区域的特征张量。对于每个候选区域的特征张量，使用RoI pooling层将其大小归一化，随后使用全连接层提取固定长度的特征向量。对于该特征向量，分别使用全连接层+softmax和全连接层+回归判断类别并计算原候选框的调整因子。</p><h2 id="候选框提取"><a href="#候选框提取" class="headerlink" title="候选框提取"></a>候选框提取</h2><p>候选框的提取与RCNN相同，使用Selective Search算法，该算法会提供一系列候选区域框，而不是遍历各种大小的子图，所以速度快于滑动框，Selective Search的具体说明参看RCNN笔记。需要指出的是，该部分是整个网络的速度瓶颈。</p><h2 id="CNN特征提取"><a href="#CNN特征提取" class="headerlink" title="CNN特征提取"></a>CNN特征提取</h2><p>网络的基本结构是VGG-16网络，相对于原网络，做了以下调整：</p><ul><li>最后一个最大值池化层用RoI池化层代替，该池化层可将不同大小的输入池化为统一大小输出。</li><li>最后一层全连接层使用两个分裂的全连接层代替，一个用于计算分类，一个用于计算候选框的调整因子</li><li>输入改为两个，分别为原图和Selective Search产生的候选框坐标</li></ul><h2 id="RoI池化层"><a href="#RoI池化层" class="headerlink" title="RoI池化层"></a>RoI池化层</h2><p>RoI池化层用于将不同大小的输入张量池化为固定大小，RoI池化层指定池化窗口的数量为$W \times H$，每个池化窗口的大小是根据池化区域变化的，例如一张图片的尺寸为$w \times h$，则每个窗口的大小为$\cfrac{w}{W} \times \cfrac{h}{H}$，假设W=4，H=4，有以下例子：</p><img src="/2018/08/07/Fast-RCNN%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/roi.png" class=""><p>如图左右各有一个大小不同的RoI区域，划分为$W \times H$个池化窗口，每个池化窗口的大小因原RoI区域尺寸不同而不同，经过RoI池化尺寸变为相同的$W \times H$。</p><h2 id="分类器与回归器"><a href="#分类器与回归器" class="headerlink" title="分类器与回归器"></a>分类器与回归器</h2><p>分类器和回归器的输入为RoI池化输出的固定大小向量经过两层全连接层后产生的特征向量，分类器用于判断物品属于哪一类（类别+背景），回归器用于计算4个调整因子，调整因子部分内容见RCNN笔记。</p><h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><p>模型的训练过程与RCNN不同，Fast-RCNN将分类器和回归器的训练统一到深度学习的框架下，在Selective Search提取出候选区域RoI后，所有的训练均在深度学习框架下进行。</p><h2 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h2><p>训练使用SGD算法，因此需要提取batch进行训练。batch的提取基于N张图片，每个batch提取$\cfrac{R}{N}$个区域，每个batch共R个数据。当N较小时，这种提取方法充分的使用了数据局部性，能提高训练速度。在本论文中，有R=128，N=2，即每个batch的数据来自两张图片，共128个RoI数据，其中要求25%的RoI为包含物体的（IoU&gt;0.5）,这些RoI被标记为对应类别，剩下的75%的RoI要求IoU在0.1~0.5之间，标记为背景。</p><h2 id="多任务代价函数"><a href="#多任务代价函数" class="headerlink" title="多任务代价函数"></a>多任务代价函数</h2><p>该网络的输入有两个：</p><ul><li>分类结果$p=(p_0,p1,…,p_K)$，共K+1个类别，包括K个物品和背景</li><li>调整因子$t_k=(t_x^k,t_y^k,t_w^k,t_h^k)$，调整的方式与RCNN相同</li></ul><p>因此，代价函数必须考虑以上两种输出的代价，最终代价函数如下所示：</p><script type="math/tex; mode=display">L(p,u.t_u,v) = L_{cls}(p,u) + \lambda[u \geq 1]L_{loc}(t^u,v)</script><p>第一个部分$L_{cls}$为分类部分的代价函数，使用交叉熵函数，公式如下，其中u为该RoI区域的标记类别，p为神经网络输出的分类向量：</p><script type="math/tex; mode=display">L_{cls}(p,u) = -log(p_u)</script><p>第二个部分$L<em>{loc}$为调整因子的代价函数，$[u \geq 1]$表示仅当当前位置不是背景时才考虑该部分代价， 超参数$\lambda$表示两个部分之间的权重，论文中取1。$L</em>{loc}$如下所示，其中t为网络输出的调整因子，v为目标调整因子。</p><script type="math/tex; mode=display">L_{loc}(t^u,v) = \sum\limits_{i \in \{x,y,w,h\}}smooth_{L_1}(t^u_i-v_i) \\smooth_{L_1}=\begin{cases}0.5x^2 & |x| <1 \\ |x|-0.5&otherwise\end{cases}</script><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>由上，可以归纳Fast_RCNN的训练过程：</p><ol><li>获取预训练模型</li><li>取N=2张图片前向传播，按批处理部分所述进行前向传播，并计算代价函数</li><li>根据代价函数反向传播更新权值跳转到2</li></ol><p>其中，RoI pooling层的反向传播与Pool层相同，详情见CNN的反向传播，不同RoI的反向传播结果对应位置相加后再反向传播到前一层。为了达成尺寸不变性，还在训练中使用了图像金字塔和数据增强的方法。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RCNN学习笔记</title>
      <link href="2018/07/19/RCNN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2018/07/19/RCNN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h1><img src="/2018/07/19/RCNN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/structure.png" class=""><p>RCNN物品目标识别系统如上图所示，如图所示，共分为四步：</p><ul><li>候选区域提取：使用Selective search选择候选区域，并进行预处理，全部处理为相同大小</li><li>CNN特征提取：使用CNN将特征区域图像提取为一个特征向量</li><li>SVM分类：使用支持向量机判断支持该候选区域是否属于某一个类别</li><li>边界回归：若确定某候选框属于某个类别，则使用回归的方式微调候选框的位置</li></ul><h2 id="候选区域提取"><a href="#候选区域提取" class="headerlink" title="候选区域提取"></a>候选区域提取</h2><p>RCNN使用Selective search算法代替滑动框，该算法可以提取类别无关的物品候选区域。该算法分为以下步骤：</p><ul><li>初始化一些小候选框</li><li>不断合并小候选框为大候选框，并保存所有未合并的候选框，产生一系列候选区域</li></ul><img src="/2018/07/19/RCNN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ss_algorithm.PNG" class=""><p>具体算法如上文所示，首先产生一系列初始区域R，并计算R中所有相邻区域之间的评分s，保存在集合S中，随后不断合并最高评分的两个区域，最终产生一系列候选区域。</p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>初始化的过程使用论文《Efficient graph-based image segmentation》过程中的方法，即使用无向图$G=(V,E)$表示一张图片，其中V表示所有无向图中所有像素，即令每一个像素对应一个顶点；E表示连接，仅有相邻的像素（顶点）之间才有连接，两个顶点之间的连接权值有不同的衡量标准。产生初始框的方式类似于类聚算法，类聚的依据如下所示：</p><script type="math/tex; mode=display">D(C_1,C_2) = \begin{cases}true & Dif(C_1,C_2) > MInt(C_1,C_2) \\false & otherwise \\\end{cases} \\Dif(C_1,C_2) = min_{v_i \in C_1,v_j \in C_2,(v_i.v_j) \in E}w(v_i,v_j) \\MInt(C_1,C_2) = min(Int(C_1)+t(C_1),Int(C_2)+t(C_2)) \\Int(C) = max_{e \in MST(C,E)}w(e) \\t(C) = \cfrac{k}{|C|}</script><p>类聚的依据为$D(C_1,C_2)$的结果，当为true时，即外部最小连接强度$Dif(C_1,C_2)$大于内部最大连接强度$MInt(C_1,C_2)$时，两个区域合并。若两个区域之间无连接，则外部链接强度为无穷大。</p><h3 id="合并候选框"><a href="#合并候选框" class="headerlink" title="合并候选框"></a>合并候选框</h3><p>候选框的合并基于一个评分，若两个区域的评分高于某个阈值，则将这两个候选框合并，评分函数如下：</p><script type="math/tex; mode=display">s(r_i,r_j) = a_1s_{colour}(r_i,r_j) + a_2s_{texture}(r_i,r_j) + a_3s_{size}(r_i,r_j) + a_4s_{fill}(r_i,r_j)</script><p>其中，${a<em>x}(x=1,2,3,4)$为权值，表示每个部分的重要性；$s</em>{i}$为评分分量：</p><ul><li>$s<em>{colour}$：颜色分量，用于评价颜色关联性，计算方法为对所选区域不同颜色空间内进行横轴被分为n份（bin=n）的一维直方图统计，可得$C_i={c^1_i,c^2_i,…,c^n_i}$，$c_i^k$表示数据落在直方图第k个区域对应范围内的像素数量，最终区域i和j的颜色分量评分为$s</em>{colour}(r<em>i,r_j)=\sum\limits</em>{k=1}^nmin(c_i^k,c_j^k)$</li><li>$s<em>{texture}$：纹理分量，用于评价纹理的关联性，使用Fast SIFT-like特征描述，与颜色分量类似做直方图统计，获得$T_i = {t_i^1,…,t_i^n}$，最终区域i和j的纹理分量评分为$s</em>{texture}(r<em>i,r_j) = \sum\limits^n</em>{k=1}min(t_i^k,t_j^k)$</li><li>$s<em>{size}$：大小分量，$s</em>{size}(r_i,r_j) = 1-\cfrac{size(r_i)+size(r_j)}{size(im)}$，用于优先考虑小尺寸图像的合并。size(im)为图片尺寸</li><li>$s<em>{fill}$：重叠分量，$s</em>{fill} = 1 - \cfrac{size(BB<em>{ij})-size(r_j)-size(r_i)}{size(im)}$，用于优先考虑重叠大的尺寸合并，im为整个图片，$BB</em>{ij}$为两个区域合并后的矩形区域。</li></ul><p>这一步合并完成后产生一系列候选框，测试集测试大约每张图片有2K个候选区域。</p><h3 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h3><p>由于候选框的尺寸不同，而后续卷积神经网络的输入要求一定，因此需要一定的预处理将图片尺寸归一化，该系统中直接使用仿射变换将图片尺寸强行变为卷积神经网络要求的输入（不考虑保证长宽比）。需要注意的是，为了保留上下文，在原有候选框的基础上将候选框外周围16个像素范围内的候选框边缘也加入候选框中。</p><p>除了尺寸，预处理还包括减去平均值。</p><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><p>卷积神经网络在本系统中用于特征提取，该卷积神经网络输入尺寸为227X227X3，使用的色彩空间为RGB。输出为一个长度为4096的向量，即提取出的特征。该网络共有5个卷积层和2个全连接层。</p><h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>支持向量机用于判断物品类别，针对每个类型训练一个二分类支持向量机，用于判断候选框是否属于某种类别。该支持向量机输入为特征向量，输出为二分类正例或反例。</p><h2 id="边界回归"><a href="#边界回归" class="headerlink" title="边界回归"></a>边界回归</h2><p>当支持向量机判断出该候选框属于某个类别后，使用该类别的边界回归器微调边框位置和大小，边界回归器的输入为卷积神经网络Pool5层的输出（即最后一层池化层的输出，第一层全连接的输入），输出调整因子$d_*(P)$：</p><script type="math/tex; mode=display">d_*(P) = w^T\phi_5(P)</script><p>其中，P为候选框的参数${P<em>x,P_y,P_w,P_h}$，$\phi_5(P)$为卷积神经网络Pool5层的输出，$w$为权值，调整因子$d</em>*(P)$包括四个部分：${d_x(P),d_y(P),d_w(P),d_h(P)}$，调整过程如下所示：</p><script type="math/tex; mode=display">G_x = P_wd_x(P)+P_x \\G_y = P_hd_y(P) + P_y \\G_w = P_we^{d_w(P)} \\G_h = P_he^{d_h(P)}</script><p>最终获得调整后的候选框${G_x,G_y,G_w,G_h}$。</p><h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><p>模型的训练包括三个部分，分别是作为特征提取器的CNN网络的训练、分类器SVM和边界回归器的训练。</p><h2 id="CNN训练"><a href="#CNN训练" class="headerlink" title="CNN训练"></a>CNN训练</h2><p>CNN使用alexnet的5层卷积+3层全连接层的网络，首先在大型数据集上预训练，训练集使用ILSVRC2012的分类任务训练集。预训练完成后开始针对特定任务微调，微调对应过程如下：</p><ul><li>网络结构修改：将原网络最后一层全连接层换为输出为N+1的全连接层（N为物品类别，+1表示背景），随机初始化最后一层全连接层参数。</li><li>标记：对于相对于真实标注IoU&gt;0.5的候选框，认为为对应物体，否则为背景</li><li>训练参数：SGD优化算法，初始学习率0.001，batch尺寸为128（32个物品+96背景）</li></ul><h2 id="SVM训练"><a href="#SVM训练" class="headerlink" title="SVM训练"></a>SVM训练</h2><p>针对每种类型训练一个二分类SVM，用于根据特征向量判断该候选框中是否有该类型物品，训练的标记与CNN网络类似使用IoU判断，若与标记物品IoU大于0.3（该阈值可依据不同人物修改），则认为是正例，否则是反例。</p><h2 id="边界回归器"><a href="#边界回归器" class="headerlink" title="边界回归器"></a>边界回归器</h2><p>边界回归器的训练基于以下公式：</p><script type="math/tex; mode=display">w_* = argmin_{w_*}\sum\limits^{N}_{i}(t_*^i - w_*^T\phi_5(P^i))^2 + \lambda||w_*||^2</script><p>其中，$t_*^i$为标签，使用以下公式计算：</p><script type="math/tex; mode=display">t_x = \cfrac{G_x-P_x}{P_w} \\t_y = \cfrac{G_y-p_y}{P_h} \\t_w = log\cfrac{G_w}{P_w} \\t_h = log\cfrac{G_h}{P_h}</script><p>其中G为物品标签中的相关位置数据，P为提取出的候选框的位置数据。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LBP特征物品识别系统</title>
      <link href="2018/07/16/LBP%E7%89%B9%E5%BE%81%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/"/>
      <url>2018/07/16/LBP%E7%89%B9%E5%BE%81%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h1><img src="/2018/07/16/LBP%E7%89%B9%E5%BE%81%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/structure.png" class=""><p>LBP是一种常规的人脸识别使用的特征，系统架构如上图所示，主要分为三个部分：</p><ul><li>滑动框：滑动框在图片上滑动，产生不同的子图</li><li>LBP特征提取器：针对滑动框产生的子图，计算LBP特征</li><li>分类器：根据LBP特征，判断当前图片是否是人脸</li></ul><h2 id="LBP特征"><a href="#LBP特征" class="headerlink" title="LBP特征"></a>LBP特征</h2><h3 id="原始LBP特征"><a href="#原始LBP特征" class="headerlink" title="原始LBP特征"></a>原始LBP特征</h3><p>原始LBP特征是一个3X3区域的区域特征。考虑一个像素的特征值，该特征值与周围的8个像素（3X3区域）有关，对于像素值大于该像素的周围像素赋值1，其他赋值0，如下图所示：</p><img src="/2018/07/16/LBP%E7%89%B9%E5%BE%81%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/base_lpb.png" class=""><p>如图中红框的中心像素，像素值为134，使用134和红框的其他像素（周围像素）比较，若大于134为1，否则为0，最后周围的8个像素的值依次为00101010，将其视为二进制数，转化为十进制就是42。</p><h3 id="圆形LBP特征"><a href="#圆形LBP特征" class="headerlink" title="圆形LBP特征"></a>圆形LBP特征</h3><p>圆形LBP特征与原始LBP特征类似，只是周围像素为一个圆形环绕的，如下图所示：</p><img src="/2018/07/16/LBP%E7%89%B9%E5%BE%81%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/c_lbp.png" class=""><p>LBP使用如图所示8个实心点位置的像素计算，其中四个红色实心点不落在像素上，使用双线性插值的方法计算对应的值，最后带入原始LBP的计算方法中计算中间像素的值。该LBP使用(P,R)表示，P表示带入计算的像素点数，R表示半径，如上图即为（8,2）</p><h3 id="系统使用的LBP"><a href="#系统使用的LBP" class="headerlink" title="系统使用的LBP"></a>系统使用的LBP</h3><p>系统使用的LBP表示为$LBP^{u2}_{P,R}$，其中u2表示统一LBP特征，即像素点的特征值的二进制最多有两次0到1或1到0跳变，如00001111为统一LBP，而10101010不为统一LBP，非统一LBP会被统一复位到一个特定值；P,R即为圆形LBP的(P,R)。</p><p>最终计算出所有统计的特征值后可统计出直方图特征，使用以下公式：</p><script type="math/tex; mode=display">H_i  = \sum\limits_{x,y}I\{f_l(x,y)==i\},i = 0,1,...,n-1 \\I\{A\} = \begin{cases} 1 & A \ is \ true \\ 0 & A \ is \ false\end{cases}</script><p>例如P=8时，最终获得256个数据，以上方法抛弃了空间特性，因此除了整体的直方图特征，还计算区域的直方图特征，将整个图片划分为m个方形区域，依次统计直方图特征：</p><script type="math/tex; mode=display">H_{i,j} = \sum\limits_{x,y} I\{f_l(x,y)=i\}I\{(x,y) \in R_j\},i=0,1,2,...,n-1,j=0,1,...,m-1</script><p>此时获得最终LBP特征，包括像素级别的特征和区域级别的特征。</p><h2 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h2><p>原论文中使用近邻分类器分类，提出了以下几种计算距离的方法：</p><script type="math/tex; mode=display">Histogram \ intersection:D(S,M) = \sum_imin(S_i,M_i) \\Log-likelihood \ statistic:L(S,M) = - \sum_iS_ilog(M_i) \\Chi square \ statistic:\chi^2(S,M) = \sum_i\cfrac{(S_i - M_i)^2}{S_i + M_i} \\Chi square \ statistic \ with\ weight:\chi^2_w(S,M) = \sum_{i,j}\cfrac{(S_{i,j} - M_{i,j})^2}{S_{i,j} + M_{i,j}}</script><p>根据以上距离公式结合近邻分类器可以完成是否是物品的分类。</p><h1 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h1><p>OpenCV中自带LBP+级联分类器的人脸识别模型，同时也提供了训练的相应工具</p><h2 id="使用默认模型测试"><a href="#使用默认模型测试" class="headerlink" title="使用默认模型测试"></a>使用默认模型测试</h2><p>该代码与使用Harr+级联分类器完全相同，唯一需要改变的是调用的模型文件改为LBP特征模型<code>lbpcascade_frontalface_improved.xml</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detectFaces</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">        img, path=<span class="string">&quot;./haarcascades/haarcascade_frontalface_alt2.xml&quot;</span></span>):</span></span><br><span class="line">    face_cascade = cv2.CascadeClassifier(path)</span><br><span class="line">    <span class="keyword">if</span> img.ndim == <span class="number">3</span>:</span><br><span class="line">        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        gray = img  </span><br><span class="line">    faces = face_cascade.detectMultiScale(</span><br><span class="line">        gray, scaleFactor=<span class="number">1.3</span>, minNeighbors=<span class="number">2</span>, minSize=(<span class="number">60</span>, <span class="number">60</span>), maxSize=(<span class="number">300</span>, <span class="number">300</span>))</span><br><span class="line">    print(faces)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> (x, y, width, height) <span class="keyword">in</span> faces:</span><br><span class="line">        result.append((x, y, x + width, y + height))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawFaces</span>(<span class="params">img, draw, color=(<span class="params"><span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span></span>)</span>):</span></span><br><span class="line">    <span class="keyword">for</span> (x1, y1, x2, y2) <span class="keyword">in</span> draw:</span><br><span class="line">        cv2.rectangle(img, (x1, y1), (x2, y2), color, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># get a frame</span></span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line"></span><br><span class="line">        frame_face1 = detectFaces(frame,<span class="string">&quot;haarcascades/lbpcascade_frontalface_improved.xml&quot;</span>)</span><br><span class="line">        frame = drawFaces(frame, frame_face1)</span><br><span class="line">        cv2.imshow(<span class="string">&quot;capture&quot;</span>, frame)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>训练部分也与Harr+级联分类器完全相同，唯一需要改变的是使用<code>opencv_traincascade.exe</code>时，添加命令行参数<code>-featureType LBP</code>，含义为指定是利用LBP特征训练。</p>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HoG特征SVM物品识别系统</title>
      <link href="2018/07/16/HoG%E7%89%B9%E5%BE%81SVM%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/"/>
      <url>2018/07/16/HoG%E7%89%B9%E5%BE%81SVM%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h1><img src="/2018/07/16/HoG%E7%89%B9%E5%BE%81SVM%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/structure.png" class=""><p>该系统仍然是基于滑动框+传统机器学习的目标识别系统，分为两个主要部分：</p><ul><li>HoG特征提取：从滑动框中提取出的子图中提取HoG特征</li><li>支持向量机（SVM）：以子图的HoG特征为输入，判断该子图中是否有物品</li></ul><h2 id="HoG特征"><a href="#HoG特征" class="headerlink" title="HoG特征"></a>HoG特征</h2><p>该系统的最大贡献为提出基于梯度的HoG（locally normalized Histogram of Oriented Gradient）特征，该特征的计算流程分为5步，分别如下所示：</p><img src="/2018/07/16/HoG%E7%89%B9%E5%BE%81SVM%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/hog.png" class=""><h3 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h3><p>归一化目的是去除光线的影响，gamma校正的公式如下所示：</p><script type="math/tex; mode=display">y(x,y) = I(x,y)^{gamma}</script><p>原论文尝试了多种输入方法，包括灰度图像和彩色图像与是否gamma校正的组合，由于这一步对最终结果影响很小，因此最终默认为使用彩色输入，不进行gamma校正。</p><h3 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h3><p>梯度的计算使用相邻或不相邻的像素值相减获得，两个方向的梯度和计算出整体梯度的角度和模。原论文尝试了多种计算方法，最终使用的计算方法如下所示：</p><script type="math/tex; mode=display">grad_x(x,y) = I(x+1,y) - I(x-1,y) \\grad_y(x,y) = I(x,y+1) - I(x,y-1) \\||grad(x,y)|| = \sqrt{grad_x(x,y)^2 + grad_y(x,y)^2} \\grad_{\theta}(x,y) = arctan(\cfrac{grad_y(x,y)}{grad_x(x,y)})</script><p>其中$grad_x(x,y)$和$grad_y(x,y)$的计算方法分别是与及其$[-1,0,1]$转置与这一步的输入图片卷积。若输入图片的输入通道不为1，那么将其所有通道的数据组合到一个向量中。</p><h3 id="直方特征统计"><a href="#直方特征统计" class="headerlink" title="直方特征统计"></a>直方特征统计</h3><p>该步骤是引入非线性的关键步骤，该步骤是基于一种被称为cell的结构，一个cell由一个正方形的块覆盖的像素组成，论文中使用的cell尺寸为4x4。对于一个cell中的所有像素统计一种直方图，该直方图的横轴为梯度方向，纵轴为梯度模，如下图所示：</p><img src="/2018/07/16/HoG%E7%89%B9%E5%BE%81SVM%E7%89%A9%E5%93%81%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/hog_binning.png" class=""><p>角度落在相同区间的梯度的模累加，作为该区间的结果。上图为0~180度分为4个区域的划分，最终产生四个数据，分别是角度落在四个角度区域的梯度的模之和。原论文中，角度区域的划分方法对最终结果有一定的影响，最终试验后使用0~180度划分9个区域的划分方法（每个20度），每个cell产生9个数据。</p><h3 id="特征归一化"><a href="#特征归一化" class="headerlink" title="特征归一化"></a>特征归一化</h3><p>特征的归一化基于block结构，该结构由一些cell组成，分为R-HoG和C-HoG两种。其中R-HoG应用较多，由相邻的构成方形的cell，block可以相互重叠，可以参考重叠的池化。C-HoG的block为圆形，未能找到资料，且论文描述较含糊。属于一个block的所有cell的数据组成一个向量。</p><p>标准化中，基于block的标准化使用cell组成的向量标准化，可以使用L2-Hys，L2标准化和带开方的L1标准化。L1与L2标准化如下所示：</p><script type="math/tex; mode=display">L1:v = \sqrt{\cfrac{v}{||v||_1 + e}} \\L2:v = \cfrac{v}{\sqrt{||v||_2^2+e}}</script><p>其中v为待标准化向量，e为为了防止除0的很小的常数。L2-Hys标准化首先进行L2标准化，对结果进行截短，再进行L2标准化，以上所述的标准化方法对结果影响均不大，论文中使用L2-Hys标准化。</p><p>除了这种标准化方式，论文中还提到了基于周围cell的标准化方式，但效果不佳。</p><h3 id="组合特征"><a href="#组合特征" class="headerlink" title="组合特征"></a>组合特征</h3><p>特征计算完成后，将所有block特征组合为一个向量，该向量即为后端SVM的输入。</p><h2 id="SVM（支持向量机）"><a href="#SVM（支持向量机）" class="headerlink" title="SVM（支持向量机）"></a>SVM（支持向量机）</h2><p>使用支持向量机判断候选框中是否有物品，支持向量机的输入为组合成向量的HoG特征，输出为是否是待检测物品。</p><h1 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detectFaces</span>(<span class="params">img</span>):</span></span><br><span class="line">    hog = cv2.HOGDescriptor()</span><br><span class="line">    <span class="keyword">if</span> img.ndim == <span class="number">3</span>:</span><br><span class="line">        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        gray = img</span><br><span class="line"></span><br><span class="line">    faces, _ = hog.detectMultiScale(</span><br><span class="line">        gray)</span><br><span class="line">    print(faces)</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> (x, y, width, height) <span class="keyword">in</span> faces:</span><br><span class="line">        result.append((x, y, x + width, y + height))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawFaces</span>(<span class="params">img, draw, color=(<span class="params"><span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span></span>)</span>):</span></span><br><span class="line">    <span class="keyword">for</span> (x1, y1, x2, y2) <span class="keyword">in</span> draw:</span><br><span class="line">        cv2.rectangle(img, (x1, y1), (x2, y2), color, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># get a frame</span></span><br><span class="line">        ret, frame = cap.read()</span><br><span class="line"></span><br><span class="line">        frame_face1 = detectFaces(frame)</span><br><span class="line">        <span class="comment"># frame_face2 = detectFaces(</span></span><br><span class="line">        <span class="comment">#     frame, &quot;./haarcascades/haarcascade_profileface.xml&quot;)</span></span><br><span class="line">        <span class="comment"># frame_eye = detectFaces(</span></span><br><span class="line">        <span class="comment">#     frame, &quot;./haarcascades/haarcascade_mcs_nose.xml&quot;)</span></span><br><span class="line">        <span class="comment"># frame_nose = detectFaces(</span></span><br><span class="line">        <span class="comment">#     frame, &quot;./haarcascades/haarcascade_mcs_rightear.xml&quot;)</span></span><br><span class="line"></span><br><span class="line">        frame = drawFaces(frame, frame_face1)</span><br><span class="line">        <span class="comment"># frame = drawFaces(frame, frame_face2, (0, 255, 0))</span></span><br><span class="line">        <span class="comment"># frame = drawFaces(frame, frame_eye, (0, 0, 255))</span></span><br><span class="line">        <span class="comment"># frame = drawFaces(frame, frame_nose, (255, 0, 255))</span></span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">&quot;capture&quot;</span>, frame)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>harr特征加级联分类器的目标检测系统</title>
      <link href="2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/"/>
      <url>2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-识别系统架构"><a href="#1-识别系统架构" class="headerlink" title="1.识别系统架构"></a>1.识别系统架构</h1><img src="/2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/harr_system.png" class=""><p>以上是Harr特征+级联分类器的识别系统架构图，系统分为以下几个部分：</p><ul><li>滑动框：固定大小的在原图上滑动的框，用于获取子图</li><li>Harr特征提取器：在子图上提取指定的四种Harr特征（获取的特征非常多）</li><li>级联分类器：基于选定的一些特征，进行分类，筛选出正例</li></ul><p>对于该目标识别器，将目标检测问题转换为目标分类问题：滑动框在原图上滑动，识别部分识别每一个滑动子图，判断是否为需要识别的目标。</p><h2 id="1-1-Harr特征"><a href="#1-1-Harr特征" class="headerlink" title="1.1.Harr特征"></a>1.1.Harr特征</h2><p>Harr特征是一类非常简单的特征，如下图所示有四个框，这四个框的大小是可变的，使用黑色部分覆盖的像素之和减去白色部分覆盖的像素之和即为Harr特征：</p><script type="math/tex; mode=display">Harr(x) = \sum pic_{black}(x) - \sum pic_{white}(x)</script><img src="/2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/harr.png" class=""><p>例如以下图片示意：</p><img src="/2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/harr_example.png" class=""><p>取第一个4x4的区域数据计算第二种harr特征，被黑色覆盖的区域和为3，被白色区域覆盖的和为2，因此可获得基于第二种模板下滑动框的harr特征为3-2=1。对于基于某一个模板，一个候选框可取多个特征，例如对于24x24的滑动框，基于第一种模板（对角线模板），可以在2x2，3x3，…，24x24等多个尺寸取特征，对于2x2的特征而言，也可以在24x24的框内取23x23个特征，因此，每个滑动框的harr特征数量都是海量的，在原论文中，使用20x20的滑动框，每个滑动框有约18k个特征值。</p><h2 id="1-2-级联分类器"><a href="#1-2-级联分类器" class="headerlink" title="1.2.级联分类器"></a>1.2.级联分类器</h2><p>由于Harr特征数量过多，已经几乎超过任何一种机器学习算法的输入特征数量极限（2001年），因此直接训练一个分类器是不现实的，于是使用多个弱分类器组成一个强分类器的方法训练。在本系统中，每一个弱分类器只针对一个单独的特征：</p><script type="math/tex; mode=display">h_j(x) = \begin{cases}  1 & f_j(x) < \theta_j \\0 & other\end{cases}</script><p>该级联分类器使用AdaBoost方法训练，训练分类器的同时也筛选特征，最终分类器的级数与使用的特征数量相同（每个分类器只使用一个特征）。最终的分类器为：</p><script type="math/tex; mode=display">h(x) = \begin{cases}1 & \sum_\limits{t=1}^{T}a_th_t(x) \geq \frac{1}{2}\sum\limits^T_{t=1}a_t \\0 & other\end{cases}</script><p>T为级联分类器的数量，同时也是选择特征的数量，级联分类器不使用的特征在计算Harr特征时可以不计算以减少计算量；$a_t$为单个分类器的权重，在训练过程中得到。</p><h1 id="2-训练方法"><a href="#2-训练方法" class="headerlink" title="2.训练方法"></a>2.训练方法</h1><p>需要训练的部分为级联分类器，由于每个弱分类器仅使用一个特征，因此每个弱分类器的参数为阈值$\theta_j$。训练算法如下图所示：</p><img src="/2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/harr_train.PNG" class=""><p>首先，初始化样本权值$w_{1,i} = \begin{cases}\frac{1}{2m} &amp; y_i = 0 \ \frac{1}{2l} &amp; y_i = 1\end{cases}$，其中$y_i$为当前样本的标签，1表示正例；m和l为反例和正例的数量。进入训练循环后，对于每次迭代：</p><ol><li>首先标准化样本权值$w<em>{t,i} = \cfrac{w</em>{t,i}}{\sum^n<em>{j=1}w</em>{t,j}}$</li><li>根据每个特征训练弱分类器$h(x)$，训练过程中，代价函数与样本权值有关，代价函数为$\epsilon_j = \sum_iw_i|h_j(x_i)-y_i| $。</li><li>所有特征对应的弱分类器训练完成后，选择代价函数最低的分类器和对应特征，同时该特征从待选则特征中移除。</li><li>最后更新样本权值：$w<em>{t+1,i} = w</em>{t,i}\beta_t^{1-e_i}$，其中$e_i = \begin{cases}1 &amp; classifid \ correctly \ 0 &amp; otherwise \end{cases}$ ；$\beta_t = \cfrac{\epsilon_t }{1-\epsilon_t}$</li></ol><p>最终获得分类器$h(x)$和每个分类器的权值$a_t = log\cfrac{1}{\beta_t}$。</p><h1 id="3-加速方法"><a href="#3-加速方法" class="headerlink" title="3.加速方法"></a>3.加速方法</h1><p>为了达到较快的检测速度，该系统分别对计算Harr特征和级联分类器提出了加速方案</p><h2 id="3-1-积分图"><a href="#3-1-积分图" class="headerlink" title="3.1.积分图"></a>3.1.积分图</h2><p>积分图用于加速计算Harr特征，其方法是生成一个与原图片大小相同的图，使用以下公式：</p><script type="math/tex; mode=display">ii(x) = \sum\limits_{x' \leq x,y' \leq y}{i(x',y')}</script><p>如下图所示，积分图的数据为以图片对应位置和图片左上角连线为对角线的矩形覆盖的所有像素的和。在按行生成计算图的过程中，每个位置的值可以由计算图上方的数据和这一行之前的累加与该位置的值相加得到，因此计算图的生成比较简单。</p><img src="/2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/harr_in.png" class=""><p>在计算harr特征时，需要计算大量的一定面积像素和，基于积分图，若要计算以下计算区域的和，仅需要计算：$A-B-C+D$即可，其中ABCD分别为积分图对应位置的值，因此任何一个矩形区域的求和都可以用3次加减法计算完成，有效的加速了Harr特征的提取速度。</p><img src="/2018/07/03/harr%E7%89%B9%E5%BE%81%E5%8A%A0%E7%BA%A7%E8%81%94%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/harr_compute_im.png" class=""><h2 id="3-2-级联计算"><a href="#3-2-级联计算" class="headerlink" title="3.2.级联计算"></a>3.2.级联计算</h2><p>在基本级联分类器需要计算全部所需要的Harr特征，尽管已经使用学习算法筛选过，特征数量仍然较多，基于大部分子图中没有需要识别的物品，提出了级联的方法：</p><ul><li>在训练筛选分类器时，不选择误差最小的分类器，而是选择最少的将正例划分为反例的分类器，即召回率最高的分类器。且下一次计算的样本集合为使用该分类器剔除反例的样本集合。</li><li>运行时，顺序计算特征-分类，当样本被一个分类器识别为反例时，直接拒绝该样本，后续的特征和分类都可以不被计算。</li></ul><h1 id="4-代码实践"><a href="#4-代码实践" class="headerlink" title="4.代码实践"></a>4.代码实践</h1><h2 id="4-1-使用自带级联分类器"><a href="#4-1-使用自带级联分类器" class="headerlink" title="4.1.使用自带级联分类器"></a>4.1.使用自带级联分类器</h2><p>OpenCV自带了一些级联分类器，可以用于识别人脸，五官和人体等等，在Python下使用方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">face_cascade = cv2.CascadeClassifier(<span class="string">&quot;./haarcascades/haarcascade_frontalface_alt2.xml&quot;</span>)</span><br><span class="line">faces = face_cascade.detectMultiScale(</span><br><span class="line">        gray, scaleFactor=<span class="number">1.3</span>, minNeighbors=<span class="number">2</span>, minSize=(<span class="number">60</span>, <span class="number">60</span>), maxSize=(<span class="number">300</span>, <span class="number">300</span>))</span><br></pre></td></tr></table></figure><p>首先调用<code>cv2.CascadeClassifier()</code>打开一个级联分类器，这里载入的xml为OpenCV自带的人脸识别级联分类器，随后调用<code>.detectMultiScale()</code>方法进行识别，参数含义为：</p><ul><li>第一个参数image：待识别图片，必须是灰度图片（channel=1）</li><li>scaleFactor：被检测对象的尺度变化，合理范围1.1~1.4，该参数越大检测越细致，速度越慢</li><li>minNeighbors：每个候选框需要保持多少个领域，该参数越大，一个候选框被接受越困难</li><li>minSize和maxSize：目标的最小尺寸和最大尺寸，当目标超过这一范围时无法识别</li></ul><p>该函数返回一个list，其中每个元素为一个有4个元素的list，分别是[x,y,w,h]，可直接用于绘制矩形框。</p><h2 id="4-2-训练级联分类器"><a href="#4-2-训练级联分类器" class="headerlink" title="4.2.训练级联分类器"></a>4.2.训练级联分类器</h2><p>选择FDDB数据集训练针对人脸的级联分类器</p><h3 id="4-2-1-处理标签"><a href="#4-2-1-处理标签" class="headerlink" title="4.2.1.处理标签"></a>4.2.1.处理标签</h3><p>FDDB的标注方式是椭圆形标注，提供椭圆形的中心，长短轴和角度信息，原label为\<major_axis_radius minor_axis_radius angle center_x center_y detection_score\>，先要将label转为<left_x top_y width height>的格式。考虑简便，使用以下公式：</p><script type="math/tex; mode=display">left\_x = clamp(center\_x -  minor\_axis\_radius,0,-1) \\top\_y = clamp(center\_y - major\_axis\_radius,0,-1) \\width = 2 \times minor\_axis\_radius \\height = 2 \times  major\_axis\_radius</script><p>该公式简单的将椭圆转为矩形，clamp为钳位函数，将输入限制在0~-1，-1表示不限制。同时限制矩形的范围一定在图片范围中。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FDDB2label</span>(<span class="params">source_path, target_path</span>):</span></span><br><span class="line">    source_list = read_ellipseList(source_path) //读取原有label文件</span><br><span class="line">    target_list = change_label(source_list)//转换label格式</span><br><span class="line">    save_rec_label(target_list, target_path)//保存label格式</span><br></pre></td></tr></table></figure><p>转换label的部分如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_label</span>(<span class="params">source</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;source:list[[path,label],...],label:[major_axis_radius minor_axis_radius angle center_x center_y detection_score]&quot;&quot;&quot;</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> name, label <span class="keyword">in</span> source:</span><br><span class="line">        name = name + <span class="string">&quot;.jpg&quot;</span></span><br><span class="line">        data = [<span class="built_in">float</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> label.replace(<span class="string">&quot;  &quot;</span>, <span class="string">&#x27; &#x27;</span>).split(<span class="string">&#x27; &#x27;</span>)]</span><br><span class="line">        data = [<span class="built_in">int</span>(data[<span class="number">3</span>] - data[<span class="number">1</span>]), <span class="built_in">int</span>(data[<span class="number">4</span>] - data[<span class="number">0</span>]),</span><br><span class="line">                <span class="built_in">int</span>(data[<span class="number">1</span>] * <span class="number">2</span>), <span class="built_in">int</span>(data[<span class="number">0</span>] * <span class="number">2</span>)]</span><br><span class="line">        data = check_label(name, data, root=<span class="string">&quot;../FDDB-folds/&quot;</span>)</span><br><span class="line">        result.append(</span><br><span class="line">            [name, data])</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>检查部分如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_label</span>(<span class="params">name, data, root=<span class="string">&quot;&quot;</span></span>):</span></span><br><span class="line">    img_shape = cv2.imread(os.path.join(root, name)).shape</span><br><span class="line">    <span class="keyword">if</span> data[<span class="number">0</span>] &lt; <span class="number">0</span>:</span><br><span class="line">        data[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> data[<span class="number">1</span>] &lt; <span class="number">0</span>:</span><br><span class="line">        data[<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> data[<span class="number">0</span>] + data[<span class="number">2</span>] &gt; img_shape[<span class="number">1</span>]:</span><br><span class="line">        data[<span class="number">2</span>] = img_shape[<span class="number">1</span>] - data[<span class="number">0</span>] - <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> data[<span class="number">1</span>] + data[<span class="number">3</span>] &gt; img_shape[<span class="number">0</span>]:</span><br><span class="line">        data[<span class="number">3</span>] = img_shape[<span class="number">0</span>] - data[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><p>共检查两种情况：</p><ul><li>物品左上角坐标小于0</li><li>物品右下角坐标超过图片限制</li></ul><h3 id="4-2-2-准备文件"><a href="#4-2-2-准备文件" class="headerlink" title="4.2.2.准备文件"></a>4.2.2.准备文件</h3><p>训练前需要准备数据，包括正例和反例。</p><h4 id="4-2-2-1-准备正例"><a href="#4-2-2-1-准备正例" class="headerlink" title="4.2.2.1.准备正例"></a>4.2.2.1.准备正例</h4><p>正例使用opencv自带的<code>opencv_createsamples.exe</code>生成，注意该exe文件不可独立运行，因此不能拷贝出来使用，其依赖OpenCV的其他文件，因此必须从OpenCV中调用（<code>opencv\build\x64\vc14\bin\opencv_createsamples.exe</code>），该工具将正例转为.vec文件，主要有以下命令行参数：</p><ul><li><code>-vec</code>：输出vec文件的路径</li><li><code>-info</code>：正例描述文件路径</li><li><code>-num</code>：生成的正例数量</li><li><code>-w</code>和<code>-h</code>：正例图片的长宽</li></ul><p>使用之前，需要准备一个描述正例文件的文件<code>info.dat</code>，其格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FDDB-folds\2002\08\11\big\img_591.jpg 1 184 38 171 247 </span><br><span class="line">FDDB-folds\2002\07\19\big\img_423.jpg 1 196 46 118 174 </span><br><span class="line">FDDB-folds\2002\08\24\big\img_490.jpg 1 110 23 70 109 </span><br><span class="line">&lt;相对路径&gt; &lt;目标数量n&gt; &lt;目标1的x,y,w,h&gt; ... &lt;目标n的x,y,w,h&gt;</span><br></pre></td></tr></table></figure><p>随后使用该工具，生成正例文件pos.vec。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\opencv\build\x64\vc14\bin\opencv_createsamples.exe <span class="literal">-vec</span> .\pos.vec <span class="literal">-info</span> info.dat <span class="literal">-num</span> <span class="number">178</span> <span class="literal">-w</span> <span class="number">40</span> <span class="literal">-h</span> <span class="number">40</span></span><br></pre></td></tr></table></figure><h4 id="4-2-2-2-准备反例"><a href="#4-2-2-2-准备反例" class="headerlink" title="4.2.2.2.准备反例"></a>4.2.2.2.准备反例</h4><p>对于反例，反例只需要准备一个文件列表<code>neg_list.dat</code>即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.\dataset\negtive\neg_img2698.jpg</span><br><span class="line">.\dataset\negtive\neg_img2699.jpg</span><br><span class="line">.\dataset\negtive\neg_img2700.jpg</span><br><span class="line">&lt;相对路径&gt;</span><br></pre></td></tr></table></figure><h3 id="4-2-3-模型训练"><a href="#4-2-3-模型训练" class="headerlink" title="4.2.3.模型训练"></a>4.2.3.模型训练</h3><p>模型训练使用OpenCV的<code>opencv_traincascade.exe</code>，主要的参数如下：</p><ul><li><code>-data</code>：最终保存分类器文件的位置</li><li><code>-vec</code>：正例vec文件的路径</li><li><code>-bg</code>：反例文件列表的路径</li><li><code>-numPos</code>和<code>-numNeg</code>：正例和反例的数量</li><li><code>-numStages</code>：多层分类器的层数</li><li><code>-w</code>和<code>-h</code>：正例文件的长宽，必须和生成样本时填入的对应长宽相同</li></ul><p>本次使用的命令行参数如下图所示：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.\opencv\build\x64\vc14\bin\opencv_traincascade.exe <span class="literal">-data</span> . <span class="literal">-vec</span> .\pos</span><br><span class="line">.vec <span class="literal">-bg</span> .\neg_list.dat <span class="literal">-numPos</span> <span class="number">178</span> <span class="literal">-numNeg</span> <span class="number">200</span> <span class="literal">-numStages</span> <span class="number">10</span> <span class="literal">-w</span> <span class="number">40</span> <span class="literal">-h</span> <span class="number">40</span></span><br></pre></td></tr></table></figure><p>最终训练的模型会保存在<code>-data/cascade.xml</code>中。</p><h3 id="4-2-4-模型测试"><a href="#4-2-4-模型测试" class="headerlink" title="4.2.4.模型测试"></a>4.2.4.模型测试</h3><p>可以使用官方提供的测试工具<code>opencv_visualisation.exe</code>测试，该工具会可视化测试过程并打印使用的分类器的类型，命令行参数如下：</p><ul><li><code>--image</code>：用于测试的图片路径</li><li><code>--model</code>：用于测试的模型（.xml文件）</li><li><code>--data</code>：保存测试结果的路径（可选）</li></ul><p>官方给出的例子如下：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.\opencv\build\x64\vc14\bin\opencv_visualisation -<span class="literal">-image</span>=\data\object.png -<span class="literal">-model</span>=\</span><br><span class="line">data\model.xml -<span class="literal">-data</span>=\data\result\</span><br></pre></td></tr></table></figure><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>理论部分：Viola P, Jones M. Rapid object detection using a boosted cascade of simple features[C]// IEEE Computer Society Conference on Computer Vision &amp; Pattern Recognition. IEEE Computer Society, 2001:511. </p><p>实践部分：<a href="https://docs.opencv.org/3.4.1/dc/d88/tutorial_traincascade.html">OpenCV官方教程——训练级联分类器</a></p>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>目标检测技术指标</title>
      <link href="2018/07/03/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF%E6%8C%87%E6%A0%87/"/>
      <url>2018/07/03/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<h1 id="mAP：识别准确率"><a href="#mAP：识别准确率" class="headerlink" title="mAP：识别准确率"></a>mAP：识别准确率</h1><p>mAP在目标检测中用于判断识别的准确率，即用于衡量物品被检测出的概率，其跟以下两个指标有关：</p><ul><li>Precision（准确率）：检测出的“物品有多少是真的物品</li><li>Recall（召回率）：数据集中的物品有多少被检出</li></ul><p>对于以上两个概念，将其置于标准二分类问题框架下有以下公式：</p><script type="math/tex; mode=display">Precision = \cfrac{TP}{TP+FP} \\Recall = \cfrac{TP}{TP+FN}</script><p>对于以上，有：</p><ul><li>TP：正例，被识别为正例</li><li>FP：反例，被识别为正例</li><li>TN：反例，被识别为正例</li><li>FN：正例，被识别为反例</li></ul><p>对于不同的识别阈值，Precision和Recall会发生变化，选取多个阈值（不重新训练模型），可以获得多组Precision和Recall，将这数据绘制图像，横轴为Recall，纵轴为Precision，曲线下的面积为参数AP</p><img src="/2018/07/03/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF%E6%8C%87%E6%A0%87/map.png" class=""><p>多次测试取平均值即为参数mAP值，该值越大说明系统性能越强</p><h1 id="IOU：检测效果"><a href="#IOU：检测效果" class="headerlink" title="IOU：检测效果"></a>IOU：检测效果</h1><p>通俗来说，IOU用于衡量目标检测中目标框的准不准，其定义为：</p><script type="math/tex; mode=display">IOU = \cfrac{A \bigcap B}{A \bigcup B}</script><p>其中A为系统预测出的框，B为数据本身的标注框，IOU衡量了预测出的框和原来的框的重叠程度，如下图所示，IOU就是阴影部分面积比整个AB组合的面积。</p><img src="/2018/07/03/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF%E6%8C%87%E6%A0%87/iou.png" class="">]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv2与YOLOv3学习笔记</title>
      <link href="2018/07/03/YOLOv2%E4%B8%8EYOLOv3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2018/07/03/YOLOv2%E4%B8%8EYOLOv3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h1><p>YOLOv2是YOLO的第二个版本，该物品检测系统仍然只需要“Look Once”，其整体结构如下所示：</p><img src="/2018/07/03/YOLOv2%E4%B8%8EYOLOv3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/yolo_main.png" class=""><p>其主要由两个部分构成：</p><ul><li>神经网络：将图片计算为一个$13\times 13 \times 125$的向量，该向量包含了预测的物品位置和类别信息</li><li>检测器：将神经网络输出的向量进行“解码”操作，输出物品的分类和位置信息。</li></ul><h2 id="神经网络部分"><a href="#神经网络部分" class="headerlink" title="神经网络部分"></a>神经网络部分</h2><p>YOLOv2的神经网络部分使用了一个带跳层的神经网络，具体结构如下所示：</p><img src="/2018/07/03/YOLOv2%E4%B8%8EYOLOv3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/yolo_net.png" class=""><p>神经网络的设计没有太大飞跃性的改变，相对于YOLOv1的神经网络设计主要有以下改变：</p><ul><li>每个卷积层后添加了批标准化层，加速了网络的收敛。</li><li>在第16层开始分为两条路径，将低层的特征直接连接到高层，可提高模型性能。</li><li>移除全连接层，最终的输出向量中保存了原来的位置信息。</li><li>输入尺寸变为$416\times 416 \times 3$，识别更高分辨率的图片。</li></ul><p>该网络最终输入图片尺寸为，$416\times 416 \times 3$输出向量尺寸为$13 \times 13 \times 125$。</p><h2 id="检测器部分"><a href="#检测器部分" class="headerlink" title="检测器部分"></a>检测器部分</h2><p>YOLOv2使用了Anchor Box的方法，神经网络输出的向量尺寸是$13\times 13 \times 125$，其中$13 \times 13$是将图片划分为13行和13列共169个cell，每个cell有125数据。对于每个cell的125个数据，分解为$125 = 5 \times (5+20)$，即每个cell包括5个anchor box，每个anchor cell包括25个数据，分别为物品存在置信度，物品中心位置(x,y)，物品尺寸(w,h)和类别信息（20个）。如下图所示：</p><img src="/2018/07/03/YOLOv2%E4%B8%8EYOLOv3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/yolo_result.png" class=""><p>对于每个cell包括5个anchor box信息，每个anchor box包括25个数据，分别：</p><ul><li>为是否有物品（1个）</li><li>物品位置（4个）</li><li>物品种类（20个）</li></ul><p>其中是否有物品的标记$conf_{ijk}$比较容易理解，表示位于$i,j$cell的第k个anchor box中有物品的置信度。20个物品种类向量也较好理解，哪一个数据最大即物品为对应的类别。</p><p>对于物品位置的四个数据分别为$x<em>{ijk},y</em>{ijk},w<em>{ijk},h</em>{ijk}$，与物品位置中心点和尺寸的关系为：</p><script type="math/tex; mode=display">b_x = f(x_{ijk}) + c_x \\ b_y = f(y_{ijk}) + c_y \\  b_w = p_w e^{w_{ijk}} \\ b_h = p_h e^{h_{ijk}}</script><p>其中，$b_x,b_y$为物品中心点的实际坐标，$b_w,b_h$为物品的尺寸（长宽）。$c_x,c_y$的为该cell（x行y列）距离图片左上角的像素数，f的含义推测为将范围为0~1的输入值缩放到0~cell长度。$p_w$和$p_h$为该anchor box的预设尺寸。如下图所示：</p><img src="/2018/07/03/YOLOv2%E4%B8%8EYOLOv3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/detection.PNG" class=""><p>每个cell包括5个anchor box，这5个anchor box有不同的预设尺寸，该预设尺寸可以手动指定也可以在训练集上训练获得。在YOLOv2中，预设尺寸是通过在测试集上进行类聚获得的。</p><h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><p>神经网络部分基于模型Darknet-19，该模型的训练部分分为两个部分：预训练和训练部分</p><ul><li>预训练：预训练是在ImageNet上按分类的方式进行预训练160轮，使用SGD优化方法，初始学习率0.1，每次下降4倍，到0.0005时终止。除了训练224x224尺寸的图像外，还是用448x448尺寸的图片。</li><li>训练：去除Darknet的最后一个卷积层，并将网络结构修改为YOLOv2的网络，在VOC数据集上进行训练。训练使用的代价函数是MSE代价函数。</li></ul><p>另外，在训练过程中，还引入了多尺寸训练，由于网络删除了全连接层，所以该网络并不关心图片的具体大小，训练时使用320~608尺寸的图像{320,352，….，608}。</p><h1 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h1><p>YOLOv3是YOLO最新的更新，其主要的改进在以下方面：</p><ul><li>网络结构改变：网络的结构由Darknet-19变为Darknet-53，跳层的现象越来越普遍。</li><li>尾部激活函数改变：尾部的激活函数（类别预测）由softmax改为sigmoid</li><li>尺度数量改变：anchor box的数量由5个改为3个</li></ul><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>网络结构如下所示：</p><img src="/2018/07/03/YOLOv2%E4%B8%8EYOLOv3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/YOLO3_net.PNG" class=""><p>网络结构明显参考了ResNet的设计，将低层的特征直接连接到高层。同时注意一点，网络可能没有使用pool层，而是使用stride=2的卷积层实现下采样。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLO1学习笔记</title>
      <link href="2018/07/03/YOLO1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2018/07/03/YOLO1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h1><p>YOLO（You Only Look Once）是一种目标检测系统，其特点是将物品识别和物品分类融合，使用一个深度学习模型直接计算出物体的位置和类型。基本思路如下所示：</p><img src="/2018/07/03/YOLO1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/yolo_basic.JPG" class=""><p>首先图片被分为$S \times S$个框，如最左边的图所示。对于每个框，若一个物体的中心落在该框中，则这个框负责该物体的类型和位置预测。对于每个框，需要计算以下数据：</p><ul><li>B个Bounding boxes的数据，共$B \times 5$个。每个框对应5个数据，分别是：<ul><li>x：物体中心x的位置</li><li>y：物体中心y的位置</li><li>w：物体水平长度</li><li>h：物品垂直长度</li><li>conf：物品置信度，即有多大的概率这个框包含了物体，定义$conf =P(object) \times IOU_{pred}^{truth}$，即该指标同时考虑物品的存在可能性和对应Bounding boxes与真实物体重叠的面积。</li></ul></li><li>所属类别：共C个，分别对应物品的种类，用于标记这个框的属于哪一个物体。</li></ul><p>在VOC数据集中，共有20类物品，即C=20。取S = 7，B = 2，因此最后数据共$7 \times 7 \times (20 + 5 \times 2) = 7 \times 7 \times 30$个，表示为维度为[7,7,30]。</p><h1 id="网络设计"><a href="#网络设计" class="headerlink" title="网络设计"></a>网络设计</h1><p>网络结构的设计如下：</p><img src="/2018/07/03/YOLO1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/yolo_network.JPG" class=""><p>网络的设计取材与GoogLeNet，其中将Inception结构简单的换成了1x1卷积和3x3卷积的串联。同时需要注意的是激活函数使用的leaky常数为0.1的leaky relu函数。</p><p>除此之外，上文所提到的x,y,w,h参数均被归一化——中心位置x,y使用框的尺寸归一化，w,h使用图片尺寸归一化。如此操作后，x,y,w,h均归一化到0~1。</p><h1 id="训练与预测"><a href="#训练与预测" class="headerlink" title="训练与预测"></a>训练与预测</h1><h2 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h2><p>该模型首先在ImageNet进行了预训练，Top-5准确率达到88%。训练开始前保留前20层卷积的参数。</p><h2 id="正式训练"><a href="#正式训练" class="headerlink" title="正式训练"></a>正式训练</h2><p>训练的代价函数分为五个部分，如下所示：</p><script type="math/tex; mode=display">Loss = L oss_{xy} + Loss_{wh} + Loss_{obj} + Loss_{noobj} + Loss_c \\Loss_{xy} = \lambda_{coord} \sum\limits_{i=0}^{S^2}{\sum\limits_{j=0}^{B}{l_{ij}^{obj}[(x_i - x'_i)^2 + (y_i-y'_i)^2]}} \\Loss_{wh} = \lambda_{coord}\sum\limits_{i=0}^{S^2}{\sum\limits_{j=0}^{B}{l_{ij}^{obj}[(\sqrt w_i -  \sqrt{ w'_i})^2 + (\sqrt h_i-\sqrt{h'_i})^2]}} \\Loss_{obj} = \sum\limits_{i=0}^{S^2}{\sum\limits_{j=0}^{B}l_{ij}^{obj}(C_i - C_i')^2} \\Loss_{noobj} = \lambda_{noobj}\sum\limits_{i=0}^{S^2}{\sum\limits_{j=0}^{B}l_{ij}^{noobj}(C_i - C_i')^2} \\Loss_c = \sum\limits^{S^2}_{i = 0}l^{obj}_i\sum\limits_{c \in classes}{(p_i(c) - p'_i(c))^2}</script><p>其中，$l<em>{i}^{obj}$用于标记是否有物体出现在i框中，若有为1，否则为0；$l</em>{ij}^{obj}$用于标记是否有物体出现框i中的第j个Bounding box中，若有为1，否则为0。由于一个框会产生多个Bounding Box，这里取与真实区域IOU最高的Bounding Box负责该物体的预测。$\lambda<em>{noobj}$和$\lambda</em>{coord}$为格点包括物体和不包括物体的两种情况区分对考虑，有$\lambda<em>{noobj} = 0.5$和$\lambda</em>{coord} = 5$。</p><p>$Loss<em>{xy}$和$Loss</em>{wh}$是针对物品位置的代价项，$Loss<em>{obj}$和$Loss</em>{noobj}$是针对物品存在置信度的代价项。$Loss<em>c$则是针对物品类别的代价项。假设一个网络输出了一个[7x7x(20+2X5)]的输出向量。假设仅在位于$a,b$的网格中有一个物体。则$l</em>{i=a \times b}^{obj} = 1,l<em>{i \neq a \times b}^{obj} = 0$，则有$Loss_c = \sum\limits</em>{c \in classes}(p<em>{a \times b}(c) - p’</em>{a \times b}(c))^2$。对于该网格，有B个Bounding Box，假如标号为k的Bounding Box与该物体的IOU最高，则$l^{obj}<em>{i = a \times b,j = k} = 1,l^{obj}</em>{i \neq a \times b,j \neq k} = 0$，即计算Loss时仅考虑k号Bounding Box的损失，k号Bounding Box被指定负责该物品的检测。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>测试时，每测试一张图片，都会获得$S \times S \times B$个Bounding Box，根据个人理解，每个格点有唯一的归属，因此可以对每个格点的B个Bounding Box取置信度最高的一个，即有$S \times S$个Bounding Box。在这些Bounding Box中，可以设置一个阈值，筛去置信度低的格点。对于最后的格点，进行非最大值抑制：即对IOU超过一定阈值且属于同一类的Bounding Box比较置信度，选择置信度最高的Bounding Box。</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DianNao系列分析</title>
      <link href="2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/"/>
      <url>2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>DianNao系列是中科院计算所推出的系列机器学习加速器，包括以下四个成员：</p><ul><li>DianNao：神经网络加速器，DianNao系列的开山之作。</li><li>DaDianNao：神经网络“超级计算机”，DianNao的多核升级版本</li><li>ShiDianNao：机器视觉专用加速器，集成了视频处理部分</li><li>PuDianNao：机器学习加速器，DianNao系列收山之作，可支持7种机器学习算法</li></ul><p>DianNao系列相比于其他神经网络加速器，除了关心运算的实现外，更关心存储的优化。</p><h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p>DianNao系列的整体架构比较类似，均分为以下三个部分：</p><ul><li>运算核心：完成对应的运算加速功能</li><li>缓存：缓存输入输出数据与参数，减小访存带宽需求</li><li>控制：协调运算核心和缓存的工作</li></ul><p>前三代（DianNao，DaDianNao，ShiDianNao）的整体架构如下图所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/DianNao_structure.png" class=""><p>其中：</p><ul><li>NBin，NBout和SB：均为存储器，分别用于存储输入数据，输出数据或临时数据和参数</li><li>NFU：运算核心，用于完成神经网络相关的运算</li></ul><p>以下为原论文中所绘制的架构图（左图为DianNao/DaDianNao，右图为ShiDianNao）：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/source_structrue.png" class=""><p>最后一代PuDianNao为了适应更多的机器学习算法（PuDianNao不专门为神经网络设计），抛弃了按功能分别缓存的方法，转而使用按重用频率缓存，因此架构上发生了一些变化，如下图所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/PuDianNao_structure.png" class=""><p>其中：</p><ul><li>HotBuf，ColdBuf：输入数据缓存，分别用于存储频繁重用和重用时间间隔较长的输入数据</li><li>OutBuf：输出数据缓存，用于存储输出数据</li><li>FU：功能模块，完成机器学习相关运算</li><li>Controller：控制核心，协调存储器和功能模块的工作</li></ul><p>原论文中绘制的系统结构图如下所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/PuDianNao.JPG" class=""><h1 id="运算模块"><a href="#运算模块" class="headerlink" title="运算模块"></a>运算模块</h1><p>运算模块用于完成待加速的运算，是加速器的核心部分之一。</p><h2 id="运算分析"><a href="#运算分析" class="headerlink" title="运算分析"></a>运算分析</h2><p>DianNao系列的论文每一篇都会花大量的篇幅阐述运算分析部分，这对学习者来说非常友好。</p><h3 id="DianNao与DaDianNao"><a href="#DianNao与DaDianNao" class="headerlink" title="DianNao与DaDianNao"></a>DianNao与DaDianNao</h3><p>这两个系列支持的神经网络计算类型较为基础，论文中概括，要想实现卷积神经网络，需要实现以下几种操作：</p><ul><li>卷积运算：$out(x,y)^{fo} = \sum \limits<em>{f_i = 0}^{K</em>{if}} \sum \limits<em>{k_x = 0}^{K_x} \sum\limits</em>{k<em>y = 0}^{K_y} w</em>{f_i,f_o}(k_x,k_y) \times in(x+k_x,y+k_y)^{f_i}$</li><li>池化运算：$out(x,y)^f = max_{0 \leq k_x \leq K_x,0 \leq k_y \leq K_y} in(x+k_x,y+k_y)^f$</li><li>LRN（区域响应标准化，当时批标准化还未流行）：$out(x,y)^f = \cfrac{in(x,y)^f}{(c + \alpha \sum \limits_{g=max(0,f-k/2)}^{min(N_f,f+k/2)}(a(x,y)^g)^2)^{\beta}}$ </li><li>矩阵乘：$out(j) = t(\sum\limits^{N<em>i}</em>{i = 0} w_{ij} \cdot in(i))$</li></ul><p>其中，DianNao未实现LRN功能，该功能在DaDianNao中才实现。另外，DaDianNao支持神经网络的训练，其训练过程所需要的运算，基本与测试过程基本相同。</p><h3 id="ShiDianNao"><a href="#ShiDianNao" class="headerlink" title="ShiDianNao"></a>ShiDianNao</h3><p>ShiDianNao除了支持DianNao所支持的操作外，对于标准化，还支持LCN（局部对比度归一化）：</p><script type="math/tex; mode=display">O^{mi}_{a,b} = \cfrac{I^{mi}_{a,b}}{(k+\alpha \times \sum\limits^{min(Mi-1,mi+M/2)}_{j=max(0,mi-M/2)}(I^j_{a,b}))^\beta}</script><h3 id="PuDianNao"><a href="#PuDianNao" class="headerlink" title="PuDianNao"></a>PuDianNao</h3><p>PuDianNao支持7种机器学习算法：神经网络，线性模型，支持向量机，决策树，朴素贝叶斯，K临近和K类聚，所需要支持的运算较多，因此PuDianNao的运算分析主要集中在存储方面，其运算核心的设计中说明PuDianNao支持的运算主要有：向量点乘，距离计算，计数，排序和非线性函数。其他未覆盖的计算使用ALU实现。</p><h2 id="运算模块设计"><a href="#运算模块设计" class="headerlink" title="运算模块设计"></a>运算模块设计</h2><h3 id="DianNao"><a href="#DianNao" class="headerlink" title="DianNao"></a>DianNao</h3><p>DianNao的运算模块奠定了DianNao系列运算模块的主基调。结构图如下所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/DianNao_nfu.JPG" class=""><p>运算模块分为三级流水线：</p><ul><li>NFU-1：乘法器阵列，16bit定点数乘法器，1位符号位，5位整数位，10位小数位</li><li>NFU-2：加法树/最大值树，将乘法器所得的结果累加或取最大值，可选的与上一次/部分和累加。这一部分的结尾处有寄存器结构，可以存储这一次运算的部分和。</li><li>NFU-3：非线性激活函数，该部分由分段线性近似实现非线性函数</li></ul><p>当需要实现向量相乘和卷积运算时，使用NFU-1完成对应位置元素相乘，NFU-2完成相乘结果相加，最后由NFU-3完成激活函数映射。完成池化运算时，使用NFU-2完成多个元素取最大值或取平均值运算。由此分析，尽管该运算模块非常简单，也覆盖了神经网络所需要的大部分运算（LRN在DianNao中未实现）</p><h3 id="DaDianNao"><a href="#DaDianNao" class="headerlink" title="DaDianNao"></a>DaDianNao</h3><p>DaDianNao的运算单元NFU与DianNao基本相同，最大的区别是为了完成训练任务多加了几条数据通路，且配置更加灵活。NFU的尺寸为16x16，即16个输出神经元，每个输出神经元有16个输入（输入端需要一次提供256个数据）。同时，NFU可以可选的跳过一些步骤以达到灵活可配置的功能。DaDianNao的NFU结构如下所示：</p><h3 id="ShiDianNao-1"><a href="#ShiDianNao-1" class="headerlink" title="ShiDianNao"></a>ShiDianNao</h3><p>ShiDianNao是DianNao系列中唯一一个考虑运算单元级数据重用的加速器，也是唯一使用二维运算阵列的加速器，其加速器的运算阵列结构如下所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_nfu.JPG" class=""><p>ShiDianNao的运算阵列为2D格点结构，对于每一个运算单元（节点）而言，运算所使用的参数统一来源于Kernel，而参与运算的数据则可能来自于：</p><ul><li>数据缓存NBin</li><li>下方的节点</li><li>右侧的节点</li></ul><p>下图为每个运算单元的结构（左）和抽象结构（右）：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_nfu_node_model.png" class=""><p>该计算节点的功能包括转发数据和进行计算：</p><ul><li>转发数据：每个数据可来源于右侧节点，下方节点和NBin，根据控制信号选择其中一个存储到输入寄存器中，且根据控制信号可选的将其存储到FIFO-H和FIFO-V中。同时根据控制信号选择FIFO-H和FIFO-V中的信号从FIFO output端口输出</li><li>进行计算：根据控制信号进行计算，包括相加，累加，乘加和比较等，并将结果存储到输出寄存器中，并根据控制信号选择寄存器或计算结果输出到PE output端口。</li></ul><p>对于计算功能，根据上文的结构图，可以发现，PE支持的运算有：kernel和输入数据相乘并与输出寄存器数据相加（乘加），输入数据与输出寄存器数据取最大或最小（应用于池化），kernel与输入数据相加（向量加法），输入数据与输出寄存器数据相加（累加）等。</p><h3 id="PuDianNao-1"><a href="#PuDianNao-1" class="headerlink" title="PuDianNao"></a>PuDianNao</h3><p>PuDianNao的运算单元是电脑系列中唯一一个异构的，除了有MLU（机器学习单元）外，还有一个ALU用于处理通用运算和MLU无法处理的运算，其运算单元（左）和MLU（右）结构如下图所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/PuDianNao_mlu_structure.png" class=""><p>MLU分为6层：</p><ul><li>计数层/比较层：这一层的处理为两个数按位与或比较大小，结果将被累加，这一层可以单独输出且可以被bypass</li><li>加法层：这一层为两个输入对应相加，这一层可以单独输出且可以被bypass</li><li>乘法层：这一层为两个输入或上一层（加法层）结果对应位置相乘，可以单独输出</li><li>加法树层：将乘法层的结果累加</li><li>累加层：将上一层（加法树层）的结果累加，可以单独输出</li><li>特殊处理层：由一个分段线性逼近实现的非线性函数和k排序器（输出上一层输出中最小的输出）组成</li></ul><p>该运算单元是DianNao系列中功能最多的单元，配置非常灵活。例如实现向量相乘（对应位置相乘后累加）时，弃用计数层，加法层，将数据从乘法层，加法树层和累加层流过即可实现。</p><h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><p>DianNao系列的存储的设计理念是分裂存储，这样有几个好处：</p><ul><li>增大带宽：相同大小的单个存储器和多个存储器相比，多个存储器能提供更大的带宽</li><li>匹配位宽：有些数据对位宽的需求不同，将位宽需求不同的数据放在不同位宽的存储器中可以避免位宽浪费</li></ul><h2 id="DianNao与DaDianNao-1"><a href="#DianNao与DaDianNao-1" class="headerlink" title="DianNao与DaDianNao"></a>DianNao与DaDianNao</h2><p>DianNao和DaDianNao的存储设计基本相同，区别在于DaDianNao使用了片上eDRAM增大了片上存储的面积，下图为DaDianNao的存储部分，DianNao的存储部分类似，可以参考整体架构中DianNao的架构图：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/DaDianNao_store.JPG" class=""><p>存储被分裂为三个部分：</p><ul><li>NBin：用于存储输入数据，需要位宽$T_n$（一次处理所需的输入数量x每个输入位宽）</li><li>NBout：用于存储部分和与最终运算结果，需要位宽$T_n$</li><li>SB：用于存储权值，需要位宽$T_n \times T_n$</li></ul><p>DianNao和DaDianNao的重用策略是重用输入数据即NBin中的数据。当需要NBin参与的运算全部完成后，NBin才会被覆盖。因此，在DaDianNao中，所有运算单元共享eDRAM实现的NBin和NBout（图中eDRAM router部分），但具有自己的SB缓存（每个节点有4个eDRAM）</p><h2 id="ShiDianNao-2"><a href="#ShiDianNao-2" class="headerlink" title="ShiDianNao"></a>ShiDianNao</h2><p>ShiDianNao的存储比较有特色，由于其特殊性，并未采用DaDianNao的eDRAM组成超大片上存储。仅使用了288KB的SRAM，因此其存储组织更值得研究，下图为NBin缓存及其控制器的设计：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_store.JPG" class=""><p>可以发现，每个存储器分裂为$2 \times P_y$个Bank，每个Bank的位宽是$P_x \times 16bit$。其中$P_y$为运算阵列的行数，$P_x$为计算阵列的列数，16bit为数据位宽。该存储器支持的读取方式有6种：</p><ul><li>读bank0~bank$P_y-1$，共$P_y \times P_x \times 16bit$数据，可以填充计算阵列中每个节点。</li><li>读bank$P_y$~bank$2 \times P_y-1$，共$P_y \times P_x \times 16bit$数据，可以填充计算阵列中每个节点。</li><li>读取一个Bank，共$P_x \times 16bit$数据，可以填充计算阵列中的一行。</li><li>读取一个Bank中的一个数据（16bit）</li><li>读取每个Bank中指定间隔的数据，共$2 \times P_y \times 16bit$数据。</li><li>读取bank$P_y$~bank$2 \times P_y-1$中每个Bank中指定位置的数据，共$P_y \times 16bit$数据，可以填充计算阵列中的一列。</li></ul><p>写方面，采用缓存-存储的方式，即现先待写入数据换存入output寄存器中，待全部运算单元完成运算后统一将数据从output寄存器中写入存储器。</p><h2 id="PuDianNao-2"><a href="#PuDianNao-2" class="headerlink" title="PuDianNao"></a>PuDianNao</h2><p>PuDianNao抛弃了按用途分裂存储器的方法，改为按重用频率分裂存储器。且其设计方法更贴近通用处理器CPU，以实现通用机器学习处理器。PuDianNao认为其能实现的7种机器学习算法在存储上分为两种：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/PuDianNao_store_analysis.JPG" class=""><p>第一种与k-NN（k-邻近算法）类似，每个数据的重用间隔（这一次使用和下一次使用之间的间隔数据数量）明确的类聚为几类。第二种与NB（朴素贝叶斯）类似，除了位置为1上的明显类聚外，数据重用间隔在一段上均有分布。因此PuDianNao实现三个片上存储，分别为：</p><ul><li>ColdBuffer：16KB，存储重用间隔较长的数据，位宽较小。</li><li>HotBuffer：8KB，存储重用数据较少的数据，位宽较大。</li><li>OutputBuffer：8KB，存储输出数据。</li></ul><h1 id="映射方法"><a href="#映射方法" class="headerlink" title="映射方法"></a>映射方法</h1><p>映射方法指现有硬件加速器如何实现神经网络中的运算，包括卷积，池化和全连接层等。</p><h2 id="DianNao与DaDianNao-2"><a href="#DianNao与DaDianNao-2" class="headerlink" title="DianNao与DaDianNao"></a>DianNao与DaDianNao</h2><p>由于DianNao和DaDianNao的论文中都没有明确阐述这两款加速器如何映射运算，因此以下内容均为<strong>个人推测</strong></p><p>DianNao和DaDianNao的运算单元均为NFU，参考其设计，其功能描述如下：</p><script type="math/tex; mode=display">mul: y_i = \sum\limits^{T_n}_{i=1} w_i \cdot x_i \\max:y_i = max\{x_1,x_2,...,x_{T_n}\}</script><h3 id="向量内积与卷积"><a href="#向量内积与卷积" class="headerlink" title="向量内积与卷积"></a>向量内积与卷积</h3><p>无论是向量内积还是卷积，其最终都是对应位置元素相乘再相加。都可以使用运算核心的MUL功能解决，即将NFU-2配置为加法树。在存储中，输入数据按[高度，宽度，通道数]维度排列，即先存储第一个数据位置的所有通道数据，再存储第二个数据位置的所有通道数据，以此类推。权值数据按[高度，宽度，输出通道数，输入通道数]排列。其实现图如下所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/DianNao_map.png" class=""><p>上图为一个$T_n = 2$的例子，其中数据含义如下所示：</p><div class="table-container"><table><thead><tr><th>标记</th><th>来源</th><th>说明</th></tr></thead><tbody><tr><td>X000</td><td>输入数据</td><td>数据位置(0,0)，通道0数据</td></tr><tr><td>X001</td><td>输入数据</td><td>数据位置(0,0)，通道1数据</td></tr><tr><td>W0000</td><td>参数</td><td>数据位置(0,0)，通道0数据对应输出通道0的参数</td></tr><tr><td>W0001</td><td>参数</td><td>数据位置(0,0)，通道1数据对应输出通道0的参数</td></tr><tr><td>W0010</td><td>参数</td><td>数据位置(0,0)，通道0数据对应输出通道1的参数</td></tr><tr><td>W0011</td><td>参数</td><td>数据位置(0,0)，通道1数据对应输出通道1的参数</td></tr></tbody></table></div><p>其实现的运算在卷积中如下所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/DianNao_conv_map.png" class=""><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>实现池化层时，输入数据按[通道数，高度，宽度]排列，NFU-2被配置为取最大值树。</p><h2 id="ShiDianNao-3"><a href="#ShiDianNao-3" class="headerlink" title="ShiDianNao"></a>ShiDianNao</h2><p>ShiDianNao由阵列实现卷积，池化，向量内积等操作，映射比较复杂。以下说明均使用$P_x=P_y=2$</p><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>ShiDianNao的每个节点的简化图形如下所示，以下说明将使用该图示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_node_model.png" class=""><p>实现卷积的第一步是初始化，将数据读入运算阵列，使用缓存读方式1或2：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_map0.png" class=""><p>随后读Bank2和Bank3的第一个神经元，将其填充到运算阵列的右侧，同时输入数据右移，这等效的是标记参与运算的数据框向右扩展：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_map1.png" class=""><p>之后读Bank2和Bank3的第二个神经元，将其填充到运算阵列右侧，同时输入数据右移，这等效的是标记参与运算的数据框向右扩展：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_map2.png" class=""><p>随后读Bank1的两个神经元，将其填充到底部，同时数据上移，这等效标记参与运算的数据框向下扩展：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_map3.png" class=""><p>下表表示了每一个运算节点使用过的权值和数据：</p><div class="table-container"><table><thead><tr><th>坐标</th><th>参数=K00</th><th>参数=K10</th><th>参数=K20</th><th>参数=K01</th></tr></thead><tbody><tr><td>0,0（左上）</td><td>X00</td><td>X10</td><td>X20</td><td>X01</td></tr><tr><td>0,1（右上）</td><td>X10</td><td>X20</td><td>X30</td><td>X11</td></tr><tr><td>1,0（左下）</td><td>X01</td><td>X11</td><td>X21</td><td>X02</td></tr><tr><td>1,1（右下）</td><td>X11</td><td>X21</td><td>X31</td><td>X12</td></tr></tbody></table></div><p>注意上文中运算单元和SB的行为为原文中注明的，存储器行为为<strong>个人推断</strong>，此外，原文中的推断到此为止，理由为保持简洁，然而下一步的操作<strong>使用以上几步无法完全推测</strong>，原文中说明该复用方法可以节约44.4%的带宽，有$4 \times 9 \times 44.4\% = 16$，所以一共读了20次，图像中有16个数据，推测就是中心处被复用最多次的X11，X21，X12和X22。该部分说明的原图如下图所示：</p><img src="/2018/05/14/DianNao%E7%B3%BB%E5%88%97%E5%88%86%E6%9E%90/ShiDianNao_map_source.JPG" class=""><h3 id="池化-1"><a href="#池化-1" class="headerlink" title="池化"></a>池化</h3><p>池化的映射方法与卷积类似，且由于池化的Stride一般不为1，因此需要注意的是FIFO-H和FIFO-V的深度不再是1。其中$S_x$和$S_y$分别是X方向和Y方向的Stride。</p><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>矩阵乘法中，每个计算节点代表一个输出神经元，除非一个输出神经元的计算全部完成，否则不会进行下一个神经元的运算。与卷积不同的是，被广播的数据是输入数据而不是权值。因为在矩阵乘运算中，权值的数量多于数据且不被复用。每次运算分为以下几个步骤：</p><ul><li>一个输入数据和$P_x \times P_y$个权值，每个计算节点接收一个数据和被广播的数据。</li><li>计算节点将输入数据和权值相乘后与之前的部分和积累。</li><li>当一个输出神经元的所有计算都完成后，将每个节点累积的结果缓存回片上存储中。</li></ul><h2 id="PuDianNao-3"><a href="#PuDianNao-3" class="headerlink" title="PuDianNao"></a>PuDianNao</h2><p>PuDianNao的映射方法比较简单，由于较多的考虑了灵活性，因此使用类似软件的方式控制整个芯片。推测方法为：</p><ul><li>控制模块控制DMA将指定数据从片外存储搬运到片上buufer中，并将其搬运到指定处理单元中</li><li>处理单元在控制模块控制下对数据进行处理</li><li>DMA将结果从处理单元单元搬运到buffer中</li></ul>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络优化算法总结</title>
      <link href="2018/04/24/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
      <url>2018/04/24/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1 id="优化算法框架"><a href="#优化算法框架" class="headerlink" title="优化算法框架"></a>优化算法框架</h1><p>优化算法的框架如下所示：</p><script type="math/tex; mode=display">w_{t+1} = w_t - \eta_t \\\eta_t = \cfrac{\alpha}{\sqrt{V_t}} \cdot m_t</script><p>其中，$w_i$为i时刻的权值，$\eta_i$为i时刻的优化量；$\alpha$为学习率，$m_t$为一阶动量，$V_t$为二阶动量。一阶动量和二阶动量都与梯度有关，如下所示：</p><script type="math/tex; mode=display">m_t = M_1(g_1,g_2,...,g_t) \\V_t = M_2(g_1,g_2,...,g_t) \\g_t = \nabla f(w_t)</script><p>一阶动量和二阶动量均是历史梯度和当前梯度的函数</p><h1 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h1><h2 id="固定学习率优化算法"><a href="#固定学习率优化算法" class="headerlink" title="固定学习率优化算法"></a>固定学习率优化算法</h2><p>学习率固定的优化算法均有一个特点：不考虑二阶动量（即$M_2(g_i) = I$）</p><h3 id="随机梯度下降（SGD）"><a href="#随机梯度下降（SGD）" class="headerlink" title="随机梯度下降（SGD）"></a>随机梯度下降（SGD）</h3><p>随机梯度下降时最简单的优化算法，有：$m_t = g_t,V_t = I$，带入公式有优化公式为：$\eta_t = \alpha \cdot g_t$</p><h3 id="带动量的随机梯度下降（SGD-with-Momentum）"><a href="#带动量的随机梯度下降（SGD-with-Momentum）" class="headerlink" title="带动量的随机梯度下降（SGD with Momentum）"></a>带动量的随机梯度下降（SGD with Momentum）</h3><p>随机梯度下降加上动量项，即考虑梯度累积，有：</p><script type="math/tex; mode=display">g_t = \nabla f(w_t) \\m_t = \beta \cdot m_{t-1} + (1-\beta)\cdot g_t \\\eta_t = \alpha \cdot m_t</script><h3 id="SGD-with-Nesterov-Acceleration"><a href="#SGD-with-Nesterov-Acceleration" class="headerlink" title="SGD with Nesterov Acceleration"></a>SGD with Nesterov Acceleration</h3><p>在计算梯度的时候向前考虑一步，即计算梯度的时候，计算再沿着上一次更新方向更新一次的权值的梯度，有：</p><script type="math/tex; mode=display">g_t = \nabla f(w_t + \alpha \cdot m_{t-1})  \\m_t = \beta \cdot m_{t-1} + (1-\beta)\cdot g_t \\\eta_t = \alpha \cdot m_t</script><h2 id="自适应学习率优化算法"><a href="#自适应学习率优化算法" class="headerlink" title="自适应学习率优化算法"></a>自适应学习率优化算法</h2><p>自适应学习率的优化算法考虑二阶动量，一般来说，一阶动量决定优化方向，二阶动量自适应学习率</p><h3 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h3><p>二阶动量取梯度平方和：$V<em>t = \sum\limits^t</em>{i=1} g^2_i$，此时，$\eta_t = \cfrac{\alpha}{\sqrt{V_t}} \cdot m_t$，可以将$\cfrac{\alpha}{\sqrt{V_t}}$视为自适应的学习率：梯度不断累积，学习率单调下降。且梯度累积越快，学习率下降越快。</p><h3 id="AdaDelta-RMSProp"><a href="#AdaDelta-RMSProp" class="headerlink" title="AdaDelta/RMSProp"></a>AdaDelta/RMSProp</h3><p>二阶动量取梯度在一定范围内的平方和：</p><script type="math/tex; mode=display">V_1 = g^2_1 \\V_t = \beta \cdot V_{t-1} + (1-\beta) \cdot g_t^2</script><h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>Adam综合使用了一阶动量项和二阶动量项，即：</p><script type="math/tex; mode=display">g_t = \nabla f(w_t) \\m_1 = g_1,V_1 = g_1^2 \\m_t = \beta_1 \cdot m_{t-1} + (1-\beta_1)\cdot g_t \\V_t = \beta_2 \cdot V_{t-1} + (1-\beta_2) \cdot g_t^2</script><h3 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h3><p>Nadam为使用了Nesterov和Adam的结合，有：</p><script type="math/tex; mode=display">g_t = \nabla f(w_t + \cfrac{\alpha}{\sqrt{V_{t-1}}} \cdot m_{t-1})  \\m_1 = g_1,V_1 = g_1^2 \\m_t = \beta_1 \cdot m_{t-1} + (1-\beta_1)\cdot g_t \\V_t = \beta_2 \cdot V_{t-1} + (1-\beta_2) \cdot g_t^2</script><h2 id="混合方法：Adam-SGD"><a href="#混合方法：Adam-SGD" class="headerlink" title="混合方法：Adam+SGD"></a>混合方法：Adam+SGD</h2><p>很多论文指出Adam虽然收敛较快，但效果不如SGD，因此，《Improving Generalization Performance by Switching from Adam to SGD》提出了一种算法，前期使用Adam算法，后期使用SGD，如下图所示：</p><img src="/2018/04/24/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/adam_sgd.jpeg" class=""><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>内容参考自<a href="https://zhuanlan.zhihu.com/p/32230623">机器学习炼丹记：Adam那么棒，为什么还对SGD念念不忘</a></p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AHB学习笔记</title>
      <link href="2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>[TOC]</p><h1 id="1-AHB概述"><a href="#1-AHB概述" class="headerlink" title="1.AHB概述"></a>1.AHB概述</h1><p>AHB总线是一种专为高性能同步传输设计的总线，层次高于APB总线，支持以下特性：</p><ul><li>突发传输</li><li>拆分事务</li><li>主设备单时钟周期传输</li><li>单时钟沿操作</li><li>非三态实现</li><li>宽数据总线配置（64/128bit）</li></ul><h2 id="1-1-典型AHB系统"><a href="#1-1-典型AHB系统" class="headerlink" title="1.1.典型AHB系统"></a>1.1.典型AHB系统</h2><img src="/2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/typical_system.JPG" class=""><p>典型的AHB系统包括以下部分：</p><ul><li>可支持高带宽传输的主干总线</li><li>AHB主设备（如高性能CPU和DMA设备等）</li><li>AHB从设备（存储器和APB桥等）</li></ul><h2 id="1-2-AHB互连"><a href="#1-2-AHB互连" class="headerlink" title="1.2.AHB互连"></a>1.2.AHB互连</h2><p>AHB的互连使用多路复用器策略，由以下几个部分组成：</p><ul><li>主设备：发起通信，所有主设备将通行地址和数据发送到主设备多路复用器</li><li>从设备：回应通信，从主设备多路复用器获得通信地址和数据，将回应数据发送到从设备多路复用器</li><li>判决器：主设备多路复用器的控制器，控制哪一个主设备的通信数据可以被发送到从机</li><li>解码器：从设备多路复用器的控制器，控制哪一个从设备的通信数据可以被发送回主机</li></ul><img src="/2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/bus_interconnect.JPG" class=""><h1 id="2-AHB信号"><a href="#2-AHB信号" class="headerlink" title="2.AHB信号"></a>2.AHB信号</h1><h2 id="2-1-基本AHB信号"><a href="#2-1-基本AHB信号" class="headerlink" title="2.1.基本AHB信号"></a>2.1.基本AHB信号</h2><div class="table-container"><table><thead><tr><th>信号名</th><th>位宽</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>HCLK</td><td>1</td><td>系统时钟</td><td>传输系统的时钟</td></tr><tr><td>HRESETn</td><td>1</td><td>复位系统</td><td>传输系统复位信号，低有效</td></tr><tr><td>HADDR</td><td>32</td><td>主机</td><td>主机发送传输目标地址</td></tr><tr><td>HTRANS</td><td>2</td><td>主机</td><td>当前发生的传输类型</td></tr><tr><td>HWRITE</td><td>1</td><td>主机</td><td>读写信号：1-写操作；0-读操作</td></tr><tr><td>HSIZE</td><td>3</td><td>主机</td><td>传输位宽，标记一次传输的位宽</td></tr><tr><td>HBURST</td><td>3</td><td>主机</td><td>突发传输类型</td></tr><tr><td>HPROT</td><td>4</td><td>主机</td><td>协议类型，标记传输使用协议的额外信息</td></tr><tr><td>HWDATA</td><td>32</td><td>主机</td><td>发送数据，主机发送到从机的数据</td></tr><tr><td>HSELx</td><td>x</td><td>解码器</td><td>标记哪一个从机被选中，由地址解码产生</td></tr><tr><td>HRDATA</td><td>32</td><td>从机</td><td>接收数据，从机发送到主机的数据</td></tr><tr><td>HREADY</td><td>1</td><td>从机</td><td>传输完成信号，高有效</td></tr><tr><td>HRESP</td><td>2</td><td>从机</td><td>传输状态的额外标记</td></tr></tbody></table></div><h2 id="2-2-多主机传输信号"><a href="#2-2-多主机传输信号" class="headerlink" title="2.2.多主机传输信号"></a>2.2.多主机传输信号</h2><div class="table-container"><table><thead><tr><th>信号名</th><th>位宽</th><th>来源</th><th>描述</th></tr></thead><tbody><tr><td>HBUSREQx</td><td>x</td><td>主机</td><td>主机x向判决器请求传输，最多支持16个主机</td></tr><tr><td>HLOCKx</td><td>x</td><td>主机</td><td>主机x向判决器请求锁定传输，其他主机在锁定期内无法使用总线</td></tr><tr><td>HGRANTx</td><td>x</td><td>判决器</td><td>主机x权限标记信号，当有效时（为高有效），主机x在AHB总线空闲时具有最高的控制权限</td></tr><tr><td>HMASTER</td><td>4</td><td>判决器</td><td>主机标号，标记当前传输由哪个主机控制</td></tr><tr><td>HMASTLOCK</td><td>1</td><td>判决器</td><td>锁定标记，标记当前总线被某个主机锁定</td></tr><tr><td>HSPLITx</td><td>16x</td><td>从机</td><td>事务分离标记，用于标记哪个主机应当重启事务</td></tr></tbody></table></div><h1 id="3-AHB传输"><a href="#3-AHB传输" class="headerlink" title="3.AHB传输"></a>3.AHB传输</h1><p>AHB传输分为以下几个部分：</p><ul><li>主机获取总线使用权：主机向判决器发送总线请求信号，判决器发送应答后主机可以开始传输</li><li>数据传输：主机向从机传输数据，分为以下两个部分：<ul><li>发送地址和控制信号：包括地址，位宽，突发类型（增量突发和回卷突发）等控制信号，仅一个时钟周期</li><li>数据传输：进行数据交换，一个或多个时钟周期</li></ul></li><li>从机应答：从机通过HRESP和HREADY标记完成状态，对于HRESP，有以下状态：<ul><li>OKAY：标记传输完成，当HRESP为该状态且HREADY拉高时，传输完成</li><li>ERROR：标记传输出错</li><li>RETRY和SPLIT：标记传输未完成，主设备仍需要占用总线</li></ul></li></ul><p>关于突发传输，理论上进行突发传输的主设备应当一直占据总线，但是为了缩短等待时间，AHB允许打断突发传输，并在一段时间后重启该突发传输</p><h2 id="3-1-基本传输"><a href="#3-1-基本传输" class="headerlink" title="3.1.基本传输"></a>3.1.基本传输</h2><p>AHB的基本传输过程由两个部分组成：</p><ul><li>地址/控制传输：传输地址信息和控制信息，仅占一个时钟周期</li><li>数据传输：可能需要多个时钟周期，由信号HREADY决定（拉高才结束数据传输）</li></ul><h3 id="3-1-1-无等待传输"><a href="#3-1-1-无等待传输" class="headerlink" title="3.1.1.无等待传输"></a>3.1.1.无等待传输</h3><img src="/2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/anr_basic_nowait.png" class=""><p>无等待传输下，一个传输与三个时钟沿有关：</p><ul><li>第一个时钟沿：第一个时钟沿后，主机将地址信息和控制信息发送到总线上</li><li>第二个时钟沿：第二个时钟沿上，从机采样主机的地址信息和控制信息。第二个时钟沿后，从机将响应信号和数据发送到总线上</li><li>第三个时钟沿：主机采样从机响应信号和数据，传输完成</li></ul><h3 id="3-1-2-有等待传输"><a href="#3-1-2-有等待传输" class="headerlink" title="3.1.2.有等待传输"></a>3.1.2.有等待传输</h3><img src="/2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ahb_basic_wait.png" class=""><p>有等待传输下，数据传输阶段可以扩展，即在HREADY拉高之前，数据传输阶段不结束。要求写数据在HREADY拉高前保持稳定，主机在HREADY拉高后采样读数据</p><h3 id="3-1-3-流水线传输"><a href="#3-1-3-流水线传输" class="headerlink" title="3.1.3.流水线传输"></a>3.1.3.流水线传输</h3><img src="/2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ahb_basic_water.png" class=""><p>AHB总线支持流水线传输，即将传输分为地址-数据两个部分流水进行，本次传输的地址必然在上一次地址之后，本次传输的数据必定紧跟在本次传输地址之后。因此，当上一次的数据传输阻塞导致传输周期增加时，下一传输的地址周期也会相应的变长：</p><ul><li>A1和C1为第一次传输的地址和控制信号</li><li>WD1和RD1是第一次传输的数据，该传输为单时钟即无阻塞的传输，同时发送的还有下一次传输的地址和控制信号：A2和C2</li><li>第二次传输为多周期传输，因此WD2和RD2占据多个时钟周期，对应的，同时发送的第三次传输地址和控制信A3和C3也被延迟相同的时钟周期数</li><li>WD3和RD3为第三次传输的数据</li></ul><h2 id="3-2-传输类型"><a href="#3-2-传输类型" class="headerlink" title="3.2.传输类型"></a>3.2.传输类型</h2><p>传输类型使用端口HTRANS标记，有以下取值：</p><ul><li>IDLE（00）：标志主机占有AHB总线，但是没有数据传输发生。从机需要使用OKAY状态回应该类型</li><li>BUSY（01）：标志主机占有AHB总线并在进行猝发传输，但下一个传输不能立刻发生。从机需要使用OKAY状态回应</li><li>NONSEQ（10）：标志主机当前发送的地址和控制信号与上一次传输无关（单次传输就是该状态）</li><li>SEQ（11）：标记主机处于猝发传输的中间部分，即当前发送的地址和控制信号与上一次地址和控制信号有关</li></ul><p>例子如下图所示：</p><img src="/2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ahb_trantype.JPG" class=""><ul><li>第一次传输，开启一次猝发传输，因此该地址与上一次传输无关，使用类型NONSEQ</li><li>第二次传输，无法立刻进行传输，因此使用BUSY标记延迟一个周期，延迟后可以进行传输，且处于猝发传输中，因此地址与上一次地址有关，使用SEQ标记</li><li>之后均为猝发传输，均使用SEQ类型</li></ul><h2 id="3-3-猝发传输"><a href="#3-3-猝发传输" class="headerlink" title="3.3.猝发传输"></a>3.3.猝发传输</h2><h3 id="3-3-1-猝发类型"><a href="#3-3-1-猝发类型" class="headerlink" title="3.3.1.猝发类型"></a>3.3.1.猝发类型</h3><p>猝发传输分为两类：</p><ul><li>增量猝发：传输过程中传输地址递增。下一次传输的地址是上一次地址加上一个增量</li><li>回卷猝发：猝发的地址范围被限制在一个固定范围之内，传输地址递增，若是超出则回到地址范围的开始的地址。例如从0x34进行增量为4，范围为16的回卷猝发，地址顺序为0x34、0x38、0x3c，0x30</li></ul><p>猝发类型使用字段HBURST标记，含义如下表所示：</p><div class="table-container"><table><thead><tr><th>HBURST[2:0]</th><th>类型</th><th>描述</th></tr></thead><tbody><tr><td>000</td><td>SINGLE</td><td>单个传输</td></tr><tr><td>001</td><td>INCR</td><td>无限制长度的增量猝发传输</td></tr><tr><td>010</td><td>WRAP4</td><td>4拍回卷猝发</td></tr><tr><td>011</td><td>INCR4</td><td>4拍增量猝发</td></tr><tr><td>100</td><td>WRAP8</td><td>8拍回卷猝发</td></tr><tr><td>101</td><td>INCR8</td><td>8拍增量猝发</td></tr><tr><td>110</td><td>WRAP16</td><td>16拍回卷猝发</td></tr><tr><td>111</td><td>INCR16</td><td>16拍增量猝发</td></tr></tbody></table></div><p>注意一次猝发传输不能跨越1kB的地址区间，且传输的起始地址必须与数据类型对应，例如传输字数据的二进制起始地址必须满足后两位为00。</p><h3 id="3-3-2-猝发终止"><a href="#3-3-2-猝发终止" class="headerlink" title="3.3.2.猝发终止"></a>3.3.2.猝发终止</h3><p>从机通过监控HTRANS发现猝发传输的终止：</p><ul><li>若下一个HTRANS标记为BUSY或SEQ：猝发传输未终止</li><li>若下一个HTRANS标记为NONSEQ或IDLE：上一次猝发传输已经终止</li></ul><p>若猝发传输是提前终止的，如总线控制权被剥夺，那么主机需要在可以进行传输时重建猝发传输。例如一个4拍传输仅发送了一拍就终止，主机需要使用INCR类型的猝发构建3拍传输以重建。</p><h3 id="3-3-3-猝发切分传输"><a href="#3-3-3-猝发切分传输" class="headerlink" title="3.3.3.猝发切分传输"></a>3.3.3.猝发切分传输</h3><p>[暂时略过，需要使用时再补充]</p><h2 id="3-4-数据总线"><a href="#3-4-数据总线" class="headerlink" title="3.4.数据总线"></a>3.4.数据总线</h2><p>当传输位宽不同时，数据总线的使用情况如下所示（小端传输）：</p><img src="/2018/04/18/AHB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ahb_data_bus.JPG" class=""><h1 id="4-控制信号"><a href="#4-控制信号" class="headerlink" title="4.控制信号"></a>4.控制信号</h1><h2 id="4-1-控制总线"><a href="#4-1-控制总线" class="headerlink" title="4.1.控制总线"></a>4.1.控制总线</h2><h3 id="4-1-1-HSIZE"><a href="#4-1-1-HSIZE" class="headerlink" title="4.1.1.HSIZE"></a>4.1.1.HSIZE</h3><p>HSIZE控制传输的数据结构位数，如下表所示：</p><div class="table-container"><table><thead><tr><th>HSIZE(bit)</th><th>位宽</th><th>描述</th></tr></thead><tbody><tr><td>000</td><td>8</td><td>字节传输（Byte）</td></tr><tr><td>001</td><td>16</td><td>半字传输（Half word）</td></tr><tr><td>010</td><td>32</td><td>字传输（Word）</td></tr><tr><td>011</td><td>64</td><td>-</td></tr><tr><td>100</td><td>128</td><td>4字传输</td></tr><tr><td>101</td><td>256</td><td>8字传输</td></tr><tr><td>110</td><td>512</td><td>-</td></tr><tr><td>111</td><td>1024</td><td>-</td></tr></tbody></table></div><h3 id="4-1-2-HPROT"><a href="#4-1-2-HPROT" class="headerlink" title="4.1.2.HPROT"></a>4.1.2.HPROT</h3><p>HPROT提供对传输协议的额外说明，如下所示：</p><ul><li>HPROT[3]：0-Cacheable；1-Not cacheable</li><li>HPROT[2]：0-Bufferable；1-Not bufferable</li><li>HPROT[1]：0-Privileged access；1-User access</li><li>HPROT[0]：0-Opcode fetch；1-Data access</li></ul><h3 id="4-1-3-HSELx"><a href="#4-1-3-HSELx" class="headerlink" title="4.1.3.HSELx"></a>4.1.3.HSELx</h3><p>HSELx由地址解码器产生，用于指示哪个从机被选中。从机当HREADY为高，即一次传输完成后锁存HSELx信号，若HSELx在HREADY为低时有效，将不会对本次传输产生影响。</p><h3 id="4-1-4-HRESETn"><a href="#4-1-4-HRESETn" class="headerlink" title="4.1.4.HRESETn"></a>4.1.4.HRESETn</h3><p>HRESETn信号是复位信号，该信号是异步触发并同步释放的，当该信号有效时，所有主机均要将相关信号复位，包括将HTRANS置为IDLE。</p><h2 id="4-2-响应信号"><a href="#4-2-响应信号" class="headerlink" title="4.2.响应信号"></a>4.2.响应信号</h2><h3 id="4-2-1-HREADY"><a href="#4-2-1-HREADY" class="headerlink" title="4.2.1.HREADY"></a>4.2.1.HREADY</h3><p>HREADY信号标志传输是否完成：0-未完成，需要插入额外周期；1-已完成</p><h3 id="4-2-2-HRESP"><a href="#4-2-2-HRESP" class="headerlink" title="4.2.2.HRESP"></a>4.2.2.HRESP</h3><p>HRESP用于标记传输完成的状态：</p><ul><li>OKAY(00)：传输完成</li><li>ERROR(01)：传输错误，例如协议错误或写入只读地址</li><li>RETRY(10)：传输未正常完成，需要重新尝试传输。该响应不会改变优先级</li><li>SPLIT(11)：传输未正常完成，需要从下一个地址重新启动传输。该响应可能改变优先级</li></ul><h2 id="4-3-总线仲裁"><a href="#4-3-总线仲裁" class="headerlink" title="4.3.总线仲裁"></a>4.3.总线仲裁</h2><p>仲裁器保证一个时刻仅有一个主设备占有总线，因此当有多个主设备提出访问请求时，仲裁器通过仲裁信号仲裁哪一个主设备获得总线使用权</p><h3 id="4-3-1-仲裁信号"><a href="#4-3-1-仲裁信号" class="headerlink" title="4.3.1.仲裁信号"></a>4.3.1.仲裁信号</h3><p>仲裁信号见[2.2.多主机传输信号]</p><h3 id="4-3-2-主机获取总线"><a href="#4-3-2-主机获取总线" class="headerlink" title="4.3.2.主机获取总线"></a>4.3.2.主机获取总线</h3><p>主机获取总线控制权分为两个步骤：</p><ol><li>主机分别通过HBUSREQx和HLOCKx分别向仲裁器申请获取或锁定总线控制权</li><li>仲裁器分配总线控制权</li></ol><p>主机通过自己的HBUSREQx向仲裁器申请总线控制权，仲裁器在时钟上升沿采样该信号，并通过内置的优先级算法决定总线控制权归属。一般来说，仲裁器仅会在一次传输完成后分配总线控制权，即将HMASTER置为获取总线控制权的主机编号且在上一次突发传输的倒数第二个传输时改变HGRANTx，因此新HGRANTx可以在上一次突发传输的最后一次传输同时被采样。</p><p>但如果需要，仲裁器也可以通过打断传输的方式优先执行优先级更高的传输。若获取总线控制权的主机申请锁定总线，其他主机将无法获得总线控制权。</p><p>对于指定突发长度的突发传输，仲裁器根据突发长度判断需要总线控制权的时间，若结束后启动下一次突发传输，需要再次请求控制权。对于未指定长度的突发传输，主机需要在传输过程中一直保持请求信号拉高，否则将仲裁器无法判断何时收回总线控制权。</p><p>当无主机申请总线时，总线的控制权被交给默认的主机，即使该主机没有申请总线控制权。此时默认主机需要将HTRANS置为IDLE状态。</p>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> AMBA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于pytorch的CapsNet代码详解</title>
      <link href="2018/04/17/%E5%9F%BA%E4%BA%8Epytorch%E7%9A%84CapsNet%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/"/>
      <url>2018/04/17/%E5%9F%BA%E4%BA%8Epytorch%E7%9A%84CapsNet%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="CapsNet基本结构"><a href="#CapsNet基本结构" class="headerlink" title="CapsNet基本结构"></a>CapsNet基本结构</h1><p>参考CapsNet的论文，提出的基本结构如下所示：</p><img src="/2018/04/17/%E5%9F%BA%E4%BA%8Epytorch%E7%9A%84CapsNet%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/capsnet_mnist.jpg" class=""><p>可以看出，CapsNet的基本结构如下所示：</p><ul><li>普通卷积层Conv1：基本的卷积层，感受野较大，达到了9x9</li><li>预胶囊层PrimaryCaps：为胶囊层准备，运算为卷积运算，最终输出为[batch,caps_num,caps_length]的三维数据：<ul><li>batch为批大小</li><li>caps_num为胶囊的数量</li><li>caps_length为每个胶囊的长度（每个胶囊为一个向量，该向量包括caps_length个分量）</li></ul></li><li>胶囊层DigitCaps：胶囊层，目的是代替最后一层全连接层，输出为10个胶囊</li></ul><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="胶囊相关组件"><a href="#胶囊相关组件" class="headerlink" title="胶囊相关组件"></a>胶囊相关组件</h2><h3 id="激活函数Squash"><a href="#激活函数Squash" class="headerlink" title="激活函数Squash"></a>激活函数Squash</h3><p>胶囊网络有特有的激活函数Squash函数：</p><script type="math/tex; mode=display">Squash(S) = \cfrac{||S||^2}{1+||S||^2} \cdot \cfrac{S}{||S||}</script><p>其中输入为S胶囊，该激活函数可以将胶囊的长度压缩，代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squash</span>(<span class="params">inputs, axis=-<span class="number">1</span></span>):</span></span><br><span class="line">    norm = torch.norm(inputs, p=<span class="number">2</span>, dim=axis, keepdim=<span class="literal">True</span>)</span><br><span class="line">    scale = norm**<span class="number">2</span> / (<span class="number">1</span> + norm**<span class="number">2</span>) / (norm + <span class="number">1e-8</span>)</span><br><span class="line">    <span class="keyword">return</span> scale * inputs</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li><code>norm = torch.norm(inputs, p=2, dim=axis, keepdim=True)</code>计算输入胶囊的长度，<code>p=2</code>表示计算的是二范数，<code>keepdim=True</code>表示保持原有的空间形状。</li><li><code>scale = norm**2 / (1 + norm**2) / (norm + 1e-8)</code>计算缩放因子，即$ \cfrac{||S||^2}{1+||S||^2} \cdot \cfrac{1}{||S||}$</li><li><code>return scale * inputs</code>完成计算</li></ul><h3 id="预胶囊层PrimaryCaps"><a href="#预胶囊层PrimaryCaps" class="headerlink" title="预胶囊层PrimaryCaps"></a>预胶囊层PrimaryCaps</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrimaryCapsule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Apply Conv2D with `out_channels` and then reshape to get capsules</span></span><br><span class="line"><span class="string">    :param in_channels: input channels</span></span><br><span class="line"><span class="string">    :param out_channels: output channels</span></span><br><span class="line"><span class="string">    :param dim_caps: dimension of capsule</span></span><br><span class="line"><span class="string">    :param kernel_size: kernel size</span></span><br><span class="line"><span class="string">    :return: output tensor, size=[batch, num_caps, dim_caps]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, dim_caps, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PrimaryCapsule, self).__init__()</span><br><span class="line">        self.dim_caps = dim_caps</span><br><span class="line">        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        outputs = self.conv2d(x)</span><br><span class="line">        outputs = outputs.view(x.size(<span class="number">0</span>), -<span class="number">1</span>, self.dim_caps)</span><br><span class="line">        <span class="keyword">return</span> squash(outputs)</span><br></pre></td></tr></table></figure><p>预胶囊层使用卷积层实现，其前向传播包括三个部分：</p><ul><li><code>outputs = self.conv2d(x)</code>：对输入进行卷积处理，这一步output的形状是[batch,out_channels,p_w,p_h]</li><li><code>outputs = outputs.view(x.size(0), -1, self.dim_caps)</code>：将4D的卷积输出变为3D的胶囊输出形式，output的形状为[batch,caps_num,dim_caps]，其中caps_num为胶囊数量，可自动计算；dim_caps为胶囊长度，需要预先指定。</li><li><code>return squash(outputs)</code>：激活函数，并返回激活后的胶囊</li></ul><h3 id="胶囊层DigitCaps"><a href="#胶囊层DigitCaps" class="headerlink" title="胶囊层DigitCaps"></a>胶囊层DigitCaps</h3><h4 id="参数定义"><a href="#参数定义" class="headerlink" title="参数定义"></a>参数定义</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_num_caps, in_dim_caps, out_num_caps, out_dim_caps, routings=<span class="number">3</span></span>):</span></span><br><span class="line">    <span class="built_in">super</span>(DenseCapsule, self).__init__()</span><br><span class="line">    self.in_num_caps = in_num_caps</span><br><span class="line">    self.in_dim_caps = in_dim_caps</span><br><span class="line">    self.out_num_caps = out_num_caps</span><br><span class="line">    self.out_dim_caps = out_dim_caps</span><br><span class="line">    self.routings = routings</span><br><span class="line">    self.weight = nn.Parameter(<span class="number">0.01</span> * torch.randn(out_num_caps, in_num_caps, out_dim_caps, in_dim_caps))</span><br></pre></td></tr></table></figure><p>参数定义如下：</p><ul><li>in_num_caps：输入胶囊的数量</li><li>in_dim_caps：输入胶囊的长度（维数）</li><li>out_num_caps：输出胶囊的数量</li><li>out_dim_caps：输出胶囊的长度（维数）</li><li>routings：动态路由迭代的次数</li></ul><p>另外，还定义了权值weight，尺寸为[out_num_caps, in_num_caps, out_dim_caps, in_dim_caps]，即每个输出和每个输出胶囊都有连接</p><h4 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    x_hat = torch.squeeze(torch.matmul(self.weight, x[:, <span class="literal">None</span>, :, :, <span class="literal">None</span>]), dim=-<span class="number">1</span>)</span><br><span class="line">    x_hat_detached = x_hat.detach()</span><br><span class="line"></span><br><span class="line">    b = Variable(torch.zeros(x.size(<span class="number">0</span>), self.out_num_caps, self.in_num_caps)).cuda()</span><br><span class="line">    <span class="keyword">assert</span> self.routings &gt; <span class="number">0</span>, <span class="string">&#x27;The \&#x27;routings\&#x27; should be &gt; 0.&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.routings):</span><br><span class="line">        c = F.softmax(b, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> i == self.routings - <span class="number">1</span>:</span><br><span class="line">            outputs = squash(torch.<span class="built_in">sum</span>(c[:, :, :, <span class="literal">None</span>] * x_hat, dim=-<span class="number">2</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            outputs = squash(torch.<span class="built_in">sum</span>(c[:, :, :, <span class="literal">None</span>] * x_hat_detached, dim=-<span class="number">2</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">            b = b + torch.<span class="built_in">sum</span>(outputs * x_hat_detached, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.squeeze(outputs, dim=-<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>前向传播分为两个部分：输入映射和动态路由。输入映射如下所示：</p><ol><li><code>x_hat = torch.squeeze(torch.matmul(self.weight, x[:, None, :, :, None]), dim=-1)</code><ul><li><code>x[:, None, :, :, None]</code>将数据维度从[batch, in_num_caps, in_dim_caps]扩展到[batch, 1,in_num_caps, in_dim_caps,1]</li><li><code>torch.matmul()</code>将weight和扩展后的输入相乘，weight的尺寸是[out_num_caps, in_num_caps, out_dim_caps, in_dim_caps]，相乘后结果尺寸为[batch, out_num_caps, in_num_caps,out_dim_caps, 1]</li><li><code>torch.squeeze()</code>去除多余的维度，去除后结果尺寸[batch,out_num_caps,in_num_caps,out_dim_caps]</li></ul></li><li><code>x_hat_detached = x_hat.detach()</code>截断梯度反向传播</li></ol><p>这一部分结束后，每个输入胶囊都产生了out_num_caps个输出胶囊，所以目前共有in_num_caps*out_num_caps个胶囊，第二部分是动态路由，动态路由的算法图如下所示：</p><img src="/2018/04/17/%E5%9F%BA%E4%BA%8Epytorch%E7%9A%84CapsNet%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/dynamic_route.jpg" class=""><p>以下部分实现了该过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">b = Variable(torch.zeros(x.size(<span class="number">0</span>), self.out_num_caps, self.in_num_caps)).cuda()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.routings):</span><br><span class="line">        c = F.softmax(b, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> i == self.routings - <span class="number">1</span>:</span><br><span class="line">            outputs = squash(torch.<span class="built_in">sum</span>(c[:, :, :, <span class="literal">None</span>] * x_hat, dim=-<span class="number">2</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            outputs = squash(torch.<span class="built_in">sum</span>(c[:, :, :, <span class="literal">None</span>] * x_hat_detached, dim=-<span class="number">2</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">            b = b + torch.<span class="built_in">sum</span>(outputs * x_hat_detached, dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ol><li>第一部分是softmax函数，使用<code>c = F.softmax(b, dim=1)</code>实现，该步骤不改变b的尺寸</li><li>第二部分是计算路由结果：<code>outputs = squash(torch.sum(c[:, :, :, None] * x_hat, dim=-2, keepdim=True))</code><ul><li><code>c[:, :, :, None]</code>扩展c的维度，以便按位置相乘时广播维度</li><li><code>torch.sum(c[:, :, :, None] * x_hat, dim=-2, keepdim=True)</code>计算出每个胶囊与对应权值的积，即算法中的$s_j$，同时在倒数第二维上求和，则该步输出的结果尺寸为[batch, out_num_caps, 1,out_dim_caps]</li><li>通过激活函数<code>squash()</code></li></ul></li><li>第三部分更新权重<code>b = b + torch.sum(outputs * x_hat_detached, dim=-1)</code>，两个按位相乘的变量尺寸分别为[batch, out_num_caps, in_num_caps, out_dim_caps]和[batch, out_num_caps, 1,out_dim_caps]，倒数第二维上有广播行为，因此最终结果为[batch, out_num_caps, in_num_caps]</li></ol><h2 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h2><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CapsuleNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A Capsule Network on MNIST.</span></span><br><span class="line"><span class="string">    :param input_size: data size = [channels, width, height]</span></span><br><span class="line"><span class="string">    :param classes: number of classes</span></span><br><span class="line"><span class="string">    :param routings: number of routing iterations</span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: (batch, channels, width, height), optional (batch, classes) .</span></span><br><span class="line"><span class="string">        - Output:((batch, classes), (batch, channels, width, height))</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, classes, routings</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CapsuleNet, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.classes = classes</span><br><span class="line">        self.routings = routings</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 1: Just a conventional Conv2D layer</span></span><br><span class="line">        self.conv1 = nn.Conv2d(input_size[<span class="number">0</span>], <span class="number">256</span>, kernel_size=<span class="number">9</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_caps, dim_caps]</span></span><br><span class="line">        self.primarycaps = PrimaryCapsule(<span class="number">256</span>, <span class="number">256</span>, <span class="number">8</span>, kernel_size=<span class="number">9</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Layer 3: Capsule layer. Routing algorithm works here.</span></span><br><span class="line">        self.digitcaps = DenseCapsule(in_num_caps=<span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>, in_dim_caps=<span class="number">8</span>,</span><br><span class="line">                                      out_num_caps=classes, out_dim_caps=<span class="number">16</span>, routings=routings)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Decoder network.</span></span><br><span class="line">        self.decoder = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">16</span>*classes, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, input_size[<span class="number">0</span>] * input_size[<span class="number">1</span>] * input_size[<span class="number">2</span>]),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, y=<span class="literal">None</span></span>):</span></span><br><span class="line">        x = self.relu(self.conv1(x))</span><br><span class="line">        x = self.primarycaps(x)</span><br><span class="line">        x = self.digitcaps(x)</span><br><span class="line">        length = x.norm(dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> y <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># during testing, no label given. create one-hot coding using `length`</span></span><br><span class="line">            index = length.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">            y = Variable(torch.zeros(length.size()).scatter_(<span class="number">1</span>, index.view(-<span class="number">1</span>, <span class="number">1</span>).cpu().data, <span class="number">1.</span>).cuda())</span><br><span class="line">        reconstruction = self.decoder((x * y[:, :, <span class="literal">None</span>]).view(x.size(<span class="number">0</span>), -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> length, reconstruction.view(-<span class="number">1</span>, *self.input_size)</span><br></pre></td></tr></table></figure><p>网络组件包括两个部分：胶囊网络和重建网络，重建网络为多层感知机，根据胶囊的结果重建了图像，这表示胶囊除了包括结果外，还可以包括一些空间信息。</p><p>注意胶囊网络的前向传播部分为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = self.relu(self.conv1(x))</span><br><span class="line">x = self.primarycaps(x)</span><br><span class="line">x = self.digitcaps(x)</span><br><span class="line">length = x.norm(dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>最终的输出为每个胶囊的二范数，即向量的长度</p><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>胶囊神经网络的胶囊部分的代价函数如下所示</p><script type="math/tex; mode=display">L_c = T_c max(0,m^+ - ||V_c||)^2 + \lambda (1 - T_c)max(0,||v_c|| - m^-) ^ 2</script><p>以下代码实现了这个部分，其中L为胶囊的代价函数计算，这里$m^+=0.9,m^-=0.1$，L_recon为重建的代价函数，为输入图像与复原图像的MSELoss函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">caps_loss</span>(<span class="params">y_true, y_pred, x, x_recon, lam_recon</span>):</span></span><br><span class="line">    L = y_true * torch.clamp(<span class="number">0.9</span> - y_pred, <span class="built_in">min</span>=<span class="number">0.</span>) ** <span class="number">2</span> + \</span><br><span class="line">        <span class="number">0.5</span> * (<span class="number">1</span> - y_true) * torch.clamp(y_pred - <span class="number">0.1</span>, <span class="built_in">min</span>=<span class="number">0.</span>) ** <span class="number">2</span></span><br><span class="line">    L_margin = L.<span class="built_in">sum</span>(dim=<span class="number">1</span>).mean()</span><br><span class="line">    L_recon = nn.MSELoss()(x_recon, x)</span><br><span class="line">    <span class="keyword">return</span> L_margin + lam_recon * L_recon</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://arxiv.org/abs/1710.09829">CapsNet论文</a></p><p><a href="https://github.com/XifengGuo/CapsNet-Pytorch">CapsNet开源代码</a></p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解感知机</title>
      <link href="2018/04/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
      <url>2018/04/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="1-模型"><a href="#1-模型" class="headerlink" title="1.模型"></a>1.模型</h1><p>感知机的模型如下图所示：</p><img src="/2018/04/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%84%9F%E7%9F%A5%E6%9C%BA/linear_classifier_structure.png" class=""><p>公式表示如下所示：</p><script type="math/tex; mode=display">f(x) = sign(w \cdot x + b)  \\sign(x) = \begin{cases} +1 & x \geq 0 \\-1 & x < 0\end{cases}</script><p>对于该分类器，其假设空间为特征空间的所有线性分类器，从几何学的角度可以理解为是特征空间中所有的超平面。那么，只要样本在特征空间中是线性可分的（可以被一个超平面完美划分），由感知机的假设空间，那么这个超平面一定在假设空间内，所以感知机是可以用于区分所有线性可分的样本。</p><h1 id="2-学习策略"><a href="#2-学习策略" class="headerlink" title="2.学习策略"></a>2.学习策略</h1><h2 id="2-1-代价函数"><a href="#2-1-代价函数" class="headerlink" title="2.1.代价函数"></a>2.1.代价函数</h2><p>感知机的目标是为了找到那个能完美划分线性可分样本的超平面。为了达到这个目标，我们需要定义代价函数。代价函数的意思是该函数刻画的是模型的性能，通常需要满足以下条件：</p><ul><li>条件一：模型性能越好，代价函数越小，模型性能越差，代价函数越大</li><li>条件二：连续可导</li></ul><p>条件一是使代价函数可以刻画模型性能，条件二是为了该模型可以使用梯度下降的方法优化</p><h2 id="2-2-感知机代价函数选择"><a href="#2-2-感知机代价函数选择" class="headerlink" title="2.2.感知机代价函数选择"></a>2.2.感知机代价函数选择</h2><p>对于感知机，选取代价函数为：</p><script type="math/tex; mode=display">L(w,b) = - \sum\limits_{x_i \in M}y_i(w \cdot x_i + b)</script><p>其中M为分类错误的样本集合。对于该代价函数，显而易见是连续可导的，且当分类错误的时候$y_i$和$w \cdot x_i + b$异号，代价为正。则当模型性能好时，M中样本少，代价较小；模型性能差时，M中样本多，代价较大。</p><p>该代价函数还可以从几何学角度解释，空间中任意一点$x_0$到超平面的距离为：</p><script type="math/tex; mode=display">\cfrac{1}{||w||} \cdot |w \cdot x_0 + b|</script><p>由此，错误分类的样本$y_i$和$w \cdot x_i + b$异号，由此有以下：</p><script type="math/tex; mode=display">\cfrac{1}{||w||} \cdot |w \cdot x_i + b| = \cfrac{1}{||w||} \cdot (w \cdot x_i + b) \cdot y_i</script><p>取M为分类错误样本集合，则所有分类错误的样本到超平面距离如下：</p><script type="math/tex; mode=display">- \cfrac{1}{||w||} \sum\limits_{x_i \in M} y_i(w \cdot x_i + b)</script><p>不考虑常数$\cfrac{1}{||w||}$，则可以获得感知机代价函数$L(w,b) = - \sum\limits_{x_i \in M}y_i(w \cdot x_i + b)$</p><h1 id="3-学习算法"><a href="#3-学习算法" class="headerlink" title="3.学习算法"></a>3.学习算法</h1><h2 id="3-1-基本算法"><a href="#3-1-基本算法" class="headerlink" title="3.1.基本算法"></a>3.1.基本算法</h2><p>感知机算法是错误驱动的，由以上的代价函数，感知机的学习算法变为：</p><script type="math/tex; mode=display">argmin_{w,b}(-\sum\limits_{x_i \in M}y_i \cdot (w \cdot x_i + b))</script><p>为了使代价函数下降最快，向代价函数的负梯度方向优化w和b。对代价函数取w和b的梯度：</p><script type="math/tex; mode=display">\nabla_wL(w,b) = - \sum\limits_{x_i \in M}y_i \cdot x_i \\\nabla_bL(w,b) = - \sum\limits_{x_i \in M}y_i</script><p>由此可获得更新方法：</p><script type="math/tex; mode=display">w^{n} = w^{n-1} - \eta \cdot \nabla_wL(w^{n-1},b^{n-1}) \\b^{n} = b^{n-1} - \eta \cdot \nabla_bL(w^{n-1},b^{n-1})</script><p>其中，$\eta$为学习率，表示每一次更新的步长，学习率越大更新越明显。由此，每次选择一批错误分类的点，进行上述的优化，多次循环即可学得可以正确分类的感知机模型</p><h2 id="3-2-对偶算法"><a href="#3-2-对偶算法" class="headerlink" title="3.2.对偶算法"></a>3.2.对偶算法</h2><p>将梯度表达式带入更新公式：</p><script type="math/tex; mode=display">w^{n} = w^{n-1} +\eta \cdot \sum\limits_{x_i \in M}y_i \cdot x_i \\b^{n} = b^{n-1} +\eta \cdot \sum\limits_{x_i \in M}y_i</script><p>若w和b的初始值都是0，$\eta = 1$，则可以认为w是错误样本的$y_i \cdot x_i$的和，b是错误样本标签的和，由此可以得到以下公式：</p><script type="math/tex; mode=display">w = \sum\limits_{x_i \in M} a_i \cdot y_i \cdot x_i \\b = \sum\limits_{x_i \in M} a_i \cdot y_i</script><p>其中$a_i$是该样本被错误分类的次数，可以发现，分类错次数越多的样本在参数中所占的比例越大。则每次选择一批数据输入，将分类错误的样本按更新公式计入参数，重复多次直到无错误样本即可。</p><h1 id="4-延伸"><a href="#4-延伸" class="headerlink" title="4.延伸"></a>4.延伸</h1><h2 id="4-1-感知机与支持向量机"><a href="#4-1-感知机与支持向量机" class="headerlink" title="4.1.感知机与支持向量机"></a>4.1.感知机与支持向量机</h2><p>感知机的对偶优化算法已经有一些支持向量机思想的影子——只有少数“关键样本”决定分类器超平面的位置，其他的样本并不重要，有对偶算法得到的w和b公式：</p><script type="math/tex; mode=display">w = \sum\limits_{x_i \in M} a_i \cdot y_i \cdot x_i \\b = \sum\limits_{x_i \in M} a_i \cdot y_i</script><p>可以将$a_i$视为样本的权值，分类错误次数越多该权值$a_i$越大，即该样本越重要。很自然的可以想到距离最终超平面越近的样本越容易分类错，这种样本的权值也就越高，这些样本也就越重要。</p><h2 id="4-2-感知机与神经网络"><a href="#4-2-感知机与神经网络" class="headerlink" title="4.2.感知机与神经网络"></a>4.2.感知机与神经网络</h2><p>感知机是神经网络的基础，感知机也被成为单层神经网络。感知机的一大缺陷是无法解决线性不可分问题，想要解决这一问题，需要将原来线性不可分的样本映射到另一个特征空间去，在该空间样本线性可分，映射方法主要有两种：</p><ul><li>人工指定映射方法：手动指定映射的方法，代表为核函数（核方法）</li><li>自动寻找映射方法：使用机器学习的方法自动获得映射方法，代表为神经网络</li></ul><p>神经网络可以分解如下：</p><img src="/2018/04/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E6%84%9F%E7%9F%A5%E6%9C%BA/linear_classifier_nn.png" class=""><p>当输入是线性不可分样本时，通过复杂的隐藏层（全连接层，卷积层或胶囊层）层层映射，最终在输出层之前将数据映射到一个线性可分的特征空间中，再由感知机进行线性分类。其中映射方法由神经网络自行学得。所有输出层为感知机层的神经网络都可以放在这个框架下理解。</p><p>除此以外，感知机还奠定了神经网络的基础理论。例如神经网络的基本学习框架也是梯度下降：使用反向传播计算梯度，优化算法迭代获得新的参数。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>《统计学习方法》李航</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>左式堆</title>
      <link href="2018/03/27/%E5%B7%A6%E5%BC%8F%E5%A0%86/"/>
      <url>2018/03/27/%E5%B7%A6%E5%BC%8F%E5%A0%86/</url>
      
        <content type="html"><![CDATA[<h1 id="左式堆"><a href="#左式堆" class="headerlink" title="左式堆"></a>左式堆</h1><h2 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h2><h3 id="零路径长"><a href="#零路径长" class="headerlink" title="零路径长"></a>零路径长</h3><p><strong>零路径长</strong>的定义为：</p><blockquote><p>零路径长：从节点X到一个没有两个子节点的（有一个子节点或没有子节点）节点的最短距离</p></blockquote><p>对于零路径长，有以下递归的计算方法：</p><ul><li>每个节点的零路径长比子节点的最小零路径长大1</li><li>NULL的节点的零路径长为-1，只有一个子节点或没有子节点的节点零路径长为0</li></ul><h3 id="左式堆-1"><a href="#左式堆-1" class="headerlink" title="左式堆"></a>左式堆</h3><p>左式堆是特殊的优先堆，除了有序性（每个节点的数据小于其子节点）以外，还有具有与<strong>零路径长</strong>相关的性质：对于左式堆，要求任一节点的左子节点零路径长大于等于右子节点的零路径长</p><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><h3 id="合并操作"><a href="#合并操作" class="headerlink" title="合并操作"></a>合并操作</h3><p>左式堆的基本操作是合并，合并的递归描述如下：</p><ul><li>当输入的两个堆都是空的，输出空堆；当有一个堆是空的，则返回非空的堆</li><li>当两个堆非空时，比较两个根节点的大小，返回为：<ul><li>堆根节点为原较小的根节点</li><li>左子树为原较小的跟节点的左子树</li><li>右子树为根节点较大的堆和跟节点较小堆右子树合并的结果</li></ul></li></ul><p>如下图所示：</p><img src="/2018/03/27/%E5%B7%A6%E5%BC%8F%E5%A0%86/merge_op.png" class=""><p>对于最终结果，可能在根节点上出现不符合左式堆的性质的情况，出现这种情况时，交换左右子节点即可：</p><img src="/2018/03/27/%E5%B7%A6%E5%BC%8F%E5%A0%86/merge_change.png" class=""><h3 id="其他操作"><a href="#其他操作" class="headerlink" title="其他操作"></a>其他操作</h3><p>有了核心操作合并，优先堆的其他操作可由合并实现：</p><ul><li>插入：通过合并单个节点和现有堆实现</li><li>弹出：将根节点返回，并合并左右子堆</li></ul><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="节点数据结构体"><a href="#节点数据结构体" class="headerlink" title="节点数据结构体"></a>节点数据结构体</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> NodeData <span class="keyword">struct</span> &#123;</span><br><span class="line">data <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="节点结构体"><a href="#节点结构体" class="headerlink" title="节点结构体"></a>节点结构体</h2><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><p>节点需要的特性有：</p><ul><li>Num：优先级标记，数值越低优先级越高</li><li>Data：节点数据</li><li>Depth：零路径长度</li><li>Right和Left：左右子节点的指针</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Node <span class="keyword">struct</span> &#123;</span><br><span class="line">Num   <span class="keyword">int</span></span><br><span class="line">Data  NodeData</span><br><span class="line">Left  *Node</span><br><span class="line">Right *Node</span><br><span class="line">Depth <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="节点方法"><a href="#节点方法" class="headerlink" title="节点方法"></a>节点方法</h3><h4 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewNode</span><span class="params">(Num <span class="keyword">int</span>, Data NodeData)</span> *<span class="title">Node</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;Node&#123;Num, Data, <span class="literal">nil</span>, <span class="literal">nil</span>, <span class="number">0</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="获取零路径长"><a href="#获取零路径长" class="headerlink" title="获取零路径长"></a>获取零路径长</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *Node)</span> <span class="title">GetDepth</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> n.Left == <span class="literal">nil</span> &amp;&amp; n.Right == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> n.Left.Depth &gt; n.Right.Depth &#123;</span><br><span class="line">n.Depth = n.Right.Depth + <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> n.Depth</span><br><span class="line">&#125;</span><br><span class="line">n.Depth = n.Left.Depth + <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> n.Depth</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">n.Depth = <span class="number">0</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="打印"><a href="#打印" class="headerlink" title="打印"></a>打印</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *Node)</span> <span class="title">Print</span><span class="params">(indent <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">fmt.Println(indent, n.Num, n.Data)</span><br><span class="line"><span class="keyword">if</span> n.Left != <span class="literal">nil</span> &#123;</span><br><span class="line">n.Left.Print(indent + <span class="string">&quot;\t&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> n.Right != <span class="literal">nil</span> &#123;</span><br><span class="line">n.Right.Print(indent + <span class="string">&quot;\t&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="左式堆结构"><a href="#左式堆结构" class="headerlink" title="左式堆结构"></a>左式堆结构</h2><h3 id="结构体-1"><a href="#结构体-1" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> LeftHeap <span class="keyword">struct</span> &#123;</span><br><span class="line">root *Node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="合并方法"><a href="#合并方法" class="headerlink" title="合并方法"></a>合并方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *LeftHeap)</span> <span class="title">Merge</span><span class="params">(Node1 *Node, Node2 *Node)</span> *<span class="title">Node</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> Node1 == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> Node2</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> Node2 == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> Node1</span><br><span class="line">&#125;</span><br><span class="line">Big, Small := Node1, Node2</span><br><span class="line"><span class="keyword">if</span> Node1.Num &lt; Node2.Num &#123;</span><br><span class="line">Big, Small = Node2, Node1</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> Small.Right == <span class="literal">nil</span> &#123;</span><br><span class="line">Small.Right = Big</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">Small.Right = l.Merge(Small.Right, Big)</span><br><span class="line">&#125;</span><br><span class="line">Small.GetDepth()</span><br><span class="line"><span class="keyword">return</span> Small</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="调整方法"><a href="#调整方法" class="headerlink" title="调整方法"></a>调整方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *LeftHeap)</span> <span class="title">Modify</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> l.root.Left == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> l.root.Right == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">l.root.Left, l.root.Right = l.root.Right, l.root.Left</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> l.root.Right == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> l.root.Left.Depth &lt; l.root.Right.Depth &#123;</span><br><span class="line">l.root.Left, l.root.Right = l.root.Right, l.root.Left</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="插入方法"><a href="#插入方法" class="headerlink" title="插入方法"></a>插入方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *LeftHeap)</span> <span class="title">Push</span><span class="params">(InsertNum <span class="keyword">int</span>, InsertData NodeData)</span></span> &#123;</span><br><span class="line">InsertNode := NewNode(InsertNum, InsertData)</span><br><span class="line">l.root = l.Merge(l.root, InsertNode)</span><br><span class="line">l.Modify()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="弹出方法"><a href="#弹出方法" class="headerlink" title="弹出方法"></a>弹出方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *LeftHeap)</span> <span class="title">DeleteMin</span><span class="params">()</span> <span class="params">(NodeData, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> l.root == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> NodeData&#123;&#125;, errors.New(<span class="string">&quot;empty heap&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">returnData := l.root.Data</span><br><span class="line">l.root = l.Merge(l.root.Left, l.root.Right)</span><br><span class="line">l.Modify()</span><br><span class="line"><span class="keyword">return</span> returnData, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="打印方法"><a href="#打印方法" class="headerlink" title="打印方法"></a>打印方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *LeftHeap)</span> <span class="title">Print</span><span class="params">()</span></span> &#123;</span><br><span class="line">l.root.Print(<span class="string">&quot;&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于gluno的Inception结构</title>
      <link href="2018/03/18/%E5%9F%BA%E4%BA%8Egluno%E7%9A%84Inception%E7%BB%93%E6%9E%84/"/>
      <url>2018/03/18/%E5%9F%BA%E4%BA%8Egluno%E7%9A%84Inception%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="Inception结构"><a href="#Inception结构" class="headerlink" title="Inception结构"></a>Inception结构</h1><h2 id="初级Inception"><a href="#初级Inception" class="headerlink" title="初级Inception"></a>初级Inception</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>初级Inception结构如下所示：</p><img src="/2018/03/18/%E5%9F%BA%E4%BA%8Egluno%E7%9A%84Inception%E7%BB%93%E6%9E%84/inception_naive.png" class=""><p>其前向传播分为4个部分：</p><ul><li>通过1x1卷积</li><li>通过3x3卷积，padding为1（不改变图片大小）</li><li>通过5x5卷积，padding为2（不改变图片大小）</li><li>通过3x3池化，为了保证图片大小与以上相同，stride应为1，padding应为1</li></ul><p>最后，将以上四个部分在feature这一维度堆叠起来，即获得最终输出</p><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>假设输入feature，每个层（卷积和池化）输出feature分别为$N_i,N_o$（即最终输出feature为$4 \times N_o$）;输入图片的尺寸为WxL，对于每一层，有：</p><ul><li>1x1卷积层：有参数$1 \times 1 \times N_i \times N_o = N_iN_o$，需要进行计算的次数为$N_o \times W \times L \times 1 \times 1 \times N_i = WLN_iN_o$</li><li>3x3卷积层：有参数$3 \times 3 \times N_i \times N_o = 9N_iN_o$，需要计算次数为$N_o \times W \times L \times 3 \times 3 \times N_i = 9WLN_iN_o$</li><li>5x5卷积层，同上，参数为$25N_iN_o$，需要计算次数为$25WLN_iN_o$</li></ul><p>因此，总的参数量为$(1+9+25)N_iN_o = 35N_iN_o$，需要的运算量为$(1+9+25)WLN_iN_o = 35WLN_iN_o$。考虑一个输入输出相同尺寸的3x3卷积，需要的参数量为$3 \times 3 \times N_i \times 4N_o = 36N_iN_o$，需要的运算量是$4N_o \times W \times L \times 3 \times 3 \times N_i = 36WLN_iN_o$，可以发现该结构在运算量和参数量近乎不变的情况下实现了多种感受野的连接。</p><h2 id="改进Inception结构"><a href="#改进Inception结构" class="headerlink" title="改进Inception结构"></a>改进Inception结构</h2><h3 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h3><p>改进的Inception结构如下图所示</p><img src="/2018/03/18/%E5%9F%BA%E4%BA%8Egluno%E7%9A%84Inception%E7%BB%93%E6%9E%84/inception.png" class=""><p>同样具有四条前向传播通路，如下所示：</p><ul><li>1x1卷积</li><li>先通过1x1卷积降维，再通过3x3卷积</li><li>先通过1x1卷积降维，再通过5x5卷积</li><li>先通过3x3maxpool，再通过1x1调整维度</li></ul><p>最后，将以上四个部分在feature这一维度堆叠起来，即获得最终输出</p><h3 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h3><p>假设同上一部分，假设每个降维将降维降到原来维度的一半，对每一部分有如下所示：</p><ul><li>每个降维的1x1层，需要的参数量是$\cfrac{1}{2}N_i^2$，运算参数量$\cfrac{1}{2}WLN_i^2$</li><li>1x1卷积层：有参数$1 \times 1 \times \cfrac{1}{2}N_i \times N_o = \cfrac{1}{2}N_iN_o$，需要进行计算的次数为$N_o \times W \times L \times 1 \times 1 \times \cfrac{1}{2}N_i = \cfrac{1}{2}WLN_iN_o$</li><li>3x3卷积层：有参数$3 \times 3 \times \cfrac{1}{2}N_i \times N_o = 9N_iN_o$，需要计算次数为$N_o \times W \times L \times 3 \times 3 \times \cfrac{1}{2}N_i = \cfrac{9}{2}WLN_iN_o$</li><li>5x5卷积层，同上，参数为$\cfrac{25}{2}N_iN_o$，需要计算次数为$\cfrac{25}{2}WLN_iN_o$</li></ul><p>假设$N_i = N_o$，参数量一共是$3 \times \cfrac{1}{2}N_i^2 + \cfrac{35}{2}N_i^2 = 19N_i^2$，需要运算的数量为$19WLN_i^2$。可以发现无论是运算量还是参数量都小于原结构</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h2 id="Inception结构搭建"><a href="#Inception结构搭建" class="headerlink" title="Inception结构搭建"></a>Inception结构搭建</h2><h3 id="Inception结构-1"><a href="#Inception结构-1" class="headerlink" title="Inception结构"></a>Inception结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">inception</span>(<span class="params">mx.gluon.Block</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,out_channel</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(inception,self).__init__()</span><br><span class="line">        <span class="keyword">with</span> self.name_scope():</span><br><span class="line">            self.conv1 = mx.gluon.nn.Conv2D(out_channel,<span class="number">1</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">            self.conv3_pre = mx.gluon.nn.Conv2D(out_channel//<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">            self.conv3 = mx.gluon.nn.Conv2D(out_channel,<span class="number">3</span>,activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="number">1</span>)</span><br><span class="line">            self.conv5_pre = mx.gluon.nn.Conv2D(out_channel//<span class="number">2</span>,<span class="number">1</span>)            </span><br><span class="line">            self.conv5 = mx.gluon.nn.Conv2D(out_channel,<span class="number">5</span>,activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="number">2</span>)</span><br><span class="line">            self.pool_post = mx.gluon.nn.Conv2D(out_channel,<span class="number">1</span>,activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">            self.pool = mx.gluon.nn.MaxPool2D(pool_size=<span class="number">3</span>,strides=<span class="number">1</span>,padding=<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        result = [</span><br><span class="line">            self.conv1(x),</span><br><span class="line">            self.conv3(self.conv3_pre(x)),</span><br><span class="line">            self.conv5(self.conv5_pre(x)),</span><br><span class="line">            self.pool_post(self.pool(x))]</span><br><span class="line">        <span class="keyword">return</span> mx.ndarray.concat(dim=<span class="number">1</span>,*result)</span><br></pre></td></tr></table></figure><h3 id="Inception结构测试"><a href="#Inception结构测试" class="headerlink" title="Inception结构测试"></a>Inception结构测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inception_model = inception(<span class="number">10</span>)</span><br><span class="line">print(inception_model)</span><br><span class="line">inception_model.collect_params().initialize(mx.init.Normal(sigma=<span class="number">.1</span>), ctx=mx.gpu())</span><br></pre></td></tr></table></figure><pre><code>inception(  (pool_post): Conv2D(None -&gt; 10, kernel_size=(1, 1), stride=(1, 1))  (pool): MaxPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)  (conv1): Conv2D(None -&gt; 10, kernel_size=(1, 1), stride=(1, 1))  (conv3): Conv2D(None -&gt; 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  (conv5_pre): Conv2D(None -&gt; 5, kernel_size=(1, 1), stride=(1, 1))  (conv5): Conv2D(None -&gt; 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))  (conv3_pre): Conv2D(None -&gt; 5, kernel_size=(1, 1), stride=(1, 1)))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">indata = mx.ndarray.zeros((<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">10</span>),mx.gpu())</span><br><span class="line">inception_model(indata).shape</span><br></pre></td></tr></table></figure><pre><code>(1, 40, 10, 10)</code></pre><h2 id="整体网络结构"><a href="#整体网络结构" class="headerlink" title="整体网络结构"></a>整体网络结构</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">network</span>(<span class="params">mx.gluon.Block</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(network,self).__init__()</span><br><span class="line">        <span class="keyword">with</span> self.name_scope():</span><br><span class="line">            self.conv1 = mx.gluon.nn.Conv2D(channels=<span class="number">8</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">            self.conv2 = inception(<span class="number">8</span>)</span><br><span class="line">            self.conv3 = inception(<span class="number">16</span>)</span><br><span class="line">            self.conv4 = inception(<span class="number">16</span>)</span><br><span class="line">            self.fc = mx.gluon.nn.Dense(<span class="number">10</span>)</span><br><span class="line">            self.pool = mx.gluon.nn.MaxPool2D(pool_size=<span class="number">3</span>,strides=<span class="number">2</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        x = self.conv2(self.conv1(x))</span><br><span class="line">        x = self.conv3(self.pool(x))</span><br><span class="line">        x = self.conv4(self.pool(x))</span><br><span class="line">        <span class="keyword">return</span> self.fc(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = network()</span><br><span class="line">print(model)</span><br><span class="line">model.collect_params().initialize(mx.init.Normal(sigma=<span class="number">.1</span>), ctx=mx.gpu())</span><br></pre></td></tr></table></figure><pre><code>network(  (pool): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)  (conv1): Conv2D(None -&gt; 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  (conv3): inception(    (pool_post): Conv2D(None -&gt; 16, kernel_size=(1, 1), stride=(1, 1))    (pool): MaxPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)    (conv1): Conv2D(None -&gt; 16, kernel_size=(1, 1), stride=(1, 1))    (conv3): Conv2D(None -&gt; 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (conv5_pre): Conv2D(None -&gt; 8, kernel_size=(1, 1), stride=(1, 1))    (conv5): Conv2D(None -&gt; 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))    (conv3_pre): Conv2D(None -&gt; 8, kernel_size=(1, 1), stride=(1, 1))  )  (conv2): inception(    (pool_post): Conv2D(None -&gt; 8, kernel_size=(1, 1), stride=(1, 1))    (pool): MaxPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)    (conv1): Conv2D(None -&gt; 8, kernel_size=(1, 1), stride=(1, 1))    (conv3): Conv2D(None -&gt; 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (conv5_pre): Conv2D(None -&gt; 4, kernel_size=(1, 1), stride=(1, 1))    (conv5): Conv2D(None -&gt; 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))    (conv3_pre): Conv2D(None -&gt; 4, kernel_size=(1, 1), stride=(1, 1))  )  (fc): Dense(None -&gt; 10, linear)  (conv4): inception(    (pool_post): Conv2D(None -&gt; 16, kernel_size=(1, 1), stride=(1, 1))    (pool): MaxPool2D(size=(3, 3), stride=(1, 1), padding=(1, 1), ceil_mode=False)    (conv1): Conv2D(None -&gt; 16, kernel_size=(1, 1), stride=(1, 1))    (conv3): Conv2D(None -&gt; 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (conv5_pre): Conv2D(None -&gt; 8, kernel_size=(1, 1), stride=(1, 1))    (conv5): Conv2D(None -&gt; 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))    (conv3_pre): Conv2D(None -&gt; 8, kernel_size=(1, 1), stride=(1, 1))  ))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">​```python</span><br><span class="line">indata = mx.ndarray.zeros((<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>),mx.gpu())</span><br><span class="line">model(indata).shape</span><br></pre></td></tr></table></figure><pre><code>(1, 10)</code></pre><h2 id="训练准备"><a href="#训练准备" class="headerlink" title="训练准备"></a>训练准备</h2><h3 id="数据集——MNIST数据集"><a href="#数据集——MNIST数据集" class="headerlink" title="数据集——MNIST数据集"></a>数据集——MNIST数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">data, label</span>):</span></span><br><span class="line">    <span class="keyword">return</span> mx.nd.transpose(data,axes=(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)).astype(np.float32)/<span class="number">255</span>, label.astype(np.float32)</span><br><span class="line">gluon_train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=<span class="literal">True</span>, transform=transform),<span class="number">100</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">gluon_test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=<span class="literal">False</span>, transform=transform),<span class="number">100</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="代价函数——交叉熵"><a href="#代价函数——交叉熵" class="headerlink" title="代价函数——交叉熵"></a>代价函数——交叉熵</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">softmax_cross_entropy = mx.gluon.loss.SoftmaxCrossEntropyLoss()</span><br></pre></td></tr></table></figure><h3 id="优化器——sgd"><a href="#优化器——sgd" class="headerlink" title="优化器——sgd"></a>优化器——sgd</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer = mx.gluon.Trainer(model.collect_params(), <span class="string">&#x27;sgd&#x27;</span>, &#123;<span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">.1</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="准确率计算"><a href="#准确率计算" class="headerlink" title="准确率计算"></a>准确率计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>(<span class="params">model</span>):</span></span><br><span class="line">    acc = mx.metric.Accuracy()</span><br><span class="line">    <span class="keyword">for</span> i, (data, lable) <span class="keyword">in</span> <span class="built_in">enumerate</span>(gluon_test_data):</span><br><span class="line">        data = data.as_in_context(mx.gpu())</span><br><span class="line">        lable = lable.as_in_context(mx.gpu())</span><br><span class="line">        output = model(data)</span><br><span class="line">        predictions = mx.nd.argmax(output, axis=<span class="number">1</span>)</span><br><span class="line">        acc.update(preds=predictions, labels=lable)</span><br><span class="line">    <span class="keyword">return</span> acc.get()[<span class="number">1</span>]</span><br><span class="line">evaluate_accuracy(model)</span><br></pre></td></tr></table></figure><pre><code>0.050200000000000002</code></pre><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> i,(data,lable) <span class="keyword">in</span> <span class="built_in">enumerate</span>(gluon_train_data):</span><br><span class="line">        data = data.as_in_context(mx.gpu())</span><br><span class="line">        lable = lable.as_in_context(mx.gpu())</span><br><span class="line">        <span class="keyword">with</span> mx.autograd.record():</span><br><span class="line">            outputs = model(data)</span><br><span class="line">            loss = softmax_cross_entropy(outputs,lable)</span><br><span class="line">        loss.backward()</span><br><span class="line">        trainer.step(data.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">1</span>:</span><br><span class="line">            print(i,loss.mean().asnumpy()[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>1 0.16968101 0.104242201 0.093354301 0.07079401 0.123301501 0.0868821 0.0325385101 0.0510763201 0.0242231301 0.0454984401 0.0788167501 0.0591589</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluate_accuracy(model)</span><br></pre></td></tr></table></figure><pre><code>0.98829999999999996</code></pre>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于优先堆的调度队列</title>
      <link href="2018/03/15/%E5%9F%BA%E4%BA%8E%E4%BC%98%E5%85%88%E5%A0%86%E7%9A%84%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97/"/>
      <url>2018/03/15/%E5%9F%BA%E4%BA%8E%E4%BC%98%E5%85%88%E5%A0%86%E7%9A%84%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h1 id="应用场景模拟"><a href="#应用场景模拟" class="headerlink" title="应用场景模拟"></a>应用场景模拟</h1><p>考虑优先堆的一种应用场景——按优先级的任务调度队列：每个任务有一个优先级和唯一标号，该调度队列需要具有以下功能：</p><ul><li>添加任务：将任务添加进调度队列并按优先级置于对应的位置</li><li>执行任务：将优先堆中优先级最高的任务取出（并执行）</li><li>删除任务：按标号删除队列中的未执行任务</li><li>修改任务优先级：修改指定标号任务的优先级</li></ul><h1 id="应用分析"><a href="#应用分析" class="headerlink" title="应用分析"></a>应用分析</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>对于任务，考虑使用类封装，对于一个任务类需要以下特征：</p><ul><li>标号：int型，用于区别任务的标号，每个任务有一个且唯一</li><li>优先级：int型，每个任务的优先级，该特征越小则优先级越高</li></ul><p>同时需要具有以下方法：</p><ul><li>任务执行方法：调用该任务表示执行了该任务</li><li>优先级修改方法：调用该任务修改优先级</li></ul><h2 id="优先堆"><a href="#优先堆" class="headerlink" title="优先堆"></a>优先堆</h2><p>定义了数据结构后，使用2D优先堆实现该优先队列，2D优先堆为完全二叉树，且任意一个节点的值小于其子节点的值。要实现场景中的几种功能，需要以下几种方法：</p><ul><li>Push：对应添加任务，将任务类插入该优先堆中，调用上移方法。</li><li>Pop：对应执行任务，取出2D优先堆根节点的任务，调用下移方法。</li><li>Delete：对应删除任务，按标号取出某一节点的任务并调整堆使其满足2D优先堆的条件，调用下移方法</li><li>Change：对应修改任务优先级，根据调整的情况调用上移或下移方法。</li></ul><p>以上提到了两种另外需要实现的方法：</p><ul><li>上移方法：将某一节点向上移动，使其满足2D优先堆的限制</li><li>下移方法：将某一节点向下移动，使其满足2D优先堆的限制</li></ul><h3 id="上移方法"><a href="#上移方法" class="headerlink" title="上移方法"></a>上移方法</h3><img src="/2018/03/15/%E5%9F%BA%E4%BA%8E%E4%BC%98%E5%85%88%E5%A0%86%E7%9A%84%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97/up.png" class=""><p>如图所示为一个上移方法，当某位置要插入一个比原先优先值小的任务时，可以调用上移方法使插入不破坏2d优先堆的性质，该方法的递归概括有以下几步，输入为待插入位置和待插入数据：</p><ol><li>边缘判断：若该节点为根节点，没有父节点，则到边缘，将待插入数据直接插入该位置</li><li>性质判断：若该节点的父节点值小于待插入值，则该位置为待插入位置，插入数据</li><li>递归：若以上均不满足，则该位置不是待插入位置，则将父节点数据插入该位置并递归调用，输入的待插入位置为当前位置的父节点，待插入数据不变</li></ol><h3 id="下移方法"><a href="#下移方法" class="headerlink" title="下移方法"></a>下移方法</h3><img src="/2018/03/15/%E5%9F%BA%E4%BA%8E%E4%BC%98%E5%85%88%E5%A0%86%E7%9A%84%E8%B0%83%E5%BA%A6%E9%98%9F%E5%88%97/down.png" class=""><p>如图为一个下移方法的例子，当某位置要插入一个比原先优先值大的任务时，可以调用下移方法使其插入不破坏2d优先堆的性质，该方法的递归概括如下所示，输入为带插入位置和待插入数据：</p><ol><li>边缘判断：若该节点为叶子节点，没有子节点，则到边缘，将待插入数据插入该位置</li><li>性质判断：若该节点的两个子节点的优先值均大于该节点，则该位置为待插入位置，插入数据</li><li>递归：若以上均不满足，则该位置不是待插入位置，则将子节点中优先值小的那个节点数据插入该位置并递归调用，输入的位置为原优先值大的子节点位置，待插入数据不变</li></ol><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><p>通过接口实现一个打印固定字符串的任务，该任务类的执行打印了结构体中包含的<code>data</code>字符串。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> PrintWork <span class="keyword">struct</span> &#123;</span><br><span class="line">Index    <span class="keyword">int</span></span><br><span class="line">Priority <span class="keyword">int</span></span><br><span class="line">data     <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *PrintWork)</span> <span class="title">Execute</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line">fmt.Println(p.data)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *PrintWork)</span> <span class="title">ChangePriority</span><span class="params">(NewPriority <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">p.Priority = NewPriority</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewWork</span><span class="params">(index <span class="keyword">int</span>, priorty <span class="keyword">int</span>, data <span class="keyword">string</span>)</span> *<span class="title">Work</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;Work&#123;index, priorty, data&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="优先堆实现"><a href="#优先堆实现" class="headerlink" title="优先堆实现"></a>优先堆实现</h2><h3 id="结构体-1"><a href="#结构体-1" class="headerlink" title="结构体"></a>结构体</h3><p>该结构体包括一个长度为17的队列，第一个位置不使用，共16个可用的位置；一个指示下一个位置的int型变量next；一个标记堆容量的变量size</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> WorkFIFO <span class="keyword">struct</span> &#123;</span><br><span class="line">heap [<span class="number">17</span>]Work</span><br><span class="line">next <span class="keyword">int</span></span><br><span class="line">size <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该结构体构造函数如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewWorkFIFO</span><span class="params">()</span> *<span class="title">WorkFIFO</span></span> &#123;</span><br><span class="line">temp := &amp;WorkFIFO&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">17</span>; i++ &#123;</span><br><span class="line">temp.heap[i] = NewWork(<span class="number">0</span>, <span class="number">999</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">temp.next = <span class="number">1</span></span><br><span class="line">temp.size = <span class="number">17</span></span><br><span class="line"><span class="keyword">return</span> temp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="上移方法-1"><a href="#上移方法-1" class="headerlink" title="上移方法"></a>上移方法</h3><p>上移方法主要用于数据插入和权值修改</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WorkFIFO)</span> <span class="title">UpFlow</span><span class="params">(data *Work, place <span class="keyword">int</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> place &gt; w.next || place == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;out of index&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> place == <span class="number">1</span> &#123;</span><br><span class="line">w.heap[<span class="number">1</span>] = data</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> data.Priority &gt;= w.heap[place/<span class="number">2</span>].Priority &#123;</span><br><span class="line">w.heap[place] = data</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">w.heap[place] = w.heap[place/<span class="number">2</span>]</span><br><span class="line"><span class="keyword">return</span> w.UpFlow(data, place/<span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="下移方法-1"><a href="#下移方法-1" class="headerlink" title="下移方法"></a>下移方法</h3><p>下移方法主要用于数据弹出，删除和权值修改</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WorkFIFO)</span> <span class="title">DownFlow</span><span class="params">(data *Work, place <span class="keyword">int</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> place &gt; w.next || place == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;out of index&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> place*<span class="number">2</span> &gt;= w.next &#123;</span><br><span class="line">w.heap[place] = data</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> data.Priority &lt;= w.heap[w.getMinSon(place)].Priority &#123;</span><br><span class="line">w.heap[place] = data</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">nextPlace := w.getMinSon(place)</span><br><span class="line">w.heap[place] = w.heap[nextPlace]</span><br><span class="line"><span class="keyword">return</span> w.DownFlow(data, nextPlace)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WorkFIFO)</span> <span class="title">getMinSon</span><span class="params">(place <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="number">2</span>*place+<span class="number">1</span> &gt;= w.next &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span> * place</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> w.heap[<span class="number">2</span>*place].Priority &gt; w.heap[<span class="number">2</span>*place+<span class="number">1</span>].Priority &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span>*place + <span class="number">1</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span> * place</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入方法"><a href="#插入方法" class="headerlink" title="插入方法"></a>插入方法</h3><p>插入方法将新的任务插入优先队列中，步骤为：</p><ol><li>判断优先堆是否满，若满返回错误</li><li>若优先堆不满，调用上移方法将任务插入优先堆，输入的插入位置为<code>next</code>属性标记的位置</li><li><code>next</code>标记的位置+1</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WorkFIFO)</span> <span class="title">WorkInsert</span><span class="params">(data *Work)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> w.next &gt; w.size &#123;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;heap is full&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">err := w.UpFlow(data, w.next)</span><br><span class="line">w.next++</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="弹出方法"><a href="#弹出方法" class="headerlink" title="弹出方法"></a>弹出方法</h3><p>弹出方法为将优先级最高的任务弹出队列，步骤为：</p><ol><li>优先堆是否空，若空则返回错误</li><li>若优先堆不空，调用下移方法，输入的位置为1（根节点），输入数据为在位置<code>next</code>-1的数据</li><li><code>next</code>标记位置-1，弹出原根节点位置数据</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WorkFIFO)</span> <span class="title">WorkPop</span><span class="params">()</span> <span class="params">(*Work, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> w.next &lt;= <span class="number">1</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;heap is empty&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">thisWork := w.heap[<span class="number">1</span>]</span><br><span class="line">w.next--</span><br><span class="line">err := w.DownFlow(w.heap[w.next], <span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> thisWork, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="删除方法"><a href="#删除方法" class="headerlink" title="删除方法"></a>删除方法</h3><p>删除方法为将指定任务（通过任务标号制定）从队列中删除，步骤为：</p><ol><li>遍历优先堆，找到该标号的任务，若没找到该任务则返回错误信息</li><li>将优先堆中的<code>next</code>-1指向的任务插入待删除任务的位置并调用下移方法维持优先堆限制</li><li>返回待删除任务，<code>next</code>标记-1</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WorkFIFO)</span> <span class="title">WorkDelete</span><span class="params">(index <span class="keyword">int</span>)</span> <span class="params">(*Work, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">1</span>; i &lt; w.next; i++ &#123;</span><br><span class="line"><span class="keyword">if</span> w.heap[i].Index == index &#123;</span><br><span class="line">temp := w.heap[i]</span><br><span class="line">err := w.DownFlow(w.heap[w.next<span class="number">-1</span>], i)</span><br><span class="line">w.next--</span><br><span class="line"><span class="keyword">return</span> temp, err</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;work undefined&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="修改优先级方法"><a href="#修改优先级方法" class="headerlink" title="修改优先级方法"></a>修改优先级方法</h3><p>修改优先级为修改指定任务（通过任务标号指定）的优先级，步骤为：</p><ol><li>遍历优先堆，找到该标号任务，若没找到则返回错误信息</li><li>修改任务的优先级，并将该任务插入原位置：若优先级提高（优先数降低），调用上移方法；否则调用下移方法。</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *WorkFIFO)</span> <span class="title">ChangePriority</span><span class="params">(index <span class="keyword">int</span>, newPriority <span class="keyword">int</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; w.next; i++ &#123;</span><br><span class="line"><span class="keyword">if</span> w.heap[i].Index == index &#123;</span><br><span class="line"><span class="keyword">if</span> w.heap[i].Priority &gt; newPriority &#123;</span><br><span class="line">w.heap[i].ChangePriority(newPriority)</span><br><span class="line">w.UpFlow(w.heap[i], i)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">w.heap[i].ChangePriority(newPriority)</span><br><span class="line">w.DownFlow(w.heap[i], i)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;work undefined&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CapsNet学习笔记</title>
      <link href="2018/03/11/CapsNet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2018/03/11/CapsNet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="理论学习"><a href="#理论学习" class="headerlink" title="理论学习"></a>理论学习</h1><h2 id="胶囊结构"><a href="#胶囊结构" class="headerlink" title="胶囊结构"></a>胶囊结构</h2><p>胶囊可以看成一种向量化的神经元。对于单个神经元而言，目前的深度网络中流动的数据均为标量。例如多层感知机的某一个神经元，其输入为若干个标量，输出为一个标量（不考虑批处理）；而对于胶囊而言，每个神经元输入为若干个向量，输出为一个向量（不考虑批处理）。前向传播如下所示：</p><img src="/2018/03/11/CapsNet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/capsule_structure.png" class=""><p>其中$I_i$为第i个输入（向量），$W_i$为第i个权值（矩阵），$U_i$为中间变量（向量），由输入和权值叉乘获得。$c_i$为路由权值（标量），需要注意的是该标量是前向传播过程中决定（使用动态路由算法）的，不是通过反向传播优化的参数。Squash为一种激活函数。前向传播使用公式表示如下所示：</p><script type="math/tex; mode=display">U_i = W_i^T \times I_i</script><script type="math/tex; mode=display">S = \sum \limits_{i = 0}^n c_i \cdot U_i</script><script type="math/tex; mode=display">Result = Squash(S) = \cfrac{||S||^2}{1+||S||^2} \cdot \cfrac{S}{||S||}</script><p>由以上可以看出，胶囊结构中流动的数据类型为向量，其激活函数Squash输入一个向量，输出一个向量。</p><h2 id="动态路由算法"><a href="#动态路由算法" class="headerlink" title="动态路由算法"></a>动态路由算法</h2><p>动态路由算法适用于确定胶囊结构中$c_i$的算法，其算法伪代码如下所示：</p><img src="/2018/03/11/CapsNet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/dynamic_route.jpg" class=""><p>首先其输入为$U_{j|i}$为本层的中间变量，其中i为这一层胶囊数量，j为下一层胶囊数量，最终获得的胶囊的输出$v_j$，其步骤描述如下：</p><ol><li>初始化：初始化一个临时变量b，为一个$i \times j$的全为0的矩阵</li><li>获取这一步的连接权值c：$c_i = softmax(b_i)$，将临时变量b通过softmax，保证$c_i$的各分量和为1</li><li>获取这一步的加权和结果S：$s<em>j = \sum_i c</em>{ij}u_{j|i}$，按这一步连接权值计算加权和</li><li>非线性激活：$v_j = squash(s_j)$，经过非线性激活函数，获取这一步的胶囊输出</li><li>迭代临时变量：$b<em>{ij} = b</em>{ij} + u<em>{i|j} \cdot v</em>{j}$，所这一步的输出与中间变量方向相近，增加临时变量b，即增加权值；若这一步输出与中间变量方向相反，减小临时变量b，即减小权值。</li><li>若已经迭代到指定次数，输出$v_j$，否侧跳到步骤2</li></ol><p>同时，对于迭代次数j，论文中表示过多的迭代会导致过拟合，实践中建议使用3次迭代。</p><h2 id="输出与代价函数"><a href="#输出与代价函数" class="headerlink" title="输出与代价函数"></a>输出与代价函数</h2><p>输出层胶囊的输出为向量，该向量的长度即为概率。也就是说，前向传播的结果为输出最长向量的输出胶囊所代表的结果。反向传播时，也需要考虑网络的输出为向量而不是标量，因此原论文中了如下的代价函数（每个输出的代价函数，代价函数为所有输出代价函数的和$L = \sum\limits_{c=0}^n L_c$）</p><script type="math/tex; mode=display">L_c = T_c max(0,m^+ - ||V_c||)^2 + \lambda (1 - T_c)max(0,||v_c|| - m^-) ^ 2</script><p>其中，$T_c$为标量，当分类结果为c时$T_c = 1$，否则$T_c = 0$；$\lambda$为固定值（一般为0.5），用于保证数值稳定性；$m^+$和$m^-$也为固定值：</p><ul><li>对于$T_c = 1$的输出胶囊，当输出向量大于$m^+$时，代价函数为0，否则不为0</li><li>对于$T_c = 0$的输出胶囊，当输出向量小于$m^-$时，代价函数为0，否则不为0</li></ul><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>原论文中使举了一个识别MNIST手写数字数据集的例子，网络架构如下图所示：</p><img src="/2018/03/11/CapsNet%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/capsnet_mnist.jpg" class=""><ul><li>第一层为普通的卷积层，使用9*9卷积，输出通道数为256，输出数据尺寸为20*20*256</li><li>第二层为卷积层，该卷积层由平行的32个卷积层组成，每个卷积层对应向量数据中的一个向量。每个卷积层均为9*9*256*8（输入channel为256，输出channel为8）。因此输出为6*6*32*8，即窗口大小为6*6，输出channel为32，每个数据为8个分量的向量。</li><li>第三层为胶囊层，行为类似于全连接层。输入为6*6*32=1152个8分量输入向量，输出为10个16分量的向量，对应的有1152*10个权值，每个权值为8*16的矩阵，最终输出为10个16分量的向量</li><li>最终输出10个16分量的向量，最终的分类结果是向量长度最大的输出。</li></ul><h1 id="代码阅读（PyTorch）"><a href="#代码阅读（PyTorch）" class="headerlink" title="代码阅读（PyTorch）"></a>代码阅读（PyTorch）</h1><blockquote><p>本次代码阅读并不关心具体的实现方式，主要阅读CapsNet的实现思路</p></blockquote><h2 id="前胶囊层（卷积层）"><a href="#前胶囊层（卷积层）" class="headerlink" title="前胶囊层（卷积层）"></a>前胶囊层（卷积层）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrimaryCaps</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_capsules=<span class="number">8</span>, in_channels=<span class="number">256</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">9</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PrimaryCaps, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.capsules = nn.ModuleList([</span><br><span class="line">            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=<span class="number">2</span>, padding=<span class="number">0</span>) </span><br><span class="line">                          <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_capsules)])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        u = [capsule(x) <span class="keyword">for</span> capsule <span class="keyword">in</span> self.capsules]</span><br><span class="line">        u = torch.stack(u, dim=<span class="number">1</span>)</span><br><span class="line">        u = u.view(x.size(<span class="number">0</span>), <span class="number">32</span> * <span class="number">6</span> * <span class="number">6</span>, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.squash(u)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">squash</span>(<span class="params">self, input_tensor</span>):</span></span><br><span class="line">        squared_norm = (input_tensor ** <span class="number">2</span>).<span class="built_in">sum</span>(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        output_tensor = squared_norm *  input_tensor / ((<span class="number">1.</span> + squared_norm) * torch.sqrt(squared_norm))</span><br><span class="line">        <span class="keyword">return</span> output_tensor</span><br></pre></td></tr></table></figure><p>重点关注forward前向传播部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">u = [capsule(x) <span class="keyword">for</span> capsule <span class="keyword">in</span> self.capsules]</span><br><span class="line">u = torch.stack(u, dim=<span class="number">1</span>)</span><br><span class="line">u = u.view(x.size(<span class="number">0</span>), <span class="number">32</span> * <span class="number">6</span> * <span class="number">6</span>, -<span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> self.squash(u)</span><br></pre></td></tr></table></figure><p><code>self.capsules</code>为<code>num_capsules</code>个<code>[in_channels,out_channels,kernel_size,kernel_size]</code>的卷积层，对应上文所述的第二层卷积层的操作。注意该部分的输出直接被变为<code>[batch size,1152,8]</code>的形式，且通过squash激活函数挤压输出向量</p><h2 id="胶囊层"><a href="#胶囊层" class="headerlink" title="胶囊层"></a>胶囊层</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DigitCaps</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_capsules=<span class="number">10</span>, num_routes=<span class="number">32</span> * <span class="number">6</span> * <span class="number">6</span>, in_channels=<span class="number">8</span>, out_channels=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DigitCaps, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.num_routes = num_routes</span><br><span class="line">        self.num_capsules = num_capsules</span><br><span class="line"></span><br><span class="line">        self.W = nn.Parameter(torch.randn(<span class="number">1</span>, num_routes, num_capsules, out_channels, in_channels))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = torch.stack([x] * self.num_capsules, dim=<span class="number">2</span>).unsqueeze(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        W = torch.cat([self.W] * batch_size, dim=<span class="number">0</span>)</span><br><span class="line">        u_hat = torch.matmul(W, x)</span><br><span class="line"></span><br><span class="line">        b_ij = Variable(torch.zeros(<span class="number">1</span>, self.num_routes, self.num_capsules, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">if</span> USE_CUDA:</span><br><span class="line">            b_ij = b_ij.cuda()</span><br><span class="line"></span><br><span class="line">        num_iterations = <span class="number">3</span></span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">            c_ij = F.softmax(b_ij)</span><br><span class="line">            c_ij = torch.cat([c_ij] * batch_size, dim=<span class="number">0</span>).unsqueeze(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">            s_j = (c_ij * u_hat).<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            v_j = self.squash(s_j)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> iteration &lt; num_iterations - <span class="number">1</span>:</span><br><span class="line">                a_ij = torch.matmul(u_hat.transpose(<span class="number">3</span>, <span class="number">4</span>), torch.cat([v_j] * self.num_routes, dim=<span class="number">1</span>))</span><br><span class="line">                b_ij = b_ij + a_ij.squeeze(<span class="number">4</span>).mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> v_j.squeeze(<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">squash</span>(<span class="params">self, input_tensor</span>):</span></span><br><span class="line">        squared_norm = (input_tensor ** <span class="number">2</span>).<span class="built_in">sum</span>(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        output_tensor = squared_norm *  input_tensor / ((<span class="number">1.</span> + squared_norm) * torch.sqrt(squared_norm))</span><br><span class="line">        <span class="keyword">return</span> output_tensor</span><br></pre></td></tr></table></figure><h3 id="获得中间向量"><a href="#获得中间向量" class="headerlink" title="获得中间向量"></a>获得中间向量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">x = torch.stack([x] * self.num_capsules, dim=<span class="number">2</span>).unsqueeze(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">W = torch.cat([self.W] * batch_size, dim=<span class="number">0</span>)</span><br><span class="line">u_hat = torch.matmul(W, x)</span><br></pre></td></tr></table></figure><p>这一部分计算中间向量$U_i$</p><h3 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">c_ij = F.softmax(b_ij)</span><br><span class="line">c_ij = torch.cat([c_ij] * batch_size, dim=<span class="number">0</span>).unsqueeze(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">s_j = (c_ij * u_hat).<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">v_j = self.squash(s_j)</span><br><span class="line">            </span><br><span class="line"><span class="keyword">if</span> iteration &lt; num_iterations - <span class="number">1</span>:</span><br><span class="line">        a_ij = torch.matmul(u_hat.transpose(<span class="number">3</span>, <span class="number">4</span>), torch.cat([v_j] * self.num_routes, dim=<span class="number">1</span>))</span><br><span class="line">        b_ij = b_ij + a_ij.squeeze(<span class="number">4</span>).mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>动态路由的结构中：</p><ul><li>第1行计算了softmax函数的结果，对用临时变量b</li><li>第5行计算加权和</li><li>第6行计算当前迭代次数的输出</li><li>第9和10行更新临时向量的值</li></ul><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">margin_loss</span>(<span class="params">self, x, labels, size_average=<span class="literal">True</span></span>):</span></span><br><span class="line">batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">v_c = torch.sqrt((x**<span class="number">2</span>).<span class="built_in">sum</span>(dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">left = F.relu(<span class="number">0.9</span> - v_c).view(batch_size, -<span class="number">1</span>)</span><br><span class="line">right = F.relu(v_c - <span class="number">0.1</span>).view(batch_size, -<span class="number">1</span>)</span><br><span class="line">loss = labels * left + <span class="number">0.5</span> * (<span class="number">1.0</span> - labels) * right</span><br><span class="line">loss = loss.<span class="built_in">sum</span>(dim=<span class="number">1</span>).mean()</span><br><span class="line"><span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><p>该函数为代价函数，分别实现了两种情况下($T_c = 0,T_c = 1$)的代价函数。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>代码来自<a href="https://github.com/higgsfield/Capsule-Network-Tutorial/blob/master/Capsule%20Network.ipynb">higgsfield’s github</a></p><p>文字资料参考<strong>weakish</strong>翻译的<strong>Max Pechyonkin</strong>的博客：</p><ul><li><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;mid=2247484099&amp;idx=1&amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;scene=21#wechat_redirect">CapsNet入门系列之一：胶囊网络背后的直觉</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;mid=2247484165&amp;idx=1&amp;sn=0ca679e3a5f499f8d8addb405fe3df83&amp;chksm=eb4ee7c6dc396ed0a330fcac12690110bcaf9a8a10794dbc5e1a326c69ecbb140140f55fd6ba&amp;scene=21#wechat_redirect">CapsNet入门系列之二：胶囊如何工作</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;mid=2247484433&amp;idx=1&amp;sn=3afe4605bc2501eebbc41c6dd1af9572&amp;chksm=eb4ee0d2dc3969c4619d6c1097d5c949c76c6c854e60d36eba4388da2c3855747818d062c90a&amp;scene=21#wechat_redirect">CapsNet入门系列之三：囊间动态路由算法</a></li><li><a href="https://mp.weixin.qq.com/s/6CRSen8P6zKaMGtX8IRfqw">CapsNet入门系列之四：胶囊网络架构</a></li></ul><p>此外还参考：</p><ul><li><a href="http://cj.sina.com.cn/article/detail/3996876140/467096?column=tech&amp;ch=5">机器之心：先读懂CapsNet架构然后用TensorFlow实现，这应该是最详细的教程了</a></li><li><a href="https://www.jiqizhixin.com/articles/capsule-implement-sara-sabour-Feb02">机器之心：Capsule官方代码开源之后，机器之心做了份核心代码解读</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于numpy构建多层感知机</title>
      <link href="2018/03/05/%E5%9F%BA%E4%BA%8Enumpy%E6%9E%84%E5%BB%BA%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
      <url>2018/03/05/%E5%9F%BA%E4%BA%8Enumpy%E6%9E%84%E5%BB%BA%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>使用numpy实现多层感知机的正向和反向传播</p><h1 id="层次构建"><a href="#层次构建" class="headerlink" title="层次构建"></a>层次构建</h1><h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><h3 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h3><p>正向传播的公式为：$Y = f(W \times X + b)$，其中，Y为输出，W为权值，b为偏置</p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>对于反向传播，已知上一层传回的梯度为dY，对应的反向传播公式为：</p><script type="math/tex; mode=display">dX = (W^{T} \times dY) \cdot f'(Y)</script><script type="math/tex; mode=display">dW = \cfrac{1}{m} dY \times X^{T}</script><script type="math/tex; mode=display">db = \cfrac{1}{m} \sum dY</script><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">numpy_fc</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channel, out_channel, optim</span>):</span></span><br><span class="line">        self.weight = np.float64(np.random.randn(out_channel, in_channel) * <span class="number">0.1</span>)</span><br><span class="line">        self.bias = np.zeros((out_channel, <span class="number">1</span>),dtype=np.float64)</span><br><span class="line">        self.in_data = np.zeros((<span class="number">1</span>, in_channel))</span><br><span class="line">        self.out_data = <span class="literal">None</span></span><br><span class="line">        self.weight_grad = <span class="literal">None</span></span><br><span class="line">        self.bias_grad = <span class="literal">None</span></span><br><span class="line">        self.optimizer = optim</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        self.in_data = data</span><br><span class="line">        self.out_data = np.dot(self.weight, data) + self.bias</span><br><span class="line">        <span class="keyword">return</span> self.out_data</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, grad</span>):</span></span><br><span class="line">        data_grad = np.dot(self.weight.T, grad)</span><br><span class="line">        self.weight_grad = np.dot(grad, self.in_data.T)</span><br><span class="line">        self.bias_grad = np.<span class="built_in">sum</span>(grad, axis=<span class="number">1</span>).reshape((-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> data_grad</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="comment">#         print(self.bias_grad.shape,self.bias.shape)</span></span><br><span class="line">        self.weight += self.optimizer(self.weight_grad)</span><br><span class="line">        self.bias += self.optimizer(self.bias_grad)</span><br></pre></td></tr></table></figure><h3 id="代码测试"><a href="#代码测试" class="headerlink" title="代码测试"></a>代码测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">test_fc = numpy_fc(<span class="number">16</span>,<span class="number">8</span>,<span class="literal">None</span>)</span><br><span class="line">test_fc_forward = test_fc.forward(np.random.rand(<span class="number">16</span>,<span class="number">10</span>))</span><br><span class="line">print(test_fc_forward.shape)</span><br><span class="line">test_fc_back = test_fc.backward(test_fc_forward)</span><br><span class="line">print(test_fc_back.shape)</span><br><span class="line">print(test_fc.weight_grad.shape,test_fc.weight.shape)</span><br><span class="line">print(test_fc.bias_grad.shape,test_fc.bias.shape)</span><br></pre></td></tr></table></figure><pre><code>(8, 10)(16, 10)(8, 16) (8, 16)(8, 1) (8, 1)</code></pre><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><p>sigmoid函数是常用的二分类问题输出层激活函数，前向传播和反向传播分别如下所示：</p><script type="math/tex; mode=display">sigmoid(x) = \cfrac{1}{1 + e^{-x}}</script><script type="math/tex; mode=display">sigmoid'(x) = sigmoid(x) \cdot (1 - sigmoid(x))</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">numpy_sigmoid</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.result = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,data</span>):</span></span><br><span class="line">        self.result = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-data))</span><br><span class="line">        <span class="keyword">return</span> self.result</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self,grad</span>):</span></span><br><span class="line">        <span class="keyword">return</span> grad * self.result * (<span class="number">1</span> - self.result)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="relu函数"><a href="#relu函数" class="headerlink" title="relu函数"></a>relu函数</h3><p>relu是现阶段最常用的隐层激活函数，前向传播和反向传播如下所示</p><script type="math/tex; mode=display">relu(x) = max\{0,x\}</script><script type="math/tex; mode=display">relu'(x)= \begin{cases}   0 &\mbox{$relu(x) \leq 0$}\\   1 &\mbox{$relu(x) > 0$ }   \end{cases}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">numpy_relu</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.result = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,data</span>):</span></span><br><span class="line">        self.result = data</span><br><span class="line">        self.result[data &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.result</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self,grad</span>):</span></span><br><span class="line">        relu_grad = self.result</span><br><span class="line">        relu_grad[self.result &gt; <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> grad * relu_grad</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h2 id="其他组件构建"><a href="#其他组件构建" class="headerlink" title="其他组件构建"></a>其他组件构建</h2><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><h4 id="MES"><a href="#MES" class="headerlink" title="MES"></a>MES</h4><p>MES代价函数的前向传播和反向传播为：</p><script type="math/tex; mode=display">MES(y\_pre,y) = \cfrac{1}{m} \sum ( y\_pre - y )^2</script><script type="math/tex; mode=display">\cfrac{dMES}{dy\_pre} = \cfrac{2}{m} |y\_pre - y|</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MES_loss</span>(<span class="params">y_pre,y</span>):</span></span><br><span class="line">    loss = np.<span class="built_in">sum</span>((y_pre - y) ** <span class="number">2</span>)</span><br><span class="line">    loss_back = np.<span class="built_in">abs</span>(y_pre - y)</span><br><span class="line">    <span class="keyword">return</span> loss,loss_back</span><br></pre></td></tr></table></figure><h4 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h4><p>交叉熵的前向传播和反向传播分别为：</p><script type="math/tex; mode=display">cross(y\_pre,y) = - \cfrac{1}{m} \sum^m_{i = 1}(ylog(y\_pre) + (1-y)log(1-y\_pre))</script><script type="math/tex; mode=display">\cfrac{dcross}{dy\_pre} = -\cfrac{1}{m}(\cfrac{y}{y\_pre} - \cfrac{1-y}{1-y\_pre})</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Cross_loss</span>(<span class="params">y_pre,y</span>):</span></span><br><span class="line">    loss = -np.<span class="built_in">sum</span>(y*np.log(y_pre)+(<span class="number">1</span>-y)*np.log(<span class="number">1</span>-y_pre))</span><br><span class="line">    loss_back = y/y_pre + (<span class="number">1</span>-y)/(<span class="number">1</span>-y_pre)</span><br><span class="line">    <span class="keyword">return</span> loss,-loss_back</span><br></pre></td></tr></table></figure><h4 id="带交叉熵的softmax函数"><a href="#带交叉熵的softmax函数" class="headerlink" title="带交叉熵的softmax函数"></a>带交叉熵的softmax函数</h4><p>softmax函数是多分类问题常用的输出激活函数，一般与交叉熵代价函数结合使用，组合函数（softmax+交叉熵）的前向传播如下：</p><script type="math/tex; mode=display">J(y\_pre,y) = - \sum y_i * log(softmax(y\_pre_i))</script><script type="math/tex; mode=display">softmax_i(x) = \cfrac{e^{x_i}}{\sum_j e^{x_j}}</script><p>反向传播如下：</p><script type="math/tex; mode=display">\cfrac{dJ(y\_pre,y)}{dy\_pre} = y\_pre - y</script><p>详细推导可参见<a href="http://vsooda.github.io/2017/03/14/softmax-logistic/#%E6%8E%A8%E5%AF%BC">这里</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Softmax_cross_loss</span>(<span class="params">y_pre,y</span>):</span></span><br><span class="line">    softmax = np.exp(y_pre) / np.<span class="built_in">sum</span>(np.exp(y_pre),axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#     print(np.sum(np.exp(y_pre),axis=1,keepdims=True))</span></span><br><span class="line"><span class="comment">#     print(np.sum(softmax,axis=0))</span></span><br><span class="line"><span class="comment">#     print(softmax)</span></span><br><span class="line">    loss = - np.<span class="built_in">sum</span>(y * np.log(softmax))</span><br><span class="line">    loss_back = softmax - y</span><br><span class="line">    <span class="keyword">return</span> loss,loss_back</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Softmax_cross_loss(np.random.randn(<span class="number">2</span>,<span class="number">4</span>),np.random.randn(<span class="number">2</span>,<span class="number">4</span>))</span><br></pre></td></tr></table></figure><pre><code>(-4.9084963417988003, array([[-0.09065384,  0.07506358,  0.32789286,  1.26735185],        [ 1.93958915,  0.01316283,  1.20922904,  2.87550082]]))</code></pre><h3 id="优化器SGD"><a href="#优化器SGD" class="headerlink" title="优化器SGD"></a>优化器SGD</h3><p>随机梯度下降优化器是一种比较简单的优化方法，优化公式如下：</p><script type="math/tex; mode=display">W_{new} = W_{old} - learning\_rate \times \cfrac{dJ}{dW_{old}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optim_sgd</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,learning_rate</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(optim_sgd,self).__init__()</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self,grad</span>):</span></span><br><span class="line">        <span class="keyword">return</span> -self.learning_rate * grad</span><br></pre></td></tr></table></figure><h1 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h1><h2 id="导入数据集——乳腺癌数据集"><a href="#导入数据集——乳腺癌数据集" class="headerlink" title="导入数据集——乳腺癌数据集"></a>导入数据集——乳腺癌数据集</h2><h3 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">data_url = <span class="string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;</span></span><br><span class="line">data_label = <span class="string">&quot;&quot;&quot; 1. Sample code number            1id number</span></span><br><span class="line"><span class="string">   2. Clump Thickness               1 - 10</span></span><br><span class="line"><span class="string">   3. Uniformity of Cell Size       1 - 10</span></span><br><span class="line"><span class="string">   4. Uniformity of Cell Shape      1 - 10</span></span><br><span class="line"><span class="string">   5. Marginal Adhesion             1 - 10</span></span><br><span class="line"><span class="string">   6. Single Epithelial Cell Size   1 - 10</span></span><br><span class="line"><span class="string">   7. Bare Nuclei                   1 - 10</span></span><br><span class="line"><span class="string">   8. Bland Chromatin               1 - 10</span></span><br><span class="line"><span class="string">   9. Normal Nucleoli               1 - 10</span></span><br><span class="line"><span class="string">  10. Mitoses                       1 - 10</span></span><br><span class="line"><span class="string">  11. Class                         2 for benign, 4 for malignant)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">data_label = [re.sub(<span class="string">r&quot;\s+\d&quot;</span>,<span class="string">&quot;&quot;</span>,x[<span class="number">2</span>:]) <span class="keyword">for</span> x <span class="keyword">in</span> re.findall(<span class="string">r&quot;\. [\w\s]+\d&quot;</span>,data_label)]</span><br><span class="line"><span class="comment"># print(data_label)</span></span><br><span class="line">data = pd.read_csv(data_url,names=data_label)</span><br><span class="line"><span class="comment"># data[&quot;Bare Nuclei&quot;] = data[&quot;Bare Nuclei&quot;].map(int)</span></span><br><span class="line">print(data.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 699 entries, 0 to 698Data columns (total 11 columns):Sample code numberid number    699 non-null int64Clump Thickness                699 non-null int64Uniformity of Cell Size        699 non-null int64Uniformity of Cell Shape       699 non-null int64Marginal Adhesion              699 non-null int64Single Epithelial Cell Size    699 non-null int64Bare Nuclei                    699 non-null objectBland Chromatin                699 non-null int64Normal Nucleoli                699 non-null int64Mitoses                        699 non-null int64Class                          699 non-null int64dtypes: int64(10), object(1)memory usage: 60.1+ KBNone</code></pre><h3 id="清洗数据集"><a href="#清洗数据集" class="headerlink" title="清洗数据集"></a>清洗数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = data.replace(to_replace=<span class="string">&quot;?&quot;</span>,value=np.nan)</span><br><span class="line">data = data.dropna(how=<span class="string">&#x27;any&#x27;</span>)</span><br><span class="line">data[<span class="string">&quot;Bare Nuclei&quot;</span>] = data[<span class="string">&quot;Bare Nuclei&quot;</span>].<span class="built_in">map</span>(<span class="built_in">int</span>)</span><br><span class="line">print(data.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 683 entries, 0 to 698Data columns (total 11 columns):Sample code numberid number    683 non-null int64Clump Thickness                683 non-null int64Uniformity of Cell Size        683 non-null int64Uniformity of Cell Shape       683 non-null int64Marginal Adhesion              683 non-null int64Single Epithelial Cell Size    683 non-null int64Bare Nuclei                    683 non-null int64Bland Chromatin                683 non-null int64Normal Nucleoli                683 non-null int64Mitoses                        683 non-null int64Class                          683 non-null int64dtypes: int64(11)memory usage: 64.0 KBNone</code></pre><h3 id="切分数据集"><a href="#切分数据集" class="headerlink" title="切分数据集"></a>切分数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(data[data_label[<span class="number">1</span>:<span class="number">10</span>]],data[data_label[<span class="number">10</span>]],test_size=<span class="number">0.25</span>,random_state=<span class="number">1</span>)</span><br><span class="line">print(x_train.shape,x_test.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line">print(pd.value_counts(y_train))</span><br></pre></td></tr></table></figure><pre><code>(512, 9) (171, 9)(512,)2    3334    179Name: Class, dtype: int64</code></pre><h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">x_train_ss = ss.fit_transform(x_train)</span><br><span class="line">x_test_ss = ss.transform(x_test)</span><br><span class="line"><span class="comment"># x_train_ss = x_train.values</span></span><br><span class="line"><span class="comment"># x_test_ss = x_test.values</span></span><br><span class="line">print(<span class="built_in">type</span>(x_train_ss))</span><br><span class="line"><span class="comment"># print(x_train[:5]/,x_train_ss[:5])</span></span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;numpy.ndarray&#39;&gt;</code></pre><p>​    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">y_standard</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (data / <span class="number">2</span>) - <span class="number">1</span></span><br><span class="line">y_train_ss = y_standard(y_train).values</span><br><span class="line">y_test_ss = y_standard(y_test).values</span><br><span class="line">print(pd.value_counts(y_train_ss))</span><br><span class="line">print(pd.value_counts(y_test_ss))</span><br></pre></td></tr></table></figure><pre><code>0.0    3331.0    179dtype: int640.0    1111.0     60dtype: int64</code></pre><h3 id="制作可迭代数据集"><a href="#制作可迭代数据集" class="headerlink" title="制作可迭代数据集"></a>制作可迭代数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dataset</span>(<span class="params">data,lable,batch_size=<span class="number">100</span>,epoch=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        index = [random.randint(<span class="number">0</span>,data.shape[<span class="number">0</span>]-<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(batch_size)]</span><br><span class="line"><span class="comment">#         print(index)</span></span><br><span class="line">        <span class="keyword">yield</span> data[index],lable[index]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print(x_train_ss,type(y_train_ss))</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dataset(x_train_ss,y_train_ss,batch_size=<span class="number">100</span>):</span><br><span class="line">    print(i[<span class="number">0</span>].shape,i[<span class="number">1</span>].shape)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><pre><code>(100, 9) (100,)</code></pre><p>​    </p><h2 id="独热码编码"><a href="#独热码编码" class="headerlink" title="独热码编码"></a>独热码编码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onehot</span>(<span class="params">data,tp_num</span>):</span></span><br><span class="line">    x = np.zeros((data.shape[<span class="number">0</span>],tp_num))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">        x[i][<span class="built_in">int</span>(data[i])] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_onehot = np.arange(<span class="number">2</span>)</span><br><span class="line">onehot(test_onehot,<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>array([[ 1.,  0.],       [ 0.,  1.]])</code></pre><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">numpy_network_base</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,network_list</span>):</span></span><br><span class="line">        self.network = network_list</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.network:</span><br><span class="line">            x = layer.forward(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self,grad</span>):</span></span><br><span class="line">        last_grad = grad.copy()</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.network[::-<span class="number">1</span>]:</span><br><span class="line">            last_grad = layer.backward(last_grad)</span><br><span class="line">        <span class="keyword">return</span> last_grad</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.network:</span><br><span class="line">            layer.step()</span><br></pre></td></tr></table></figure><h2 id="准确率计算"><a href="#准确率计算" class="headerlink" title="准确率计算"></a>准确率计算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">y_pre,lable</span>):</span></span><br><span class="line">    y_pre = np.argmax(y_pre,axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> np.mean(np.int8(y_pre == lable))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">4</span>*<span class="number">8</span>).reshape((<span class="number">4</span>,<span class="number">8</span>))</span><br><span class="line">b = np.ones((<span class="number">1</span>,<span class="number">8</span>)) * <span class="number">3</span></span><br><span class="line">accuracy(a,b)</span><br></pre></td></tr></table></figure><pre><code>1.0</code></pre><h1 id="网络训练与测试"><a href="#网络训练与测试" class="headerlink" title="网络训练与测试"></a>网络训练与测试</h1><h2 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">network = numpy_network_base([numpy_fc(<span class="number">9</span>,<span class="number">20</span>,optim_sgd(<span class="number">0.001</span>)),numpy_relu(),numpy_fc(<span class="number">20</span>,<span class="number">2</span>,optim_sgd(<span class="number">0.001</span>))])</span><br><span class="line"><span class="keyword">for</span> i,(din,lable) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset(x_train_ss,y_train_ss,epoch=<span class="number">10</span>,batch_size=<span class="number">100</span>)):</span><br><span class="line"><span class="comment">#     print(din)</span></span><br><span class="line">    result = network.forward(din.T)</span><br><span class="line"><span class="comment">#     print(result)</span></span><br><span class="line"><span class="comment">#     print(np.argmax(result,axis=0),lable)</span></span><br><span class="line">    loss,grad = Softmax_cross_loss(result.T,onehot(lable,<span class="number">2</span>))</span><br><span class="line"><span class="comment">#     print(loss)</span></span><br><span class="line"><span class="comment">#     print(pd.get_dummies(lable))</span></span><br><span class="line"><span class="comment">#     print(grad.shape)</span></span><br><span class="line">    print(accuracy(result,lable))</span><br><span class="line">    network.backward(grad.T)</span><br><span class="line">    network.step()</span><br></pre></td></tr></table></figure><pre><code>0.190.320.860.960.940.930.90.960.980.95</code></pre><h2 id="网络测试"><a href="#网络测试" class="headerlink" title="网络测试"></a>网络测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = network.forward(x_test_ss.T)</span><br><span class="line">print(accuracy(result,y_test_ss))</span><br></pre></td></tr></table></figure><pre><code>0.982456140351</code></pre><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基本2D优先堆</title>
      <link href="2018/02/28/%E5%9F%BA%E6%9C%AC2D%E4%BC%98%E5%85%88%E5%A0%86/"/>
      <url>2018/02/28/%E5%9F%BA%E6%9C%AC2D%E4%BC%98%E5%85%88%E5%A0%86/</url>
      
        <content type="html"><![CDATA[<h1 id="基本优先队列"><a href="#基本优先队列" class="headerlink" title="基本优先队列"></a>基本优先队列</h1><p>考虑一种队列：每次取出的数据是队列中最小的元素。这种队列可用于程序调度，作业分配等领域，这种队列被称为优先队列，核心的方法有：</p><ul><li>Insert()方法：将数据插入优先队列</li><li>DeleteMin()方法：将队列中的数据中最小的输出并删除</li></ul><p>优先队列可以使用堆这一数据结构实现</p><h1 id="二叉堆实现优先队列"><a href="#二叉堆实现优先队列" class="headerlink" title="二叉堆实现优先队列"></a>二叉堆实现优先队列</h1><h2 id="二叉堆"><a href="#二叉堆" class="headerlink" title="二叉堆"></a>二叉堆</h2><p>二叉堆是除了底层外被完全填满的二叉树，最底层的数据也是从左到右填入（完全二叉树）。因为其填满的特性，可以直接使用数组实现该树型结构：一个位于数组i位置的节点的子节点分别是2*i和2*i+1</p><h2 id="优先队列实现"><a href="#优先队列实现" class="headerlink" title="优先队列实现"></a>优先队列实现</h2><p>当一个二叉堆实现优先队列时，除了要满足堆的基本特性，还要满足一个特性：对任意一个节点，其值小于其所有的子节点（若有子节点）。则递归的来看，位于根（数组位置0）的节点即为最小的数据。</p><h3 id="插入方法"><a href="#插入方法" class="headerlink" title="插入方法"></a>插入方法</h3><p>对于堆，每次插入的位置是固定的，若直接将插入元素插入该位置，则优先队列的特性被破坏，因此，需要找到合适的插入位置。操作方法为递归的比较插入位置和插入位置父节点的大小，若满足特性则插入，不满足则交换待插入位置和父节点的数据（将父节点数据写入待插入位置，待插入位置为新的父节点）</p><img src="/2018/02/28/%E5%9F%BA%E6%9C%AC2D%E4%BC%98%E5%85%88%E5%A0%86/2d_heap_insert.png" class=""><h3 id="删除方法"><a href="#删除方法" class="headerlink" title="删除方法"></a>删除方法</h3><p>删除方法有两个功能，第一个功能是将最小的数据弹出，这可以直接返回根节点的值实现；第二个功能是更新新的元素，由于堆少了一个节点，而该节点的位置必须是底层最右侧的节点。因此将该节点数据取出，并插入到跟节点的位置，这样堆的特性被破坏。于是取跟节点为待插入位置，递归的比较待插入节点和子节点的最小节点，获得插入该元素的位置。</p><img src="/2018/02/28/%E5%9F%BA%E6%9C%AC2D%E4%BC%98%E5%85%88%E5%A0%86/2d_heap_delete.png" class=""><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><blockquote><p>这段代码写的时候状态比较差，仅供参考</p></blockquote><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> nodeData <span class="keyword">struct</span> &#123;</span><br><span class="line">num  <span class="keyword">int</span></span><br><span class="line">data <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> heap2D <span class="keyword">struct</span> &#123;</span><br><span class="line">heap   [<span class="number">17</span>]nodeData</span><br><span class="line">lenght <span class="keyword">int</span></span><br><span class="line">size   <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewHeap2D</span><span class="params">()</span> *<span class="title">heap2D</span></span> &#123;</span><br><span class="line">newHeap := &amp;heap2D&#123;&#125;</span><br><span class="line">newHeap.size = <span class="number">15</span></span><br><span class="line">newHeap.lenght = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; newHeap.size; i++ &#123;</span><br><span class="line">newHeap.heap[i] = nodeData&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> newHeap</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入方法-1"><a href="#插入方法-1" class="headerlink" title="插入方法"></a>插入方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *heap2D)</span> <span class="title">Insert</span><span class="params">(din nodeData)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> h.lenght &gt; h.size &#123;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;heap full&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">i := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i = h.lenght; h.heap[i/<span class="number">2</span>].num &gt;= din.num &amp;&amp; i != <span class="number">0</span>; i = i / <span class="number">2</span> &#123;</span><br><span class="line">h.heap[i] = h.heap[i/<span class="number">2</span>]</span><br><span class="line">        <span class="comment">// 若插入标记小于父节点标记，则向父节点移动</span></span><br><span class="line">&#125;</span><br><span class="line">h.heap[i] = din <span class="comment">//插入</span></span><br><span class="line">h.lenght++</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="弹出方法"><a href="#弹出方法" class="headerlink" title="弹出方法"></a>弹出方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *heap2D)</span> <span class="title">DeleteMin</span><span class="params">()</span> <span class="params">(nodeData, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> h.lenght == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> nodeData&#123;&#125;, errors.New(<span class="string">&quot;heap empty&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">dout := h.heap[<span class="number">1</span>] <span class="comment">//取出根节点数据，该数据为优先级最高的节点</span></span><br><span class="line">err := h.DownFlow(<span class="number">1</span>, h.heap[h.lenght<span class="number">-1</span>]) <span class="comment">//调用下移方法将堆中的最后一个节点从根节点插入</span></span><br><span class="line">h.lenght--</span><br><span class="line"><span class="keyword">return</span> dout, err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="下移方法"><a href="#下移方法" class="headerlink" title="下移方法"></a>下移方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *heap2D)</span> <span class="title">DownFlow</span><span class="params">(nodeNum <span class="keyword">int</span>, insert nodeData)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> nodeNum &gt;= h.lenght &#123;</span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;errors&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> <span class="number">2</span>*nodeNum &gt;= h.lenght &#123;</span><br><span class="line"><span class="comment">// 无子节点，直接插入</span></span><br><span class="line">h.heap[nodeNum] = insert</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> insert.num &lt; h.heap[h.findMinSon(nodeNum)].num &#123;</span><br><span class="line"><span class="comment">// 两个子节点均大于待插入数据，直接插入</span></span><br><span class="line">h.heap[nodeNum] = insert</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 两个子节点的最小标号小于带插入数据标号，递归该过程</span></span><br><span class="line">next := h.findMinSon(nodeNum)</span><br><span class="line">h.heap[nodeNum] = h.heap[next]</span><br><span class="line"><span class="keyword">return</span> h.DownFlow(next, insert)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 该方法用于计算出最小子节点标号</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *heap2D)</span> <span class="title">findMinSon</span><span class="params">(nodeNum <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="number">2</span>*nodeNum+<span class="number">1</span> &gt;= h.lenght &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span> * nodeNum</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> h.heap[<span class="number">2</span>*nodeNum].num &gt; h.heap[<span class="number">2</span>*nodeNum+<span class="number">1</span>].num &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span>*nodeNum + <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span> * nodeNum</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN的反向传播</title>
      <link href="2018/02/21/CNN%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
      <url>2018/02/21/CNN%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</url>
      
        <content type="html"><![CDATA[<h1 id="DNN中的反向传播"><a href="#DNN中的反向传播" class="headerlink" title="DNN中的反向传播"></a>DNN中的反向传播</h1><p>反向传播算法是神经网络的训练的基本算法组成之一，在训练神经网络时，训练分为两个步骤：计算梯度和更新权值。其中反向传播负责的是梯度的计算，而训练算法的区分主要在更新权值的方式上。对于DNN，基本的反向传播思路为：</p><script type="math/tex; mode=display">\cfrac{dz}{dw_{i}} = \cfrac{dz}{da_{i+1}} \times \cfrac{da_{i+1}}{dw_{i}}</script><p>其中，$\cfrac{dz}{dw<em>{i}}$为输出（多为代价函数输出）对第i层的权值的梯度，$\cfrac{da</em>{i+1}}{dw_{i}}$为本层输出对权值的梯度。于是梯度的计算被分为反向传播链条上的几个部分，将复杂的求导分割为层内运算的求导，上一层的梯度可以由本层的梯度递归的求出。</p><h1 id="卷积神经网络中的反向传播"><a href="#卷积神经网络中的反向传播" class="headerlink" title="卷积神经网络中的反向传播"></a>卷积神经网络中的反向传播</h1><p>卷积神经网络相比于多层感知机，增加了两种新的层次——卷积层与池化层。由于反向传播链的存在，要求出这两种层结构的梯度，仅需要解决输出对权值的梯度即可。</p><h2 id="池化层的梯度"><a href="#池化层的梯度" class="headerlink" title="池化层的梯度"></a>池化层的梯度</h2><p>池化层用于削减数据量，在这一层上前向传播的数据会有损失，则在反向传播时，传播来的梯度也会有所损失。一般来说，池化层没有参数，于是仅需要计算梯度反向传播的结果。</p><h3 id="理论分析"><a href="#理论分析" class="headerlink" title="理论分析"></a>理论分析</h3><p>池化层的反向传播的方法是upsample，先将矩阵还原成原大小，之后：</p><ul><li>对于最大值池化，将梯度放置于每个池化区域取得最大值的位置，其他位置为0</li><li>对于平均值池化，则把的所有子矩阵的各个池化局域的值取平均后放在还原后的子矩阵位置</li></ul><p>例如对于矩阵：</p><script type="math/tex; mode=display">\left( \begin{array}{} 1& 2 \\ 3& 4 \end{array} \right)</script><p>假设经过2*2的池化，还原为原来大小：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} 0&0&0&0 \\ 0&1& 2&0 \\ 0&3&4&0 \\ 0&0&0&0 \end{array} \right)</script><p>若是最大值池化，假设每个窗口的最大值位置都是左上，则传播结果为：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} 1&0&2&0 \\ 0&0& 0&0 \\ 3&0&4&0 \\ 0&0&0&0 \end{array} \right)</script><p>若是经过平均值池化，则传播结果为：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} 0.25&0.25&0.5&0.5 \\ 0.25&0.25& 0.5&0.5 \\ 0.75&0.75&1&1 \\ 0.75&0.75&1&1 \end{array} \right)</script><h3 id="代码验证"><a href="#代码验证" class="headerlink" title="代码验证"></a>代码验证</h3><h4 id="最大值池化"><a href="#最大值池化" class="headerlink" title="最大值池化"></a>最大值池化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">test_model = pt.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">test = pt.autograd.Variable(pt.arange(<span class="number">0</span>, <span class="number">16</span>).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(test)</span><br><span class="line">result = test_model(test)</span><br><span class="line">print(result)</span><br><span class="line">result.backward(result.data)</span><br><span class="line">print(test.grad)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">   0   1   2   3</span><br><span class="line">   4   5   6   7</span><br><span class="line">   8   9  10  11</span><br><span class="line">  12  13  14  15</span><br><span class="line">[torch.FloatTensor of size 1x1x4x4]</span><br><span class="line"></span><br><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">   5   7</span><br><span class="line">  13  15</span><br><span class="line">[torch.FloatTensor of size 1x1x2x2]</span><br><span class="line"></span><br><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">   0   0   0   0</span><br><span class="line">   0   5   0   7</span><br><span class="line">   0   0   0   0</span><br><span class="line">   0  13   0  15</span><br><span class="line">[torch.FloatTensor of size 1x1x4x4]</span><br></pre></td></tr></table></figure><h4 id="平均值池化"><a href="#平均值池化" class="headerlink" title="平均值池化"></a>平均值池化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">test_model = pt.nn.AvgPool2d(<span class="number">2</span>)</span><br><span class="line">test = pt.autograd.Variable(pt.arange(<span class="number">0</span>, <span class="number">16</span>).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(test)</span><br><span class="line">result = test_model(test)</span><br><span class="line">print(result)</span><br><span class="line">result.backward(result.data)</span><br><span class="line">print(test.grad)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">   0   1   2   3</span><br><span class="line">   4   5   6   7</span><br><span class="line">   8   9  10  11</span><br><span class="line">  12  13  14  15</span><br><span class="line">[torch.FloatTensor of size 1x1x4x4]</span><br><span class="line"></span><br><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">   2.5000   4.5000</span><br><span class="line">  10.5000  12.5000</span><br><span class="line">[torch.FloatTensor of size 1x1x2x2]</span><br><span class="line"></span><br><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">  0.6250  0.6250  1.1250  1.1250</span><br><span class="line">  0.6250  0.6250  1.1250  1.1250</span><br><span class="line">  2.6250  2.6250  3.1250  3.1250</span><br><span class="line">  2.6250  2.6250  3.1250  3.1250</span><br><span class="line">[torch.FloatTensor of size 1x1x4x4]</span><br></pre></td></tr></table></figure><h2 id="卷积层梯度"><a href="#卷积层梯度" class="headerlink" title="卷积层梯度"></a>卷积层梯度</h2><p>卷积层具有权值，因此梯度计算包括反向传播的梯度和权值梯度</p><h3 id="反向传播梯度"><a href="#反向传播梯度" class="headerlink" title="反向传播梯度"></a>反向传播梯度</h3><h4 id="理论分析-1"><a href="#理论分析-1" class="headerlink" title="理论分析"></a>理论分析</h4><p>对于卷积网络，前向传播公式为：</p><script type="math/tex; mode=display">a^l= \sigma(z^l) = \sigma(a^{l-1}*W^l +b^l)</script><p>其中$*$为卷积运算（不为乘法运算），DNN的反向传播公式为：</p><script type="math/tex; mode=display">\delta^{l} = \cfrac{\partial J(W,b)}{\partial z^l} = \cfrac{\partial J(W,b)}{\partial z^{l+1}}\cfrac{\partial z^{l+1}}{\partial z^{l}} = \delta^{l+1}\cfrac{\partial z^{l+1}}{\partial z^{l}}</script><p>其中$\delta^{l}$为第l层的梯度，$\cfrac{\partial z^{l+1}}{\partial z^{l}}$为卷积层的输出对输入的梯度，则反向传播的梯度为：</p><script type="math/tex; mode=display">\delta^{l-1} =  \delta^{l}\cfrac{\partial z^{l}}{\partial z^{l-1}} = \delta^{l}*rot180(W^{l}) \odot  \sigma^{'}(z^{l-1})</script><p>其中$rot180(W^{l})$为卷积核旋转180度的函数，*为卷积。</p><p>举一个例子来说，对于以下卷积等式：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} a_{11}&a_{12}&a_{13} \\ a_{21}&a_{22}&a_{23}\\ a_{31}&a_{32}&a_{33} \end{array} \right)    *  \left( \begin{array}{ccc} w_{11}&w_{12}\\ w_{21}&w_{22} \end{array} \right) = \left( \begin{array}{ccc} z_{11}&z_{12}\\ z_{21}&z_{22} \end{array} \right)</script><p>对于$a<em>{11}$，有$z</em>{11} = a<em>{11}w</em>{11} + a<em>{12}w</em>{12} + a<em>{21}w</em>{21} +   a<em>{22}w</em>{22}$，仅$z<em>{11}$与其有关，则有$\nabla a</em>{11} = \delta<em>{11}w</em>{11}$。</p><p>对于$a<em>{22}$，所有z项都和该数有关，有$\nabla a</em>{22} = \delta<em>{11}w</em>{22} + \delta<em>{12}w</em>{21} + \delta<em>{21}w</em>{12} + \delta<em>{22}w</em>{11}$</p><p>依次类推，可得：</p><p>$\left( \begin{array}{ccc} 0&amp;0&amp;0&amp;0 \ 0&amp;\delta<em>{11}&amp; \delta</em>{12}&amp;0 \ 0&amp;\delta<em>{21}&amp;\delta</em>{22}&amp;0 \ 0&amp;0&amp;0&amp;0 \end{array} \right) * \left( \begin{array}{ccc} w<em>{22}&amp;w</em>{21}\ w<em>{12}&amp;w</em>{11} \end{array} \right)  = \left( \begin{array}{ccc} \nabla a<em>{11}&amp;\nabla a</em>{12}&amp;\nabla a<em>{13} \ \nabla a</em>{21}&amp;\nabla a<em>{22}&amp;\nabla a</em>{23}\ \nabla a<em>{31}&amp;\nabla a</em>{32}&amp;\nabla a_{33} \end{array} \right)$</p><h4 id="代码验证-1"><a href="#代码验证-1" class="headerlink" title="代码验证"></a>代码验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = pt.autograd.Variable(pt.arange(<span class="number">0</span>, <span class="number">9</span>).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">weight = pt.autograd.Variable(pt.arange(<span class="number">0</span>,<span class="number">4</span>).view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">bias = pt.autograd.Variable(pt.zeros(<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">result = pt.nn.functional.conv2d(data,weight,bias)</span><br><span class="line">print(result)</span><br><span class="line">result.backward(result.data)</span><br><span class="line">print(data.grad)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">  19  25</span><br><span class="line">  37  43</span><br><span class="line">[torch.FloatTensor of size 1x1x2x2]</span><br><span class="line"></span><br><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">    0   19   25</span><br><span class="line">   38  144  118</span><br><span class="line">   74  197  129</span><br><span class="line">[torch.FloatTensor of size 1x1x3x3]</span><br></pre></td></tr></table></figure><p>该代码中，前向传播为：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} 0&1&2 \\ 3&4&5\\ 6&7&8 \end{array} \right)    *  \left( \begin{array}{ccc} 0&1\\ 2&3 \end{array} \right) = \left( \begin{array}{ccc} 19&25\\ 37&43 \end{array} \right)</script><p>反向传播为：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} 0&0&0&0 \\ 0&19&25&0 \\ 0&37&43&0 \\ 0&0&0&0 \end{array} \right) * \left( \begin{array}{ccc} 3&2\\ 1&0 \end{array} \right)  = \left( \begin{array}{ccc} 0&19&25 \\ 38&144&118\\ 74&197&129 \end{array} \right)</script><h3 id="权值梯度"><a href="#权值梯度" class="headerlink" title="权值梯度"></a>权值梯度</h3><h4 id="理论推导"><a href="#理论推导" class="headerlink" title="理论推导"></a>理论推导</h4><p>类似于上一节的公式，对权值的梯度为：</p><script type="math/tex; mode=display">\cfrac{\partial J(W,b)}{\partial W^{l}} = \cfrac{\partial J(W,b)}{\partial z^{l}}\cfrac{\partial z^{l}}{\partial W^{l}} =rot180(\delta^l*a^{l-1})</script><p>同样对于前向传播：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} a_{11}&a_{12}&a_{13} \\ a_{21}&a_{22}&a_{23}\\ a_{31}&a_{32}&a_{33} \end{array} \right)    *  \left( \begin{array}{ccc} w_{11}&w_{12}\\ w_{21}&w_{22} \end{array} \right) = \left( \begin{array}{ccc} z_{11}&z_{12}\\ z_{21}&z_{22} \end{array} \right)</script><p>对于$z$，有以下：</p><ul><li>$z<em>{11} = a</em>{11}w<em>{11} + a</em>{12}w<em>{12} + a</em>{21}w<em>{21} +   a</em>{22}w_{22}$</li><li>$z<em>{12} = a</em>{12}w<em>{11} + a</em>{13}w<em>{12} + a</em>{22}w<em>{21} +   a</em>{23}w_{22}$</li><li>$z<em>{21} = a</em>{21}w<em>{11} + a</em>{22}w<em>{12} + a</em>{31}w<em>{21} +   a</em>{32}w_{22}$</li><li>$z<em>{22} = a</em>{22}w<em>{11} + a</em>{23}w<em>{12} + a</em>{32}w<em>{21} +   a</em>{33}w_{22}$</li></ul><p>有梯度：</p><ul><li>$\nabla w<em>{11} = \delta</em>{11}a<em>{11} + \delta</em>{12}a<em>{12} + \delta</em>{21}a<em>{21} + \delta</em>{22}a_{22}$</li><li>$\nabla w<em>{12} = \delta</em>{11}a<em>{12} + \delta</em>{12}a<em>{13} + \delta</em>{21}a<em>{22} + \delta</em>{22}a_{12}$</li><li>$\nabla w<em>{21} = \delta</em>{11}a<em>{21} + \delta</em>{12}a<em>{22} + \delta</em>{21}a<em>{31} + \delta</em>{22}a_{32}$</li><li>$\nabla w<em>{22} = \delta</em>{11}a<em>{22} + \delta</em>{12}a<em>{23} + \delta</em>{32}a<em>{21} + \delta</em>{33}a_{22}$</li></ul><p>反向传播为：</p><p>$\left( \begin{array}{ccc} 0&amp;0&amp;0&amp;0 \ 0&amp;\delta<em>{11}&amp; \delta</em>{12}&amp;0 \ 0&amp;\delta<em>{21}&amp;\delta</em>{22}&amp;0 \ 0&amp;0&amp;0&amp;0 \end{array} \right) * \left( \begin{array}{ccc} a<em>{11}&amp;a</em>{12}&amp;a<em>{13}\ a</em>{21}&amp;a<em>{22}&amp;a</em>{23}\ a<em>{31}&amp;a</em>{32}&amp;a<em>{33} \end{array} \right)  = \left( \begin{array}{ccc} \nabla w</em>{22}&amp;\nabla w<em>{21}\ \nabla w</em>{12}&amp;\nabla w_{11} \end{array} \right)$</p><h4 id="代码验证-2"><a href="#代码验证-2" class="headerlink" title="代码验证"></a>代码验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = pt.autograd.Variable(pt.arange(<span class="number">0</span>, <span class="number">9</span>).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">weight = pt.autograd.Variable(pt.arange(<span class="number">0</span>,<span class="number">4</span>).view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">bias = pt.autograd.Variable(pt.zeros(<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">result = pt.nn.functional.conv2d(data,weight,bias)</span><br><span class="line">print(result)</span><br><span class="line">result.backward(result.data)</span><br><span class="line">print(weight.grad)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">  19  25</span><br><span class="line">  37  43</span><br><span class="line">[torch.FloatTensor of size 1x1x2x2]</span><br><span class="line"></span><br><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">  308  432</span><br><span class="line">  680  804</span><br><span class="line">[torch.FloatTensor of size 1x1x2x2]</span><br></pre></td></tr></table></figure><p>反向传播为：</p><script type="math/tex; mode=display">\left( \begin{array}{ccc} 0&0&0&0 \\ 0&19&25&0 \\ 0&37&43&0 \\ 0&0&0&0 \end{array} \right) * \left( \begin{array}{ccc} 0&1&2 \\ 3&4&5\\ 6&7&8 \end{array} \right) =  \left( \begin{array}{ccc} 804&680\\ 432&308 \end{array} \right)</script><h3 id="偏置梯度"><a href="#偏置梯度" class="headerlink" title="偏置梯度"></a>偏置梯度</h3><p>偏置梯度较为简单，为上一层梯度和：</p><script type="math/tex; mode=display">\cfrac{\partial J(W,b)}{\partial b^{l}} = \cfrac{\partial J(W,b)}{\partial z^{l}} \cdot \cfrac{dz^{l}}{db^l}= \sum\limits_{u,v}(\delta^l)_{u,v}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = pt.autograd.Variable(pt.arange(<span class="number">0</span>, <span class="number">9</span>).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">weight = pt.autograd.Variable(pt.arange(<span class="number">0</span>,<span class="number">4</span>).view(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">bias = pt.autograd.Variable(pt.zeros(<span class="number">1</span>),requires_grad=<span class="literal">True</span>)</span><br><span class="line">result = pt.nn.functional.conv2d(data,weight,bias)</span><br><span class="line">print(result)</span><br><span class="line">result.backward(result.data)</span><br><span class="line">print(bias.grad)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Variable containing:</span><br><span class="line">(0 ,0 ,.,.) &#x3D;</span><br><span class="line">  19  25</span><br><span class="line">  37  43</span><br><span class="line">[torch.FloatTensor of size 1x1x2x2]</span><br><span class="line"></span><br><span class="line">Variable containing:</span><br><span class="line"> 124</span><br><span class="line">[torch.FloatTensor of size 1]</span><br></pre></td></tr></table></figure><p>有$124 = 19 + 25 + 37 + 43$</p><p><strong>参考</strong></p><p><a href="https://www.cnblogs.com/pinard/p/6494810.html#!comments">刘建平Pinard</a></p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MIPS指令集与简单分析</title>
      <link href="2018/02/18/MIPS%E6%8C%87%E4%BB%A4%E9%9B%86%E4%B8%8E%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90/"/>
      <url>2018/02/18/MIPS%E6%8C%87%E4%BB%A4%E9%9B%86%E4%B8%8E%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="R格式指令"><a href="#R格式指令" class="headerlink" title="R格式指令"></a>R格式指令</h1><h2 id="基本格式"><a href="#基本格式" class="headerlink" title="基本格式"></a>基本格式</h2><div class="table-container"><table><thead><tr><th style="text-align:center">标记</th><th style="text-align:center">op</th><th style="text-align:center">rs</th><th style="text-align:center">rt</th><th style="text-align:center">rd</th><th style="text-align:center">shamt</th><th style="text-align:center">funct</th></tr></thead><tbody><tr><td style="text-align:center">位数</td><td style="text-align:center">31-26</td><td style="text-align:center">25-21</td><td style="text-align:center">20-16</td><td style="text-align:center">15-11</td><td style="text-align:center">10-6</td><td style="text-align:center">5-0</td></tr><tr><td style="text-align:center">功能</td><td style="text-align:center">操作符</td><td style="text-align:center">源操作数寄存器1</td><td style="text-align:center">源操作数寄存器2</td><td style="text-align:center">目的操作数寄存器</td><td style="text-align:center">位移量</td><td style="text-align:center">操作符附加段</td></tr></tbody></table></div><h2 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h2><h3 id="算数类指令"><a href="#算数类指令" class="headerlink" title="算数类指令"></a>算数类指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rt</th><th>rd</th><th>shamt</th><th>funct</th><th>功能</th></tr></thead><tbody><tr><td>add</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100000</td><td>rd=rs+rt</td></tr><tr><td>addu</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100001</td><td>rd=rs+rt（无符号数）</td></tr><tr><td>sub</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100010</td><td>rd=rs-rt</td></tr><tr><td>subu</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100011</td><td>rd=rs-rt（无符号数）</td></tr><tr><td>slt</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>101010</td><td>rd=(rs&lt;rt)?1:0</td></tr><tr><td>sltu</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>101011</td><td>rd=(rs&lt;rt)?1:0（无符号数）</td></tr></tbody></table></div><h3 id="逻辑类指令"><a href="#逻辑类指令" class="headerlink" title="逻辑类指令"></a>逻辑类指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rt</th><th>rd</th><th>shamt</th><th>funct</th><th>功能</th></tr></thead><tbody><tr><td>and</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100100</td><td>rd=rs&amp;rt</td></tr><tr><td>or</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100101</td><td>rd=rs\</td><td>rt</td></tr><tr><td>xor</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100110</td><td>rd=rs xor rd</td></tr><tr><td>nor</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>100111</td><td>rd=!(rs\</td><td>rt)</td></tr></tbody></table></div><h3 id="位移类指令"><a href="#位移类指令" class="headerlink" title="位移类指令"></a>位移类指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rt</th><th>rd</th><th>shamt</th><th>funct</th><th>功能</th></tr></thead><tbody><tr><td>sll</td><td>000000</td><td>00000</td><td>rt</td><td>rd</td><td>shamt</td><td>000000</td><td>rd=rt&lt;&lt;shamt</td></tr><tr><td>srl</td><td>000000</td><td>00000</td><td>rt</td><td>rd</td><td>shamt</td><td>000010</td><td>rd=rt&gt;&gt;shamt</td></tr><tr><td>sra</td><td>000000</td><td>00000</td><td>rt</td><td>rd</td><td>shamt</td><td>000011</td><td>rd=rt&gt;&gt;shamt（符号位保留）</td></tr><tr><td>sllv</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>000100</td><td>rd=rt&lt;&lt;rs</td></tr><tr><td>srlv</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>000110</td><td>rd=rt&gt;&gt;rs</td></tr><tr><td>srav</td><td>000000</td><td>rs</td><td>rt</td><td>rd</td><td>00000</td><td>000111</td><td>rd=rt&gt;&gt;rs（符号位保留）</td></tr></tbody></table></div><h3 id="跳转指令"><a href="#跳转指令" class="headerlink" title="跳转指令"></a>跳转指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rt</th><th>rd</th><th>shamt</th><th>funct</th><th>功能</th></tr></thead><tbody><tr><td>jr</td><td>000000</td><td>rs</td><td>00000</td><td>00000</td><td>00000</td><td>001000</td><td>PC=rs</td></tr></tbody></table></div><h1 id="I格式指令"><a href="#I格式指令" class="headerlink" title="I格式指令"></a>I格式指令</h1><h2 id="基本格式-1"><a href="#基本格式-1" class="headerlink" title="基本格式"></a>基本格式</h2><div class="table-container"><table><thead><tr><th>标记</th><th>op</th><th>rs</th><th>rd</th><th>im</th></tr></thead><tbody><tr><td>位数</td><td>31-26</td><td>25-21</td><td>20-16</td><td>15-0</td></tr><tr><td>功能</td><td>操作符</td><td>源操作数寄存器</td><td>目的操作数寄存器</td><td>立即数</td></tr></tbody></table></div><h2 id="指令-1"><a href="#指令-1" class="headerlink" title="指令"></a>指令</h2><h3 id="算数指令"><a href="#算数指令" class="headerlink" title="算数指令"></a>算数指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rd</th><th>im</th><th>功能</th></tr></thead><tbody><tr><td>addi</td><td>001000</td><td>rs</td><td>rd</td><td>im</td><td>rd=rs+im</td></tr><tr><td>addiu</td><td>001001</td><td>rs</td><td>rd</td><td>im</td><td>rd=rs+im（无符号数）</td></tr><tr><td>slti</td><td>001010</td><td>rs</td><td>rd</td><td>im</td><td>rd=(rs&lt;im)?1:0</td></tr><tr><td>sltiu</td><td>001011</td><td>rs</td><td>rd</td><td>im</td><td>rd=(rs&lt;im)?1:0（无符号数）</td></tr></tbody></table></div><h3 id="逻辑类指令-1"><a href="#逻辑类指令-1" class="headerlink" title="逻辑类指令"></a>逻辑类指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rd</th><th>im</th><th>功能</th></tr></thead><tbody><tr><td>andi</td><td>001100</td><td>rs</td><td>rd</td><td>im</td><td>rd=rs&amp;im</td></tr><tr><td>ori</td><td>001101</td><td>rs</td><td>rd</td><td>im</td><td>rd=rs\</td><td>im</td></tr><tr><td>xori</td><td>001110</td><td>rs</td><td>rd</td><td>im</td><td>rd=rs xor im</td></tr></tbody></table></div><h3 id="载入类指令"><a href="#载入类指令" class="headerlink" title="载入类指令"></a>载入类指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rd</th><th>im</th><th>功能</th></tr></thead><tbody><tr><td>lui</td><td>001111</td><td>00000</td><td>rd</td><td>im</td><td>rt=im*65536</td></tr><tr><td>lw</td><td>100011</td><td>rs</td><td>rd</td><td>im</td><td>rt=memory[rs+im]</td></tr><tr><td>sw</td><td>101011</td><td>rs</td><td>rd</td><td>im</td><td>memory[rs+im]=rt</td></tr></tbody></table></div><h3 id="跳转类指令"><a href="#跳转类指令" class="headerlink" title="跳转类指令"></a>跳转类指令</h3><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>rs</th><th>rd</th><th>im</th><th>功能</th></tr></thead><tbody><tr><td>beq</td><td>000100</td><td>rs</td><td>rd</td><td>im</td><td>PC=(rs==rt)?PC+4+im&lt;&lt;2:PC</td></tr><tr><td>bne</td><td>000101</td><td>rs</td><td>rd</td><td>im</td><td>PC=(rs!=rt)?PC+4+im&lt;&lt;2:PC</td></tr></tbody></table></div><h1 id="J格式指令"><a href="#J格式指令" class="headerlink" title="J格式指令"></a>J格式指令</h1><h2 id="基本格式-2"><a href="#基本格式-2" class="headerlink" title="基本格式"></a>基本格式</h2><div class="table-container"><table><thead><tr><th>标记</th><th>op</th><th>address</th></tr></thead><tbody><tr><td>位数</td><td>31-26</td><td>25-0</td></tr><tr><td>功能</td><td>操作符</td><td>地址</td></tr></tbody></table></div><h2 id="指令-2"><a href="#指令-2" class="headerlink" title="指令"></a>指令</h2><div class="table-container"><table><thead><tr><th>指令</th><th>op</th><th>address</th><th>功能</th></tr></thead><tbody><tr><td>j</td><td>000010</td><td>addr</td><td>PC={(PC+4)[31,28],addr,00}</td></tr><tr><td>jal</td><td>000011</td><td>addr</td><td>$31=PC;PC={(PC+4)[31,28],addr,00}</td></tr></tbody></table></div><h1 id="指令分析"><a href="#指令分析" class="headerlink" title="指令分析"></a>指令分析</h1><h2 id="指令格式"><a href="#指令格式" class="headerlink" title="指令格式"></a>指令格式</h2><img src="/2018/02/18/MIPS%E6%8C%87%E4%BB%A4%E9%9B%86%E4%B8%8E%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90/MIPS_order.png" class=""><p>不同格式的指令具有不同的功能，其中：</p><ul><li>R格式指令为纯寄存器指令，所有的操作数（除移位外）均保存在寄存器中。Op字段均为0，使用funct字段区分指令</li><li>I格式指令为带立即数的指令，最多使用两个寄存器，同时包括了load/store指令。使用Op字段区分指令</li><li>J格式指令为长跳转指令，仅有一个立即数操作数。使用Op字段区分指令</li></ul><h2 id="数据通路"><a href="#数据通路" class="headerlink" title="数据通路"></a>数据通路</h2><p>以上的指令包括以下几种与指令有关的数据通路：</p><ul><li>指令——寄存器组：R格式指令均为寄存器指令，需要指令提供寄存器地址</li><li>指令——运算单元（ALU）：运算指令由指令提供运算类型，同时提供参与运算的立即数和位移量</li><li>指令——存储器：load/store指令的寻址方式仅为寄存器偏移量寻址，需要指令提供立即数偏移量</li><li>指令——PC：J格式指令需要将指令中的立即数载入PC中</li></ul><p>同时还有几种必备的与指令无关的数据通路：</p><ul><li>寄存器组——运算单元（ALU）：寄存器组为运算单元提供操作数，运算结果存在寄存器组中</li><li>寄存器组——存储器：load/store指令的两端</li><li>寄存器组——PC：跳转指令与寄存器组有关</li></ul><p>当使用哈弗结构时，数据通路框图如下所示：</p><img src="/2018/02/18/MIPS%E6%8C%87%E4%BB%A4%E9%9B%86%E4%B8%8E%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90/MIPS_dataflow.png" class=""><h2 id="流水线划分"><a href="#流水线划分" class="headerlink" title="流水线划分"></a>流水线划分</h2><p>若使用流水线实现，可以将流水线划分为：取指-&gt;译码-&gt;准备操作数-&gt;执行-&gt;回写四个阶段：</p><ul><li>取指阶段：按PC从指令寄存器中取出完整的32位指令，之后PC自增</li><li>译码阶段：按指令的高6位（Op字段）将指令解释为相应的格式</li><li>准备操作数阶段：按指令中的对应字段准备操作数，包括：计算地址（load/store指令），取出寄存器中的操作数置于数据总线（寄存器指令），计算PC值（跳转指令）等</li><li>执行阶段：执行指令，包括：访问存储器（load/store指令），ALU运算（计算类指令），刷新PC值（跳转指令）等</li><li>回写阶段：将结果存入寄存器中，包括：ALU的运算结果（计算类指令），访存结果（load指令），原PC值（带返回跳转指令）等</li></ul>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> MIPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于MXnet的RNN简要剖析</title>
      <link href="2018/01/31/%E5%9F%BA%E4%BA%8EMXnet%E7%9A%84RNN%E7%AE%80%E8%A6%81%E5%89%96%E6%9E%90/"/>
      <url>2018/01/31/%E5%9F%BA%E4%BA%8EMXnet%E7%9A%84RNN%E7%AE%80%E8%A6%81%E5%89%96%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import mxnet as mx</span><br></pre></td></tr></table></figure><h1 id="官方github教程部分代码"><a href="#官方github教程部分代码" class="headerlink" title="官方github教程部分代码"></a>官方github教程部分代码</h1><h2 id="网络生成"><a href="#网络生成" class="headerlink" title="网络生成"></a>网络生成</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">num_layers = <span class="number">2</span></span><br><span class="line">num_hidden = <span class="number">256</span></span><br><span class="line">stack = mx.rnn.SequentialRNNCell()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">    stack.add(mx.rnn.LSTMCell(num_hidden=num_hidden, prefix=<span class="string">&#x27;lstm_l%d_&#x27;</span>%i))</span><br></pre></td></tr></table></figure><ul><li><code>mx.rnn.SequentialRNNCell()</code>:RNN容器，用于组合多个RNN层</li><li><code>mx.rnn.LSTMCell(num_hidden=num_hidden, prefix=&#39;lstm_l%d_&#39;%i)</code>:LSTM单元</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">num_embed = <span class="number">256</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sym_gen</span>(<span class="params">seq_len</span>):</span></span><br><span class="line">    data = mx.sym.Variable(<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">    label = mx.sym.Variable(<span class="string">&#x27;softmax_label&#x27;</span>)</span><br><span class="line">    embed = mx.sym.Embedding(data=data, input_dim=<span class="number">1000</span>,output_dim=num_embed, name=<span class="string">&#x27;embed&#x27;</span>)</span><br><span class="line"><span class="comment">#   数据生成，定义Variable并进行词向量化</span></span><br><span class="line"></span><br><span class="line">    stack.reset()</span><br><span class="line">    outputs, states = stack.unroll(seq_len, inputs=embed, merge_outputs=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#   按时间展开输出和状态</span></span><br><span class="line">    </span><br><span class="line">    pred = mx.sym.Reshape(outputs, shape=(-<span class="number">1</span>, num_hidden))</span><br><span class="line">    pred = mx.sym.FullyConnected(data=pred, num_hidden=<span class="number">1000</span>, name=<span class="string">&#x27;pred&#x27;</span>)</span><br><span class="line"><span class="comment">#   变换输出形式，将输出变为(-1,num_hidden)尺寸</span></span><br><span class="line"></span><br><span class="line">    label = mx.sym.Reshape(label, shape=(-<span class="number">1</span>,))</span><br><span class="line">    pred = mx.sym.SoftmaxOutput(data=pred, label=label, name=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"><span class="comment">#   展平label，并计算代价函数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> pred, (<span class="string">&#x27;data&#x27;</span>,), (<span class="string">&#x27;softmax_label&#x27;</span>,)</span><br><span class="line">sym_gen(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>(&lt;Symbol softmax&gt;, (&#39;data&#39;,), (&#39;softmax_label&#39;,))</code></pre><ul><li><code>unroll()</code>函数按时间展开RNN单元，输出最终的运算结果</li><li>输出接全连接层，再转换为词向量</li></ul><h2 id="官方API文档代码"><a href="#官方API文档代码" class="headerlink" title="官方API文档代码"></a>官方API文档代码</h2><h3 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">step_input = mx.symbol.Variable(<span class="string">&#x27;step_data&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># First we embed our raw input data to be used as LSTM&#x27;s input.</span></span><br><span class="line">embedded_step = mx.symbol.Embedding(data=step_input, \</span><br><span class="line">                                    input_dim=<span class="number">50</span>, \</span><br><span class="line">                                    output_dim=<span class="number">50</span>)</span><br><span class="line"><span class="comment"># print(embedded_step.shape)</span></span><br><span class="line">mx.viz.plot_network(symbol=embedded_step)</span><br><span class="line"><span class="comment"># Then we create an LSTM cell.</span></span><br></pre></td></tr></table></figure><img src="/2018/01/31/%E5%9F%BA%E4%BA%8EMXnet%E7%9A%84RNN%E7%AE%80%E8%A6%81%E5%89%96%E6%9E%90/output_7_0.png" class=""><p><code>Embedding</code>是一种词向量化技术，这种技术可以保持语义（例如相近语义的词的向量距离会较近），将尺寸为(d0,d1…dn)的输入向量进行词向量化技术后转换为尺寸为(d0,d1,…,dn,out_dim)的向量，多出的一维为词向量，即使用一个向量代替原来一个词的位置。</p><ul><li>参数input_dim为输入向量的范围，即输入data的范围在[0,input_dim)之间</li><li>参数output_dim为词向量大小</li><li>可选参数weight，可传入指定的词向量字典</li><li>可选参数name，可传入名称</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vocabulary_size = <span class="number">26</span></span><br><span class="line">embed_dim = <span class="number">16</span></span><br><span class="line">seq_len, batch_size = (<span class="number">10</span>, <span class="number">64</span>)</span><br><span class="line"><span class="built_in">input</span> = mx.sym.Variable(<span class="string">&#x27;letters&#x27;</span>)</span><br><span class="line">op = mx.sym.Embedding(data=<span class="built_in">input</span>, input_dim=vocabulary_size, output_dim=embed_dim,name=<span class="string">&#x27;embed&#x27;</span>)</span><br><span class="line">op.infer_shape(letters=(seq_len, batch_size))</span><br></pre></td></tr></table></figure><pre><code>([(10, 64), (26, 16)], [(10, 64, 16)], [])</code></pre><p>上文的例子可以看出输入向量尺寸为（10,64）,输出向量尺寸变为了（10,64,16）</p><h3 id="网络构建"><a href="#网络构建" class="headerlink" title="网络构建"></a>网络构建</h3><p>使用了隐层为50的LSTM单元，并带入转换好的数据，该图绘制出的lstm图较经典LSTM有一些出入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lstm_cell = mx.rnn.LSTMCell(num_hidden=<span class="number">50</span>)</span><br><span class="line">begin_state = lstm_cell.begin_state()</span><br><span class="line">output, states = lstm_cell(embedded_step, begin_state)</span><br><span class="line">mx.viz.plot_network(symbol=output)</span><br></pre></td></tr></table></figure><img src="/2018/01/31/%E5%9F%BA%E4%BA%8EMXnet%E7%9A%84RNN%E7%AE%80%E8%A6%81%E5%89%96%E6%9E%90/output_11_0.png" class=""><p>LSTM的源码的构造函数如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_hidden, prefix=<span class="string">&#x27;lstm_&#x27;</span>, params=<span class="literal">None</span>, forget_bias=<span class="number">1.0</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LSTMCell, self).__init__(prefix=prefix, params=params)</span><br><span class="line"></span><br><span class="line">        self._num_hidden = num_hidden</span><br><span class="line">        self._iW = self.params.get(<span class="string">&#x27;i2h_weight&#x27;</span>)</span><br><span class="line">        self._hW = self.params.get(<span class="string">&#x27;h2h_weight&#x27;</span>)</span><br><span class="line">        <span class="comment"># we add the forget_bias to i2h_bias, this adds the bias to the forget gate activation</span></span><br><span class="line">        self._iB = self.params.get(<span class="string">&#x27;i2h_bias&#x27;</span>, init=init.LSTMBias(forget_bias=forget_bias))</span><br><span class="line">        self._hB = self.params.get(<span class="string">&#x27;h2h_bias&#x27;</span>)</span><br></pre></td></tr></table></figure><br>其中：<code>self.params.get()</code>方法为尝试找到传入名称对应的Variable，若找不到则新建，因此该LSTM单元一共仅有两对参数：iW和iB，hW和hB</p><p>前向传播函数如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, inputs, states</span>):</span></span><br><span class="line">    self._counter += <span class="number">1</span></span><br><span class="line">    name = <span class="string">&#x27;%st%d_&#x27;</span>%(self._prefix, self._counter)</span><br><span class="line">    i2h = symbol.FullyConnected(data=inputs, weight=self._iW, bias=self._iB,</span><br><span class="line">                                num_hidden=self._num_hidden*<span class="number">4</span>,</span><br><span class="line">                                name=<span class="string">&#x27;%si2h&#x27;</span>%name)</span><br><span class="line">    h2h = symbol.FullyConnected(data=states[<span class="number">0</span>], weight=self._hW, bias=self._hB,</span><br><span class="line">                                num_hidden=self._num_hidden*<span class="number">4</span>,</span><br><span class="line">                                name=<span class="string">&#x27;%sh2h&#x27;</span>%name)</span><br><span class="line">    gates = i2h + h2h</span><br><span class="line">    slice_gates = symbol.SliceChannel(gates, num_outputs=<span class="number">4</span>,name=<span class="string">&quot;%sslice&quot;</span>%name)</span><br><span class="line">    in_gate = symbol.Activation(slice_gates[<span class="number">0</span>], act_type=<span class="string">&quot;sigmoid&quot;</span>,name=<span class="string">&#x27;%si&#x27;</span>%name)</span><br><span class="line">    forget_gate = symbol.Activation(slice_gates[<span class="number">1</span>], act_type=<span class="string">&quot;sigmoid&quot;</span>,name=<span class="string">&#x27;%sf&#x27;</span>%name)</span><br><span class="line">    in_transform = symbol.Activation(slice_gates[<span class="number">2</span>], act_type=<span class="string">&quot;tanh&quot;</span>,name=<span class="string">&#x27;%sc&#x27;</span>%name)</span><br><span class="line">    out_gate = symbol.Activation(slice_gates[<span class="number">3</span>], act_type=<span class="string">&quot;sigmoid&quot;</span>,name=<span class="string">&#x27;%so&#x27;</span>%name)</span><br><span class="line">    next_c = symbol._internal._plus(forget_gate * states[<span class="number">1</span>], in_gate * in_transform,name=<span class="string">&#x27;%sstate&#x27;</span>%name)</span><br><span class="line">    next_h = symbol._internal._mul(out_gate, symbol.Activation(next_c, act_type=<span class="string">&quot;tanh&quot;</span>),name=<span class="string">&#x27;%sout&#x27;</span>%name)</span><br><span class="line">    <span class="keyword">return</span> next_h, [next_h, next_c]</span><br></pre></td></tr></table></figure><br>可以看出，LSTM的实现过程如下所示</p><ol><li>计算隐层输入与状态，隐层的channel数量是配置的hidden_num的四倍</li><li>将隐层输入结果和隐层状态相加，并按channel数量切分为4份<ul><li>第一份作为输入门层，经过sigmoid函数</li><li>第二份作为忘记门层，经过sigmoid函数</li><li>第三份作为输入转换层，经过tanh函数</li><li>第四份作为输出门层，经过sigmoid函数</li></ul></li><li>产生输出<ul><li>输出状态为忘记门层乘状态的一部分加输入门层乘输入转换层</li><li>输出结果为输出状态经过tanh乘输出门层</li></ul></li></ol><h3 id="结果生成"><a href="#结果生成" class="headerlink" title="结果生成"></a>结果生成</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sequence_length = <span class="number">10</span></span><br><span class="line">input_dim = <span class="number">10</span></span><br><span class="line">seq_input = mx.symbol.Variable(<span class="string">&#x27;seq_data&#x27;</span>)</span><br><span class="line">embedded_seq = mx.symbol.Embedding(data=seq_input, \</span><br><span class="line">                                   input_dim=input_dim, \</span><br><span class="line">                                   output_dim=embed_dim)</span><br><span class="line">outputs, states = lstm_cell.unroll(length=sequence_length, \</span><br><span class="line">                                   inputs=embedded_seq, \</span><br><span class="line">                                   layout=<span class="string">&#x27;NTC&#x27;</span>, \</span><br><span class="line">                                   merge_outputs=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>使用<code>unroll</code>方法按时间展平运算，输入数据为(batch_size,lenght,…)（layout=”NTC）或(lenght,batch,…)(layout=”TNC)</p><p>该函数的源码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unroll</span>(<span class="params">self, length, inputs, begin_state=<span class="literal">None</span>, layout=<span class="string">&#x27;NTC&#x27;</span>, merge_outputs=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.reset()</span><br><span class="line"></span><br><span class="line">        inputs, _ = _normalize_sequence(length, inputs, layout, <span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> begin_state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            begin_state = self.begin_state()</span><br><span class="line">        states = begin_state</span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">            output, states = self(inputs[i], states)</span><br><span class="line">            outputs.append(output)</span><br><span class="line">        outputs, _ = _normalize_sequence(length, outputs, layout, merge_outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs, states</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>方法<code>_normalize_sequence</code>是对输入做一些处理，由一个for循环可以看出该方法循环了网络运算</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于巧克力数据集的数据分析</title>
      <link href="2018/01/25/%E5%85%B3%E4%BA%8E%E5%B7%A7%E5%85%8B%E5%8A%9B%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>2018/01/25/%E5%85%B3%E4%BA%8E%E5%B7%A7%E5%85%8B%E5%8A%9B%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><h1 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = pd.read_csv(<span class="string">&quot;./flavors_of_cacao.csv&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset.columns = dataset.columns.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.replace(<span class="string">&quot;\n&quot;</span>,<span class="string">&quot; &quot;</span>))</span><br><span class="line">dataset.columns = dataset.columns.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.replace(<span class="string">&quot;\xa0&quot;</span>,<span class="string">&quot;&quot;</span>))</span><br><span class="line">dataset.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1795 entries, 0 to 1794Data columns (total 9 columns):Company (Maker-if known)            1795 non-null objectSpecific Bean Origin or Bar Name    1795 non-null objectREF                                 1795 non-null int64Review Date                         1795 non-null int64Cocoa Percent                       1795 non-null objectCompany Location                    1795 non-null objectRating                              1795 non-null float64Bean Type                           1794 non-null objectBroad Bean Origin                   1794 non-null objectdtypes: float64(1), int64(2), object(6)memory usage: 126.3+ KB</code></pre><p>每个列的含义如下：</p><ul><li>Company：生产公司</li><li>Specific Bean Origin or Bar Name：产品名称</li><li>REF：不祥</li><li>Review Date：</li><li>Cocoa Percent：可可含量</li><li>Company Location：公司地址</li><li>Rating：等级</li><li>Bean Type：可可豆类型</li><li>Broad Bean Origin：原产地</li></ul><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="缺失值丢弃"><a href="#缺失值丢弃" class="headerlink" title="缺失值丢弃"></a>缺失值丢弃</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset_nona = dataset.dropna()</span><br><span class="line">dataset_nona = dataset_nona.drop([<span class="string">&quot;REF&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">dataset_nona.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 1793 entries, 0 to 1794Data columns (total 8 columns):Company (Maker-if known)            1793 non-null objectSpecific Bean Origin or Bar Name    1793 non-null objectReview Date                         1793 non-null int64Cocoa Percent                       1793 non-null objectCompany Location                    1793 non-null objectRating                              1793 non-null float64Bean Type                           1793 non-null objectBroad Bean Origin                   1793 non-null objectdtypes: float64(1), int64(1), object(6)memory usage: 126.1+ KB</code></pre><h2 id="百分比转换"><a href="#百分比转换" class="headerlink" title="百分比转换"></a>百分比转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset_nona[<span class="string">&quot;Cocoa Percent&quot;</span>] = dataset_nona[<span class="string">&quot;Cocoa Percent&quot;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x:<span class="built_in">float</span>(x.strip(<span class="string">&#x27;%&#x27;</span>)) / <span class="number">100</span>)</span><br><span class="line">dataset_nona.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 1793 entries, 0 to 1794Data columns (total 8 columns):Company (Maker-if known)            1793 non-null objectSpecific Bean Origin or Bar Name    1793 non-null objectReview Date                         1793 non-null int64Cocoa Percent                       1793 non-null float64Company Location                    1793 non-null objectRating                              1793 non-null float64Bean Type                           1793 non-null objectBroad Bean Origin                   1793 non-null objectdtypes: float64(2), int64(1), object(5)memory usage: 126.1+ KB</code></pre><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><h2 id="Where-are-the-best-cocoa-beans-grown"><a href="#Where-are-the-best-cocoa-beans-grown" class="headerlink" title="Where are the best cocoa beans grown?"></a>Where are the best cocoa beans grown?</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_been = dataset_nona[[<span class="string">&quot;Broad Bean Origin&quot;</span>,<span class="string">&quot;Rating&quot;</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">best_been_data = best_been.groupby([<span class="string">&quot;Broad Bean Origin&quot;</span>]).apply(np.mean)</span><br><span class="line">best_been_data.sort_values(by=<span class="string">&quot;Rating&quot;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">print(best_been_data[-<span class="number">10</span>:])</span><br></pre></td></tr></table></figure><pre><code>                              RatingBroad Bean Origin                   Dominican Rep., Bali            3.75Peru, Belize                    3.75Ven.,Ecu.,Peru,Nic.             3.75DR, Ecuador, Peru               3.75Venez,Africa,Brasil,Peru,Mex    3.75Dom. Rep., Madagascar           4.00Venezuela, Java                 4.00Gre., PNG, Haw., Haiti, Mad     4.00Guat., D.R., Peru, Mad., PNG    4.00Peru, Dom. Rep                  4.00</code></pre><p>可看出最好的可可豆生长在秘鲁的Dom. Rep，危地马拉的D.R., Peru, Mad., PNG等地</p><h2 id="Which-countries-produce-the-highest-rated-bars"><a href="#Which-countries-produce-the-highest-rated-bars" class="headerlink" title="Which countries produce the highest-rated bars?"></a>Which countries produce the highest-rated bars?</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">best_country = dataset_nona[[<span class="string">&quot;Company Location&quot;</span>,<span class="string">&quot;Rating&quot;</span>]]</span><br><span class="line">best_country.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 1793 entries, 0 to 1794Data columns (total 2 columns):Company Location    1793 non-null objectRating              1793 non-null float64dtypes: float64(1), object(1)memory usage: 42.0+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">best_country_data = best_country.groupby([<span class="string">&quot;Company Location&quot;</span>]).apply(np.mean)</span><br><span class="line">best_country_data.sort_values(by=[<span class="string">&quot;Rating&quot;</span>],inplace=<span class="literal">True</span>)</span><br><span class="line">print(best_country_data[-<span class="number">10</span>:])</span><br></pre></td></tr></table></figure><pre><code>                    RatingCompany Location          Guatemala         3.350000Australia         3.357143Poland            3.375000Brazil            3.397059Vietnam           3.409091Iceland           3.416667Philippines       3.500000Netherlands       3.500000Amsterdam         3.500000Chile             3.750000</code></pre><p>可以看出生产出巧克力较好的是智利，荷兰等地</p><h2 id="what’s-the-relationship-between-cocoa-solids-percentage-and-rating"><a href="#what’s-the-relationship-between-cocoa-solids-percentage-and-rating" class="headerlink" title="what’s the relationship between cocoa solids percentage and rating?"></a>what’s the relationship between cocoa solids percentage and rating?</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">best_coco = dataset_nona[[<span class="string">&quot;Cocoa Percent&quot;</span>,<span class="string">&quot;Rating&quot;</span>]]</span><br><span class="line">best_coco.columns = best_coco.columns.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.replace(<span class="string">&quot; &quot;</span>,<span class="string">&quot;&quot;</span>))</span><br><span class="line">best_coco.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 1793 entries, 0 to 1794Data columns (total 2 columns):CocoaPercent    1793 non-null float64Rating          1793 non-null float64dtypes: float64(2)memory usage: 42.0 KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(best_coco.corr())</span><br></pre></td></tr></table></figure><pre><code>              CocoaPercent    RatingCocoaPercent      1.000000 -0.164758Rating           -0.164758  1.000000</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.close()</span><br><span class="line"><span class="comment"># print(best_coco[&quot;CocoaPercent&quot;])</span></span><br><span class="line">plt.scatter(best_coco[<span class="string">&quot;CocoaPercent&quot;</span>].values,best_coco[<span class="string">&quot;Rating&quot;</span>].values)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2018/01/25/%E5%85%B3%E4%BA%8E%E5%B7%A7%E5%85%8B%E5%8A%9B%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/output_20_0.png" class=""><p>可以看出巧克力质量和含可可量没有明显的关系</p><h1 id="探索分析"><a href="#探索分析" class="headerlink" title="探索分析"></a>探索分析</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(dataset_nona.groupby([<span class="string">&quot;Review Date&quot;</span>]).apply(<span class="keyword">lambda</span> x:x[<span class="string">&quot;Rating&quot;</span>].<span class="built_in">sum</span>() / x.shape[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>Review Date2006    3.1250002007    3.1623382008    2.9946242009    3.0731712010    3.1486492011    3.2515242012    3.1817012013    3.1970112014    3.1892712015    3.2464912016    3.2260272017    3.312500dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">coco_type = dataset_nona[[<span class="string">&quot;Bean Type&quot;</span>,<span class="string">&quot;Rating&quot;</span>]]</span><br><span class="line">coco_type = coco_type.groupby([<span class="string">&quot;Bean Type&quot;</span>]).apply(np.mean)</span><br><span class="line">print(coco_type.sort_values(by=<span class="string">&quot;Rating&quot;</span>)[-<span class="number">10</span>:])</span><br></pre></td></tr></table></figure><pre><code>                          RatingBean Type                       Amazon, ICS                3.625Criollo (Ocumare 77)       3.750Trinitario, TCGA           3.750Blend-Forastero,Criollo    3.750Amazon mix                 3.750Trinitario, Nacional       3.750Forastero (Amelonado)      3.750Trinitario (85% Criollo)   3.875Criollo (Wild)             4.000Criollo (Ocumare 67)       4.000</code></pre><p>最好的可可豆是Criollo</p>]]></content>
      
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开放地址法散列</title>
      <link href="2018/01/23/%E5%BC%80%E6%94%BE%E5%9C%B0%E5%9D%80%E6%B3%95%E6%95%A3%E5%88%97/"/>
      <url>2018/01/23/%E5%BC%80%E6%94%BE%E5%9C%B0%E5%9D%80%E6%B3%95%E6%95%A3%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h1 id="开放地址法"><a href="#开放地址法" class="headerlink" title="开放地址法"></a>开放地址法</h1><p>开放地址法是另一种（相对于分离链接法）解决散列冲突的方法。适用于装填因子（散列表中元素个数和散列表长度比）较小（小于0.5）的散列表。</p><p>开放地址法中索引的计算方法为<script type="math/tex">h_{i}(x) = (Hash(X) + F(i)) \% TableSize</script>，其中：</p><ul><li>Hash(x)为索引的计算方法</li><li>F(i)为冲突的解决函数，有F(0) = 0，i为已经尝试计算索引的次数</li></ul><p>F(i)一般有：</p><ul><li>线性探测法：<script type="math/tex">F(i) = i</script>，即每次冲突则向下寻找1个位置，直到找到不冲突的位置，容易产生“一次聚集”的现象（数据集中在某一个地址区域）</li><li>平方探测法：<script type="math/tex">F(i)=i^{2}</script>，每次冲突按平方寻找下一个位置，直到找到不冲突的位置</li><li>双散列：<script type="math/tex">F(i) = i\cdot hash_{2}(x)</script>，即发生冲突后使用第二个散列函数计算下一个位置</li></ul><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 节点数据</span></span><br><span class="line"><span class="keyword">type</span> tableData <span class="keyword">struct</span> &#123;</span><br><span class="line">data <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 节点</span></span><br><span class="line"><span class="keyword">type</span> tableNode <span class="keyword">struct</span> &#123;</span><br><span class="line">flag <span class="keyword">bool</span><span class="comment">//是否已经插入数据，用于冲突检测</span></span><br><span class="line">key  <span class="keyword">string</span><span class="comment">//关键字</span></span><br><span class="line">data tableData<span class="comment">//节点数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newTableNode</span><span class="params">(key <span class="keyword">string</span>, data tableData)</span> *<span class="title">tableNode</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;tableNode&#123;<span class="literal">false</span>, key, data&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h2><h3 id="结构体-1"><a href="#结构体-1" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hashTable <span class="keyword">struct</span> &#123;</span><br><span class="line">table  [<span class="number">17</span>]tableNode</span><br><span class="line">length <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="计算散列值"><a href="#计算散列值" class="headerlink" title="计算散列值"></a>计算散列值</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *hashTable)</span> <span class="title">hashCompute</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">hash := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> key &#123;</span><br><span class="line">hash = hash + <span class="keyword">int</span>(key[i])*<span class="number">32</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> hash % h.length</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="插入方法"><a href="#插入方法" class="headerlink" title="插入方法"></a>插入方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *hashTable)</span> <span class="title">insert</span><span class="params">(key <span class="keyword">string</span>, data tableData)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">hash, i := h.hashCompute(key), <span class="number">0</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">// 若发生冲突，则搜索下一个位置 </span></span><br><span class="line"><span class="keyword">for</span> i = <span class="number">0</span>; h.table[(i+hash)%h.length].flag != <span class="literal">false</span> &amp;&amp; h.table[(i+hash)%h.length].key != key; i++ &#123;</span><br><span class="line"><span class="keyword">if</span> i == h.length &#123;</span><br><span class="line"><span class="comment">// 若找不到，则表满，返回错误</span></span><br><span class="line"><span class="keyword">return</span> errors.New(<span class="string">&quot;table full&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">hash = (i + hash) % h.length</span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入数据</span></span><br><span class="line">h.table[hash].data = data</span><br><span class="line">h.table[hash].flag = <span class="literal">true</span></span><br><span class="line">h.table[hash].key = key</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="访问方法"><a href="#访问方法" class="headerlink" title="访问方法"></a>访问方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *hashTable)</span> <span class="title">visit</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="params">(tableData, error)</span></span> &#123;</span><br><span class="line">hash := h.hashCompute(key)</span><br><span class="line"><span class="keyword">for</span> index := <span class="number">0</span>; h.table[(index+hash)%h.length].flag == <span class="literal">true</span>; index++ &#123;</span><br><span class="line"><span class="keyword">if</span> h.table[(index+hash)%h.length].key == key &#123;</span><br><span class="line"><span class="keyword">return</span> h.table[(index+hash)%h.length].data, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> tableData&#123;&#125;, errors.New(<span class="string">&quot;not find&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数-1"><a href="#构造函数-1" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newHashTable</span><span class="params">()</span> *<span class="title">hashTable</span></span> &#123;</span><br><span class="line">data := &amp;hashTable&#123;&#125;</span><br><span class="line">data.length = <span class="number">17</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> data.table &#123;</span><br><span class="line">data.table[i] = *newTableNode(<span class="string">&quot;&quot;</span>, tableData&#123;&#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> data</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>流水线乘加树</title>
      <link href="2018/01/21/%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B9%98%E5%8A%A0%E6%A0%91/"/>
      <url>2018/01/21/%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B9%98%E5%8A%A0%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ul><li>计算两个长度为2的幂次方的向量的对应位置相乘相加结果</li><li>输入为补码，输出为补码（支持负数）</li><li>输入位宽可配置，输入向量的宽度可配置，输出位宽由以上两项决定</li></ul><h1 id="设计规划"><a href="#设计规划" class="headerlink" title="设计规划"></a>设计规划</h1><h2 id="参数表"><a href="#参数表" class="headerlink" title="参数表"></a>参数表</h2><div class="table-container"><table><thead><tr><th>参数名称</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>DIN_WIDTH</td><td>输入位宽</td><td>8</td></tr><tr><td>DIN_NUM_LOG</td><td>输入向量的宽度的log2值（宽度<script type="math/tex">2^{DIN\_NUM\_LOG}</script>）</td><td>2</td></tr></tbody></table></div><p>注：输出位宽由以上决定，为<script type="math/tex">DOUT\_WIDTH = DIN\_WIDTH \times 2 + DIN\_NUM\_LOG - 1</script></p><h2 id="端口列表"><a href="#端口列表" class="headerlink" title="端口列表"></a>端口列表</h2><div class="table-container"><table><thead><tr><th>端口名</th><th>类型</th><th>位宽</th><th>说明</th></tr></thead><tbody><tr><td>clk</td><td>input</td><td>1</td><td>系统时钟</td></tr><tr><td>rst_n</td><td>input</td><td>1</td><td>系统复位</td></tr><tr><td>din_valid</td><td>input</td><td>1</td><td>输入数据有效，高有效</td></tr><tr><td>mla_din1</td><td>input</td><td>(2 <em>* DIN_NUM_LOG) </em> DIN_WIDTH</td><td>输入向量1</td></tr><tr><td>mla_din2</td><td>input</td><td>(2 <em>* DIN_NUM_LOG) </em> DIN_WIDTH</td><td>输入向量2</td></tr><tr><td>dout_valid</td><td>output</td><td>1</td><td>输出信号有效，高有效</td></tr><tr><td>mla_dout</td><td>output</td><td>DIN_WIDTH * 2 + DIN_NUM_LOG - 1</td><td>输出结果</td></tr></tbody></table></div><h2 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h2><h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><p>$mla_dout = \sum_{i = 0}^{2^{DIN_NUM_LOG}} mla_din1[i] \times mla_din2[i] $</p><p>其中，mla_din1[i]和mla_din2[i]按位宽存储在输入mla_din1和mla_din2，每个均为补码中，如图：</p><img src="/2018/01/21/%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B9%98%E5%8A%A0%E6%A0%91/mla_din.png" class=""><h3 id="时序"><a href="#时序" class="headerlink" title="时序"></a>时序</h3><ul><li>当输入有效din_valid有效时，开始计算；当dout_valid有效时，结果有效。</li><li>设计为流水线式，输入可以连续送入，输出可以连续输出，输出具有保序性。</li><li>输入有效到输出有效的间隔由DIN_NUM_LOG决定</li></ul><img src="/2018/01/21/%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B9%98%E5%8A%A0%E6%A0%91/in_out_timing.png" class=""><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>以DIN_NUM_LOG=2为例：</p><img src="/2018/01/21/%E6%B5%81%E6%B0%B4%E7%BA%BF%E4%B9%98%E5%8A%A0%E6%A0%91/structure.png" class=""><ul><li>输入的mla_din在内部被分解并对应相乘</li><li>使用每层带寄存器的加法树实现累加</li><li>有效信号随对应数据流动</li></ul><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="RTL设计"><a href="#RTL设计" class="headerlink" title="RTL设计"></a>RTL设计</h2><h3 id="module声明"><a href="#module声明" class="headerlink" title="module声明"></a>module声明</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> mla_tree #(</span><br><span class="line">    <span class="keyword">parameter</span> DIN_WIDTH = <span class="number">8</span>,</span><br><span class="line">    <span class="keyword">parameter</span> DIN_NUM_LOG = <span class="number">2</span></span><br><span class="line">)(</span><br><span class="line">    <span class="keyword">input</span> clk,</span><br><span class="line">    <span class="keyword">input</span> rst_n,</span><br><span class="line"></span><br><span class="line">    <span class="keyword">input</span> din_valid,</span><br><span class="line">    <span class="keyword">input</span> [(<span class="number">2</span> ** DIN_NUM_LOG) * DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>]mla_din1,</span><br><span class="line">    <span class="keyword">input</span> [(<span class="number">2</span> ** DIN_NUM_LOG) * DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>]mla_din2,</span><br><span class="line"></span><br><span class="line">    <span class="keyword">output</span> dout_valid,</span><br><span class="line">    <span class="keyword">output</span> [DIN_WIDTH * <span class="number">2</span> + DIN_NUM_LOG - <span class="number">2</span>:<span class="number">0</span>]mla_dout</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="解码输入"><a href="#解码输入" class="headerlink" title="解码输入"></a>解码输入</h3><ul><li>将输入的向量解码进入数组，方便代码编写</li><li>处理输入数据，将补码形式转为“符号位-原码”表示，便于使用无符号乘法器</li><li>din_valid随数据流动，产生unpack_valid</li></ul><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>]din1_unpack[<span class="number">2</span> ** DIN_NUM_LOG - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">reg</span> [DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>]din2_unpack[<span class="number">2</span> ** DIN_NUM_LOG - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">integer</span> j;</span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span> (~rst_n) <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; <span class="number">2</span> ** DIN_NUM_LOG ; j = j + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">            din1_unpack[j] &lt;= <span class="number">&#x27;b0</span>; </span><br><span class="line">            din2_unpack[j] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span> (din_valid)<span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; <span class="number">2</span> ** DIN_NUM_LOG ; j = j + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">            din1_unpack[j][DIN_WIDTH - <span class="number">1</span>] &lt;= mla_din1[DIN_WIDTH * (j + <span class="number">1</span>) - <span class="number">1</span>];</span><br><span class="line">            din1_unpack[j][DIN_WIDTH - <span class="number">2</span>:<span class="number">0</span>] &lt;= (mla_din1[DIN_WIDTH * (j + <span class="number">1</span>) - <span class="number">1</span>])?(~mla_din1[DIN_WIDTH * j +:DIN_WIDTH - <span class="number">1</span>]+<span class="number">1&#x27;b1</span>):mla_din1[DIN_WIDTH * j +:DIN_WIDTH - <span class="number">1</span>];</span><br><span class="line">            din2_unpack[j][DIN_WIDTH - <span class="number">1</span>] &lt;= mla_din2[DIN_WIDTH * (j + <span class="number">1</span>) - <span class="number">1</span>];</span><br><span class="line">            din2_unpack[j][DIN_WIDTH - <span class="number">2</span>:<span class="number">0</span>] &lt;= (mla_din2[DIN_WIDTH * (j + <span class="number">1</span>) - <span class="number">1</span>])?(~mla_din2[DIN_WIDTH * j +:DIN_WIDTH - <span class="number">1</span>]+<span class="number">1&#x27;b1</span>):mla_din2[DIN_WIDTH * j +:DIN_WIDTH - <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> unpack_valid;</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span> (~rst_n) <span class="keyword">begin</span></span><br><span class="line">        unpack_valid &lt;= <span class="number">&#x27;b0</span>;        </span><br><span class="line">    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">        unpack_valid &lt;= din_valid;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="乘法器"><a href="#乘法器" class="headerlink" title="乘法器"></a>乘法器</h3><ul><li>将输入数值部分相乘，同时手动控制结果的符号位</li><li>unpack_valid随数据流动，产生mul_valid</li></ul><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">integer</span> y;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span>:<span class="number">0</span>]mul_result[<span class="number">2</span> ** DIN_NUM_LOG - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span> (~rst_n) <span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">for</span> (y = <span class="number">0</span>; y &lt; <span class="number">2</span> ** DIN_NUM_LOG ; y = y + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">            mul_result[y] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(unpack_valid)<span class="keyword">begin</span></span><br><span class="line">        <span class="keyword">for</span> (y = <span class="number">0</span>; y &lt; <span class="number">2</span> ** DIN_NUM_LOG ; y = y + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">            <span class="keyword">if</span> (din1_unpack[y] != <span class="number">&#x27;b0</span> &amp;&amp; din2_unpack[y] != <span class="number">&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">                mul_result[y][<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span>] &lt;= din1_unpack[y][DIN_WIDTH - <span class="number">1</span>] ^ din2_unpack[y][DIN_WIDTH - <span class="number">1</span>];</span><br><span class="line">            <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">                mul_result[y][<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span>] &lt;= <span class="number">&#x27;b0</span>; </span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            mul_result[y][<span class="number">2</span> * DIN_WIDTH - <span class="number">3</span>:<span class="number">0</span>] &lt;= din1_unpack[y][DIN_WIDTH - <span class="number">2</span>:<span class="number">0</span>] * din2_unpack[y][DIN_WIDTH - <span class="number">2</span>:<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> mul_valid;</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span> (~rst_n) <span class="keyword">begin</span></span><br><span class="line">        mul_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">        mul_valid &lt;= unpack_valid;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="加法树"><a href="#加法树" class="headerlink" title="加法树"></a>加法树</h3><ul><li>将输入转换为补码，之后逐级相加</li><li>mul_valid逐级流动，产生每层的layer_dout_valid</li></ul><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">genvar</span> i,k;</span><br><span class="line"><span class="keyword">generate</span></span><br><span class="line">    <span class="keyword">for</span> (k = DIN_NUM_LOG; k &gt; <span class="number">0</span>; k = k - <span class="number">1</span>) <span class="keyword">begin</span>:mla_layer</span><br><span class="line"></span><br><span class="line">        <span class="keyword">wire</span> [<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span> + (DIN_NUM_LOG - k):<span class="number">0</span>]layer_din[<span class="number">2</span> ** k - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">wire</span> layer_din_valid;</span><br><span class="line">        <span class="keyword">reg</span> [<span class="number">2</span> * DIN_WIDTH - <span class="number">1</span> + (DIN_NUM_LOG - k):<span class="number">0</span>]layer_dout[<span class="number">2</span> ** (k - <span class="number">1</span>) - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">reg</span> layer_dout_valid;</span><br><span class="line">        <span class="keyword">integer</span> x;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (k == DIN_NUM_LOG) <span class="keyword">begin</span></span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">2</span> ** k ; i = i + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">                <span class="keyword">assign</span> layer_din[i][<span class="number">2</span> * DIN_WIDTH - <span class="number">3</span>:<span class="number">0</span>] = (mul_result[i][<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span>])?(~mul_result[i][<span class="number">2</span> * DIN_WIDTH - <span class="number">3</span>:<span class="number">0</span>] + <span class="number">1&#x27;b1</span>):mul_result[i][<span class="number">2</span> * DIN_WIDTH - <span class="number">3</span>:<span class="number">0</span>]; </span><br><span class="line">                <span class="keyword">assign</span> layer_din[i][<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span>] = mul_result[i][<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span>];</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">assign</span> layer_din_valid = mul_valid;</span><br><span class="line">        <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">2</span> ** k; i = i + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">                <span class="keyword">assign</span> layer_din[i] = mla_layer[k + <span class="number">1</span>]<span class="variable">.layer_dout</span>[i];</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">assign</span> layer_din_valid = mla_layer[k + <span class="number">1</span>]<span class="variable">.layer_dout_valid</span>;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line">            <span class="keyword">if</span> (~rst_n) <span class="keyword">begin</span></span><br><span class="line">                <span class="keyword">for</span> (x = <span class="number">0</span>; x &lt; <span class="number">2</span> ** (k - <span class="number">1</span>) ; x = x + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">                    layer_dout[x] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span> (layer_din_valid) <span class="keyword">begin</span></span><br><span class="line">                <span class="keyword">for</span> (x = <span class="number">0</span>; x &lt; <span class="number">2</span> ** (k - <span class="number">1</span>) ; x = x + <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">                    layer_dout[x] &lt;= &#123;layer_din[<span class="number">2</span> * x][<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span> + (DIN_NUM_LOG - k)],layer_din[<span class="number">2</span> * x]&#125; + &#123;layer_din[<span class="number">2</span> * x + <span class="number">1</span>][<span class="number">2</span> * DIN_WIDTH - <span class="number">2</span> + (DIN_NUM_LOG - k)],layer_din[<span class="number">2</span> * x + <span class="number">1</span>]&#125;;</span><br><span class="line">                    <span class="comment">// layer_dout[x] &lt;= layer_din[2 * x] + layer_din[2 * x + 1];</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line">            <span class="keyword">if</span> (~rst_n) <span class="keyword">begin</span></span><br><span class="line">                layer_dout_valid &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">            <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">                layer_dout_valid &lt;= layer_din_valid;</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">endgenerate</span></span><br></pre></td></tr></table></figure><h3 id="取出结果"><a href="#取出结果" class="headerlink" title="取出结果"></a>取出结果</h3><p>从循环生成语句的最后一级取出输出</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assign</span> dout_valid = mla_layer[<span class="number">1</span>]<span class="variable">.layer_dout_valid</span>;</span><br><span class="line"><span class="keyword">assign</span> mla_dout = mla_layer[<span class="number">1</span>]<span class="variable">.layer_dout</span>[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span> <span class="comment">// mla_tree</span></span><br></pre></td></tr></table></figure><h2 id="Testbench"><a href="#Testbench" class="headerlink" title="Testbench"></a>Testbench</h2><h3 id="dut声明与连接"><a href="#dut声明与连接" class="headerlink" title="dut声明与连接"></a>dut声明与连接</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> tb_mla_tree();</span><br><span class="line"></span><br><span class="line"><span class="keyword">parameter</span> DIN_WIDTH = <span class="number">8</span>;</span><br><span class="line"><span class="keyword">parameter</span> DIN_NUM_LOG = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> clk;</span><br><span class="line"><span class="keyword">logic</span> rst_n;</span><br><span class="line"><span class="keyword">logic</span> din_valid;</span><br><span class="line"><span class="keyword">logic</span> [(<span class="number">2</span> ** DIN_NUM_LOG) * DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>]mla_din1;</span><br><span class="line"><span class="keyword">logic</span> [(<span class="number">2</span> ** DIN_NUM_LOG) * DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>]mla_din2;</span><br><span class="line"><span class="keyword">logic</span> dout_valid;</span><br><span class="line"><span class="keyword">logic</span> [DIN_WIDTH * <span class="number">2</span> + DIN_NUM_LOG - <span class="number">2</span>:<span class="number">0</span>]mla_dout;</span><br><span class="line"></span><br><span class="line">mla_tree #(</span><br><span class="line"><span class="variable">.DIN_WIDTH</span>  (DIN_WIDTH),</span><br><span class="line"><span class="variable">.DIN_NUM_LOG</span>(DIN_NUM_LOG)</span><br><span class="line">) dut (</span><br><span class="line"><span class="variable">.clk</span>       (clk),</span><br><span class="line"><span class="variable">.rst_n</span>     (rst_n),</span><br><span class="line"><span class="variable">.din_valid</span> (din_valid),</span><br><span class="line"><span class="variable">.mla_din1</span>  (mla_din1),</span><br><span class="line"><span class="variable">.mla_din2</span>  (mla_din2),</span><br><span class="line"><span class="variable">.dout_valid</span>(dout_valid),</span><br><span class="line"><span class="variable">.mla_dout</span>  (mla_dout)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="时钟与复位信号"><a href="#时钟与复位信号" class="headerlink" title="时钟与复位信号"></a>时钟与复位信号</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">clk = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">#<span class="number">50</span> clk = ~clk;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line">#<span class="number">5</span> rst_n = <span class="number">1&#x27;b0</span>;</span><br><span class="line">#<span class="number">10</span> rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="激励产生"><a href="#激励产生" class="headerlink" title="激励产生"></a>激励产生</h3><h4 id="激励产生函数"><a href="#激励产生函数" class="headerlink" title="激励产生函数"></a>激励产生函数</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="keyword">logic</span>[DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>] data_random();</span><br><span class="line"><span class="keyword">integer</span> x;</span><br><span class="line">x = (DIN_WIDTH)&#x27;($urandom_range(<span class="number">0</span>,<span class="number">2</span> ** DIN_WIDTH));</span><br><span class="line">  <span class="keyword">if</span> (x[DIN_WIDTH - <span class="number">1</span>] == <span class="number">1&#x27;b1</span> &amp;&amp; x[DIN_WIDTH - <span class="number">2</span>:<span class="number">0</span>] == <span class="number">&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;<span class="comment">//不产生 -2 ** (DIN_WIDTH - 1)</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">return</span> x;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">endfunction</span></span><br></pre></td></tr></table></figure><h4 id="激励产生-1"><a href="#激励产生-1" class="headerlink" title="激励产生"></a>激励产生</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">din_valid = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">repeat</span>(<span class="number">100</span>) <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span> ** DIN_NUM_LOG ; i++) <span class="keyword">begin</span></span><br><span class="line">        mla_din1[i * DIN_WIDTH +:DIN_WIDTH] = data_random();</span><br><span class="line">        mla_din2[i * DIN_WIDTH +:DIN_WIDTH] = data_random();</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    @(<span class="keyword">negedge</span> clk);</span><br><span class="line">    din_valid = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">    <span class="built_in">$stop</span>;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="参考模型"><a href="#参考模型" class="headerlink" title="参考模型"></a>参考模型</h3><h4 id="输入解码函数"><a href="#输入解码函数" class="headerlink" title="输入解码函数"></a>输入解码函数</h4><p>将补码形式的logic数据转为带符号的integer类型数据</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="keyword">integer</span> decode(<span class="keyword">logic</span>[DIN_WIDTH - <span class="number">1</span>:<span class="number">0</span>] din);</span><br><span class="line"><span class="keyword">if</span>(din[DIN_WIDTH - <span class="number">1</span>] == <span class="number">1&#x27;b1</span>) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">integer</span>&#x27;(din) - <span class="number">2</span> ** DIN_WIDTH;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">integer</span>&#x27;(din);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">endfunction</span></span><br></pre></td></tr></table></figure><h4 id="参考模型-1"><a href="#参考模型-1" class="headerlink" title="参考模型"></a>参考模型</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">integer</span> tb_din1[<span class="number">2</span> ** DIN_NUM_LOG - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">integer</span> tb_din2[<span class="number">2</span> ** DIN_NUM_LOG - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">integer</span> tb_result;</span><br><span class="line"><span class="keyword">integer</span> scoreboard[$]; <span class="comment">//计分板</span></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">posedge</span> clk);</span><br><span class="line"><span class="keyword">if</span>(din_valid == <span class="number">1&#x27;b1</span>) <span class="keyword">begin</span></span><br><span class="line"><span class="comment">// 获取输入数据</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span> ** DIN_NUM_LOG ; i++) <span class="keyword">begin</span></span><br><span class="line">tb_din1[i] = decode(mla_din1[i * DIN_WIDTH +:DIN_WIDTH]);</span><br><span class="line">tb_din2[i] = decode(mla_din2[i * DIN_WIDTH +:DIN_WIDTH]);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">// 计算参考结果</span></span><br><span class="line">tb_result = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span> ** DIN_NUM_LOG ; i++) <span class="keyword">begin</span></span><br><span class="line">tb_result = tb_result + tb_din1[i] * tb_din2[i];</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">// 将参考结果送入计分板</span></span><br><span class="line">scoreboard<span class="variable">.push_back</span>(tb_result);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="计分板"><a href="#计分板" class="headerlink" title="计分板"></a>计分板</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">integer</span> tb_compare;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line"><span class="keyword">if</span> (dout_valid) <span class="keyword">begin</span></span><br><span class="line">tb_compare = scoreboard<span class="variable">.pop_front</span>();</span><br><span class="line"><span class="keyword">if</span> ((DIN_WIDTH * <span class="number">2</span> + DIN_NUM_LOG - <span class="number">1</span>)&#x27;(tb_compare) == mla_dout) <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;%d == %d&quot;</span>,tb_compare,<span class="keyword">integer</span>&#x27;(mla_dout));</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;%h != %h&quot;</span>,(DIN_WIDTH * <span class="number">2</span> + DIN_NUM_LOG - <span class="number">1</span>)&#x27;(tb_compare),mla_dout);</span><br><span class="line"><span class="built_in">$stop</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的特征筛选</title>
      <link href="2018/01/20/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%89%B9%E5%BE%81%E7%AD%9B%E9%80%89/"/>
      <url>2018/01/20/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%89%B9%E5%BE%81%E7%AD%9B%E9%80%89/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h2 id="特征筛选的作用"><a href="#特征筛选的作用" class="headerlink" title="特征筛选的作用"></a>特征筛选的作用</h2><p>样本中的有些特征是所谓的“优秀特征”，使用这些特征可以显著的提高泛化能力。而有些特征在样本类别区分上并不明显，在训练中引入这些特征会导致算力的浪费；另外有些特征对样本的分类有反作用，引入这些特征反而会导致泛化能力下降</p><h2 id="特征筛选"><a href="#特征筛选" class="headerlink" title="特征筛选"></a>特征筛选</h2><p>与PCA（主成分分析）不同，特征筛选不修改特征值，而是寻找对模型性能提升较大的尽量少的特征</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h2 id="引入数据集——Titanic数据集"><a href="#引入数据集——Titanic数据集" class="headerlink" title="引入数据集——Titanic数据集"></a>引入数据集——Titanic数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">titan = pd.read_csv(<span class="string">&quot;http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt&quot;</span>)</span><br><span class="line">titan.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 11 columns):row.names    1313 non-null int64pclass       1313 non-null objectsurvived     1313 non-null int64name         1313 non-null objectage          633 non-null float64embarked     821 non-null objecthome.dest    754 non-null objectroom         77 non-null objectticket       69 non-null objectboat         347 non-null objectsex          1313 non-null objectdtypes: float64(1), int64(2), object(8)memory usage: 112.9+ KB</code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="分离数据与标签"><a href="#分离数据与标签" class="headerlink" title="分离数据与标签"></a>分离数据与标签</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_source = titan.drop([<span class="string">&quot;row.names&quot;</span>,<span class="string">&quot;name&quot;</span>,<span class="string">&quot;survived&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">x_source.info()</span><br><span class="line">y_source = titan[<span class="string">&quot;survived&quot;</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 8 columns):pclass       1313 non-null objectage          633 non-null float64embarked     821 non-null objecthome.dest    754 non-null objectroom         77 non-null objectticket       69 non-null objectboat         347 non-null objectsex          1313 non-null objectdtypes: float64(1), object(7)memory usage: 82.1+ KB</code></pre><h3 id="缺失数据填充"><a href="#缺失数据填充" class="headerlink" title="缺失数据填充"></a>缺失数据填充</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_source[<span class="string">&#x27;age&#x27;</span>].fillna(x_source[<span class="string">&#x27;age&#x27;</span>].mean(),inplace=<span class="literal">True</span>)</span><br><span class="line">x_source.fillna(<span class="string">&#x27;UNKNOWN&#x27;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">x_source.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 8 columns):pclass       1313 non-null objectage          1313 non-null float64embarked     1313 non-null objecthome.dest    1313 non-null objectroom         1313 non-null objectticket       1313 non-null objectboat         1313 non-null objectsex          1313 non-null objectdtypes: float64(1), object(7)memory usage: 82.1+ KB</code></pre><h3 id="数据分割"><a href="#数据分割" class="headerlink" title="数据分割"></a>数据分割</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x_source,y_source,random_state=<span class="number">33</span>,test_size=<span class="number">0.25</span>)</span><br><span class="line">x_train.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 984 entries, 1086 to 1044Data columns (total 8 columns):pclass       984 non-null objectage          984 non-null float64embarked     984 non-null objecthome.dest    984 non-null objectroom         984 non-null objectticket       984 non-null objectboat         984 non-null objectsex          984 non-null objectdtypes: float64(1), object(7)memory usage: 69.2+ KB</code></pre><h3 id="特征向量化"><a href="#特征向量化" class="headerlink" title="特征向量化"></a>特征向量化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">vec = DictVectorizer()</span><br><span class="line">x_train = vec.fit_transform(x_train.to_dict(orient=<span class="string">&#x27;record&#x27;</span>))</span><br><span class="line">x_test = vec.transform(x_test.to_dict(orient=<span class="string">&#x27;record&#x27;</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(vec.feature_names_)</span><br></pre></td></tr></table></figure><pre><code>474</code></pre><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br></pre></td></tr></table></figure><h3 id="基本决策树模型"><a href="#基本决策树模型" class="headerlink" title="基本决策树模型"></a>基本决策树模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">dt.fit(x_train,y_train)</span><br><span class="line">dt.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.82066869300911849</code></pre><h3 id="带特征筛选的决策树"><a href="#带特征筛选的决策树" class="headerlink" title="带特征筛选的决策树"></a>带特征筛选的决策树</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> feature_selection</span><br><span class="line">fs = feature_selection.SelectPercentile(feature_selection.chi2,percentile=<span class="number">7</span>)</span><br><span class="line">x_train_fs = fs.fit_transform(x_train,y_train)</span><br><span class="line">x_test_fs = fs.transform(x_test)</span><br><span class="line">print(x_train.shape,x_train_fs.shape)</span><br></pre></td></tr></table></figure><pre><code>(984, 474) (984, 33)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dt.fit(x_train_fs,y_train)</span><br><span class="line">dt.score(x_test_fs,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.85410334346504557</code></pre>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分离链接的散列</title>
      <link href="2018/01/16/%E5%88%86%E7%A6%BB%E9%93%BE%E6%8E%A5%E7%9A%84%E6%95%A3%E5%88%97/"/>
      <url>2018/01/16/%E5%88%86%E7%A6%BB%E9%93%BE%E6%8E%A5%E7%9A%84%E6%95%A3%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h1 id="散列"><a href="#散列" class="headerlink" title="散列"></a>散列</h1><p>散列为一种用于以常数平均时间执行插入，删除和查找的技术。一般的实现方法是使通过数据的关键字可以计算出该数据所在散列中的位置，类似于Python中的字典。关于散列需要解决以下问题：</p><ul><li>散列的关键字如何映射为一个数（索引）——散列函数</li><li>当两个关键字的散列函数结果相同时，如何解决——冲突</li></ul><h2 id="散列函数"><a href="#散列函数" class="headerlink" title="散列函数"></a>散列函数</h2><p>散列函数为关键字-&gt;索引的函数，常用的关键字为字符串，则需要一个字符串-&gt;整数的映射关系，常见的三种散列函数为：</p><ul><li>ASCII码累加（简单）</li><li>计算前三个字符的加权和$\sum key[i] * 27^{i}$ （不太好，3个字母的常用组合远远小于可能组合）</li><li>计算所有字符加权和并对散列长度取余$(\sum key[i] * 32^{i}) \% tablesize$（较好）</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 累加</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">hashSum</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">hash := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> n.key &#123;</span><br><span class="line">hash += <span class="keyword">int</span>(n.key[i])</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> hash</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 前三个字符和</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">hashTop3</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">hash := <span class="number">0</span></span><br><span class="line">time := utf8.RuneCountInString(n.key)</span><br><span class="line"><span class="keyword">if</span> time &gt; <span class="number">3</span> &#123;</span><br><span class="line">time = <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; time; i++ &#123;</span><br><span class="line">hash += <span class="keyword">int</span>(n.key[i])</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> hash</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 所有字符和取余</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">hashMod</span><span class="params">(lenght <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">hash := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> n.key &#123;</span><br><span class="line">hash += <span class="keyword">int</span>(n.key[i]) * <span class="number">32</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> hash % lenght</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="冲突"><a href="#冲突" class="headerlink" title="冲突"></a>冲突</h2><p>当不同关键字计算出的散列值相同时，发生冲突，本次使用分离链接法解决：</p><ul><li>每个散列中的数据结构有一个指针可以指向下一个数据，因此散列表可以看成链表头的集合</li><li>当插入时，将数据插入在对应散列值的链表中</li><li>访问时，遍历对应散列值的链表，直到找到关键字</li></ul><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="散列节点"><a href="#散列节点" class="headerlink" title="散列节点"></a>散列节点</h2><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> nodeData <span class="keyword">struct</span> &#123;</span><br><span class="line">data <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> node <span class="keyword">struct</span> &#123;</span><br><span class="line">key  <span class="keyword">string</span></span><br><span class="line">hash <span class="keyword">int</span></span><br><span class="line">data nodeData</span><br><span class="line">next *node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="散列值计算（使用第三种）"><a href="#散列值计算（使用第三种）" class="headerlink" title="散列值计算（使用第三种）"></a>散列值计算（使用第三种）</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span> <span class="title">HashCompute</span><span class="params">(lenght <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">n.hash = n.hashMod(lenght)</span><br><span class="line"><span class="comment">// fmt.Println(&quot;key:&quot;, n.key, &quot;hash:&quot;, n.hash)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newNode</span><span class="params">(data nodeData, key <span class="keyword">string</span>)</span> *<span class="title">node</span></span> &#123;</span><br><span class="line">temp := &amp;node&#123;key, <span class="number">0</span>, data, <span class="literal">nil</span>&#125;</span><br><span class="line"><span class="keyword">return</span> temp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h2><h3 id="结构体-1"><a href="#结构体-1" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hashTable <span class="keyword">struct</span> &#123;</span><br><span class="line">table [<span class="number">17</span>]node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入方法"><a href="#插入方法" class="headerlink" title="插入方法"></a>插入方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *hashTable)</span> <span class="title">insert</span><span class="params">(data nodeData, key <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">temp := newNode(data, key)</span><br><span class="line">temp.HashCompute(<span class="built_in">len</span>(h.table))</span><br><span class="line">temp.next = h.table[temp.hash].next</span><br><span class="line">h.table[temp.hash].next = temp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="访问方法"><a href="#访问方法" class="headerlink" title="访问方法"></a>访问方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *hashTable)</span> <span class="title">visit</span><span class="params">(key <span class="keyword">string</span>)</span> <span class="params">(nodeData, error)</span></span> &#123;</span><br><span class="line">temp := newNode(nodeData&#123;&#125;, key)</span><br><span class="line">temp.HashCompute(<span class="built_in">len</span>(h.table))</span><br><span class="line">    <span class="comment">//设计失误，仅有节点有计算散列值的方法，因此需要定义一个散列节点用于计算散列值</span></span><br><span class="line">point := h.table[temp.hash].next</span><br><span class="line"><span class="keyword">for</span> point != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> point.key == key &#123;</span><br><span class="line"><span class="keyword">return</span> point.data, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">point = point.next</span><br><span class="line">&#125; <span class="comment">//遍历链表，搜索关键字</span></span><br><span class="line"><span class="keyword">return</span> temp.data, errors.New(<span class="string">&quot;not exsist&quot;</span>)</span><br><span class="line">    <span class="comment">// 失败退出</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数-1"><a href="#构造函数-1" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newHashTable</span><span class="params">()</span> *<span class="title">hashTable</span></span> &#123;</span><br><span class="line">temp := &amp;hashTable&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> temp.table &#123;</span><br><span class="line">temp.table[i] = *newNode(nodeData&#123;&#125;, <span class="string">&quot;&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> temp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows平台Python调用C++(swig)</title>
      <link href="2018/01/14/Windows%E5%B9%B3%E5%8F%B0Python%E8%B0%83%E7%94%A8C-swig/"/>
      <url>2018/01/14/Windows%E5%B9%B3%E5%8F%B0Python%E8%B0%83%E7%94%A8C-swig/</url>
      
        <content type="html"><![CDATA[<h1 id="步骤0：swig简介"><a href="#步骤0：swig简介" class="headerlink" title="步骤0：swig简介"></a>步骤0：swig简介</h1><p>swig是一种可以将C++代码转换为多种脚本语言封装的工具，可以在<a href="www.swig.org">swig官网</a>下载，解压后将swig.exe的路径添加到环境变量path中即可使用swig</p><h1 id="步骤1：准备C-代码"><a href="#步骤1：准备C-代码" class="headerlink" title="步骤1：准备C++代码"></a>步骤1：准备C++代码</h1><p>编写需要在Python中调用的C++代码，最好将函数和类的声明统一放到头文件中，函数和类的实现放到源文件中</p><h2 id="C-头文件"><a href="#C-头文件" class="headerlink" title="C++头文件"></a>C++头文件</h2><p>头文件主要包括：</p><ul><li><code>#include</code>调用（例如<code>#include &lt;iostream&gt;</code>）</li><li>命名空间指定<code>using namespace std;</code></li><li>函数和类的声明</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">example</span> &#123;</span></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="keyword">int</span> num;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say_hello</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">change</span><span class="params">(<span class="keyword">int</span> din)</span></span>;</span><br><span class="line">        <span class="function"><span class="keyword">int</span> <span class="title">get_num</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="C-源文件"><a href="#C-源文件" class="headerlink" title="C++源文件"></a>C++源文件</h2><p>源文件为头文件中函数和类的实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;example.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">example::say_hello</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;hello python,I am C++&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">example::change</span><span class="params">(<span class="keyword">int</span> din)</span> </span>&#123;</span><br><span class="line">    num = din;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">example::get_num</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="步骤二：使用swig封装"><a href="#步骤二：使用swig封装" class="headerlink" title="步骤二：使用swig封装"></a>步骤二：使用swig封装</h1><h2 id="编写封装说明文件"><a href="#编写封装说明文件" class="headerlink" title="编写封装说明文件"></a>编写封装说明文件</h2><p>swig封装需要一个<code>.i</code>后缀文件的封装说明，其中</p><ul><li><code>%module &lt;name&gt;</code>为封装名称，Python调用的包名就是<code>&lt;name&gt;</code></li><li><code>%&#123;...%&#125;</code>为附加的函数说明和头文件，源文件以外的部分都要包括在这里，包括头文件和宏定义等</li><li>之后为要封装的函数或类，可以直接引用头文件（若已经将要封装的部分的声明写在头文件中）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%module Example_swig</span><br><span class="line"></span><br><span class="line">%&#123;</span><br><span class="line">#include &quot;example.h&quot;</span><br><span class="line">%&#125;</span><br><span class="line"></span><br><span class="line">%include &quot;example.h&quot;</span><br></pre></td></tr></table></figure><h2 id="调用swig封装"><a href="#调用swig封装" class="headerlink" title="调用swig封装"></a>调用swig封装</h2><p>在命令行中输入<code>swig -python -c++ &lt;swig_config&gt;.i</code>，其中<code>&lt;swig_config&gt;.i</code>为上面写的说明文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">swig -python -c++ example.i</span><br></pre></td></tr></table></figure><p>调用后生成两个文件：</p><ul><li>\<cpp_source\>_wrap.cxx文件</li><li>\<name\>.py文件</li></ul><h1 id="步骤三：使用VS编译"><a href="#步骤三：使用VS编译" class="headerlink" title="步骤三：使用VS编译"></a>步骤三：使用VS编译</h1><h2 id="安装VC140编译器"><a href="#安装VC140编译器" class="headerlink" title="安装VC140编译器"></a>安装VC140编译器</h2><p>python3.5使用的编译器是VC140编译器，对应版本是VS2015，本次使用的是VS2017使用VC141编译器。需要在VS2017中安装VC140编辑器，可以直接在<code>工具-&gt;获取工具和功能</code>中安装</p><h2 id="配置VS编译环境"><a href="#配置VS编译环境" class="headerlink" title="配置VS编译环境"></a>配置VS编译环境</h2><p>在C++的空工程基础上建立环境</p><h3 id="配置输出类型"><a href="#配置输出类型" class="headerlink" title="配置输出类型"></a>配置输出类型</h3><p>在<code>生成-&gt;配置管理器</code>中设置：</p><ul><li><code>活动解决方案配置</code>为<code>Release</code></li><li><code>活动解决方案平台</code>为<code>X64</code>（本机为64位机）</li></ul><img src="/2018/01/14/Windows%E5%B9%B3%E5%8F%B0Python%E8%B0%83%E7%94%A8C-swig/config_output.JPG" class=""><h3 id="引入Python库（关键）"><a href="#引入Python库（关键）" class="headerlink" title="引入Python库（关键）"></a>引入Python库（关键）</h3><p>在<code>项目-&gt;属性</code>中配置Python的库</p><ul><li>在<code>VC++目录</code>中的<code>包含目录</code>中，导入Python安装路径下的include路径（包含Python.h）</li><li>在<code>链接器-&gt;常规</code>的<code>附加库目录</code>中，导入Python安装路径下的libs路径（注意不是Lib路径，包括dll文件）</li></ul><img src="/2018/01/14/Windows%E5%B9%B3%E5%8F%B0Python%E8%B0%83%E7%94%A8C-swig/config_include.JPG" class=""><img src="/2018/01/14/Windows%E5%B9%B3%E5%8F%B0Python%E8%B0%83%E7%94%A8C-swig/config_lib.JPG" class=""><h2 id="编译输出"><a href="#编译输出" class="headerlink" title="编译输出"></a>编译输出</h2><p>选择<code>生成-&gt;生成解决方案</code>，在X64-&gt;Release文件夹下有一个dll文件，即为编译输出的动态链接库。将其名称改为<code>_&lt;name&gt;.pyd</code>（本例中为<code>_Example_swig.pyd</code>），将其与swig生成的<code>&lt;name&gt;.py</code>文件放在同一目录中</p><h1 id="步骤四：测试调用"><a href="#步骤四：测试调用" class="headerlink" title="步骤四：测试调用"></a>步骤四：测试调用</h1><p>在python，使用<code>import &lt;name&gt;</code>即可调用刚才生成的包（同一目录下）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Example_swig</span><br><span class="line"></span><br><span class="line">a = Example_swig.example()</span><br><span class="line">a.say_hello()</span><br><span class="line"></span><br><span class="line">a.change(<span class="number">3</span>)</span><br><span class="line">print(a.get_num())</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hello python,I am C++</span><br><span class="line">3</span><br><span class="line">[Finished in 0.2s]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python应用手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>空难数据集的探索分析</title>
      <link href="2018/01/10/%E7%A9%BA%E9%9A%BE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/"/>
      <url>2018/01/10/%E7%A9%BA%E9%9A%BE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<blockquote><p>写在前面：<br>这是我见过的最严肃的数据集，几乎每一行数据背后都是生命和鲜血的代价。这次探索分析并不妄图说明什么，仅仅是对数据处理能力的锻炼。因此本次的探索分析只会展示数据该有的样子而不会进行太多的评价。有一句话叫“因为珍爱和平，我们回首战争”。这里也是，因为珍爱生命，所以回首空难。现在安全的飞行是10万多无辜的人通过性命换来的，向这些伟大的探索者致敬。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h1 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crash = pd.read_csv(<span class="string">&quot;./Airplane_Crashes_and_Fatalities_Since_1908.csv&quot;</span>)</span><br><span class="line">crash.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 5268 entries, 0 to 5267Data columns (total 13 columns):Date            5268 non-null objectTime            3049 non-null objectLocation        5248 non-null objectOperator        5250 non-null objectFlight #        1069 non-null objectRoute           3562 non-null objectType            5241 non-null objectRegistration    4933 non-null objectcn/In           4040 non-null objectAboard          5246 non-null float64Fatalities      5256 non-null float64Ground          5246 non-null float64Summary         4878 non-null objectdtypes: float64(3), object(10)memory usage: 535.1+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crash = crash.drop([<span class="string">&quot;Summary&quot;</span>,<span class="string">&quot;cn/In&quot;</span>,<span class="string">&quot;Flight #&quot;</span>,<span class="string">&quot;Route&quot;</span>,<span class="string">&quot;Location&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">crash.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 5268 entries, 0 to 5267Data columns (total 8 columns):Date            5268 non-null objectTime            3049 non-null objectOperator        5250 non-null objectType            5241 non-null objectRegistration    4933 non-null objectAboard          5246 non-null float64Fatalities      5256 non-null float64Ground          5246 non-null float64dtypes: float64(3), object(5)memory usage: 329.3+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(crash[<span class="number">2200</span>:<span class="number">2205</span>])</span><br></pre></td></tr></table></figure><pre><code>            Date   Time                      Operator              Type  \2200  03/06/1968   8:00     Military - U.S. Air Force  Fairchild C-123K   2201  03/08/1968  19:18                    Air Manila    Fairchild F-27   2202  03/09/1968  23:20   Military - French Air Force      Douglas DC6B   2203  03/19/1968  19:37     Viking Airways - Air Taxi        Cessna 182   2204  03/23/1968  13:00  Fortaire Aviation - Air Taxi       Brantly 305        Registration  Aboard  Fatalities  Ground  2200      54-0590    49.0        49.0     0.0  2201      PI-C871    14.0        14.0     0.0  2202        43748    20.0        19.0     0.0  2203       N2623F     2.0         2.0     0.0  2204       N2224U     5.0         3.0     0.0  </code></pre><h1 id="伤亡分析"><a href="#伤亡分析" class="headerlink" title="伤亡分析"></a>伤亡分析</h1><h2 id="伤亡排序"><a href="#伤亡排序" class="headerlink" title="伤亡排序"></a>伤亡排序</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(crash[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>())</span><br><span class="line">fatal_crash = crash[crash[<span class="string">&quot;Fatalities&quot;</span>].notnull()]</span><br><span class="line">fatal_crash = fatal_crash.sort_values(by=<span class="string">&quot;Fatalities&quot;</span>)</span><br><span class="line">print(fatal_crash[-<span class="number">5</span>:])</span><br></pre></td></tr></table></figure><pre><code>105479.0            Date   Time                                    Operator  \3562  06/23/1985   7:15                                   Air India   2726  03/03/1974  11:41                      Turkish Airlines (THY)   4455  11/12/1996  18:40  Saudi Arabian Airlines / Kazastan Airlines   3568  08/12/1985  18:56                             Japan Air Lines   2963  03/27/1977  17:07            Pan American World Airways / KLM                                         Type    Registration  Aboard  \3562                     Boeing B-747-237B          VT-EFO   329.0   2726            McDonnell Douglas DC-10-10          TC-JAV   346.0   4455  Boeing B-747-168B / Ilyushin IL-76TD  HZAIH/UN-76435   349.0   3568                     Boeing B-747-SR46          JA8119   524.0   2963  Boeing B-747-121 / Boeing B-747-206B   N736PA/PH-BUF   644.0         Fatalities  Ground  3562       329.0     0.0  2726       346.0     0.0  4455       349.0     0.0  3568       520.0     0.0  2963       583.0     0.0  </code></pre><ul><li>内特里费空难：两架波音-747相撞，死亡583人，又称世纪大空难</li><li>日航123空难：波音747撞富士山，单架飞机失事最高死亡记录</li><li>恰尔基达德里撞机事件，最严重的的空中撞机事件</li><li>土耳其航空981号班机空难：货舱门未锁定导致爆炸性施压</li><li>印度航空182号班机：恐怖袭击</li></ul><h2 id="伤亡概率"><a href="#伤亡概率" class="headerlink" title="伤亡概率"></a>伤亡概率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(fatal_crash[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>() / fatal_crash[<span class="string">&quot;Aboard&quot;</span>].<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><pre><code>0.729700936002</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(fatal_crash[fatal_crash[<span class="string">&quot;Fatalities&quot;</span>] != <span class="number">0</span>][<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>() / fatal_crash[fatal_crash[<span class="string">&quot;Fatalities&quot;</span>] != <span class="number">0</span>][<span class="string">&quot;Aboard&quot;</span>].<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><pre><code>0.754191781605    </code></pre><h1 id="机型处理"><a href="#机型处理" class="headerlink" title="机型处理"></a>机型处理</h1><h2 id="处理函数"><a href="#处理函数" class="headerlink" title="处理函数"></a>处理函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">type_crash = fatal_crash[<span class="string">&quot;Type&quot;</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">type_handle</span>(<span class="params">x</span>):</span></span><br><span class="line">    x = <span class="built_in">str</span>(x)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;McDonnell Douglas&quot;</span> <span class="keyword">in</span> x:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;McDonnell Douglas&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;Douglas&quot;</span> <span class="keyword">in</span> x:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Douglas&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;Boeing&quot;</span> <span class="keyword">in</span> x:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Boeing&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;Airbus&quot;</span> <span class="keyword">in</span> x:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Airbus&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;Embraer&quot;</span> <span class="keyword">in</span> x:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Embraer&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;Ilyushin&quot;</span> <span class="keyword">in</span> x:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Ilyushin&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;other&quot;</span></span><br><span class="line">company_crash = type_crash.<span class="built_in">map</span>(type_handle)</span><br><span class="line">print(pd.value_counts(company_crash))</span><br></pre></td></tr></table></figure><pre><code>other                3581Douglas               984Boeing                376McDonnell Douglas     123Ilyushin               96Embraer                61Airbus                 35Name: Type, dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fatal_crash[<span class="string">&quot;company&quot;</span>] = company_crash</span><br><span class="line">print(fatal_crash[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure><pre><code>            Date   Time          Operator               Type Registration  \108   10/21/1926  13:15  Imperial Airways  Handley Page W-10       G-EBMS   5178  11/08/2007   8:00    Juba Air Cargo         Antonov 12       ST-JUA         Aboard  Fatalities  Ground  year month company  108     12.0         0.0     0.0  1926    10   other  5178     4.0         0.0     2.0  2007    11   other  </code></pre><h2 id="处理结果"><a href="#处理结果" class="headerlink" title="处理结果"></a>处理结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">airplane_counte</span>(<span class="params">x</span>):</span></span><br><span class="line">    fatal_ratio = x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>() / x[<span class="string">&quot;Aboard&quot;</span>].<span class="built_in">sum</span>()</span><br><span class="line">    crash_time = x.shape[<span class="number">0</span>]</span><br><span class="line">    fatal_num = x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> pd.Series(&#123;<span class="string">&quot;fatal_num&quot;</span>:fatal_num,<span class="string">&quot;crash_time&quot;</span>:crash_time,<span class="string">&quot;fatal_ratio&quot;</span>:fatal_ratio&#125;)</span><br><span class="line"></span><br><span class="line">company = fatal_crash.groupby([<span class="string">&#x27;company&#x27;</span>]).apply(airplane_counte)</span><br><span class="line">print(company)</span><br><span class="line">plt.close()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">company[<span class="string">&#x27;crash_time&#x27;</span>].drop(<span class="string">&quot;other&quot;</span>).plot(kind=<span class="string">&#x27;bar&#x27;</span>,title=<span class="string">&quot;time&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">company[<span class="string">&#x27;fatal_num&#x27;</span>].drop(<span class="string">&quot;other&quot;</span>).plot(kind=<span class="string">&#x27;bar&#x27;</span>,title=<span class="string">&quot;fatal_num&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">company[<span class="string">&#x27;fatal_ratio&#x27;</span>].plot(kind=<span class="string">&#x27;bar&#x27;</span>,title=<span class="string">&quot;fatal_ratio&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>                   crash_time  fatal_num  fatal_ratiocompany                                              Airbus                   35.0     2980.0     0.510711Boeing                  376.0    18705.0     0.649434Douglas                 984.0    16899.0     0.794350Embraer                  61.0      644.0     0.779661Ilyushin                 96.0     4547.0     0.883084McDonnell Douglas       123.0     6827.0     0.531946other                  3581.0    54877.0     0.785854</code></pre><img src="/2018/01/10/%E7%A9%BA%E9%9A%BE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/output_15_1.png" class=""><h1 id="时间分析"><a href="#时间分析" class="headerlink" title="时间分析"></a>时间分析</h1><h2 id="年"><a href="#年" class="headerlink" title="年"></a>年</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_year</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">fatal_crash[<span class="string">&#x27;year&#x27;</span>] = fatal_crash[<span class="string">&quot;Date&quot;</span>].<span class="built_in">map</span>(get_year)</span><br><span class="line">year_fatal = fatal_crash[fatal_crash[<span class="string">&quot;year&quot;</span>] != np.NaN][[<span class="string">&quot;year&quot;</span>,<span class="string">&quot;Fatalities&quot;</span>,<span class="string">&quot;Aboard&quot;</span>]]</span><br><span class="line">year_fatal.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 5256 entries, 108 to 2963Data columns (total 3 columns):year          5256 non-null objectFatalities    5256 non-null float64Aboard        5246 non-null float64dtypes: float64(2), object(1)memory usage: 164.2+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">year_analysis</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> pd.Series(&#123;<span class="string">&quot;fatal_num&quot;</span>:x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>(),<span class="string">&quot;time&quot;</span>:x.shape[<span class="number">0</span>],<span class="string">&quot;fatal_ratio&quot;</span>:x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>() / x[<span class="string">&quot;Aboard&quot;</span>].<span class="built_in">sum</span>()&#125;)</span><br><span class="line">year = year_fatal.groupby([<span class="string">&quot;year&quot;</span>]).apply(year_analysis)</span><br><span class="line">year = year.sort_index()</span><br><span class="line">year.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Index: 98 entries, 1908 to 2009Data columns (total 3 columns):fatal_num      98 non-null float64fatal_ratio    98 non-null float64time           98 non-null float64dtypes: float64(3)memory usage: 3.1+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.close()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">year[<span class="string">&quot;fatal_num&quot;</span>].plot(title=<span class="string">&quot;fatal_num&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">year[<span class="string">&quot;time&quot;</span>].plot(title=<span class="string">&quot;crash_time&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">year[<span class="string">&quot;fatal_ratio&quot;</span>].plot(title=<span class="string">&quot;fatal_ratio&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2018/01/10/%E7%A9%BA%E9%9A%BE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/output_19_0.png" class=""><h2 id="月"><a href="#月" class="headerlink" title="月"></a>月</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_month</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x.split(<span class="string">&quot;/&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">fatal_crash[<span class="string">&#x27;month&#x27;</span>] = fatal_crash[<span class="string">&quot;Date&quot;</span>].<span class="built_in">map</span>(get_month)</span><br><span class="line">month_fatal = fatal_crash[fatal_crash[<span class="string">&quot;month&quot;</span>] != np.NaN][[<span class="string">&quot;month&quot;</span>,<span class="string">&quot;Fatalities&quot;</span>,<span class="string">&quot;Aboard&quot;</span>]]</span><br><span class="line">month_fatal.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 5256 entries, 108 to 2963Data columns (total 3 columns):month         5256 non-null objectFatalities    5256 non-null float64Aboard        5246 non-null float64dtypes: float64(2), object(1)memory usage: 164.2+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">month_analysis</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> pd.Series(&#123;<span class="string">&quot;fatal_num&quot;</span>:x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>(),<span class="string">&quot;time&quot;</span>:x.shape[<span class="number">0</span>],<span class="string">&quot;fatal_ratio&quot;</span>:x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>() / x[<span class="string">&quot;Aboard&quot;</span>].<span class="built_in">sum</span>()&#125;)</span><br><span class="line">month = month_fatal.groupby([<span class="string">&quot;month&quot;</span>]).apply(year_analysis)</span><br><span class="line">month = month.sort_index()</span><br><span class="line">print(month)</span><br></pre></td></tr></table></figure><pre><code>       fatal_num  fatal_ratio   timemonth                               01        8425.0     0.768354  494.002        7966.0     0.693057  395.003        8708.0     0.787057  453.004        6769.0     0.711852  378.005        7130.0     0.731807  370.006        7909.0     0.681399  385.007        9232.0     0.700349  427.008       10174.0     0.729162  474.009       10286.0     0.760349  458.010        8388.0     0.778758  452.011       10033.0     0.766522  454.012       10459.0     0.668478  516.0</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.close()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">month[<span class="string">&quot;fatal_num&quot;</span>].plot(kind=<span class="string">&quot;bar&quot;</span>,title=<span class="string">&quot;fatal_num&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">month[<span class="string">&quot;time&quot;</span>].plot(kind=<span class="string">&quot;bar&quot;</span>,title=<span class="string">&quot;crash_time&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">month[<span class="string">&quot;fatal_ratio&quot;</span>].plot(kind=<span class="string">&quot;bar&quot;</span>,title=<span class="string">&quot;fatal_ratio&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2018/01/10/%E7%A9%BA%E9%9A%BE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/output_23_0.png" class=""><h2 id="小时"><a href="#小时" class="headerlink" title="小时"></a>小时</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_hour</span>(<span class="params">x</span>):</span></span><br><span class="line">    hour = x.split(<span class="string">&quot;:&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        hour = <span class="built_in">float</span>(hour)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">int</span>(hour) == hour <span class="keyword">and</span> hour &lt; <span class="number">24</span>:</span><br><span class="line">            <span class="keyword">return</span> hour</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.nan</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> np.nan</span><br><span class="line">    </span><br><span class="line">time_fatal = fatal_crash[fatal_crash[<span class="string">&quot;Time&quot;</span>].isnull() == <span class="literal">False</span>]</span><br><span class="line">time_fatal[<span class="string">&quot;hour&quot;</span>] = time_fatal[<span class="string">&quot;Time&quot;</span>].<span class="built_in">map</span>(get_hour)</span><br><span class="line">time_fatal.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 3049 entries, 108 to 2963Data columns (total 13 columns):Date            3049 non-null objectTime            3049 non-null objectOperator        3046 non-null objectType            3048 non-null objectRegistration    2952 non-null objectAboard          3049 non-null float64Fatalities      3049 non-null float64Ground          3046 non-null float64airplane        3049 non-null objectcompany         3049 non-null objectyear            3049 non-null objectmonth           3049 non-null objecthour            3036 non-null float64dtypes: float64(4), object(9)memory usage: 333.5+ KBc:\users\qiank\appdata\local\programs\python\python35\lib\site-packages\ipykernel_launcher.py:13: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.Try using .loc[row_indexer,col_indexer] = value insteadSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy  del sys.path[0]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hour_analysis</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> pd.Series(&#123;<span class="string">&quot;fatal_num&quot;</span>:x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>(),<span class="string">&quot;time&quot;</span>:x.shape[<span class="number">0</span>],<span class="string">&quot;fatal_ratio&quot;</span>:x[<span class="string">&quot;Fatalities&quot;</span>].<span class="built_in">sum</span>() / x[<span class="string">&quot;Aboard&quot;</span>].<span class="built_in">sum</span>()&#125;)</span><br><span class="line">hour = time_fatal.groupby([<span class="string">&quot;hour&quot;</span>]).apply(hour_analysis)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.close()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">hour[<span class="string">&quot;fatal_num&quot;</span>].plot(title=<span class="string">&quot;fatal_num&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">hour[<span class="string">&quot;time&quot;</span>].plot(title=<span class="string">&quot;crash_time&quot;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">hour[<span class="string">&quot;fatal_ratio&quot;</span>].plot(title=<span class="string">&quot;fatal_ratio&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2018/01/10/%E7%A9%BA%E9%9A%BE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/output_27_0.png" class="">]]></content>
      
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于mxnet的LSTM实现</title>
      <link href="2018/01/07/%E5%9F%BA%E4%BA%8Emxnet%E7%9A%84LSTM%E5%AE%9E%E7%8E%B0/"/>
      <url>2018/01/07/%E5%9F%BA%E4%BA%8Emxnet%E7%9A%84LSTM%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="RNN理论基础"><a href="#RNN理论基础" class="headerlink" title="RNN理论基础"></a>RNN理论基础</h1><h2 id="基本RNN结构"><a href="#基本RNN结构" class="headerlink" title="基本RNN结构"></a>基本RNN结构</h2><img src="/2018/01/07/%E5%9F%BA%E4%BA%8Emxnet%E7%9A%84LSTM%E5%AE%9E%E7%8E%B0/rnn_base.png" class=""><p>RNN的基本结构如上左图所示，输出除了与当前输入有关，还与上一时刻状态有关。RNN结构展开可视为上右图，传播过程如下所示：</p><ul><li>$ I_{n} $ 为当前状态的输入</li><li>$ S<em>{n} $ 为当前状态，与当前输入与上一时刻状态有关，即 $ S</em>{n} = f(W \times S<em>{n - 1} + U \times I</em>{n}) $ ，其中f(x)为激活函数</li><li>$ O<em>{n} $ 为当前输出，与状态有关，为 $ O</em>{n} = g(V \times S_{n}) $ ，其中f(x)为激活函数</li></ul><p>整个结构共享参数U,W,V。</p><p>当输入很长时，RNN的状态中的包含最早输入的信息会被“遗忘”，因此RNN无法处理非常长的输入</p><h2 id="基本LSTM结构"><a href="#基本LSTM结构" class="headerlink" title="基本LSTM结构"></a>基本LSTM结构</h2><img src="/2018/01/07/%E5%9F%BA%E4%BA%8Emxnet%E7%9A%84LSTM%E5%AE%9E%E7%8E%B0/lstm_base.png" class=""><p>LSTM为特殊为保存长时记忆而设计的RNN单元，传递过程如下：</p><ul><li>遗忘：决定上一时刻的状态有多少被遗忘，由遗忘门层完成，有 $ f<em>{n} = sigmoid(W</em>{f} \times [h<em>{n-1},x</em>{n}] + b<em>{f}) $ ，该结果输出的矩阵与 $ C</em>{n-1} $ 对应位置相乘，对状态起衰减作用</li><li>输入：决定哪些新信息被整合进状态，由输入值层和输入门层完成：<ul><li>输入值层决定新输入数据，有 $ CX<em>{n} = tanh(W</em>{c} \times [h<em>{n - 1},x</em>{n}] + b_{c}) $ </li><li>输入门层决定哪些新数据被整合入状态，有 $ I<em>{n} = sigmoid(W</em>{i} \times [h<em>{n - 1},x</em>{n}] + b_{i}) $ </li><li>最终汇入状态的输入有 $ C<em>{n} = C</em>{n-1} \times f<em>{n} + I</em>{n} \times CX_{n} $ </li></ul></li><li>输出：决定哪些状态被输出，由输出门层完成：<ul><li>输出门层决定哪些状态被输出，有 $ O<em>{n} = sigmoid(W</em>{o} \times [h<em>{n-1},x</em>{n}] + b_{o}) $ </li><li>最终输入为 $ h<em>{n} = O</em>{n} \times tanh(C_{n}) $ </li></ul></li></ul><p>参数一共有4对，如下表所示</p><div class="table-container"><table><thead><tr><th>参数功能</th><th>参数对</th></tr></thead><tbody><tr><td>忘记门层，决定哪些状态被遗忘</td><td>$ W<em>{f} $ , $ b</em>{f} $</td></tr><tr><td>输入门层，决定哪些新输入被累积入状态</td><td>$ W<em>{c} $ , $ b</em>{c} $</td></tr><tr><td>输入值层，产生新输入</td><td>$ W<em>{i} $ , $ b</em>{i} $</td></tr><tr><td>输出门层，决定哪些状态被输出</td><td>$ W<em>{o} $ , $ b</em>{o} $</td></tr></tbody></table></div><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br></pre></td></tr></table></figure><h2 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h2><h3 id="下载数据"><a href="#下载数据" class="headerlink" title="下载数据"></a>下载数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_data</span>(<span class="params">url,name</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(name):</span><br><span class="line">        file_content = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(name,<span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(file_content.content)</span><br><span class="line"></span><br><span class="line">download_data(<span class="string">&quot;https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/ptb/ptb.train.txt&quot;</span>,<span class="string">&quot;./ptb.train.txt&quot;</span>)</span><br><span class="line">download_data(<span class="string">&quot;https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/ptb/ptb.valid.txt&quot;</span>,<span class="string">&quot;./ptb.valid.txt&quot;</span>)</span><br><span class="line">download_data(<span class="string">&quot;https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/ptb/ptb.test.txt&quot;</span>,<span class="string">&quot;./ptb.test.txt&quot;</span>)</span><br><span class="line">download_data(<span class="string">&quot;https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt&quot;</span>,<span class="string">&quot;./input.txt&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="数据处理函数"><a href="#数据处理函数" class="headerlink" title="数据处理函数"></a>数据处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_text</span>(<span class="params">fname, vocab=<span class="literal">None</span>, invalid_label=-<span class="number">1</span>, start_label=<span class="number">0</span></span>):</span></span><br><span class="line">    lines = <span class="built_in">open</span>(fname).readlines()</span><br><span class="line">    lines = [<span class="built_in">filter</span>(<span class="literal">None</span>, i.split(<span class="string">&#x27; &#x27;</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> lines]</span><br><span class="line">    sentences, vocab = mx.rnn.encode_sentences(lines, vocab=vocab, invalid_label=invalid_label,</span><br><span class="line">                                               start_label=start_label)</span><br><span class="line">    <span class="keyword">return</span> sentences, vocab</span><br></pre></td></tr></table></figure><h3 id="可迭代数据生成"><a href="#可迭代数据生成" class="headerlink" title="可迭代数据生成"></a>可迭代数据生成</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">start_label = <span class="number">1</span></span><br><span class="line">invalid_label = <span class="number">0</span></span><br><span class="line">train_sent, vocab = tokenize_text(<span class="string">&quot;./ptb.train.txt&quot;</span>, start_label=start_label,invalid_label=invalid_label)</span><br><span class="line">val_sent, _ = tokenize_text(<span class="string">&quot;./ptb.test.txt&quot;</span>, vocab=vocab, start_label=start_label,invalid_label=invalid_label)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="built_in">type</span>(vocab),<span class="built_in">len</span>(vocab))</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;dict&#39;&gt; 10000    </code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="built_in">type</span>(train_sent),train_sent[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;list&#39;&gt; [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 0], [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 27, 0], [39, 26, 40, 41, 42, 26, 43, 32, 44, 45, 46, 0], [47, 26, 27, 28, 29, 48, 49, 41, 42, 50, 51, 52, 53, 54, 55, 35, 36, 37, 42, 56, 57, 58, 59, 0], [35, 60, 42, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 35, 71, 72, 42, 73, 74, 75, 35, 46, 42, 76, 77, 64, 78, 79, 80, 27, 28, 81, 82, 83, 0]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">50</span></span><br><span class="line">buckets = [<span class="number">10</span>,<span class="number">20</span>,<span class="number">40</span>,<span class="number">60</span>,<span class="number">80</span>]</span><br><span class="line"><span class="comment"># buckets = None</span></span><br><span class="line">data_train = mx.rnn.BucketSentenceIter(train_sent, batch_size, buckets=buckets,invalid_label=invalid_label)</span><br><span class="line">data_val = mx.rnn.BucketSentenceIter(val_sent, batch_size, buckets=buckets,invalid_label=invalid_label)</span><br></pre></td></tr></table></figure><pre><code>WARNING: discarded 4 sentences longer than the largest bucket.WARNING: discarded 0 sentences longer than the largest bucket.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_train):</span><br><span class="line">    print(i.data[<span class="number">0</span>][:<span class="number">2</span>],i.label[<span class="number">0</span>][:<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><pre><code>[[ 1203.   373.   141.   119.    79.    64.    32.   891.    80.  4220.   3864.   119.  1407.   860.   467.  1930.    42.   668.     0.     0.] [   35.   114.    81.  5793.   119.   840.   432.  1516.   232.   926.    181.   923.  5845.   225.    98.     0.     0.     0.     0.     0.]]&lt;NDArray 2x20 @cpu(0)&gt; [[  373.   141.   119.    79.    64.    32.   891.    80.  4220.  3864.    119.  1407.   860.   467.  1930.    42.   668.     0.     0.     0.] [  114.    81.  5793.   119.   840.   432.  1516.   232.   926.   181.    923.  5845.   225.    98.     0.     0.     0.     0.     0.     0.]]&lt;NDArray 2x20 @cpu(0)&gt;</code></pre><p>可以发现，可迭代数据的label为下一时刻（data向左平移一个单词）的数据</p><h2 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">num_layers = <span class="number">2</span></span><br><span class="line">num_hidden = <span class="number">256</span></span><br><span class="line">stack = mx.rnn.SequentialRNNCell()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">    stack.add(mx.rnn.LSTMCell(num_hidden=num_hidden, prefix=<span class="string">&#x27;lstm_l%d_&#x27;</span>%i))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">num_embed = <span class="number">256</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sym_gen</span>(<span class="params">seq_len</span>):</span></span><br><span class="line">    data = mx.sym.Variable(<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line">    label = mx.sym.Variable(<span class="string">&#x27;softmax_label&#x27;</span>)</span><br><span class="line">    embed = mx.sym.Embedding(data=data, input_dim=<span class="built_in">len</span>(vocab),output_dim=num_embed, name=<span class="string">&#x27;embed&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    stack.reset()</span><br><span class="line">    outputs, states = stack.unroll(seq_len, inputs=embed, merge_outputs=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    pred = mx.sym.Reshape(outputs, shape=(-<span class="number">1</span>, num_hidden))</span><br><span class="line">    pred = mx.sym.FullyConnected(data=pred, num_hidden=<span class="built_in">len</span>(vocab), name=<span class="string">&#x27;pred&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    label = mx.sym.Reshape(label, shape=(-<span class="number">1</span>,))</span><br><span class="line">    pred = mx.sym.SoftmaxOutput(data=pred, label=label, name=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pred, (<span class="string">&#x27;data&#x27;</span>,), (<span class="string">&#x27;softmax_label&#x27;</span>,)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a,_,_ = sym_gen(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">mx.viz.plot_network(symbol=a)</span><br></pre></td></tr></table></figure><img src="/2018/01/07/%E5%9F%BA%E4%BA%8Emxnet%E7%9A%84LSTM%E5%AE%9E%E7%8E%B0/output_14_0.png" class=""><h2 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.getLogger().setLevel(logging.DEBUG)  <span class="comment"># logging to stdout</span></span><br><span class="line">model = mx.mod.BucketingModule(sym_gen=sym_gen,default_bucket_key=data_train.default_bucket_key,context=mx.gpu())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model.fit(</span><br><span class="line">        train_data          = data_train,</span><br><span class="line">        eval_data           = data_val,</span><br><span class="line">        eval_metric         = mx.metric.Perplexity(invalid_label),</span><br><span class="line">        kvstore             = <span class="string">&#x27;device&#x27;</span>,</span><br><span class="line">        optimizer           = <span class="string">&#x27;sgd&#x27;</span>,</span><br><span class="line">        optimizer_params    = &#123; <span class="string">&#x27;learning_rate&#x27;</span>:<span class="number">0.01</span>,</span><br><span class="line">                                <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.0</span>,</span><br><span class="line">                                <span class="string">&#x27;wd&#x27;</span>: <span class="number">0.00001</span> &#125;,</span><br><span class="line">        initializer         = mx.init.Xavier(factor_type=<span class="string">&quot;in&quot;</span>, magnitude=<span class="number">2.34</span>),</span><br><span class="line">        num_epoch           = <span class="number">2</span>,</span><br><span class="line">        batch_end_callback  = mx.callback.Speedometer(batch_size, <span class="number">50</span>, auto_reset=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure><pre><code>WARNING:root:Already bound, ignoring bind()WARNING:root:optimizer already initialized, ignoring.INFO:root:Epoch[0] Batch [50]    Speed: 240.74 samples/sec    perplexity=1230.415304INFO:root:Epoch[0] Batch [100]    Speed: 203.97 samples/sec    perplexity=1176.951186INFO:root:Epoch[0] Batch [150]    Speed: 222.01 samples/sec    perplexity=1161.217528INFO:root:Epoch[0] Batch [200]    Speed: 214.61 samples/sec    perplexity=1130.756199INFO:root:Epoch[0] Batch [250]    Speed: 209.55 samples/sec    perplexity=1109.315310INFO:root:Epoch[0] Batch [300]    Speed: 213.95 samples/sec    perplexity=1093.083615INFO:root:Epoch[0] Batch [350]    Speed: 232.20 samples/sec    perplexity=1084.233586INFO:root:Epoch[0] Batch [400]    Speed: 202.13 samples/sec    perplexity=1069.696013INFO:root:Epoch[0] Batch [450]    Speed: 218.14 samples/sec    perplexity=1057.711184INFO:root:Epoch[0] Batch [500]    Speed: 236.57 samples/sec    perplexity=1048.120406INFO:root:Epoch[0] Train-perplexity=1044.812667INFO:root:Epoch[0] Time cost=118.042INFO:root:Epoch[0] Validation-perplexity=853.844612INFO:root:Epoch[1] Batch [50]    Speed: 228.59 samples/sec    perplexity=932.793729INFO:root:Epoch[1] Batch [100]    Speed: 210.51 samples/sec    perplexity=933.630035INFO:root:Epoch[1] Batch [150]    Speed: 215.88 samples/sec    perplexity=941.272076INFO:root:Epoch[1] Batch [200]    Speed: 226.13 samples/sec    perplexity=937.232755INFO:root:Epoch[1] Batch [250]    Speed: 199.27 samples/sec    perplexity=926.975004INFO:root:Epoch[1] Batch [300]    Speed: 196.35 samples/sec    perplexity=913.408955INFO:root:Epoch[1] Batch [350]    Speed: 216.76 samples/sec    perplexity=907.031329INFO:root:Epoch[1] Batch [400]    Speed: 198.65 samples/sec    perplexity=899.224687INFO:root:Epoch[1] Batch [450]    Speed: 238.68 samples/sec    perplexity=896.943083INFO:root:Epoch[1] Batch [500]    Speed: 205.63 samples/sec    perplexity=892.764729INFO:root:Epoch[1] Batch [550]    Speed: 206.36 samples/sec    perplexity=888.453916INFO:root:Epoch[1] Batch [600]    Speed: 218.98 samples/sec    perplexity=885.808878INFO:root:Epoch[1] Batch [650]    Speed: 229.98 samples/sec    perplexity=884.451112INFO:root:Epoch[1] Batch [700]    Speed: 226.57 samples/sec    perplexity=882.243212INFO:root:Epoch[1] Batch [750]    Speed: 234.16 samples/sec    perplexity=878.481937INFO:root:Epoch[1] Batch [800]    Speed: 218.44 samples/sec    perplexity=874.363066INFO:root:Epoch[1] Train-perplexity=869.764287INFO:root:Epoch[1] Time cost=194.924INFO:root:Epoch[1] Validation-perplexity=747.663144</code></pre><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.jianshu.com/p/9dc9f41f0b29">[译] 理解 LSTM 网络</a></p><p><a href="https://weibo.com/ttarticle/p/show?id=2309404131548776517452">RNN的入门烹饪指南</a></p><p><a href="http://friskit.me/2016/10/09/translation-wildml-recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">[翻译] WILDML RNN系列教程 第一部分 RNN简介</a></p><p><a href="http://www.pytorchtutorial.com/4-3-rnn-for-regression/">[莫烦 PyTorch 系列教程] 4.3 - RNN 循环神经网络 (回归 Regression)</a></p><p><a href="https://github.com/apache/incubator-mxnet/tree/master/example/rnn">MXnet官方例程</a></p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的文本特征抽取</title>
      <link href="2018/01/06/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/"/>
      <url>2018/01/06/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><p>机器学习的样本一般都是特征向量，但是除了特征向量以外经常有非特征化的数据，最常见的就是文本</p><h2 id="结构化数据"><a href="#结构化数据" class="headerlink" title="结构化数据"></a>结构化数据</h2><p>当某个特征为有限的几个字符串时，可以看成一种结构化数据，处理这种特征的方法一般是将其转为独热码的几个特征。例如仅能取三个字符串的特征：a,b,c，可以将其转换为001,010,100的三个特征和</p><h2 id="非结构化数据"><a href="#非结构化数据" class="headerlink" title="非结构化数据"></a>非结构化数据</h2><p>当特征仅是一系列字符串时，可以使用词袋法处理，这种方法不考虑词汇顺序，仅考虑出现的频率</p><ul><li>count vectorizer：仅考虑每种词汇出现的频率</li><li>tfidf vectorizer：除了考虑词汇出现的频率，还考虑词汇在样本总体中出现频率的倒数，可以理解为抑制每个样本中都经常出现的词汇</li></ul><p>对于经常出现的无意义词汇，如the和a等，可以将其指定为停用词消除其对于结果的干扰</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</span><br><span class="line">news = fetch_20newsgroups(subset=<span class="string">&#x27;all&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(news.data,news.target,test_size=<span class="number">0.25</span>,random_state=<span class="number">33</span>)</span><br><span class="line">print(<span class="built_in">len</span>(x_train),<span class="built_in">len</span>(x_test))</span><br></pre></td></tr></table></figure><pre><code>14134 4712</code></pre><h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br></pre></td></tr></table></figure><h3 id="count-vectorizer"><a href="#count-vectorizer" class="headerlink" title="count vectorizer"></a>count vectorizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c_vec = CountVectorizer()</span><br><span class="line">x_count_train = c_vec.fit_transform(x_train)</span><br><span class="line">x_count_test = c_vec.transform(x_test)</span><br></pre></td></tr></table></figure><h3 id="count-vectorizer-去除停用词"><a href="#count-vectorizer-去除停用词" class="headerlink" title="count vectorizer+去除停用词"></a>count vectorizer+去除停用词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c_vec_s = CountVectorizer(analyzer=<span class="string">&#x27;word&#x27;</span>,stop_words=<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line">x_count_stop_train = c_vec_s.fit_transform(x_train)</span><br><span class="line">x_count_stop_test = c_vec_s.transform(x_test)</span><br></pre></td></tr></table></figure><h3 id="tfidf-vectorizer"><a href="#tfidf-vectorizer" class="headerlink" title="tfidf vectorizer"></a>tfidf vectorizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t_vec = TfidfVectorizer()</span><br><span class="line">x_tfidf_train = t_vec.fit_transform(x_train)</span><br><span class="line">x_tfidf_test = t_vec.transform(x_test)</span><br></pre></td></tr></table></figure><h3 id="tfidf-vectorizer-去除停用词"><a href="#tfidf-vectorizer-去除停用词" class="headerlink" title="tfidf vectorizer+去除停用词"></a>tfidf vectorizer+去除停用词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t_vec_s = TfidfVectorizer(analyzer=<span class="string">&#x27;word&#x27;</span>,stop_words=<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line">x_tfidf_stop_train = t_vec_s.fit_transform(x_train)</span><br><span class="line">x_tfidf_stop_test = t_vec_s.transform(x_test)</span><br></pre></td></tr></table></figure><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br></pre></td></tr></table></figure><h3 id="count-vectorizer-1"><a href="#count-vectorizer-1" class="headerlink" title="count vectorizer"></a>count vectorizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nb_c = MultinomialNB()</span><br><span class="line">nb_c.fit(x_count_train,y_train)</span><br><span class="line">nb_c.score(x_count_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.83977079796264853</code></pre><h3 id="count-vectorizer-去除停用词-1"><a href="#count-vectorizer-去除停用词-1" class="headerlink" title="count vectorizer+去除停用词"></a>count vectorizer+去除停用词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nb_cs = MultinomialNB()</span><br><span class="line">nb_cs.fit(x_count_stop_train,y_train)</span><br><span class="line">nb_cs.score(x_count_stop_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.86375212224108655</code></pre><h3 id="tfidf-vectorizer-1"><a href="#tfidf-vectorizer-1" class="headerlink" title="tfidf vectorizer"></a>tfidf vectorizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nb_t = MultinomialNB()</span><br><span class="line">nb_t.fit(x_tfidf_train,y_train)</span><br><span class="line">nb_t.score(x_tfidf_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.84634974533106966</code></pre><h3 id="tfidf-vectorizer-去除停用词-1"><a href="#tfidf-vectorizer-去除停用词-1" class="headerlink" title="tfidf vectorizer+去除停用词"></a>tfidf vectorizer+去除停用词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nb_ts = MultinomialNB()</span><br><span class="line">nb_ts.fit(x_tfidf_stop_train,y_train)</span><br><span class="line">nb_ts.score(x_tfidf_stop_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.88264006791171479</code></pre>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AVL二叉查找树</title>
      <link href="2017/12/25/AVL%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/"/>
      <url>2017/12/25/AVL%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="AVL二叉查找树"><a href="#AVL二叉查找树" class="headerlink" title="AVL二叉查找树"></a>AVL二叉查找树</h1><p>AVL二叉查找树是一种特殊的二叉查找树，其规定</p><blockquote><p>每个节点的左子树和右子树的高度差最多是1</p></blockquote><h2 id="AVL调整算法"><a href="#AVL调整算法" class="headerlink" title="AVL调整算法"></a>AVL调整算法</h2><p>AVL树插入一个新的节点到某个节点下破坏AVL树的要求时，对于破坏条件的第一个节点a（最靠近底部/深度最深的节点），具有四种情况：</p><ul><li>插入a的左儿子节点的左子树</li><li>插入a的左儿子节点的右子树</li><li>插入a的右儿子节点的左子树</li><li>插入a的右儿子节点的右子树</li></ul><p>其中，第一种和第四种可以看成一种情况的镜像，均是插入外侧；第二种和第三种可以看成另一种情况的镜像，均是插入内侧。这两种情况分别对应两种不同调整方法——单旋转和双旋转。其核心思想都相同，都是尽量将违规子树的父节点的位置尽量向上提。</p><h3 id="单旋转调整"><a href="#单旋转调整" class="headerlink" title="单旋转调整"></a>单旋转调整</h3><p>考虑入下左图所示的情况，假设X与Z的深度相同且，整棵树符合AVL条件：</p><img src="/2017/12/25/AVL%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/simple.png" class=""><p>若插入一个小于b的值，则X的深度将+1，从a节点来看，左子树的深度就比右子树大2，不符合条件。调整的方法如右图所示，以下是调整的合理性：</p><ul><li>查找树条件：X子树存储的数据小于b，Z子树存储的数据大于a，Y子树存储的数据范围时(b,a)，且a&gt;b，由此看出转换后的数依然是一颗查找树。</li><li>AVL条件：X深度比Z深1，但Z的位置要比X低1，因此a节点开始的树满足AVL条件。a树原来的深度为max{X+2,Y+2,Z+1}，现在a树的深度是max{X+1,Y+2,Z+2}。由于原树满足AVL条件，则Y的深度不会比原来X的深度深，所以深度分别为X1+2，X2+1，其中X2=X1+1，所以a节点深度不变，不影响上层AVL结构。</li></ul><p>由此，只要将b提为树根，a放到b的右子树，再将Y挂到a的左子树就可以完成调整</p><div class="table-container"><table><thead><tr><th>待调整指针</th><th>调整前</th><th>调整后</th></tr></thead><tbody><tr><td>树根指针</td><td>a</td><td>b</td></tr><tr><td>b左儿子（不变）</td><td>X</td><td>X</td></tr><tr><td>b右儿子</td><td>Y</td><td>a</td></tr><tr><td>a左儿子</td><td>b</td><td>Y</td></tr><tr><td>a右儿子（不变）</td><td>Z</td><td>Z</td></tr></tbody></table></div><h3 id="双旋转"><a href="#双旋转" class="headerlink" title="双旋转"></a>双旋转</h3><p>考虑下左图情况</p><img src="/2017/12/25/AVL%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/double.png" class=""><p>设左图为一颗AVL树，X,Y的深度比W,Z浅1（X,Y深度相等，W,Z深度相等），假若在X或Y中插入一个节点，在a节点的AVL条件将不同，需要使用双旋转调整，调整成右图的样子，合理性如下：</p><ul><li>查找树条件：对于W中的w，有w\<b；对于X中的x，有b\<x\<c；对于Y中的y，有c\<y\<a；对于Z中的z，有z\>a。且有b\&lt;c\&lt;a。在右侧数中以上均成立</li><li>AVL条件：c的子树深度为1+max{W,X}，右侧深度为1+max{Y,Z}，W,X,Y,Z中有三个相同，另一个比其他都要浅1，则a的AVL条件成立。双旋转处理后c树深度不变，因此不影响上层的AVL条件</li></ul><p>调整情况如下</p><div class="table-container"><table><thead><tr><th>待调整指针</th><th>调整前</th><th>调整后</th></tr></thead><tbody><tr><td>树根节点</td><td>a</td><td>c</td></tr><tr><td>a左儿子</td><td>b</td><td>Y</td></tr><tr><td>a右儿子（不变）</td><td>Z</td><td>Z</td></tr><tr><td>b左儿子（不变）</td><td>W</td><td>W</td></tr><tr><td>b右儿子</td><td>c</td><td>X</td></tr><tr><td>c左儿子</td><td>X</td><td>b</td></tr><tr><td>c右儿子</td><td>Y</td><td>a</td></tr></tbody></table></div><p>同时，双旋转可以看成b-c和c-a之间的两次单旋转：</p><img src="/2017/12/25/AVL%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/d_to_s.png" class=""><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> tree_data <span class="keyword">struct</span> &#123;</span><br><span class="line">data <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> tree_node <span class="keyword">struct</span> &#123;</span><br><span class="line">num    <span class="keyword">int</span></span><br><span class="line">height <span class="keyword">int</span></span><br><span class="line">data   tree_data</span><br><span class="line">parent *tree_node</span><br><span class="line">left   *tree_node</span><br><span class="line">right  *tree_node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New_tree_node</span><span class="params">(num <span class="keyword">int</span>, data tree_data, parent *tree_node)</span> *<span class="title">tree_node</span></span> &#123;</span><br><span class="line">node := tree_node&#123;&#125;</span><br><span class="line">node.num = num</span><br><span class="line">node.data = data</span><br><span class="line">node.height = <span class="number">0</span></span><br><span class="line">node.left = <span class="literal">nil</span></span><br><span class="line">node.right = <span class="literal">nil</span></span><br><span class="line">node.parent = parent</span><br><span class="line"><span class="keyword">return</span> &amp;node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入方法"><a href="#插入方法" class="headerlink" title="插入方法"></a>插入方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">Insert</span><span class="params">(num <span class="keyword">int</span>, data tree_data)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> num &gt; t.num &#123;</span><br><span class="line"><span class="keyword">if</span> t.right != <span class="literal">nil</span> &#123;</span><br><span class="line">t.right.Insert(num, data)</span><br><span class="line">           <span class="comment">//调整算法，向右子树插入，只能是右侧深度破坏条件</span></span><br><span class="line"><span class="keyword">if</span> t.GetLenght(t.right) &gt; t.GetLenght(t.left)+<span class="number">1</span> &#123;</span><br><span class="line"><span class="keyword">if</span> num &gt; t.right.num &#123;</span><br><span class="line">                    <span class="comment">//当待插入的数大于右侧标签，为插入右节点的右子树，单旋转</span></span><br><span class="line">t.RightSimpleRotate()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//当待插入的数小于右侧标签，为插入右节点的左子树，双旋转</span></span><br><span class="line">t.RightDoubleRotate()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">//新建节点不会导致条件破坏</span></span><br><span class="line">t.right = New_tree_node(num, data, t)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> num &lt; t.num &#123;</span><br><span class="line"><span class="keyword">if</span> t.left != <span class="literal">nil</span> &#123;</span><br><span class="line">t.left.Insert(num, data)</span><br><span class="line">           <span class="comment">//调整算法，向左子树插入，只能是左侧深度破坏条件</span></span><br><span class="line"><span class="keyword">if</span> t.GetLenght(t.left) &gt; t.GetLenght(t.right)+<span class="number">1</span> &#123;</span><br><span class="line"><span class="keyword">if</span> num &lt; t.left.num &#123;</span><br><span class="line">                    <span class="comment">//当待插入的数小于左侧标签，为插入左节点的左子树，单旋转</span></span><br><span class="line">t.LeftSimpleRotate()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//当待插入的数大于左侧标签，为插入左节点的右子树，双旋转</span></span><br><span class="line">t.LeftDoubleRotate()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">//新建节点不会导致条件破坏</span></span><br><span class="line">t.left = New_tree_node(num, data, t)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.data = data</span><br><span class="line">&#125;</span><br><span class="line">t.compute_height()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="单旋转方法"><a href="#单旋转方法" class="headerlink" title="单旋转方法"></a>单旋转方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">LeftSimpleRotate</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.parent.left == t &#123;</span><br><span class="line">t.parent.left = t.left</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.parent.right = t.left</span><br><span class="line">&#125;</span><br><span class="line">temp := t.left.right</span><br><span class="line">t.left.right = t</span><br><span class="line">t.left.parent = t.parent</span><br><span class="line"></span><br><span class="line">t.parent = t.left</span><br><span class="line">t.left = temp</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">RightSimpleRotate</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.parent.left == t &#123;</span><br><span class="line">t.parent.left = t.right</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.parent.right = t.right</span><br><span class="line">&#125;</span><br><span class="line">temp := t.right.left</span><br><span class="line">t.right.left = t</span><br><span class="line">t.right.parent = t.parent</span><br><span class="line"></span><br><span class="line">t.parent = t.right</span><br><span class="line">t.right = temp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="双旋转-1"><a href="#双旋转-1" class="headerlink" title="双旋转"></a>双旋转</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">LeftDoubleRotate</span><span class="params">()</span></span> &#123;</span><br><span class="line">t.left.RightSimpleRotate()</span><br><span class="line">t.LeftSimpleRotate()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">RightDoubleRotate</span><span class="params">()</span></span> &#123;</span><br><span class="line">t.right.LeftSimpleRotate()</span><br><span class="line">t.RightSimpleRotate()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h3><h4 id="计算深度"><a href="#计算深度" class="headerlink" title="计算深度"></a>计算深度</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">compute_height</span><span class="params">()</span></span> &#123;</span><br><span class="line">t.height = <span class="keyword">int</span>(math.Max(<span class="keyword">float64</span>(t.GetLenght(t.left)), <span class="keyword">float64</span>(t.GetLenght(t.right)))) + <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="获得深度"><a href="#获得深度" class="headerlink" title="获得深度"></a>获得深度</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">GetLenght</span><span class="params">(node *tree_node)</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> node == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> node.height</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">Visit</span><span class="params">(indent <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">fmt.Println(indent, t.num, t.GetLenght(t.left), t.GetLenght(t.right))</span><br><span class="line"><span class="keyword">if</span> t.left != <span class="literal">nil</span> &#123;</span><br><span class="line">t.left.Visit(indent + <span class="string">&quot;  &quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> t.right != <span class="literal">nil</span> &#123;</span><br><span class="line">t.right.Visit(indent + <span class="string">&quot;  &quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>有基础mxnet和gluon快速入门</title>
      <link href="2017/12/18/%E6%9C%89%E5%9F%BA%E7%A1%80mxnet%E5%92%8Cgluon%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
      <url>2017/12/18/%E6%9C%89%E5%9F%BA%E7%A1%80mxnet%E5%92%8Cgluon%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.getLogger().setLevel(logging.DEBUG)  <span class="comment"># logging to stdout</span></span><br></pre></td></tr></table></figure><h1 id="mxnet基本数据结构"><a href="#mxnet基本数据结构" class="headerlink" title="mxnet基本数据结构"></a>mxnet基本数据结构</h1><h2 id="ndarray"><a href="#ndarray" class="headerlink" title="ndarray"></a>ndarray</h2><p>ndarray是mxnet中最基本的数据结构，ndarray和mxnet的关系与tensor和pytorch的关系类似。该数据结构可以看成numpy的一种变体，基本上numpy的操作ndarray都可以实现。与ndarray相关的部分是<code>mxnet.nd.</code>，关于ndarray操作的API可查看官方<a href="https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html">API文档</a></p><h3 id="ndarray操作"><a href="#ndarray操作" class="headerlink" title="ndarray操作"></a>ndarray操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = mx.nd.random.normal(shape=(<span class="number">4</span>,<span class="number">3</span>))</span><br><span class="line">b = mx.nd.ones((<span class="number">4</span>,<span class="number">3</span>))</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br><span class="line">print(a + b)</span><br></pre></td></tr></table></figure><pre><code>[[ 0.23107234  0.30030754 -0.32433936] [ 1.04932904  0.7368623  -0.0097888 ] [ 0.46656415  1.72023427  0.87809837] [-1.07333779 -0.86925656 -0.26717702]]&lt;NDArray 4x3 @cpu(0)&gt;[[ 1.  1.  1.] [ 1.  1.  1.] [ 1.  1.  1.] [ 1.  1.  1.]]&lt;NDArray 4x3 @cpu(0)&gt;[[ 1.23107231  1.30030751  0.67566061] [ 2.04932904  1.7368623   0.99021119] [ 1.46656418  2.72023439  1.87809837] [-0.07333779  0.13074344  0.73282301]]&lt;NDArray 4x3 @cpu(0)&gt;</code></pre><h3 id="ndarray与numpy相互转换"><a href="#ndarray与numpy相互转换" class="headerlink" title="ndarray与numpy相互转换"></a>ndarray与numpy相互转换</h3><ul><li><code>mxnet.nd.array()</code>传入一个numpy矩阵可以将其转换为ndarray</li><li>使用<code>ndarray.asnumpy()</code>方法将ndarray转为numpy矩阵</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">print(a,<span class="built_in">type</span>(a))</span><br><span class="line">b = mx.nd.array(a)</span><br><span class="line">print(b,<span class="built_in">type</span>(b))</span><br><span class="line">b = b.asnumpy()</span><br><span class="line">print(b,<span class="built_in">type</span>(b))</span><br></pre></td></tr></table></figure><pre><code>[[ 0.85512384 -0.58311797 -1.41627038] [-0.56862628  1.15431958  0.13168715]] &lt;class &#39;numpy.ndarray&#39;&gt;[[ 0.85512382 -0.58311796 -1.41627038] [-0.56862628  1.15431952  0.13168715]]&lt;NDArray 2x3 @cpu(0)&gt; &lt;class &#39;mxnet.ndarray.ndarray.NDArray&#39;&gt;[[ 0.85512382 -0.58311796 -1.41627038] [-0.56862628  1.15431952  0.13168715]] &lt;class &#39;numpy.ndarray&#39;&gt;</code></pre><h2 id="symbol"><a href="#symbol" class="headerlink" title="symbol"></a>symbol</h2><p>symbol是另一个重要的概念，可以理解为符号，就像我们平时使用的代数符号x，y，z一样。一个简单的类比，一个函数$f(x) = x^{2}$，符号x就是symbol，而具体x的值就是ndarray，关于symbol的是<code>mxnet.sym.</code>，具体可参照官方<a href="https://mxnet.incubator.apache.org/api/python/symbol/symbol.html">API文档</a></p><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><ul><li>使用<code>mxnet.sym.Variable()</code>传入名称可建立一个symbol</li><li>使用<code>mxnet.viz.plot_network(symbol=)</code>传入symbol可以绘制运算图</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = mx.sym.Variable(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">b = mx.sym.Variable(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">c = mx.sym.add_n(a,b,name=<span class="string">&quot;c&quot;</span>)</span><br><span class="line">mx.viz.plot_network(symbol=c)</span><br></pre></td></tr></table></figure><img src="/2017/12/18/%E6%9C%89%E5%9F%BA%E7%A1%80mxnet%E5%92%8Cgluon%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/output_6_0.png" class=""><h3 id="带入ndarray"><a href="#带入ndarray" class="headerlink" title="带入ndarray"></a>带入ndarray</h3><p>使用<code>mxnet.sym.bind()</code>方法可以获得一个带入操作数的对象，再使用<code>forward()</code>方法可运算出数值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = c.bind(ctx=mx.cpu(),args=&#123;<span class="string">&quot;a&quot;</span>: mx.nd.ones(<span class="number">5</span>),<span class="string">&quot;b&quot;</span>:mx.nd.ones(<span class="number">5</span>)&#125;)</span><br><span class="line">result = x.forward()</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><pre><code>[[ 2.  2.  2.  2.  2.]&lt;NDArray 5 @cpu(0)&gt;]</code></pre><h1 id="mxnet的数据载入"><a href="#mxnet的数据载入" class="headerlink" title="mxnet的数据载入"></a>mxnet的数据载入</h1><p>深度学习中数据的载入方式非常重要，mxnet提供了<code>mxnet.io.</code>的一系列dataiter用于处理数据载入，详细可参照<a href="https://mxnet.incubator.apache.org/api/python/io/io.html">官方API文档</a>。同时，动态图接口gluon也提供了<code>mxnet.gluon.data.</code>系列的dataiter用于数据载入,详细可参照<a href="https://mxnet.incubator.apache.org/api/python/gluon/data.html">官方API文档</a></p><h2 id="mxnet-io数据载入"><a href="#mxnet-io数据载入" class="headerlink" title="mxnet.io数据载入"></a>mxnet.io数据载入</h2><p><code>mxnet.io</code>的数据载入核心是<code>mxnet.io.DataIter</code>类及其派生类，例如ndarray的iter：<code>NDArrayIter</code></p><ul><li>参数<code>data=</code>：传入一个(名称-数据)的数据dict</li><li>参数<code>label=</code>：传入一个(名称-标签)的标签dict</li><li>参数<code>batch_size=</code>：传入batch大小</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataset = mx.io.NDArrayIter(data=&#123;<span class="string">&#x27;data&#x27;</span>:mx.nd.ones((<span class="number">10</span>,<span class="number">5</span>))&#125;,label=&#123;<span class="string">&#x27;label&#x27;</span>:mx.nd.arange(<span class="number">10</span>)&#125;,batch_size=<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dataset:</span><br><span class="line">    print(i)</span><br><span class="line">    print(i.data,<span class="built_in">type</span>(i.data[<span class="number">0</span>]))</span><br><span class="line">    print(i.label,<span class="built_in">type</span>(i.label[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>DataBatch: data shapes: [(5, 5)] label shapes: [(5,)][[[ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.]]&lt;NDArray 5x5 @cpu(0)&gt;] &lt;class &#39;mxnet.ndarray.ndarray.NDArray&#39;&gt;[[ 0.  1.  2.  3.  4.]&lt;NDArray 5 @cpu(0)&gt;] &lt;class &#39;mxnet.ndarray.ndarray.NDArray&#39;&gt;DataBatch: data shapes: [(5, 5)] label shapes: [(5,)][[[ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.]]&lt;NDArray 5x5 @cpu(0)&gt;] &lt;class &#39;mxnet.ndarray.ndarray.NDArray&#39;&gt;[[ 5.  6.  7.  8.  9.]&lt;NDArray 5 @cpu(0)&gt;] &lt;class &#39;mxnet.ndarray.ndarray.NDArray&#39;&gt;</code></pre><h2 id="gluon-data数据载入"><a href="#gluon-data数据载入" class="headerlink" title="gluon.data数据载入"></a>gluon.data数据载入</h2><p>gluon的数据API几乎与pytorch相同，均是<code>Dataset</code>+<code>DataLoader</code>的方式：</p><ul><li>Dataset：存储数据，使用时需要继承该基类并重载<code>__len__(self)</code>和<code>__getitem__(self,idx)</code>方法</li><li>DataLoader：将Dataset变成能产生batch的可迭代对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataset = mx.gluon.data.ArrayDataset(mx.nd.ones((<span class="number">10</span>,<span class="number">5</span>)),mx.nd.arange(<span class="number">10</span>))</span><br><span class="line">loader = mx.gluon.data.DataLoader(dataset,batch_size=<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">    print(i)</span><br><span class="line">    print(data)</span><br></pre></td></tr></table></figure><pre><code>0[[[ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.]]&lt;NDArray 5x5 @cpu(0)&gt;, [ 0.  1.  2.  3.  4.]&lt;NDArray 5 @cpu(0)&gt;]1[[[ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.] [ 1.  1.  1.  1.  1.]]&lt;NDArray 5x5 @cpu(0)&gt;, [ 5.  6.  7.  8.  9.]&lt;NDArray 5 @cpu(0)&gt;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestSet</span>(<span class="params">mx.gluon.data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.x = mx.nd.zeros((<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">        self.y = mx.nd.arange(<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self,i</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.x[i],self.y[i]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(mx.gluon.data.DataLoader(TestSet(),batch_size=<span class="number">5</span>)):</span><br><span class="line">    print(data)</span><br></pre></td></tr></table></figure><pre><code>[[[ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.]]&lt;NDArray 5x5 @cpu(0)&gt;, [[ 0.] [ 1.] [ 2.] [ 3.] [ 4.]]&lt;NDArray 5x1 @cpu(0)&gt;][[[ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  0.]]&lt;NDArray 5x5 @cpu(0)&gt;, [[ 5.] [ 6.] [ 7.] [ 8.] [ 9.]]&lt;NDArray 5x1 @cpu(0)&gt;]</code></pre><h1 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h1><h2 id="mxnet网络搭建"><a href="#mxnet网络搭建" class="headerlink" title="mxnet网络搭建"></a>mxnet网络搭建</h2><p>mxnet网络搭建类似于TensorFlow，使用symbol搭建出网络，再用一个module封装</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">data = mx.sym.Variable(<span class="string">&#x27;data&#x27;</span>)</span><br><span class="line"><span class="comment"># layer1</span></span><br><span class="line">conv1 = mx.sym.Convolution(data=data, kernel=(<span class="number">5</span>,<span class="number">5</span>), num_filter=<span class="number">32</span>,name=<span class="string">&quot;conv1&quot;</span>)</span><br><span class="line">relu1 = mx.sym.Activation(data=conv1,act_type=<span class="string">&quot;relu&quot;</span>,name=<span class="string">&quot;relu1&quot;</span>)</span><br><span class="line">pool1 = mx.sym.Pooling(data=relu1,pool_type=<span class="string">&quot;max&quot;</span>,kernel=(<span class="number">2</span>,<span class="number">2</span>),stride=(<span class="number">2</span>,<span class="number">2</span>),name=<span class="string">&quot;pool1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layer2</span></span><br><span class="line">conv2 = mx.sym.Convolution(data=pool1, kernel=(<span class="number">3</span>,<span class="number">3</span>), num_filter=<span class="number">64</span>,name=<span class="string">&quot;conv2&quot;</span>)</span><br><span class="line">relu2 = mx.sym.Activation(data=conv2,act_type=<span class="string">&quot;relu&quot;</span>,name=<span class="string">&quot;relu2&quot;</span>)</span><br><span class="line">pool2 = mx.sym.Pooling(data=relu2,pool_type=<span class="string">&quot;max&quot;</span>,kernel=(<span class="number">2</span>,<span class="number">2</span>),stride=(<span class="number">2</span>,<span class="number">2</span>),name=<span class="string">&quot;pool2&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layer3</span></span><br><span class="line">fc1 = mx.symbol.FullyConnected(data=mx.sym.flatten(pool2), num_hidden=<span class="number">256</span>,name=<span class="string">&quot;fc1&quot;</span>)</span><br><span class="line">relu3 = mx.sym.Activation(data=fc1, act_type=<span class="string">&quot;relu&quot;</span>,name=<span class="string">&quot;relu3&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layer4</span></span><br><span class="line">fc2 = mx.symbol.FullyConnected(data=relu3, num_hidden=<span class="number">10</span>,name=<span class="string">&quot;fc2&quot;</span>)</span><br><span class="line">out = mx.sym.SoftmaxOutput(data=fc2, label=mx.sym.Variable(<span class="string">&quot;label&quot;</span>),name=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mxnet_model = mx.mod.Module(symbol=out,label_names=[<span class="string">&quot;label&quot;</span>],context=mx.gpu())</span><br><span class="line">mx.viz.plot_network(symbol=out)</span><br></pre></td></tr></table></figure><img src="/2017/12/18/%E6%9C%89%E5%9F%BA%E7%A1%80mxnet%E5%92%8Cgluon%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/output_15_0.png" class=""><h2 id="Gluon模型搭建"><a href="#Gluon模型搭建" class="headerlink" title="Gluon模型搭建"></a>Gluon模型搭建</h2><p>Gluon模型搭建与pytorch类似，通过继承一个<code>mx.gluon.Block</code>或使用<code>mx.gluon.nn.Sequential()</code>来实现</p><h3 id="一般搭建方法"><a href="#一般搭建方法" class="headerlink" title="一般搭建方法"></a>一般搭建方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">mx.gluon.Block</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__(**kwargs)</span><br><span class="line">        <span class="keyword">with</span> self.name_scope():</span><br><span class="line">            self.dense0 = mx.gluon.nn.Dense(<span class="number">256</span>)</span><br><span class="line">            self.dense1 = mx.gluon.nn.Dense(<span class="number">64</span>)</span><br><span class="line">            self.dense2 = mx.gluon.nn.Dense(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = mx.nd.relu(self.dense0(x))</span><br><span class="line">        x = mx.nd.relu(self.dense1(x))</span><br><span class="line">        x = self.dense2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">gluon_model = MLP()</span><br><span class="line">print(gluon_model)</span><br><span class="line"><span class="comment"># mx.viz.plot_network(symbol=gluon_model)</span></span><br></pre></td></tr></table></figure><pre><code>MLP(  (dense0): Dense(None -&gt; 256, linear)  (dense2): Dense(None -&gt; 10, linear)  (dense1): Dense(None -&gt; 64, linear))</code></pre><h3 id="快速搭建方法"><a href="#快速搭建方法" class="headerlink" title="快速搭建方法"></a>快速搭建方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">gluon_model2 = mx.gluon.nn.Sequential()</span><br><span class="line"><span class="keyword">with</span> gluon_model2.name_scope():</span><br><span class="line">    gluon_model2.add(mx.gluon.nn.Dense(<span class="number">256</span>,activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    gluon_model2.add(mx.gluon.nn.Dense(<span class="number">64</span>,activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    gluon_model2.add(mx.gluon.nn.Dense(<span class="number">10</span>,activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">print(gluon_model2)</span><br></pre></td></tr></table></figure><pre><code>Sequential(  (0): Dense(None -&gt; 256, Activation(relu))  (1): Dense(None -&gt; 64, Activation(relu))  (2): Dense(None -&gt; 10, Activation(relu)))</code></pre><h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><h2 id="mxnet模型训练"><a href="#mxnet模型训练" class="headerlink" title="mxnet模型训练"></a>mxnet模型训练</h2><p>mxnet提供了两套不同层次上的训练封装，一般使用最方便的顶层封装<code>fit()</code>即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist = mx.test_utils.get_mnist()</span><br><span class="line">train_iter = mx.io.NDArrayIter(mnist[<span class="string">&#x27;train_data&#x27;</span>], mnist[<span class="string">&#x27;train_label&#x27;</span>], batch_size=<span class="number">100</span>, data_name=<span class="string">&#x27;data&#x27;</span>,label_name=<span class="string">&#x27;label&#x27;</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line">val_iter = mx.io.NDArrayIter(mnist[<span class="string">&#x27;test_data&#x27;</span>], mnist[<span class="string">&#x27;test_label&#x27;</span>], batch_size=<span class="number">100</span>,data_name=<span class="string">&#x27;data&#x27;</span>,label_name=<span class="string">&#x27;label&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:root:train-labels-idx1-ubyte.gz exists, skipping downloadINFO:root:train-images-idx3-ubyte.gz exists, skipping downloadINFO:root:t10k-labels-idx1-ubyte.gz exists, skipping downloadINFO:root:t10k-images-idx3-ubyte.gz exists, skipping download</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mxnet_model.fit(train_iter,  <span class="comment"># train data</span></span><br><span class="line">              eval_data=val_iter,  <span class="comment"># validation data</span></span><br><span class="line">              optimizer=<span class="string">&#x27;adam&#x27;</span>,  <span class="comment"># use SGD to train</span></span><br><span class="line">              optimizer_params=&#123;<span class="string">&#x27;learning_rate&#x27;</span>:<span class="number">0.01</span>&#125;,  <span class="comment"># use fixed learning rate</span></span><br><span class="line">              eval_metric=<span class="string">&#x27;acc&#x27;</span>,  <span class="comment"># report accuracy during training</span></span><br><span class="line">              batch_end_callback = mx.callback.Speedometer(<span class="number">100</span>, <span class="number">200</span>), <span class="comment"># output progress for each 100 data batches</span></span><br><span class="line">              num_epoch=<span class="number">3</span>)  <span class="comment"># train for at most 3 dataset passes</span></span><br></pre></td></tr></table></figure><pre><code>INFO:root:Epoch[0] Batch [200]    Speed: 5239.83 samples/sec    accuracy=0.890348INFO:root:Epoch[0] Batch [400]    Speed: 5135.49 samples/sec    accuracy=0.971450INFO:root:Epoch[0] Train-accuracy=0.977236INFO:root:Epoch[0] Time cost=11.520INFO:root:Epoch[0] Validation-accuracy=0.980300INFO:root:Epoch[1] Batch [200]    Speed: 5336.36 samples/sec    accuracy=0.979453INFO:root:Epoch[1] Batch [400]    Speed: 5312.22 samples/sec    accuracy=0.982550INFO:root:Epoch[1] Train-accuracy=0.984724INFO:root:Epoch[1] Time cost=11.704INFO:root:Epoch[1] Validation-accuracy=0.980500INFO:root:Epoch[2] Batch [200]    Speed: 5522.89 samples/sec    accuracy=0.982388INFO:root:Epoch[2] Batch [400]    Speed: 5562.08 samples/sec    accuracy=0.984550INFO:root:Epoch[2] Train-accuracy=0.985075INFO:root:Epoch[2] Time cost=10.860INFO:root:Epoch[2] Validation-accuracy=0.978000</code></pre><h2 id="gluon模型训练"><a href="#gluon模型训练" class="headerlink" title="gluon模型训练"></a>gluon模型训练</h2><p>gluon的模型训练包括：</p><ol><li>初始化模型参数</li><li>定义代价函数和优化器</li><li>计算前向传播</li><li>反向传播计算梯度</li><li>调用优化器优化模型</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">data, label</span>):</span></span><br><span class="line">    <span class="keyword">return</span> data.astype(np.float32)/<span class="number">255</span>, label.astype(np.float32)</span><br><span class="line">gluon_train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=<span class="literal">True</span>, transform=transform),</span><br><span class="line">                                      <span class="number">100</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">gluon_test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=<span class="literal">False</span>, transform=transform),</span><br><span class="line">                                     <span class="number">100</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gluon_model.collect_params().initialize(mx.init.Normal(sigma=<span class="number">.1</span>), ctx=mx.gpu())</span><br><span class="line">softmax_cross_entropy = mx.gluon.loss.SoftmaxCrossEntropyLoss()</span><br><span class="line">trainer = mx.gluon.Trainer(gluon_model.collect_params(), <span class="string">&#x27;sgd&#x27;</span>, &#123;<span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">.1</span>&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> i,(data,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(gluon_train_data):</span><br><span class="line">        data = data.as_in_context(mx.gpu()).reshape((-<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">        label = label.as_in_context(mx.gpu())</span><br><span class="line">        <span class="keyword">with</span> mx.autograd.record():</span><br><span class="line">            outputs = gluon_model(data)</span><br><span class="line">            loss = softmax_cross_entropy(outputs,label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        trainer.step(data.shape[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">1</span>:</span><br><span class="line">            print(loss.mean().asnumpy()[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>2.31960.2803450.2688110.4190940.2608730.2525750.1621170.2473610.1693660.1848990.09864930.251358</code></pre><h1 id="准确率计算"><a href="#准确率计算" class="headerlink" title="准确率计算"></a>准确率计算</h1><h2 id="mxnet模型准确率计算"><a href="#mxnet模型准确率计算" class="headerlink" title="mxnet模型准确率计算"></a>mxnet模型准确率计算</h2><p>mxnet的模型提供<code>score()</code>方法用于计算指标，用法与sklearn类似，除了用该API，也可以使用ndarray搭建评估函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">acc = mx.metric.Accuracy()</span><br><span class="line">mxnet_model.score(val_iter,acc)</span><br><span class="line">print(acc)</span><br></pre></td></tr></table></figure><pre><code>EvalMetric: &#123;&#39;accuracy&#39;: 0.97799999999999998&#125;</code></pre><h2 id="gluon模型准确率计算"><a href="#gluon模型准确率计算" class="headerlink" title="gluon模型准确率计算"></a>gluon模型准确率计算</h2><p>gluon官方教程中没有使用提供好的准确率计算方法，需要使用mxnet函数的<code>metric.Accuracy()</code>搭建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>():</span></span><br><span class="line">    acc = mx.metric.Accuracy()</span><br><span class="line">    <span class="keyword">for</span> i, (data, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(gluon_test_data):</span><br><span class="line">        data = data.as_in_context(mx.gpu()).reshape((-<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">        label = label.as_in_context(mx.gpu())</span><br><span class="line">        output = gluon_model(data)</span><br><span class="line">        predictions = mx.nd.argmax(output, axis=<span class="number">1</span>)</span><br><span class="line">        acc.update(preds=predictions, labels=label)</span><br><span class="line">    <span class="keyword">return</span> acc.get()[<span class="number">1</span>]</span><br><span class="line">evaluate_accuracy()</span><br></pre></td></tr></table></figure><pre><code>0.95079999999999998</code></pre><h1 id="模型保存与载入"><a href="#模型保存与载入" class="headerlink" title="模型保存与载入"></a>模型保存与载入</h1><h2 id="mxnet"><a href="#mxnet" class="headerlink" title="mxnet"></a>mxnet</h2><h3 id="mxnet保存模型"><a href="#mxnet保存模型" class="headerlink" title="mxnet保存模型"></a>mxnet保存模型</h3><ul><li>mxnet在fit中使用<code>mx.callback.module_checkpoint()</code>作为fit参数<code>epoch_end_callback</code>可以在训练中保存模型</li><li>训练完成后可以使用<code>module.save_checkpoint()</code>保存模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mxnet_model.save_checkpoint(<span class="string">&quot;mxnet_&quot;</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure><pre><code>INFO:root:Saved checkpoint to &quot;mxnet_-0003.params&quot;</code></pre><h3 id="mxnet载入模型"><a href="#mxnet载入模型" class="headerlink" title="mxnet载入模型"></a>mxnet载入模型</h3><p>使用<code>mx.model.load_checkpoint()</code>和<code>mx.model.set_params</code>载入模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mxnet_model2 = mx.mod.Module(symbol=out,label_names=[&quot;label&quot;],context=mx.gpu())</span></span><br><span class="line">sym, arg_params, aux_params = mx.model.load_checkpoint(<span class="string">&quot;mxnet_&quot;</span>, <span class="number">3</span>)</span><br><span class="line">mxnet_model2 = mx.mod.Module(symbol=sym,label_names=[<span class="string">&quot;label&quot;</span>],context=mx.gpu())</span><br><span class="line">mxnet_model2.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)</span><br><span class="line">mxnet_model2.set_params(arg_params,aux_params)</span><br><span class="line">mxnet_model2.score(val_iter,acc)</span><br><span class="line">print(acc)</span><br></pre></td></tr></table></figure><pre><code>EvalMetric: &#123;&#39;accuracy&#39;: 0.97799999999999998&#125;</code></pre><h2 id="gluon"><a href="#gluon" class="headerlink" title="gluon"></a>gluon</h2><h3 id="gluon保存模型"><a href="#gluon保存模型" class="headerlink" title="gluon保存模型"></a>gluon保存模型</h3><p>使用<code>gluon.Block.save_params()</code>可以保存模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluon_model.save_params(<span class="string">&quot;gluon_model&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="gluon载入模型"><a href="#gluon载入模型" class="headerlink" title="gluon载入模型"></a>gluon载入模型</h3><p>使用<code>gluon.Block.load_params()</code>可以载入模型参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">gluon_model2.load_params(<span class="string">&quot;gluon_model&quot;</span>,ctx=mx.gpu())</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span>():</span></span><br><span class="line">    acc = mx.metric.Accuracy()</span><br><span class="line">    <span class="keyword">for</span> i, (data, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(gluon_test_data):</span><br><span class="line">        data = data.as_in_context(mx.gpu()).reshape((-<span class="number">1</span>, <span class="number">784</span>))</span><br><span class="line">        label = label.as_in_context(mx.gpu())</span><br><span class="line">        output = gluon_model2(data)</span><br><span class="line">        predictions = mx.nd.argmax(output, axis=<span class="number">1</span>)</span><br><span class="line">        acc.update(preds=predictions, labels=label)</span><br><span class="line">    <span class="keyword">return</span> acc.get()[<span class="number">1</span>]</span><br><span class="line">evaluate_accuracy()</span><br></pre></td></tr></table></figure><pre><code>0.95079999999999998</code></pre>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python硬件建模——链表FIFO管理器</title>
      <link href="2017/12/17/Python%E7%A1%AC%E4%BB%B6%E5%BB%BA%E6%A8%A1%E2%80%94%E2%80%94%E9%93%BE%E8%A1%A8FIFO%E7%AE%A1%E7%90%86%E5%99%A8/"/>
      <url>2017/12/17/Python%E7%A1%AC%E4%BB%B6%E5%BB%BA%E6%A8%A1%E2%80%94%E2%80%94%E9%93%BE%E8%A1%A8FIFO%E7%AE%A1%E7%90%86%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="软件建模需求"><a href="#软件建模需求" class="headerlink" title="软件建模需求"></a>软件建模需求</h1><p>建立一个软件模型，在事物级对硬件链表FIFO管理器的各个部分进行建模，包括：</p><ul><li>RAM模型</li><li>链表地址管理模型</li><li>系统模型</li></ul><p>能够模拟的行为包括：</p><ul><li>初始化</li><li>外部读</li><li>外部写</li></ul><h1 id="技术路线选择"><a href="#技术路线选择" class="headerlink" title="技术路线选择"></a>技术路线选择</h1><div class="table-container"><table><thead><tr><th>项目</th><th>技术路线</th></tr></thead><tbody><tr><td>建模语言</td><td>python 3.5</td></tr><tr><td>第三方库</td><td>numpy</td></tr></tbody></table></div><h1 id="软件建模结构"><a href="#软件建模结构" class="headerlink" title="软件建模结构"></a>软件建模结构</h1><img src="/2017/12/17/Python%E7%A1%AC%E4%BB%B6%E5%BB%BA%E6%A8%A1%E2%80%94%E2%80%94%E9%93%BE%E8%A1%A8FIFO%E7%AE%A1%E7%90%86%E5%99%A8/model_structure.png" class=""><p>平台由三个类组成：</p><ul><li>hardware_link_model：对controller和initialize的建模</li><li>addr_manager：对addr_manager的建模，负责管理start_addr和final_addr</li><li>ram_model：对RAM建模，包括读和写</li></ul><h1 id="模型运行流程"><a href="#模型运行流程" class="headerlink" title="模型运行流程"></a>模型运行流程</h1><h2 id="initialize"><a href="#initialize" class="headerlink" title="initialize"></a>initialize</h2><img src="/2017/12/17/Python%E7%A1%AC%E4%BB%B6%E5%BB%BA%E6%A8%A1%E2%80%94%E2%80%94%E9%93%BE%E8%A1%A8FIFO%E7%AE%A1%E7%90%86%E5%99%A8/initialize.png" class=""><h2 id="write"><a href="#write" class="headerlink" title="write"></a>write</h2><img src="/2017/12/17/Python%E7%A1%AC%E4%BB%B6%E5%BB%BA%E6%A8%A1%E2%80%94%E2%80%94%E9%93%BE%E8%A1%A8FIFO%E7%AE%A1%E7%90%86%E5%99%A8/write.png" class=""><h2 id="read"><a href="#read" class="headerlink" title="read"></a>read</h2><img src="/2017/12/17/Python%E7%A1%AC%E4%BB%B6%E5%BB%BA%E6%A8%A1%E2%80%94%E2%80%94%E9%93%BE%E8%A1%A8FIFO%E7%AE%A1%E7%90%86%E5%99%A8/read.png" class=""><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="基本数据结构——结点"><a href="#基本数据结构——结点" class="headerlink" title="基本数据结构——结点"></a>基本数据结构——结点</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">node_data</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;docstring for node_data&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, page_capacity_width=<span class="number">4</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(node_data, self).__init__()</span><br><span class="line">        page_capacity = <span class="number">2</span> ** page_capacity_width - <span class="number">2</span></span><br><span class="line">        self.data = np.zeros(page_capacity)</span><br><span class="line">        self.next_node = <span class="number">0</span></span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>属性</th><th>类型</th><th>功能</th></tr></thead><tbody><tr><td>data</td><td>ndarray</td><td>数据</td></tr><tr><td>next_node</td><td>number</td><td>下一节点地址</td></tr></tbody></table></div><h2 id="hardware-link-model"><a href="#hardware-link-model" class="headerlink" title="hardware_link_model"></a>hardware_link_model</h2><h3 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h3><div class="table-container"><table><thead><tr><th>属性</th><th>类型</th><th>功能</th></tr></thead><tbody><tr><td>ram</td><td>class:ram_model</td><td>软件ram模型</td></tr><tr><td>data_addr_manager</td><td>class:addr_manager</td><td>数据FIFO管理器</td></tr><tr><td>empty_addr_manager</td><td>class:addr_manager</td><td>空白地址FIFO管理器</td></tr><tr><td>ram_cap</td><td>number</td><td>ram容量</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, ram_cap=<span class="number">8</span></span>):</span></span><br><span class="line">    <span class="built_in">super</span>(hardware_link_model, self).__init__()</span><br><span class="line">    self.ram = ram_model(ram_cap)</span><br><span class="line">    self.data_addr_manager = addr_manager(start=<span class="number">0</span>, final=<span class="number">0</span>)</span><br><span class="line">    self.empty_addr_manager = addr_manager(start=<span class="number">0</span>, final=<span class="number">2</span> ** ram_cap - <span class="number">1</span>)</span><br><span class="line">    self.ram_cap = <span class="number">2</span> ** ram_cap</span><br></pre></td></tr></table></figure><h3 id="initialize方法"><a href="#initialize方法" class="headerlink" title="initialize方法"></a>initialize方法</h3><p>初始化ram</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initializer</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.ram_cap - <span class="number">1</span>):</span><br><span class="line">        self.ram.write(i, node_data(i + <span class="number">1</span>))</span><br><span class="line">    self.ram.write(self.ram_cap - <span class="number">1</span>, node_data(self.ram_cap - <span class="number">1</span>))</span><br></pre></td></tr></table></figure><h3 id="write方法"><a href="#write方法" class="headerlink" title="write方法"></a>write方法</h3><p>输入din(ndarray)，将该数据插入FIFO数据链表的尾部</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span>(<span class="params">self, din</span>):</span></span><br><span class="line">    <span class="comment"># Apply for empty node A from empty FIFO</span></span><br><span class="line">    node_addr = self.empty_addr_manager.start_addr</span><br><span class="line">    <span class="comment"># Read next node address of the node A</span></span><br><span class="line">    next_node_addr = self.ram.read_addr(node_addr)</span><br><span class="line">    self.empty_addr_manager.update_start(next_node_addr)</span><br><span class="line">    <span class="comment"># Write data in the node A</span></span><br><span class="line">    node = node_data(node_addr)</span><br><span class="line">    node.data = din</span><br><span class="line">    self.ram.write(node_addr, node)</span><br><span class="line">    <span class="comment"># Append node A to data FIFO</span></span><br><span class="line">    last_final_addr = self.data_addr_manager.final_addr</span><br><span class="line">    self.ram.write_addr(last_final_addr, node_addr)</span><br><span class="line">    self.data_addr_manager.update_final(node_addr)</span><br></pre></td></tr></table></figure><h3 id="read方法"><a href="#read方法" class="headerlink" title="read方法"></a>read方法</h3><p>返FIFO数据链表头部的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="comment"># Apply for data node A from empty FIFO</span></span><br><span class="line">    node_addr = self.data_addr_manager.start_addr</span><br><span class="line">    <span class="comment"># Read next node address of the node A</span></span><br><span class="line">    next_node_addr = self.ram.read_addr(node_addr)</span><br><span class="line">    self.data_addr_manager.update_start(next_node_addr)</span><br><span class="line">    <span class="comment"># Write next node addr of node A</span></span><br><span class="line">    self.ram.write_addr(node_addr, node_addr)</span><br><span class="line">    <span class="comment"># Read data in the node A</span></span><br><span class="line">    node = self.ram.read(node_addr)</span><br><span class="line">    <span class="comment"># Append node A to empty FIFO</span></span><br><span class="line">    last_final_addr = self.empty_addr_manager.final_addr</span><br><span class="line">    self.ram.write_addr(last_final_addr, node_addr)</span><br><span class="line">    self.empty_addr_manager.update_final(node_addr)</span><br><span class="line">    <span class="keyword">return</span> node.data</span><br></pre></td></tr></table></figure><h2 id="addr-manger"><a href="#addr-manger" class="headerlink" title="addr manger"></a>addr manger</h2><h3 id="构造方法-1"><a href="#构造方法-1" class="headerlink" title="构造方法"></a>构造方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, start, final</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(addr_manager, self).__init__()</span><br><span class="line">    self.start_addr = start</span><br><span class="line">    self.final_addr = final</span><br></pre></td></tr></table></figure><h3 id="updata方法"><a href="#updata方法" class="headerlink" title="updata方法"></a>updata方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_start</span>(<span class="params">self, data</span>):</span></span><br><span class="line">    self.start_addr = data</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_final</span>(<span class="params">self, data</span>):</span></span><br><span class="line">    self.final_addr = data</span><br></pre></td></tr></table></figure><h2 id="ram-model"><a href="#ram-model" class="headerlink" title="ram_model"></a>ram_model</h2><h3 id="构造方法-2"><a href="#构造方法-2" class="headerlink" title="构造方法"></a>构造方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cap</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(ram_model, self).__init__()</span><br><span class="line">    self.data = [node_data(<span class="number">0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** cap)]</span><br></pre></td></tr></table></figure><h3 id="读方法"><a href="#读方法" class="headerlink" title="读方法"></a>读方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span>(<span class="params">self, addr</span>):</span></span><br><span class="line">    <span class="keyword">return</span> self.data[addr]</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_addr</span>(<span class="params">self, addr</span>):</span></span><br><span class="line">    <span class="keyword">return</span> self.data[addr].next_node</span><br></pre></td></tr></table></figure><h3 id="写方法"><a href="#写方法" class="headerlink" title="写方法"></a>写方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span>(<span class="params">self, addr, data</span>):</span></span><br><span class="line">    self.data[addr] = data</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_addr</span>(<span class="params">self, addr, data</span>):</span></span><br><span class="line">    self.data[addr].next_node = data</span><br></pre></td></tr></table></figure><h2 id="simulation"><a href="#simulation" class="headerlink" title="simulation"></a>simulation</h2><h3 id="debug函数"><a href="#debug函数" class="headerlink" title="debug函数"></a>debug函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fifo_debug</span>(<span class="params">model, addr</span>):</span></span><br><span class="line">    print(<span class="string">&quot;this:&quot;</span>, addr, model.ram.data[addr])</span><br><span class="line">    <span class="keyword">if</span> model.ram.read_addr(addr) != addr:</span><br><span class="line">        fifo_debug(model, model.ram.read_addr(addr))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="随机数据写入"><a href="#随机数据写入" class="headerlink" title="随机数据写入"></a>随机数据写入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ramdom_write</span>(<span class="params">model</span>):</span></span><br><span class="line">    din = np.random.randn(<span class="number">2</span>**<span class="number">4</span> - <span class="number">2</span>)</span><br><span class="line">    model.write(din)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python应用手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的主成分分析</title>
      <link href="2017/12/16/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
      <url>2017/12/16/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h1><h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><p>特征降维是无监督学习的一种应用：将n维的数据降维为m维的数据（n&gt;m）。可应用于数据压缩等领域</p><h2 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h2><p>主成分分析是一种常用的特征降维方法，对于m维的数据A，可以降维获得一个n维的数据B（m&gt;n），满足$B = f(A)$且$A \approx g(f(A))$，其中f(x)为编码函数，g(x)为解码函数。</p><p>当进行主成分分析时，优化目标为$c = argmin ||x - g(c)||_{2}$，其中c为编码，g(c)为解码函数</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">digits_train = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">digits_test = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes&#x27;</span>, header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><h2 id="分割数据与标签"><a href="#分割数据与标签" class="headerlink" title="分割数据与标签"></a>分割数据与标签</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_x,train_y = digits_train[np.arange(<span class="number">64</span>)],digits_train[<span class="number">64</span>]</span><br><span class="line">test_x,test_y = digits_test[np.arange(<span class="number">64</span>)],digits_test[<span class="number">64</span>]</span><br></pre></td></tr></table></figure><h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">estimator = PCA(n_components=<span class="number">20</span>)</span><br><span class="line">pca_train_x = estimator.fit_transform(train_x)</span><br><span class="line">pca_test_x = estimator.transform(test_x)</span><br></pre></td></tr></table></figure><h2 id="训练支持向量机"><a href="#训练支持向量机" class="headerlink" title="训练支持向量机"></a>训练支持向量机</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br></pre></td></tr></table></figure><h3 id="原始数据"><a href="#原始数据" class="headerlink" title="原始数据"></a>原始数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">svc = LinearSVC()</span><br><span class="line">svc.fit(X=train_x,y=train_y)</span><br><span class="line">svc.score(test_x,test_y)</span><br></pre></td></tr></table></figure><pre><code>0.9393433500278241</code></pre><h3 id="PCA处理后数据"><a href="#PCA处理后数据" class="headerlink" title="PCA处理后数据"></a>PCA处理后数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">svc_pca = LinearSVC()</span><br><span class="line">svc_pca.fit(pca_train_x,train_y)</span><br><span class="line">svc_pca.score(pca_test_x,test_y)</span><br></pre></td></tr></table></figure><pre><code>0.91819699499165275</code></pre>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二叉查找树</title>
      <link href="2017/12/14/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/"/>
      <url>2017/12/14/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="二叉查找树"><a href="#二叉查找树" class="headerlink" title="二叉查找树"></a>二叉查找树</h1><p>二叉查找树是一种特殊的二叉树，该数据结构的核心性质是：</p><blockquote><p>对于树中的每个节点X，它的左子树中所有关键字值小于X的关键字值，而它的右子树中所有关键字值大于X的关键字值</p></blockquote><h2 id="二叉查找树ADT"><a href="#二叉查找树ADT" class="headerlink" title="二叉查找树ADT"></a>二叉查找树ADT</h2><ul><li>MakeEmpty：清空二叉查找树</li><li>Find：给出关键字值，返回该关键字值的节点指针</li><li>FindMin与FindMax：返回最小关键字值和最大关键字值的节点指针</li><li>Insert：插入一个给定关键字值的节点</li><li>Delete：删除一个指定关键字值的节点</li></ul><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> tree_data <span class="keyword">struct</span> &#123;</span><br><span class="line">data <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> tree_node <span class="keyword">struct</span> &#123;</span><br><span class="line">num         <span class="keyword">int</span></span><br><span class="line">data        tree_data</span><br><span class="line">left_point  *tree_node</span><br><span class="line">right_point *tree_node</span><br><span class="line">parent      *tree_node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New_tree_node</span><span class="params">(num <span class="keyword">int</span>, data tree_data, parent *tree_node)</span> *<span class="title">tree_node</span></span> &#123;</span><br><span class="line">node := tree_node&#123;&#125;</span><br><span class="line">node.num = num</span><br><span class="line">node.data = data</span><br><span class="line">node.left_point = <span class="literal">nil</span></span><br><span class="line">node.right_point = <span class="literal">nil</span></span><br><span class="line">node.parent = parent</span><br><span class="line"><span class="keyword">return</span> &amp;node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="清空方法"><a href="#清空方法" class="headerlink" title="清空方法"></a>清空方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">MakeEmpty</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_point != <span class="literal">nil</span> &#123;</span><br><span class="line">t.left_point.MakeEmpty()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> t.right_point != <span class="literal">nil</span> &#123;</span><br><span class="line">t.right_point.MakeEmpty()</span><br><span class="line">&#125;</span><br><span class="line">t.num = <span class="number">0</span></span><br><span class="line">t.data = tree_data&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查找方法"><a href="#查找方法" class="headerlink" title="查找方法"></a>查找方法</h3><p>查找时：</p><ul><li>当待查标号大于本节点标号时，向右子树查询</li><li>当待查标号小于本节点标号时，向左子树查询</li><li>当待查标号等于本节点标号时，命中，返回本节点指针</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">Find</span><span class="params">(num <span class="keyword">int</span>)</span> <span class="params">(*tree_node, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> num &gt; t.num &#123;</span><br><span class="line"><span class="keyword">if</span> t.right_point == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;tree_node&#123;&#125;, errors.New(<span class="string">&quot;num not exsist&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> t.right_point.Find(num)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> num &lt; t.num &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_point == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;tree_node&#123;&#125;, errors.New(<span class="string">&quot;num not exsist&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> t.left_point.Find(num)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> t, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查找最小值-最大值方法"><a href="#查找最小值-最大值方法" class="headerlink" title="查找最小值/最大值方法"></a>查找最小值/最大值方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">FindMin</span><span class="params">()</span> *<span class="title">tree_node</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_point != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> t.left_point.FindMin()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> t</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">FindMax</span><span class="params">()</span> *<span class="title">tree_node</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.right_point != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> t.right_point.FindMax()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> t</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入方法"><a href="#插入方法" class="headerlink" title="插入方法"></a>插入方法</h3><p>插入时：</p><ul><li>当插入标号大于本节点标号，向右子树插入</li><li>当插入标号小于本节点标号，向左子树插入</li><li>当插入标号等于本节点标号，覆盖原值</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">Insert</span><span class="params">(num <span class="keyword">int</span>, data tree_data)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> num &gt; t.num &#123;</span><br><span class="line"><span class="keyword">if</span> t.right_point != <span class="literal">nil</span> &#123;</span><br><span class="line">t.right_point.Insert(num, data)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.right_point = New_tree_node(num, data, t)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> num &lt; t.num &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_point != <span class="literal">nil</span> &#123;</span><br><span class="line">t.left_point.Insert(num, data)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.left_point = New_tree_node(num, data, t)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.data = data</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="删除方法"><a href="#删除方法" class="headerlink" title="删除方法"></a>删除方法</h3><p>删除时，若删除的是本节点，则：</p><ul><li>当本节点没有子树（是树叶）时，直接将母节点指向该节点指针置<code>nil</code>（删除该节点）</li><li>当本节点仅有一个子树时，直接将本节点替换为子节点</li><li>当本节点有两个子树时，找到右节点的最小节点a，将本节点数据与标号替换为a节点的数据和标号，再递归的删除节点a</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">Delete</span><span class="params">(num <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> num &lt; t.num &#123;</span><br><span class="line">t.left_point.Delete(num)</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> num &gt; t.num &#123;</span><br><span class="line">t.right_point.Delete(num)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_point == <span class="literal">nil</span> &amp;&amp; t.right_point == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.parent.left_point.num &gt; t.num &#123;</span><br><span class="line">t.parent.left_point = <span class="literal">nil</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.parent.right_point = <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_point == <span class="literal">nil</span> &#123;</span><br><span class="line">t.parent = t.right_point</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> t.right_point == <span class="literal">nil</span> &#123;</span><br><span class="line">t.parent = t.left_point</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">temp := t.right_point.FindMin()</span><br><span class="line">t.num = temp.num</span><br><span class="line">t.data = temp.data</span><br><span class="line">temp.Delete(temp.num)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于蘑菇数据集的探索分析</title>
      <link href="2017/12/13/%E5%85%B3%E4%BA%8E%E8%98%91%E8%8F%87%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/"/>
      <url>2017/12/13/%E5%85%B3%E4%BA%8E%E8%98%91%E8%8F%87%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h1 id="数据集描述"><a href="#数据集描述" class="headerlink" title="数据集描述"></a>数据集描述</h1><p>蘑菇数据集，包括毒性，大小，表面，颜色等，所有数据均为字符串类型，分析毒性与其他属性的关系</p><h1 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = pd.read_csv(<span class="string">&quot;./mushrooms.csv&quot;</span>)</span><br><span class="line">dataset.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 8124 entries, 0 to 8123Data columns (total 23 columns):class                       8124 non-null objectcap-shape                   8124 non-null objectcap-surface                 8124 non-null objectcap-color                   8124 non-null objectbruises                     8124 non-null objectodor                        8124 non-null objectgill-attachment             8124 non-null objectgill-spacing                8124 non-null objectgill-size                   8124 non-null objectgill-color                  8124 non-null objectstalk-shape                 8124 non-null objectstalk-root                  8124 non-null objectstalk-surface-above-ring    8124 non-null objectstalk-surface-below-ring    8124 non-null objectstalk-color-above-ring      8124 non-null objectstalk-color-below-ring      8124 non-null objectveil-type                   8124 non-null objectveil-color                  8124 non-null objectring-number                 8124 non-null objectring-type                   8124 non-null objectspore-print-color           8124 non-null objectpopulation                  8124 non-null objecthabitat                     8124 non-null objectdtypes: object(23)memory usage: 1.4+ MB</code></pre><p>可以发现，一共包括23个属性，没有缺失值</p><h1 id="直观分析——颜色鲜艳的蘑菇都有毒？"><a href="#直观分析——颜色鲜艳的蘑菇都有毒？" class="headerlink" title="直观分析——颜色鲜艳的蘑菇都有毒？"></a>直观分析——颜色鲜艳的蘑菇都有毒？</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">poison = dataset[dataset[<span class="string">&quot;class&quot;</span>] == <span class="string">&quot;p&quot;</span>][<span class="string">&quot;cap-color&quot;</span>]</span><br><span class="line">not_poison = dataset[dataset[<span class="string">&quot;class&quot;</span>] != <span class="string">&quot;p&quot;</span>][<span class="string">&quot;cap-color&quot;</span>]</span><br><span class="line"><span class="comment"># print(pd.value_counts(not_poison))</span></span><br><span class="line">poison_color = pd.concat([pd.value_counts(poison),pd.value_counts(not_poison),pd.value_counts(dataset[<span class="string">&quot;cap-color&quot;</span>])],axis=<span class="number">1</span>,keys=[<span class="string">&quot;poison&quot;</span>,<span class="string">&quot;normal&quot;</span>,<span class="string">&quot;all&quot;</span>])</span><br><span class="line">poison_color = poison_color.fillna(value=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># print(poison_color)</span></span><br><span class="line">poison_color = poison_color.groupby(poison_color.columns,axis=<span class="number">1</span>).apply(<span class="keyword">lambda</span> x:x / x.<span class="built_in">sum</span>())</span><br><span class="line">print(poison_color.sort_values(by=<span class="string">&quot;poison&quot;</span>).loc[[<span class="string">&quot;p&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;y&quot;</span>,<span class="string">&quot;e&quot;</span>]])</span><br></pre></td></tr></table></figure><pre><code>     poison    normal       allp  0.022472  0.013308  0.017725b  0.030644  0.011407  0.020679y  0.171604  0.095057  0.131955e  0.223698  0.148289  0.184638</code></pre><p>可得还是有一定道理的，尤其是黄色和红色的蘑菇</p><h1 id="相关性分析——判断各指标与毒性相关性"><a href="#相关性分析——判断各指标与毒性相关性" class="headerlink" title="相关性分析——判断各指标与毒性相关性"></a>相关性分析——判断各指标与毒性相关性</h1><p>计算各不同指标下有毒的概率判断单独指标与毒性之间的关系</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analysis_poison</span>(<span class="params">data,index_name</span>):</span></span><br><span class="line">    data[<span class="string">&quot;class&quot;</span>].replace(&#123;<span class="string">&quot;p&quot;</span>:<span class="number">1</span>,<span class="string">&quot;e&quot;</span>:<span class="number">0</span>&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> data.groupby([index_name])[<span class="string">&quot;class&quot;</span>].<span class="built_in">sum</span>() / pd.value_counts(data[index_name])</span><br><span class="line"><span class="comment">#     pd.value_counts(a)</span></span><br><span class="line"><span class="comment"># analysis_poison(dataset[[&quot;class&quot;,&quot;cap-color&quot;]],&quot;cap-color&quot;)   </span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">plt.close()</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">30</span>))</span><br><span class="line">i = <span class="number">1</span></span><br><span class="line">danger=[]</span><br><span class="line"><span class="keyword">for</span> index_name <span class="keyword">in</span> dataset.columns[<span class="number">1</span>:]:</span><br><span class="line">    result = analysis_poison(dataset[[<span class="string">&quot;class&quot;</span>,index_name]],index_name)</span><br><span class="line">    ax = plt.subplot(<span class="number">6</span>,<span class="number">4</span>,i)</span><br><span class="line">    ax.set_title(index_name)</span><br><span class="line">    result.plot(kind=<span class="string">&quot;bar&quot;</span>)</span><br><span class="line">    temp = result[result &gt; <span class="number">0.75</span>]</span><br><span class="line">    temp = temp.rename(index=<span class="keyword">lambda</span> x:<span class="string">&quot;:&quot;</span>.join([index_name,x]))</span><br><span class="line">    danger.append(temp)</span><br><span class="line"><span class="comment">#     plt.bar(range(len(result)),result.data)</span></span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">plt.show()</span><br><span class="line">pd.concat(danger)</span><br></pre></td></tr></table></figure><pre><code>c:\users\qiank\appdata\local\programs\python\python35\lib\site-packages\pandas\core\generic.py:3924: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrameSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy  self._update_inplace(new_data)</code></pre><img src="/2017/12/13/%E5%85%B3%E4%BA%8E%E8%98%91%E8%8F%87%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%8E%A2%E7%B4%A2%E5%88%86%E6%9E%90/mushroom.png" class=""><pre><code>cap-shape:c                   1.000000cap-surface:g                 1.000000odor:c                        1.000000odor:f                        1.000000odor:m                        1.000000odor:p                        1.000000odor:s                        1.000000odor:y                        1.000000gill-size:n                   0.885350gill-color:b                  1.000000gill-color:r                  1.000000stalk-surface-above-ring:k    0.939292stalk-surface-below-ring:k    0.937500stalk-color-above-ring:b      1.000000stalk-color-above-ring:c      1.000000stalk-color-above-ring:n      0.964286stalk-color-above-ring:y      1.000000stalk-color-below-ring:b      1.000000stalk-color-below-ring:c      1.000000stalk-color-below-ring:n      0.875000stalk-color-below-ring:y      1.000000veil-color:y                  1.000000ring-number:n                 1.000000ring-type:l                   1.000000ring-type:n                   1.000000spore-print-color:h           0.970588spore-print-color:r           1.000000spore-print-color:w           0.758794habitat:p                     0.881119dtype: float64</code></pre><p>由上可以发现气味，菌褶颜色，孢子颜色是区分度最大的特征</p><h1 id="模型训练——使用决策树模型"><a href="#模型训练——使用决策树模型" class="headerlink" title="模型训练——使用决策树模型"></a>模型训练——使用决策树模型</h1><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="特征向量化"><a href="#特征向量化" class="headerlink" title="特征向量化"></a>特征向量化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_label = dataset[<span class="string">&quot;class&quot;</span>].replace(&#123;<span class="string">&quot;p&quot;</span>:<span class="number">1</span>,<span class="string">&quot;e&quot;</span>:<span class="number">0</span>&#125;)</span><br><span class="line">model_dataset = pd.get_dummies(dataset.drop([<span class="string">&quot;class&quot;</span>],axis=<span class="number">1</span>))</span><br><span class="line">print(model_dataset.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 8124 entries, 0 to 8123Columns: 117 entries, cap-shape_b to habitat_wdtypes: uint8(117)memory usage: 928.3 KBNone</code></pre><h3 id="切分数据集"><a href="#切分数据集" class="headerlink" title="切分数据集"></a>切分数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(model_dataset,model_label,test_size=<span class="number">0.1</span>,random_state=<span class="number">33</span>)</span><br><span class="line">print(x_train.info())</span><br><span class="line">print(x_test.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 7311 entries, 6849 to 7188Columns: 117 entries, cap-shape_b to habitat_wdtypes: uint8(117)memory usage: 892.5 KBNone&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;Int64Index: 813 entries, 851 to 4472Columns: 117 entries, cap-shape_b to habitat_wdtypes: uint8(117)memory usage: 99.2 KBNone</code></pre><h2 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span>  DecisionTreeClassifier</span><br><span class="line">tr = DecisionTreeClassifier()</span><br><span class="line">tr.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=None,            max_features=None, max_leaf_nodes=None,            min_impurity_decrease=0.0, min_impurity_split=None,            min_samples_leaf=1, min_samples_split=2,            min_weight_fraction_leaf=0.0, presort=False, random_state=None,            splitter=&#39;best&#39;)</code></pre><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>1.0</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>树与二叉表达树</title>
      <link href="2017/12/12/%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E8%A1%A8%E8%BE%BE%E6%A0%91/"/>
      <url>2017/12/12/%E6%A0%91%E4%B8%8E%E4%BA%8C%E5%8F%89%E8%A1%A8%E8%BE%BE%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="树基础"><a href="#树基础" class="headerlink" title="树基础"></a>树基础</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="数的定义"><a href="#数的定义" class="headerlink" title="数的定义"></a>数的定义</h3><p>可以使用递归的方法定义：一棵树是一些节点的集合。一棵树由根节点和0~多个非空树（即子树）组成。这些子树中的每一颗根节点都被来自母树跟的一条有向边链接。母树的根节点被称为父节点，子树的根节点被称为子节点。</p><h3 id="其他定义"><a href="#其他定义" class="headerlink" title="其他定义"></a>其他定义</h3><ul><li>树叶：没有子节点的节点</li><li>n到m的路径的<strong>长</strong>：n到m路径上边的数量</li><li>n的深度：从根节点到n节点的唯一路径长度</li><li>n的高：从n节点到树叶的最长路径长度</li></ul><h2 id="树的实现"><a href="#树的实现" class="headerlink" title="树的实现"></a>树的实现</h2><p>可以由链表实现：</p><ul><li>对于确定子节点数量不多或固定的情况下（如二叉树），每个节点具有所有子节点的指针</li><li>对于一般数，每个节点具有一个子节点和一个兄弟节点的指针</li></ul><h2 id="树的遍历"><a href="#树的遍历" class="headerlink" title="树的遍历"></a>树的遍历</h2><p>树的遍历可以用递归实现，对于每一个节点，分为为两步：</p><ul><li>处理当前节点内容（如打印等）</li><li>递归调用处理子节点</li></ul><p>该顺序成为先序遍历，以上两个步骤顺序可以调换，为后序遍历（先处理子节点，再处理本节点）</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">read_tree</span><span class="params">(path, indent <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">files, _ := ioutil.ReadDir(path)</span><br><span class="line">fmt.Println(indent, path)</span><br><span class="line"><span class="keyword">for</span> _, i := <span class="keyword">range</span> files &#123;</span><br><span class="line"><span class="keyword">if</span> i.IsDir() &#123;</span><br><span class="line">read_tree(path+<span class="string">&quot;/&quot;</span>+i.Name(), <span class="string">&quot;\t&quot;</span>+indent)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">&quot;\t&quot;</span> + indent + path + <span class="string">&quot;/&quot;</span> + i.Name())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该函数即实现了文件树的遍历并打印路径，方式是先序遍历</p><h2 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h2><p>二叉树表示每个节点最多拥有两个子节点的树</p><h1 id="二叉表达树"><a href="#二叉表达树" class="headerlink" title="二叉表达树"></a>二叉表达树</h1><p>二叉表达数是一种表达算式的方式，其中每个叶子节点为操作数，其他节点均为操作符。操作符节点的左右子树代表的就是该操作符的两个操作数</p><h2 id="二叉表达树节点"><a href="#二叉表达树节点" class="headerlink" title="二叉表达树节点"></a>二叉表达树节点</h2><h3 id="数据结构体"><a href="#数据结构体" class="headerlink" title="数据结构体"></a>数据结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> node_data <span class="keyword">struct</span> &#123;</span><br><span class="line">num <span class="keyword">int</span></span><br><span class="line">exp <span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> tree_node <span class="keyword">struct</span> &#123;</span><br><span class="line">data       node_data</span><br><span class="line">left_node  *tree_node</span><br><span class="line">right_node *tree_node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="打印方法"><a href="#打印方法" class="headerlink" title="打印方法"></a>打印方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">print_data</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.data.exp == <span class="string">&quot;n&quot;</span> &#123;</span><br><span class="line">fmt.Println(t.data.num)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">fmt.Println(t.data.exp)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="前序遍历方法"><a href="#前序遍历方法" class="headerlink" title="前序遍历方法"></a>前序遍历方法</h3><p>依次访问：本节点-&gt;左侧节点-&gt;右侧节点。因为先访问本节点，故被称为前序遍历</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">preorder_traversal</span><span class="params">()</span></span> &#123;</span><br><span class="line">t.print_data()</span><br><span class="line"><span class="keyword">if</span> t.left_node != <span class="literal">nil</span> &#123;</span><br><span class="line">t.left_node.preorder_traversal()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> t.right_node != <span class="literal">nil</span> &#123;</span><br><span class="line">t.right_node.preorder_traversal()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="中序遍历方法"><a href="#中序遍历方法" class="headerlink" title="中序遍历方法"></a>中序遍历方法</h3><p>访问顺序为：左侧节点-&gt;本节点-&gt;右侧节点</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">inorder_traversal</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_node != <span class="literal">nil</span> &#123;</span><br><span class="line">t.left_node.inorder_traversal()</span><br><span class="line">&#125;</span><br><span class="line">t.print_data()</span><br><span class="line"><span class="keyword">if</span> t.right_node != <span class="literal">nil</span> &#123;</span><br><span class="line">t.right_node.inorder_traversal()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="后续遍历方法"><a href="#后续遍历方法" class="headerlink" title="后续遍历方法"></a>后续遍历方法</h3><p>访问顺序为：左侧节点-&gt;右侧节点-&gt;本节点</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *tree_node)</span> <span class="title">postorder_traversal</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.left_node != <span class="literal">nil</span> &#123;</span><br><span class="line">t.left_node.postorder_traversal()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> t.right_node != <span class="literal">nil</span> &#123;</span><br><span class="line">t.right_node.postorder_traversal()</span><br><span class="line">&#125;</span><br><span class="line">t.print_data()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">new_tree_node</span><span class="params">(data node_data)</span> *<span class="title">tree_node</span></span> &#123;</span><br><span class="line">temp := &amp;tree_node&#123;&#125;</span><br><span class="line">temp.data = data</span><br><span class="line">temp.left_node = <span class="literal">nil</span></span><br><span class="line">temp.right_node = <span class="literal">nil</span></span><br><span class="line"><span class="keyword">return</span> temp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二叉表达树构造"><a href="#二叉表达树构造" class="headerlink" title="二叉表达树构造"></a>二叉表达树构造</h2><h3 id="结构体-1"><a href="#结构体-1" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> expression_tree_structrue <span class="keyword">struct</span> &#123;</span><br><span class="line">tree []*tree_node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="表达树构造"><a href="#表达树构造" class="headerlink" title="表达树构造"></a>表达树构造</h3><ul><li>若输入运算符，将切片中的后两个节点弹出，分别挂载在该运算符节点的左右叶子位置，再将该运算符节点从后方加入切片</li><li>若数据操作数，直接从后方插入切片</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *expression_tree_structrue)</span> <span class="title">din</span><span class="params">(data node_data)</span></span> &#123;</span><br><span class="line">indata := new_tree_node(data)</span><br><span class="line"><span class="keyword">if</span> data.exp != <span class="string">&quot;n&quot;</span> &#123;</span><br><span class="line">indata.left_node = e.tree[<span class="built_in">len</span>(e.tree)<span class="number">-2</span>]</span><br><span class="line">indata.right_node = e.tree[<span class="built_in">len</span>(e.tree)<span class="number">-1</span>]</span><br><span class="line">e.tree = <span class="built_in">append</span>(e.tree[:<span class="built_in">len</span>(e.tree)<span class="number">-2</span>], indata)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">e.tree = <span class="built_in">append</span>(e.tree, indata)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="遍历方法"><a href="#遍历方法" class="headerlink" title="遍历方法"></a>遍历方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *expression_tree_structrue)</span> <span class="title">preorder_traversal</span><span class="params">()</span></span> &#123;</span><br><span class="line">e.tree[<span class="number">0</span>].preorder_traversal()</span><br><span class="line">fmt.Println(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *expression_tree_structrue)</span> <span class="title">inorder_traversal</span><span class="params">()</span></span> &#123;</span><br><span class="line">e.tree[<span class="number">0</span>].inorder_traversal()</span><br><span class="line">fmt.Println(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *expression_tree_structrue)</span> <span class="title">postorder_traversal</span><span class="params">()</span></span> &#123;</span><br><span class="line">e.tree[<span class="number">0</span>].postorder_traversal()</span><br><span class="line">fmt.Println(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的K均值类聚</title>
      <link href="2017/12/10/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84K%E5%9D%87%E5%80%BC%E7%B1%BB%E8%81%9A/"/>
      <url>2017/12/10/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84K%E5%9D%87%E5%80%BC%E7%B1%BB%E8%81%9A/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p>无监督学习是相对于有监督学习的概念，无监督学习的样本只有数据没有标签（label），由模型自主发现样本之间的关系。可用于数据的类聚（类聚算法）和降维（主成分分析）等。</p><h2 id="无监督学习的结果评估"><a href="#无监督学习的结果评估" class="headerlink" title="无监督学习的结果评估"></a>无监督学习的结果评估</h2><h3 id="ARI指标"><a href="#ARI指标" class="headerlink" title="ARI指标"></a>ARI指标</h3><p>当样本有真实指标（带label）时，可以使用ARI（调整兰德指数），公式为<script type="math/tex">RI = \cfrac{a + b}{C_{2}^{n_{sample}}}</script> <script type="math/tex">ARI = \cfrac{RI - E(RI)}{max(RI) - E(RI)}</script><br>其中：</p><ul><li>a:在预测结果和测试结果中同属于一类的样本对数</li><li>b:在预测结果和测试结果中均不属于一类的样本对数</li></ul><p>该值越大，说明结果越好</p><h3 id="轮廓系数"><a href="#轮廓系数" class="headerlink" title="轮廓系数"></a>轮廓系数</h3><p>轮廓系数不需要先验知识，计算过程如下：</p><ol><li>对于每一个样本，计算同类样本中其他样本到该样本的评价距离a</li><li>分别计算其他类样本中各类样本到这个样本的平均距离，找到平均距离最近的一个类到该样本的平均距离</li><li>计算轮廓系数$sc=\cfrac{b - a}{max(a,b)}$</li></ol><p>对所有样本重复该过程，取平均值为轮廓系数</p><h2 id="k-均值类聚（k-mean）"><a href="#k-均值类聚（k-mean）" class="headerlink" title="k 均值类聚（k-mean）"></a>k 均值类聚（k-mean）</h2><p>k均值类聚是一种简单的无监督学习模型，该模型是基于距离的类聚模型，将把特征空间中距离相近的点进行类聚。<br>在训练k均值类聚模型中，有以下步骤：</p><ol><li>随机在特征空间中指定k个质心</li><li>计算每个样本到质心的距离，归入最近的质心一类</li><li>对每个质心的样本分别求平均，得到新的k个质心</li><li>第二步与第三步不断迭代，直到某次类聚结果不变（或改变归属的样本少于某个值），迭代结束</li></ol><h1 id="代码实现——手写数字识别"><a href="#代码实现——手写数字识别" class="headerlink" title="代码实现——手写数字识别"></a>代码实现——手写数字识别</h1><h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">digits_train = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra&#x27;</span>, header=<span class="literal">None</span>)</span><br><span class="line">digits_test = pd.read_csv(<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes&#x27;</span>, header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><h2 id="数据预处理——分离数据与label"><a href="#数据预处理——分离数据与label" class="headerlink" title="数据预处理——分离数据与label"></a>数据预处理——分离数据与label</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(digits_test[:<span class="number">2</span>])</span><br></pre></td></tr></table></figure><pre><code>   0   1   2   3   4   5   6   7   8   9  ...  55  56  57  58  59  60  61  62  \0   0   0   5  13   9   1   0   0   0   0 ...   0   0   0   6  13  10   0   0   1   0   0   0  12  13   5   0   0   0   0 ...   0   0   0   0  11  16  10   0      63  64  0   0   0  1   0   1  [2 rows x 65 columns]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_train = digits_train[np.arange(<span class="number">64</span>)]</span><br><span class="line">x_test = digits_test[np.arange(<span class="number">64</span>)]</span><br><span class="line">y_train = digits_train[<span class="number">64</span>]</span><br><span class="line">y_test = digits_test[<span class="number">64</span>]</span><br></pre></td></tr></table></figure><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">kme = KMeans(n_clusters=<span class="number">10</span>)</span><br><span class="line">model = kme.fit(x_train,y_train)</span><br><span class="line">y_pre = kme.predict(x_test)</span><br></pre></td></tr></table></figure><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="ARI指标-1"><a href="#ARI指标-1" class="headerlink" title="ARI指标"></a>ARI指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> adjusted_rand_score</span><br><span class="line">adjusted_rand_score(y_test,y_pre)</span><br></pre></td></tr></table></figure><pre><code>0.66305779493265249</code></pre><h3 id="轮廓系数-1"><a href="#轮廓系数-1" class="headerlink" title="轮廓系数"></a>轮廓系数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line">silhouette_score(y_test.values.reshape(-<span class="number">1</span>,<span class="number">1</span>),y_pre.reshape(-<span class="number">1</span>,<span class="number">1</span>),metric=<span class="string">&quot;euclidean&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>c:\users\qiank\appdata\local\programs\python\python35\lib\site-packages\sklearn\utils\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().  y = column_or_1d(y, warn=True)0.27296875226980805</code></pre>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>队列及其实现</title>
      <link href="2017/12/04/%E9%98%9F%E5%88%97%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/"/>
      <url>2017/12/04/%E9%98%9F%E5%88%97%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><p>队列即FIFO，一言以蔽之就是先进先出。比如入队列的顺序是1,2,3,4，那么出队列的顺序也是1,2,3,4</p><h1 id="队列的实现"><a href="#队列的实现" class="headerlink" title="队列的实现"></a>队列的实现</h1><h2 id="软件——GO语言实现"><a href="#软件——GO语言实现" class="headerlink" title="软件——GO语言实现"></a>软件——GO语言实现</h2><p>除了使用链表和数组实现链表以外，GO语言内置一种新的数据结构叫切片，可以实现类似于动态语言中的<code>list</code>的一些功能（切片和append），用这个数据结构实现队列非常容易</p><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> fifo <span class="keyword">struct</span> &#123;</span><br><span class="line">data   []<span class="keyword">int</span></span><br><span class="line">length <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="出队列方法"><a href="#出队列方法" class="headerlink" title="出队列方法"></a>出队列方法</h3><p><code>f.data[1:]</code>就是类似于python中的切片操作，表示切掉第一个值，剩下的保留</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *fifo)</span> <span class="title">Pop</span><span class="params">()</span> <span class="params">(<span class="keyword">int</span>, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(f.data) == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>, errors.New(<span class="string">&quot;empty fifo&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">temp := f.data[<span class="number">0</span>]</span><br><span class="line">f.data = f.data[<span class="number">1</span>:]</span><br><span class="line">f.length--</span><br><span class="line"><span class="keyword">return</span> temp, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="入队列方法"><a href="#入队列方法" class="headerlink" title="入队列方法"></a>入队列方法</h3><p>append方法是go语言自带的切片处理方法，第一个参数是要操作的切片，随后的参数都是要插入到切片之后的变量，返回值是完成插入后新的切片</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *fifo)</span> <span class="title">Push</span><span class="params">(din <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">f.data = <span class="built_in">append</span>(f.data, din)</span><br><span class="line">f.length++</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New_fifo</span><span class="params">()</span> *<span class="title">fifo</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;fifo&#123;[]<span class="keyword">int</span>&#123;&#125;, <span class="number">0</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="硬件——Verilog实现"><a href="#硬件——Verilog实现" class="headerlink" title="硬件——Verilog实现"></a>硬件——Verilog实现</h2><p>fifo由于其不改变数据顺序常用于实现buffer，常用双口ram+控制逻辑的方法实现fifo</p><h3 id="端口定义"><a href="#端口定义" class="headerlink" title="端口定义"></a>端口定义</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> fifo_control #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">8</span>,</span><br><span class="line"><span class="keyword">parameter</span> DEPTH_LOG = <span class="number">8</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> fifo_write_req,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]fifo_write_data,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> fifo_full,</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> fifo_read_req,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> fifo_empty,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> ram_write_req,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [DEPTH_LOG - <span class="number">1</span>:<span class="number">0</span>]ram_write_addr,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]ram_write_data,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [DEPTH_LOG - <span class="number">1</span>:<span class="number">0</span>]ram_read_addr</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="线网定义"><a href="#线网定义" class="headerlink" title="线网定义"></a>线网定义</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [DEPTH_LOG - <span class="number">1</span>:<span class="number">0</span>]write_point,read_point;</span><br><span class="line"><span class="keyword">wire</span> almost_full = (write_point == read_point - <span class="number">1&#x27;b1</span>)?<span class="number">1&#x27;b1</span>:<span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">wire</span> almost_empty = (write_point == read_point + <span class="number">1&#x27;b1</span>)?<span class="number">1&#x27;b1</span>:<span class="number">1&#x27;b0</span>;</span><br></pre></td></tr></table></figure><h3 id="写指针控制"><a href="#写指针控制" class="headerlink" title="写指针控制"></a>写指针控制</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">write_point &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">ram_write_req &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>((!fifo_full || fifo_read_req) &amp;&amp; fifo_write_req) <span class="keyword">begin</span></span><br><span class="line">write_point &lt;= write_point + <span class="number">1&#x27;b1</span>;</span><br><span class="line">ram_write_req &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">ram_write_req &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><code>(!fifo_full || fifo_read_req) &amp;&amp; fifo_write_req</code>为写执行条件：</p><ul><li>fifo不满且写请求</li><li>读写同时又请求（不可能溢出）</li></ul><h3 id="fifo满信号生成"><a href="#fifo满信号生成" class="headerlink" title="fifo满信号生成"></a>fifo满信号生成</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">fifo_full &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(fifo_read_req &amp;&amp; fifo_write_req) <span class="keyword">begin</span></span><br><span class="line">fifo_full &lt;= fifo_full;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(fifo_read_req) <span class="keyword">begin</span></span><br><span class="line">fifo_full &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(almost_full &amp;&amp; fifo_write_req) <span class="keyword">begin</span></span><br><span class="line">fifo_full &lt;= <span class="number">&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><ul><li><code>fifo_read_req &amp;&amp; fifo_write_req</code>当读写同时进行时，满信号状态不会改变</li><li><code>almost_full &amp;&amp; fifo_write_req</code>当写请求有效且只剩一个空位时，满信号置位</li><li><code>fifo_read_req</code>只要读过一次，不可能满</li></ul><h3 id="写地址与数据生成"><a href="#写地址与数据生成" class="headerlink" title="写地址与数据生成"></a>写地址与数据生成</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">ram_write_data &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">ram_write_addr &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">ram_write_data &lt;= fifo_write_data;</span><br><span class="line">ram_write_addr &lt;= write_point;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="读指针-地址控制"><a href="#读指针-地址控制" class="headerlink" title="读指针/地址控制"></a>读指针/地址控制</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">read_point &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">ram_read_addr &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(!fifo_empty &amp;&amp; fifo_read_req) <span class="keyword">begin</span></span><br><span class="line">read_point &lt;= read_point + <span class="number">1&#x27;b1</span>;</span><br><span class="line">ram_read_addr &lt;= read_point;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><ul><li><code>!fifo_empty &amp;&amp; fifo_read_req</code>当fifo非空时，读fifo</li></ul><h3 id="fifo空信号生成"><a href="#fifo空信号生成" class="headerlink" title="fifo空信号生成"></a>fifo空信号生成</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">fifo_empty &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(fifo_read_req &amp;&amp; fifo_write_req) <span class="keyword">begin</span></span><br><span class="line">fifo_empty &lt;= fifo_empty;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(fifo_write_req) <span class="keyword">begin</span></span><br><span class="line">fifo_empty &lt;= <span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(almost_empty &amp;&amp; fifo_read_req) <span class="keyword">begin</span></span><br><span class="line">fifo_empty &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>栈的应用</title>
      <link href="2017/12/03/%E6%A0%88%E7%9A%84%E5%BA%94%E7%94%A8/"/>
      <url>2017/12/03/%E6%A0%88%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="中缀表达式转换为后缀表达式"><a href="#中缀表达式转换为后缀表达式" class="headerlink" title="中缀表达式转换为后缀表达式"></a>中缀表达式转换为后缀表达式</h1><h2 id="后缀表达式"><a href="#后缀表达式" class="headerlink" title="后缀表达式"></a>后缀表达式</h2><p>做数学运算时，经常使用的是中缀表达式，即“操作数 运算符 操作数”。在计算机处理的时候更习惯后缀表达式，即“操作数 操作数 运算符”。例如<code>a + b * c</code>转换为后缀表达式<code>a b c * +</code>，使用栈可以将中缀表达式转换为后缀表达式，具体的方法为：</p><ul><li>扫描到数字直接输出</li><li>扫描到运算符则与栈顶比较，若扫描到的运算符优先级低于或等于栈顶运算符的优先级，则弹栈直到栈空或栈顶运算符优先级低于扫描到的运算符，之后运算符入栈；否则直接入栈。</li><li>若扫描到<code>)</code>，则一直弹栈直到<code>(</code>出栈</li></ul><h2 id="代码实现——调用链表栈"><a href="#代码实现——调用链表栈" class="headerlink" title="代码实现——调用链表栈"></a>代码实现——调用链表栈</h2><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Stack_data <span class="keyword">struct</span> &#123;</span><br><span class="line">Num <span class="keyword">int</span></span><br><span class="line">Op  <span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="运算符优先级MAP"><a href="#运算符优先级MAP" class="headerlink" title="运算符优先级MAP"></a>运算符优先级MAP</h2><p>使用一个全局变量map保存各个运算符的优先级</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> priority_dict = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>&#123;</span><br><span class="line"><span class="string">&quot;+&quot;</span>: <span class="number">0</span>,</span><br><span class="line"><span class="string">&quot;-&quot;</span>: <span class="number">0</span>,</span><br><span class="line"><span class="string">&quot;*&quot;</span>: <span class="number">1</span>,</span><br><span class="line"><span class="string">&quot;/&quot;</span>: <span class="number">1</span>,</span><br><span class="line"><span class="string">&quot;(&quot;</span>: <span class="number">-1</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> To_postfix <span class="keyword">struct</span> &#123;</span><br><span class="line">data_stack base_stack.Link_stack</span><br><span class="line">result     []base_stack.Stack_data</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="计算优先级"><a href="#计算优先级" class="headerlink" title="计算优先级"></a>计算优先级</h3><p>根据栈顶运算符优先级和传入运算符优先级比较，确定传入的运算符是否直接入栈</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *To_postfix)</span> <span class="title">priority_compute</span><span class="params">(in_data base_stack.Stack_data)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> t.data_stack.Is_empty() &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">top_data, _ := t.data_stack.Get_head()</span><br><span class="line"><span class="keyword">return</span> priority_dict[in_data.Op] &gt; priority_dict[top_data.Op]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="数字处理"><a href="#数字处理" class="headerlink" title="数字处理"></a>数字处理</h3><p>数字不入栈，直接进入结果切片</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *To_postfix)</span> <span class="title">handle_num</span><span class="params">(in_data base_stack.Stack_data)</span></span> &#123;</span><br><span class="line">t.result = <span class="built_in">append</span>(t.result, in_data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="左括号处理"><a href="#左括号处理" class="headerlink" title="左括号处理"></a>左括号处理</h3><p>左括号直接入栈</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">func (t *To_postfix) handle_left_bracket(in_data base_stack.Stack_data) &#123;</span><br><span class="line">t.data_stack.Push(in_data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="右括号处理"><a href="#右括号处理" class="headerlink" title="右括号处理"></a>右括号处理</h3><p>右括号不入栈，弹栈直到一个左括号出栈</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *To_postfix)</span> <span class="title">handle_right_bracket</span><span class="params">(in_data base_stack.Stack_data)</span></span> &#123;</span><br><span class="line">top_data, err := t.data_stack.Pop()</span><br><span class="line"><span class="keyword">for</span> err == <span class="literal">nil</span> &amp;&amp; top_data.Op != <span class="string">&quot;(&quot;</span> &#123;</span><br><span class="line">t.result = <span class="built_in">append</span>(t.result, top_data)</span><br><span class="line">top_data, err = t.data_stack.Pop()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运算符处理"><a href="#运算符处理" class="headerlink" title="运算符处理"></a>运算符处理</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *To_postfix)</span> <span class="title">handle_op</span><span class="params">(in_data base_stack.Stack_data)</span></span> &#123;</span><br><span class="line">tempdata := base_stack.Stack_data&#123;&#125;</span><br><span class="line">can_insert := t.priority_compute(in_data)</span><br><span class="line"><span class="keyword">for</span> !can_insert &#123;</span><br><span class="line">tempdata, _ = t.data_stack.Pop()</span><br><span class="line">t.result = <span class="built_in">append</span>(t.result, tempdata)</span><br><span class="line">&#125;</span><br><span class="line">t.data_stack.Push(in_data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总处理方法"><a href="#总处理方法" class="headerlink" title="总处理方法"></a>总处理方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *To_postfix)</span> <span class="title">Handle</span><span class="params">(din []base_stack.Stack_data)</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> temp base_stack.Stack_data</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> din &#123;</span><br><span class="line"><span class="keyword">switch</span> din[i].Op &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;n&quot;</span>:</span><br><span class="line">t.handle_num(din[i])</span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;(&quot;</span>:</span><br><span class="line">t.handle_left_bracket(din[i])</span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;)&quot;</span>:</span><br><span class="line">t.handle_right_bracket(din[i])</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">t.handle_op(din[i])</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> !t.data_stack.Is_empty() &#123;</span><br><span class="line">temp, _ = t.data_stack.Pop()</span><br><span class="line">t.result = <span class="built_in">append</span>(t.result, temp)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="结果返回函数"><a href="#结果返回函数" class="headerlink" title="结果返回函数"></a>结果返回函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *To_postfix)</span> <span class="title">Return_result</span><span class="params">()</span> []<span class="title">base_stack</span>.<span class="title">Stack_data</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> t.result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New_to_post</span><span class="params">()</span> *<span class="title">To_postfix</span></span> &#123;</span><br><span class="line">link := *base_stack.New_link_stack()</span><br><span class="line">topost := To_postfix&#123;&#125;</span><br><span class="line">topost.data_stack = link</span><br><span class="line"><span class="keyword">return</span> &amp;topost</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="后缀表达式的计算"><a href="#后缀表达式的计算" class="headerlink" title="后缀表达式的计算"></a>后缀表达式的计算</h1><h2 id="计算方法"><a href="#计算方法" class="headerlink" title="计算方法"></a>计算方法</h2><p>后缀表达式的计算比较简单，顺序扫描整个后缀表达式：</p><ul><li>若遇到数字，直接入栈</li><li>若遇到运算符，弹栈两次取出两个数字，按运算符运算，将结果再次入栈</li></ul><p>这样扫描完整个后缀表达式之后，栈中就应该只有一个数，弹栈即可得到结果</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="结构体-1"><a href="#结构体-1" class="headerlink" title="结构体"></a>结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Compute <span class="keyword">struct</span> &#123;</span><br><span class="line">data_stack base_stack.Link_stack</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运算符处理方法"><a href="#运算符处理方法" class="headerlink" title="运算符处理方法"></a>运算符处理方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Compute)</span> <span class="title">operator</span><span class="params">(op base_stack.Stack_data)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">data1, _ := c.data_stack.Pop()</span><br><span class="line">data2, _ := c.data_stack.Pop()</span><br><span class="line"><span class="keyword">switch</span> op.Op &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;+&quot;</span>:</span><br><span class="line"><span class="keyword">return</span> data1.Num + data2.Num</span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;-&quot;</span>:</span><br><span class="line"><span class="keyword">return</span> data1.Num - data2.Num</span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;*&quot;</span>:</span><br><span class="line"><span class="keyword">return</span> data1.Num * data2.Num</span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;&quot;</span>:</span><br><span class="line"><span class="keyword">return</span> data1.Num / data2.Num</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> data1.Num</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运算方法"><a href="#运算方法" class="headerlink" title="运算方法"></a>运算方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Compute)</span> <span class="title">Compute</span><span class="params">(expression []base_stack.Stack_data)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> expression &#123;</span><br><span class="line"><span class="keyword">if</span> expression[i].Op == <span class="string">&quot;n&quot;</span> &#123;</span><br><span class="line">c.data_stack.Push(expression[i])</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">c.data_stack.Push(base_stack.Stack_data&#123;c.operator(expression[i]), <span class="string">&quot;n&quot;</span>&#125;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="结果返回方法"><a href="#结果返回方法" class="headerlink" title="结果返回方法"></a>结果返回方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Compute)</span> <span class="title">Result</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">result, _ := c.data_stack.Pop()</span><br><span class="line"><span class="keyword">return</span> result.Num</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的一些回归器模型</title>
      <link href="2017/12/03/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9B%9E%E5%BD%92%E5%99%A8%E6%A8%A1%E5%9E%8B/"/>
      <url>2017/12/03/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9B%9E%E5%BD%92%E5%99%A8%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h2 id="支持向量机回归器"><a href="#支持向量机回归器" class="headerlink" title="支持向量机回归器"></a>支持向量机回归器</h2><p>支持向量机回归器与分类器相似，关键在于从大量样本中选出对模型训练最有用的一部分向量。回归器和分类器的区别仅在于label为连续值</p><h2 id="K临近回归器"><a href="#K临近回归器" class="headerlink" title="K临近回归器"></a>K临近回归器</h2><p>K临近回归器任然是取特征向量最接近的k个训练样本，计算这几个样本的平均值获得结果（分类器是投票）</p><h2 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h2><p>回归树相对于分类树的最大区别在于叶子节点的值时“连续值”，理论上来书回归树也是一种分类器，只是分的类别较多</p><h2 id="集成回归器"><a href="#集成回归器" class="headerlink" title="集成回归器"></a>集成回归器</h2><p>随机森林和提升树本质上来说都是决策树的衍生，回归树也可以衍生出回归版本的随机森林和提升树。另外，随机森林还可以衍生出极端随机森林，其每个节点的特征划分并不是完全随机的</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line">print(boston.DESCR)</span><br></pre></td></tr></table></figure><pre><code>Boston House Prices dataset===========================Notes------Data Set Characteristics:      :Number of Instances: 506     :Number of Attributes: 13 numeric/categorical predictive    :Median Value (attribute 14) is usually the target    :Attribute Information (in order):        - CRIM     per capita crime rate by town        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.        - INDUS    proportion of non-retail business acres per town        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)        - NOX      nitric oxides concentration (parts per 10 million)        - RM       average number of rooms per dwelling        - AGE      proportion of owner-occupied units built prior to 1940        - DIS      weighted distances to five Boston employment centres        - RAD      index of accessibility to radial highways        - TAX      full-value property-tax rate per $10,000        - PTRATIO  pupil-teacher ratio by town        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town        - LSTAT    % lower status of the population        - MEDV     Median value of owner-occupied homes in $1000&#39;s    :Missing Attribute Values: None    :Creator: Harrison, D. and Rubinfeld, D.L.This is a copy of UCI ML housing dataset.http://archive.ics.uci.edu/ml/datasets/HousingThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.The Boston house-price data of Harrison, D. and Rubinfeld, D.L. &#39;Hedonicprices and the demand for clean air&#39;, J. Environ. Economics &amp; Management,vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics...&#39;, Wiley, 1980.   N.B. Various transformations are used in the table onpages 244-261 of the latter.The Boston house-price data has been used in many machine learning papers that address regressionproblems.   **References**   - Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&#39;, Wiley, 1980. 244-261.   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)</code></pre><h3 id="数据分割"><a href="#数据分割" class="headerlink" title="数据分割"></a>数据分割</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(boston.data,boston.target,random_state=<span class="number">33</span>,test_size=<span class="number">0.25</span>)</span><br><span class="line">print(x_test.shape)</span><br></pre></td></tr></table></figure><pre><code>(127, 13)    </code></pre><h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss_x,ss_y = StandardScaler(),StandardScaler()</span><br><span class="line">x_train = ss_x.fit_transform(x_train)</span><br><span class="line">x_test = ss_x.transform(x_test)</span><br><span class="line">y_train = ss_y.fit_transform(y_train.reshape([-<span class="number">1</span>,<span class="number">1</span>])).reshape(-<span class="number">1</span>)</span><br><span class="line">y_test = ss_y.transform(y_test.reshape([-<span class="number">1</span>,<span class="number">1</span>])).reshape(-<span class="number">1</span>)</span><br><span class="line">print(y_train.shape)</span><br></pre></td></tr></table></figure><pre><code>(379,)</code></pre><h2 id="模型训练与评估"><a href="#模型训练与评估" class="headerlink" title="模型训练与评估"></a>模型训练与评估</h2><h3 id="支持向量机回归器-1"><a href="#支持向量机回归器-1" class="headerlink" title="支持向量机回归器"></a>支持向量机回归器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br></pre></td></tr></table></figure><h4 id="线性核函数"><a href="#线性核函数" class="headerlink" title="线性核函数"></a>线性核函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">l_svr = SVR(kernel=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">l_svr.fit(x_train,y_train)</span><br><span class="line">l_svr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.65171709742960804</code></pre><h4 id="多项式核函数"><a href="#多项式核函数" class="headerlink" title="多项式核函数"></a>多项式核函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n_svr = SVR(kernel=<span class="string">&quot;poly&quot;</span>)</span><br><span class="line">n_svr.fit(x_train,y_train)</span><br><span class="line">n_svr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.40445405800289286</code></pre><h4 id="径向基核函数"><a href="#径向基核函数" class="headerlink" title="径向基核函数"></a>径向基核函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r_svr = SVR(kernel=<span class="string">&quot;rbf&quot;</span>)</span><br><span class="line">r_svr.fit(x_train,y_train)</span><br><span class="line">r_svr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.75640689122739346</code></pre><h3 id="K临近回归器-1"><a href="#K临近回归器-1" class="headerlink" title="K临近回归器"></a>K临近回归器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line">knn = KNeighborsRegressor(weights=<span class="string">&quot;uniform&quot;</span>)</span><br><span class="line">knn.fit(x_train,y_train)</span><br><span class="line">knn.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.69034545646065615</code></pre><h3 id="回归树-1"><a href="#回归树-1" class="headerlink" title="回归树"></a>回归树</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">dt = DecisionTreeRegressor()</span><br><span class="line">dt.fit(x_train,y_train)</span><br><span class="line">dt.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.68783308418825428</code></pre><h3 id="集成模型"><a href="#集成模型" class="headerlink" title="集成模型"></a>集成模型</h3><h4 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">rfr = RandomForestRegressor()</span><br><span class="line">rfr.fit(x_train,y_train)</span><br><span class="line">rfr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.79055864833158895</code></pre><h4 id="极端森林"><a href="#极端森林" class="headerlink" title="极端森林"></a>极端森林</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesRegressor</span><br><span class="line">etr = ExtraTreesRegressor()</span><br><span class="line">etr.fit(x_train,y_train)</span><br><span class="line">etr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.7349024110033624</code></pre><h4 id="提升树"><a href="#提升树" class="headerlink" title="提升树"></a>提升树</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line">gbr = GradientBoostingRegressor()</span><br><span class="line">gbr.fit(x_train,y_train)</span><br><span class="line">gbr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.84501318676123161</code></pre>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>栈与栈的实现</title>
      <link href="2017/11/28/%E6%A0%88%E4%B8%8E%E6%A0%88%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
      <url>2017/11/28/%E6%A0%88%E4%B8%8E%E6%A0%88%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h1><p>栈是一种基础的数据结构，只从一端读写数据。基本特点就”后进先出“，例如顺序入栈1,2,3,4,5，再顺序出栈是5,4,3,2,1</p><h1 id="栈的基本操作"><a href="#栈的基本操作" class="headerlink" title="栈的基本操作"></a>栈的基本操作</h1><p>栈的基本操作有如下几种：</p><ul><li>检测栈是否为空</li><li>返回栈存储数据的数量</li><li>返回栈顶数据/返回栈顶数据并将其弹出</li><li>将数据压入栈</li><li>清空栈</li></ul><h1 id="栈的实现"><a href="#栈的实现" class="headerlink" title="栈的实现"></a>栈的实现</h1><h2 id="软件实现——GO语言"><a href="#软件实现——GO语言" class="headerlink" title="软件实现——GO语言"></a>软件实现——GO语言</h2><p>软件的栈可以使用链表基本结构实现或使用数组实现：使用链表栈的优势是栈的容量几乎不限，确定是入栈出栈都需要开销较大的声明结构体；数组实现的优势是速度快（自增自减一般有指令实现），但是空间必须预先指定。</p><h3 id="统一adt接口"><a href="#统一adt接口" class="headerlink" title="统一adt接口"></a>统一adt接口</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Stack_adt <span class="keyword">interface</span> &#123;</span><br><span class="line">Is_empty() <span class="keyword">bool</span></span><br><span class="line">Get_depth() <span class="keyword">int</span></span><br><span class="line">Push(data Stack_data)</span><br><span class="line">Pop() (Stack_data, error)</span><br><span class="line">Get_head() (Stack_data, error)</span><br><span class="line">Clear()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="链表栈"><a href="#链表栈" class="headerlink" title="链表栈"></a>链表栈</h3><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> stack_node <span class="keyword">struct</span> &#123;</span><br><span class="line">data Stack_data</span><br><span class="line">next *stack_node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Link_stack <span class="keyword">struct</span> &#123;</span><br><span class="line">length <span class="keyword">int</span></span><br><span class="line">head   *stack_node</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="判空方法"><a href="#判空方法" class="headerlink" title="判空方法"></a>判空方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *Link_stack)</span> <span class="title">Is_empty</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> l.head.next == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="获取栈中数据量方法"><a href="#获取栈中数据量方法" class="headerlink" title="获取栈中数据量方法"></a>获取栈中数据量方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *Link_stack)</span> <span class="title">Get_depth</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> l.length</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="压栈方法"><a href="#压栈方法" class="headerlink" title="压栈方法"></a>压栈方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *Link_stack)</span> <span class="title">Push</span><span class="params">(data Stack_data)</span></span> &#123;</span><br><span class="line">new_node := stack_node&#123;data, l.head.next&#125;</span><br><span class="line">l.head.next = &amp;new_node</span><br><span class="line">l.length++</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于入栈数据，建立链表节点并将其插入到头结点后（读取位置），保证后进先出</p><h4 id="弹栈方法"><a href="#弹栈方法" class="headerlink" title="弹栈方法"></a>弹栈方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *Link_stack)</span> <span class="title">Pop</span><span class="params">()</span> <span class="params">(Stack_data, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> l.Is_empty() &#123;</span><br><span class="line"><span class="keyword">return</span> Stack_data&#123;&#125;, errors.New(<span class="string">&quot;empty stack&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">data := l.head.next.data</span><br><span class="line">l.head.next = l.head.next.next</span><br><span class="line">l.length--</span><br><span class="line"><span class="keyword">return</span> data, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>直接取出头结点后的节点，若本来就是空栈则返回一个空栈的<code>errors</code>异常，否则该异常为<code>nil</code></p><h4 id="获取栈顶数据（仅获取，不弹出）"><a href="#获取栈顶数据（仅获取，不弹出）" class="headerlink" title="获取栈顶数据（仅获取，不弹出）"></a>获取栈顶数据（仅获取，不弹出）</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *Link_stack)</span> <span class="title">Get_head</span><span class="params">()</span> <span class="params">(Stack_data, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> l.Is_empty() &#123;</span><br><span class="line"><span class="keyword">return</span> Stack_data&#123;&#125;, errors.New(<span class="string">&quot;empty stack&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> l.head.next.data, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>与弹栈相同，不同的是读取后不将读取的节点移出链表</p><h4 id="清空栈"><a href="#清空栈" class="headerlink" title="清空栈"></a>清空栈</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(l *Link_stack)</span> <span class="title">Clear</span><span class="params">()</span></span> &#123;</span><br><span class="line">_, err := l.Pop()</span><br><span class="line"><span class="keyword">for</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">_, err = l.Pop()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不断弹栈并查看异常（抛弃读出数据），直到报出空栈异常（返回异常不为<code>nil</code>）</p><h3 id="数组栈"><a href="#数组栈" class="headerlink" title="数组栈"></a>数组栈</h3><h4 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> DEPTH = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Array_stack <span class="keyword">struct</span> &#123;</span><br><span class="line">data   [DEPTH]Stack_data</span><br><span class="line">length <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>data为数组，用于存储数据；length为存入数据的数量，同时也是“栈顶指针”，标记入栈位置</p><h4 id="判空方法-1"><a href="#判空方法-1" class="headerlink" title="判空方法"></a>判空方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *Array_stack)</span> <span class="title">Is_empty</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> a.length == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="获取栈中数据量方法-1"><a href="#获取栈中数据量方法-1" class="headerlink" title="获取栈中数据量方法"></a>获取栈中数据量方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *Array_stack)</span> <span class="title">Get_depth</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> a.length</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="压栈方法-1"><a href="#压栈方法-1" class="headerlink" title="压栈方法"></a>压栈方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *Array_stack)</span> <span class="title">Push</span><span class="params">(data Stack_data)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> a.length &gt;= DEPTH &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">a.data[a.length] = data</span><br><span class="line">a.length++</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于入栈数据，若入栈位置已经超出数组尺寸，则栈满，不入栈。否则将输入数据插入<code>length</code>标记的入栈位置，并将<code>length</code>自加</p><h4 id="弹栈方法-1"><a href="#弹栈方法-1" class="headerlink" title="弹栈方法"></a>弹栈方法</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *Array_stack)</span> <span class="title">Pop</span><span class="params">()</span> <span class="params">(Stack_data, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> a.length == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> Stack_data&#123;&#125;, errors.New(<span class="string">&quot;empty stack&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">a.length--</span><br><span class="line"><span class="keyword">return</span> a.data[a.length], <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先将<code>length</code>自减，获得上一个入栈元素的位置，再返回该值</p><h4 id="获取栈顶数据（仅获取，不弹出）-1"><a href="#获取栈顶数据（仅获取，不弹出）-1" class="headerlink" title="获取栈顶数据（仅获取，不弹出）"></a>获取栈顶数据（仅获取，不弹出）</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *Array_stack)</span> <span class="title">Get_head</span><span class="params">()</span> <span class="params">(Stack_data, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> a.length == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> Stack_data&#123;&#125;, errors.New(<span class="string">&quot;empty stack&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> a.data[a.length<span class="number">-1</span>], <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>与弹栈相同，不同的是读取后不改变“栈顶指针”的位置</p><h4 id="清空栈-1"><a href="#清空栈-1" class="headerlink" title="清空栈"></a>清空栈</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *Array_stack)</span> <span class="title">Clear</span><span class="params">()</span></span> &#123;</span><br><span class="line">a.length = <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 直接将“栈顶指针”清零即可实现清空栈</p><h3 id="切片栈"><a href="#切片栈" class="headerlink" title="切片栈"></a>切片栈</h3><p>切片是一种Go语言特有的数据结构，类似于动态数组，使用切片可以实现深度可变的栈。</p><h2 id="硬件实现——Verilog语言"><a href="#硬件实现——Verilog语言" class="headerlink" title="硬件实现——Verilog语言"></a>硬件实现——Verilog语言</h2><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> stack_controller #(</span><br><span class="line"><span class="keyword">parameter</span> DEPTH_LOG = <span class="number">4</span>,</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">8</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> stack_write_req,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]stack_write_data,</span><br><span class="line"><span class="keyword">input</span> stack_read_req,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> stack_empty,</span><br><span class="line"><span class="keyword">output</span> stack_full,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> ram_write_req,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [DEPTH_LOG - <span class="number">1</span>:<span class="number">0</span>]ram_addr,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]ram_write_data</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [DEPTH_LOG:<span class="number">0</span>]stack_point;</span><br><span class="line"><span class="keyword">wire</span> is_full = (stack_point == <span class="number">2</span> ** DEPTH_LOG)?<span class="number">1&#x27;b1</span>:<span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">wire</span> is_empty = (stack_point == <span class="number">&#x27;b0</span>)?<span class="number">1&#x27;b1</span>:<span class="number">1&#x27;b0</span>;</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> <span class="comment">//control point of stack</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">stack_point &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(stack_write_req &amp;&amp; stack_read_req) <span class="keyword">begin</span> <span class="comment">//lock</span></span><br><span class="line">stack_point &lt;= stack_point;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(stack_write_req &amp;&amp; !is_full) <span class="keyword">begin</span> <span class="comment">//write when stack is not full</span></span><br><span class="line">stack_point &lt;= stack_point + <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(stack_read_req &amp;&amp; !is_empty) <span class="keyword">begin</span> <span class="comment">// read when stack is not empty</span></span><br><span class="line">stack_point &lt;= stack_point - <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">assign</span> stack_full = stack_point[DEPTH_LOG];</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> <span class="comment">//generate empty signal</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">stack_empty &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(ram_addr == <span class="number">&#x27;b0</span> &amp;&amp; is_empty) <span class="keyword">begin</span> <span class="comment">// delay signal</span></span><br><span class="line">stack_empty &lt;= <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">stack_empty &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> <span class="comment">//generate ram_write_req</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">ram_write_req &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(!is_full) <span class="keyword">begin</span></span><br><span class="line">ram_write_req &lt;= stack_write_req;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">ram_write_req &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span> <span class="comment">//prepare the addr and data for push</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">ram_addr &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">ram_write_data &lt;= stack_write_data;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">ram_addr &lt;= stack_point[DEPTH_LOG - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line">ram_write_data &lt;= stack_write_data;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p>Verilog实现栈的关键点有三个：</p><ul><li>控制栈顶指针</li><li>栈满信号生成</li><li>栈空信号生成</li></ul><p>该硬件栈的栈顶指针指向下一个入栈的位置，且位数比ram地址位多一位，当最高位为1时，可认为栈溢出，停止写入；同理，当栈顶指针指向0，该栈为空栈。</p>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的线性回归器</title>
      <link href="2017/11/25/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%99%A8/"/>
      <url>2017/11/25/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h2 id="线性回归器"><a href="#线性回归器" class="headerlink" title="线性回归器"></a>线性回归器</h2><p>相比于线性分类器，线性回归器更加自然。回归任务的label是连续的变量（不像分类任务label是离散变量），线性回归器就是直接通过权值与输入对应相乘再相加直接计算出结果<script type="math/tex">y = w^{T}*x + b</script><br>其中，w为权值，x是输入，y是输出</p><h2 id="回归器的优化"><a href="#回归器的优化" class="headerlink" title="回归器的优化"></a>回归器的优化</h2><p>与分类器类似，回归器也是通过梯度优化的，一般来说分类问题常用均方误差函数来标定结果的质量（即代价函数）<script type="math/tex">L(w,b) = \sum (y - y')</script><br>其中y为模型输出，y’为期望值。</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="数据集导入"><a href="#数据集导入" class="headerlink" title="数据集导入"></a>数据集导入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line">print(boston.DESCR)</span><br></pre></td></tr></table></figure><pre><code>Boston House Prices dataset===========================Notes------Data Set Characteristics:      :Number of Instances: 506     :Number of Attributes: 13 numeric/categorical predictive    :Median Value (attribute 14) is usually the target    :Attribute Information (in order):        - CRIM     per capita crime rate by town        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.        - INDUS    proportion of non-retail business acres per town        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)        - NOX      nitric oxides concentration (parts per 10 million)        - RM       average number of rooms per dwelling        - AGE      proportion of owner-occupied units built prior to 1940        - DIS      weighted distances to five Boston employment centres        - RAD      index of accessibility to radial highways        - TAX      full-value property-tax rate per $10,000        - PTRATIO  pupil-teacher ratio by town        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town        - LSTAT    % lower status of the population        - MEDV     Median value of owner-occupied homes in $1000&#39;s    :Missing Attribute Values: None    :Creator: Harrison, D. and Rubinfeld, D.L.This is a copy of UCI ML housing dataset.http://archive.ics.uci.edu/ml/datasets/HousingThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.The Boston house-price data of Harrison, D. and Rubinfeld, D.L. &#39;Hedonicprices and the demand for clean air&#39;, J. Environ. Economics &amp; Management,vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics...&#39;, Wiley, 1980.   N.B. Various transformations are used in the table onpages 244-261 of the latter.The Boston house-price data has been used in many machine learning papers that address regressionproblems.   **References**   - Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&#39;, Wiley, 1980. 244-261.   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)    </code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="数据分割"><a href="#数据分割" class="headerlink" title="数据分割"></a>数据分割</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x_data,boston.target,random_state=<span class="number">33</span>,test_size=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure><h3 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># print(type(y_test))</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss_x = StandardScaler()</span><br><span class="line">ss_y = StandardScaler()</span><br><span class="line"></span><br><span class="line">x_train = ss_x.fit_transform(x_train)</span><br><span class="line">x_test = ss_x.transform(x_test)</span><br><span class="line"></span><br><span class="line">y_train = ss_y.fit_transform(y_train.reshape(-<span class="number">1</span>,<span class="number">1</span>)).reshape(-<span class="number">1</span>)</span><br><span class="line">y_test = ss_y.transform(y_test.reshape(-<span class="number">1</span>,<span class="number">1</span>)).reshape(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(y_train.shape)</span><br></pre></td></tr></table></figure><pre><code>(379,) </code></pre><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><h3 id="线性回归模型"><a href="#线性回归模型" class="headerlink" title="线性回归模型"></a>线性回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</code></pre><h3 id="SGD回归模型"><a href="#SGD回归模型" class="headerlink" title="SGD回归模型"></a>SGD回归模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line">sgd = SGDRegressor()</span><br><span class="line">sgd.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>c:\users\qiank\appdata\local\programs\python\python35\lib\site-packages\sklearn\linear_model\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in &lt;class &#39;sklearn.linear_model.stochastic_gradient.SGDRegressor&#39;&gt; in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.  &quot;and default tol will be 1e-3.&quot; % type(self), FutureWarning)SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,       fit_intercept=True, l1_ratio=0.15, learning_rate=&#39;invscaling&#39;,       loss=&#39;squared_loss&#39;, max_iter=5, n_iter=None, penalty=&#39;l2&#39;,       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,       warm_start=False)</code></pre><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="自带评估器"><a href="#自带评估器" class="headerlink" title="自带评估器"></a>自带评估器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.67634038309987021</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sgd.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.65777103520375069</code></pre><h3 id="平均绝对误差"><a href="#平均绝对误差" class="headerlink" title="平均绝对误差"></a>平均绝对误差</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line">print(<span class="string">&quot;lr:&quot;</span>,mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(lr.predict(x_test))))</span><br><span class="line">print(<span class="string">&quot;sgd:&quot;</span>,mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(sgd.predict(x_test))))</span><br></pre></td></tr></table></figure><pre><code>lr: 0.379976703913sgd: 0.377629585475</code></pre><h3 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line">print(<span class="string">&quot;lr:&quot;</span>,mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(lr.predict(x_test))))</span><br><span class="line">print(<span class="string">&quot;sgd:&quot;</span>,mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(sgd.predict(x_test))))</span><br></pre></td></tr></table></figure><pre><code>lr: 0.29143408577sgd: 0.30815455581</code></pre><h3 id="R-squared误差（1-回归平方误差-数据内方差）"><a href="#R-squared误差（1-回归平方误差-数据内方差）" class="headerlink" title="R-squared误差（1 - 回归平方误差/数据内方差）"></a>R-squared误差（1 - 回归平方误差/数据内方差）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">print(<span class="string">&quot;lr:&quot;</span>,r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(lr.predict(x_test))))</span><br><span class="line">print(<span class="string">&quot;sgd:&quot;</span>,r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(sgd.predict(x_test))))</span><br></pre></td></tr></table></figure><pre><code>lr: 0.6763403831sgd: 0.657771035204</code></pre>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>表的应用——排序与多项式</title>
      <link href="2017/11/22/%E8%A1%A8%E7%9A%84%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E6%8E%92%E5%BA%8F%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F/"/>
      <url>2017/11/22/%E8%A1%A8%E7%9A%84%E5%BA%94%E7%94%A8%E2%80%94%E2%80%94%E6%8E%92%E5%BA%8F%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><h2 id="朴素排序"><a href="#朴素排序" class="headerlink" title="朴素排序"></a>朴素排序</h2><p>在链表建立的过程中可以直接完成排序功能，即建立一个新链表并将源数据一个一个存进新链表中，每个元素存储的位置在小于这个元素的节点和大于这个元素的节点之间</p><h3 id="排序部分"><a href="#排序部分" class="headerlink" title="排序部分"></a>排序部分</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *sort_table)</span> <span class="title">append</span><span class="params">(data <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">node := s.head</span><br><span class="line"><span class="keyword">for</span> (node.next != <span class="literal">nil</span>) &amp;&amp; (node.next.data.data &lt;= data) &#123;</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line">new_data := table_data&#123;data&#125;</span><br><span class="line">new_node := &amp;table_node&#123;new_data, node.next&#125;</span><br><span class="line">node.next = new_node</span><br><span class="line">s.length++</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>判断要插入的值是否刚比下一个值小，若小则插入这一个节点与下一个节点之间。若无比要插入值大的节点则将待插入值插入链表的最后</p><h3 id="遍历部分"><a href="#遍历部分" class="headerlink" title="遍历部分"></a>遍历部分</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *sort_table)</span> <span class="title">return_result</span><span class="params">()</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">result := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">node := s.head.next</span><br><span class="line"><span class="keyword">for</span> node != <span class="literal">nil</span> &#123;</span><br><span class="line">result = <span class="built_in">append</span>(result, node.data.data)</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从头开始顺序遍历，直到所有值被取出</p><h2 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h2><p>这是一种类似于桶排序的排序方法，以基10排序为例，首先建立10个桶，分别是0~9，按十进制数的最低位送进对应的桶中，再<strong>按桶顺序</strong>取出，<strong>依次</strong>再按次低位送进桶中，重复到最高位，再<strong>依次取出</strong>则得到排序结果（顺序均是从0桶到9桶，同一个桶先进先出）</p><h3 id="桶ADT"><a href="#桶ADT" class="headerlink" title="桶ADT"></a>桶ADT</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> card_sort <span class="keyword">struct</span> &#123;</span><br><span class="line">link_table</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *card_sort)</span> <span class="title">pop</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.head.next == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">data := c.head.next.data.data</span><br><span class="line">c.head.next = c.head.next.next</span><br><span class="line"><span class="keyword">return</span> data</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>“继承”链表的方法，添加从头取出节点的方法<code>pop()</code></p><h3 id="初始化桶函数"><a href="#初始化桶函数" class="headerlink" title="初始化桶函数"></a>初始化桶函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">initial_bucket</span><span class="params">()</span> [10]*<span class="title">card_sort</span></span> &#123;</span><br><span class="line">bucket := [<span class="number">10</span>]*card_sort&#123;&#125;</span><br><span class="line">new_data := link_table&#123;table_node&#123;table_data&#123;&#125;, <span class="literal">nil</span>&#125;, <span class="number">0</span>&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(bucket); i++ &#123;</span><br><span class="line">bucket[i] = &amp;card_sort&#123;new_data&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> bucket</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>初始化一个尺寸为10的桶数组</p><h3 id="获得基数函数"><a href="#获得基数函数" class="headerlink" title="获得基数函数"></a>获得基数函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">get_num</span><span class="params">(num <span class="keyword">int</span>, data <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">int</span>(<span class="keyword">float64</span>(data)/math.Pow(<span class="number">10</span>, <span class="keyword">float64</span>(num))) % <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>获取传入参数data的第num（从0开始计数）位数</p><h3 id="入桶函数"><a href="#入桶函数" class="headerlink" title="入桶函数"></a>入桶函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">in_bucket</span><span class="params">(data []<span class="keyword">int</span>, num <span class="keyword">int</span>)</span> [10]*<span class="title">card_sort</span></span> &#123;</span><br><span class="line">bucket := initial_bucket()</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> data &#123;</span><br><span class="line">bucket[get_num(num, data[i])].<span class="built_in">append</span>(table_data&#123;data[i]&#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> bucket</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>按顺序</strong>将切片带入的数据根据获得的基数送入对应的桶中</p><h3 id="出桶函数"><a href="#出桶函数" class="headerlink" title="出桶函数"></a>出桶函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">out_bucket</span><span class="params">(bucket [10]*card_sort)</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">temp := <span class="number">0</span></span><br><span class="line">data := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> bucket &#123;</span><br><span class="line">temp = bucket[i].pop()</span><br><span class="line"><span class="keyword">for</span> temp != <span class="number">-1</span> &#123;</span><br><span class="line">data = <span class="built_in">append</span>(data, temp)</span><br><span class="line">temp = bucket[i].pop()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// fmt.Println(data)</span></span><br><span class="line"><span class="keyword">return</span> data</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从桶0开始<strong>依次</strong>将桶中的数据取出放入一个切片中</p><h3 id="一次桶排序函数"><a href="#一次桶排序函数" class="headerlink" title="一次桶排序函数"></a>一次桶排序函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">card_sort_step</span><span class="params">(bucket [10]*card_sort, num <span class="keyword">int</span>)</span> [10]*<span class="title">card_sort</span></span> &#123;</span><br><span class="line">data := out_bucket(bucket)</span><br><span class="line"><span class="keyword">return</span> in_bucket(data, num)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先出桶，后按给定的位数num入桶</p><h3 id="桶排序函数"><a href="#桶排序函数" class="headerlink" title="桶排序函数"></a>桶排序函数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">card_sort_eval</span><span class="params">(data []<span class="keyword">int</span>, num <span class="keyword">int</span>)</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">bucket := in_bucket(data, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">1</span>; i &lt; num; i++ &#123;</span><br><span class="line">bucket = card_sort_step(bucket, i)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> out_bucket(bucket)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="多项式ADT"><a href="#多项式ADT" class="headerlink" title="多项式ADT"></a>多项式ADT</h1><p>使用表的方式可以描数单元的多项式（如果使用链表，则数据部分就是{系数，幂次数}）</p><h3 id="多项式链表结构体"><a href="#多项式链表结构体" class="headerlink" title="多项式链表结构体"></a>多项式链表结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Table_data <span class="keyword">struct</span> &#123;</span><br><span class="line">coefficient <span class="keyword">int</span></span><br><span class="line">index       <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> table_node <span class="keyword">struct</span> &#123;</span><br><span class="line">data Table_data</span><br><span class="line">next *table_node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Mult <span class="keyword">struct</span> &#123;</span><br><span class="line">head   *table_node</span><br><span class="line">length <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多项式插入方法"><a href="#多项式插入方法" class="headerlink" title="多项式插入方法"></a>多项式插入方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Mult)</span> <span class="title">Append</span><span class="params">(data Table_data)</span></span> &#123;</span><br><span class="line">node := s.head</span><br><span class="line"><span class="keyword">for</span> (node.next != <span class="literal">nil</span>) &amp;&amp; (node.next.data.index &lt;= data.index) &#123;</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> node.data.index == data.index &#123;</span><br><span class="line">node.data.coefficient += data.coefficient</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">new_node := &amp;table_node&#123;data, node.next&#125;</span><br><span class="line">node.next = new_node</span><br><span class="line">s.length++</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>寻找到恰好大于待插入值的节点，for循环结束后，结果可能有两种：</p><ul><li>待插入值等于现节点，直接合并</li><li>待插入值不等于现节点，插入新节点</li></ul><h3 id="结果显示方法"><a href="#结果显示方法" class="headerlink" title="结果显示方法"></a>结果显示方法</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Mult)</span> <span class="title">Return_result</span><span class="params">()</span> []<span class="title">Table_data</span></span> &#123;</span><br><span class="line">result := []Table_data&#123;&#125;</span><br><span class="line">node := s.head.next</span><br><span class="line"><span class="keyword">for</span> node != <span class="literal">nil</span> &#123;</span><br><span class="line">result = <span class="built_in">append</span>(result, node.data)</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>遍历多项式，打印系数与幂次</p><h3 id="多项式相加"><a href="#多项式相加" class="headerlink" title="多项式相加"></a>多项式相加</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(self *Mult)</span> <span class="title">Add_</span><span class="params">(adder *Mult)</span></span> &#123;</span><br><span class="line">adder_node := adder.head.next</span><br><span class="line"><span class="keyword">for</span> adder_node != <span class="literal">nil</span> &#123;</span><br><span class="line">self.Append(adder_node.data)</span><br><span class="line">adder_node = adder_node.next</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将一个多项式的全部取出并插入另一个多项式即完成多项式相加</p><h3 id="多项式相乘"><a href="#多项式相乘" class="headerlink" title="多项式相乘"></a>多项式相乘</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(self *Mult)</span> <span class="title">Dot</span><span class="params">(mul *Mult)</span> *<span class="title">Mult</span></span> &#123;</span><br><span class="line">mul_node, node := mul.head.next, self.head.next</span><br><span class="line">new_index, new_co := <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">new_table := New_mult()</span><br><span class="line"><span class="keyword">for</span> node != <span class="literal">nil</span> &#123;</span><br><span class="line">mul_node = mul.head.next</span><br><span class="line"><span class="keyword">for</span> mul_node != <span class="literal">nil</span> &#123;</span><br><span class="line">new_index = mul_node.data.index + node.data.index</span><br><span class="line">new_co = mul_node.data.coefficient * node.data.coefficient</span><br><span class="line">new_table.Append(Table_data&#123;new_co, new_index&#125;)</span><br><span class="line">mul_node = mul_node.next</span><br><span class="line">&#125;</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> new_table</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将两个多项式的节点取出两两相乘（幂指数相加，系数相乘），将结果插入一个新多项式中完成多项式相加</p><h1 id="GO语言笔记"><a href="#GO语言笔记" class="headerlink" title="GO语言笔记"></a>GO语言笔记</h1><h2 id="同package多文件"><a href="#同package多文件" class="headerlink" title="同package多文件"></a>同package多文件</h2><p>当一个package由多个文件描述时，应当将所有文件放在同一目录下，运行时包括所有.go文件</p><h2 id="自定义包"><a href="#自定义包" class="headerlink" title="自定义包"></a>自定义包</h2><p>将包放在一个文件夹中，文件夹名与package名相同，调用时路径写到文件夹即可。另外包中的需要在包外被调用的函数/变量/常量/结构体等首字母要大写</p>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的集成分类器</title>
      <link href="2017/11/19/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E9%9B%86%E6%88%90%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>2017/11/19/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E9%9B%86%E6%88%90%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h1><h2 id="集成模型"><a href="#集成模型" class="headerlink" title="集成模型"></a>集成模型</h2><p>集成分类器模型是综合考虑多种机器学习模型的训练结果，做出分类决策的分类器模型</p><ul><li>投票式：平行训练多种机器学习模型，每个模型的输出进行投票做出分类决策</li><li>顺序式：按顺序搭建多个模型，模型之间存在依赖关系，最终整合模型</li></ul><h2 id="随机森林分类器"><a href="#随机森林分类器" class="headerlink" title="随机森林分类器"></a>随机森林分类器</h2><p>随机森林分类器是投票式的集成模型，核心思想是训练数个并行的决策树，对所有决策树的输出做投票处理，为了防止所有决策树生长成相同的样子，决策树的特征选取由最大熵增变为随机选取</p><h2 id="梯度上升决策树"><a href="#梯度上升决策树" class="headerlink" title="梯度上升决策树"></a>梯度上升决策树</h2><p>梯度上升决策树不常用于分类问题（可查找到的资料几乎全在讲回归树），其基本思想是每次训练的数据是（上次训练数据,残差）组成（不清楚分类问题的残差是如何计算的），最后按权值组合出每个决策树的结果</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="导入数据集——泰坦尼克遇难者数据"><a href="#导入数据集——泰坦尼克遇难者数据" class="headerlink" title="导入数据集——泰坦尼克遇难者数据"></a>导入数据集——泰坦尼克遇难者数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">titan = pd.read_csv(<span class="string">&quot;http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt&quot;</span>)</span><br><span class="line">print(titan.head())</span><br></pre></td></tr></table></figure><pre><code>   row.names pclass  survived  \0          1    1st         1   1          2    1st         0   2          3    1st         0   3          4    1st         0   4          5    1st         1                                                 name      age     embarked  \0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   1                      Allison, Miss Helen Loraine   2.0000  Southampton   2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   4                    Allison, Master Hudson Trevor   0.9167  Southampton                            home.dest room      ticket   boat     sex  0                     St Louis, MO  B-5  24160 L221      2  female  1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male  </code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="选取特征"><a href="#选取特征" class="headerlink" title="选取特征"></a>选取特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = titan[[<span class="string">&#x27;pclass&#x27;</span>,<span class="string">&#x27;age&#x27;</span>,<span class="string">&quot;sex&quot;</span>]]</span><br><span class="line">y = titan[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line">print(x.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 3 columns):pclass    1313 non-null objectage       633 non-null float64sex       1313 non-null objectdtypes: float64(1), object(2)memory usage: 30.9+ KBNone</code></pre><h3 id="缺失数据处理"><a href="#缺失数据处理" class="headerlink" title="缺失数据处理"></a>缺失数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.fillna(x[<span class="string">&#x27;age&#x27;</span>].mean(),inplace=<span class="literal">True</span>)</span><br><span class="line">print(x.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 3 columns):pclass    1313 non-null objectage       1313 non-null float64sex       1313 non-null objectdtypes: float64(1), object(2)memory usage: 30.9+ KBNonec:\users\qiank\appdata\local\programs\python\python35\lib\site-packages\pandas\core\frame.py:2754: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrameSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy  downcast=downcast, **kwargs)</code></pre><h3 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.25</span>,random_state=<span class="number">1</span>)</span><br><span class="line">print(x_train.shape,x_test.shape)</span><br></pre></td></tr></table></figure><pre><code>(984, 3) (329, 3)</code></pre><h3 id="特征向量化"><a href="#特征向量化" class="headerlink" title="特征向量化"></a>特征向量化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">vec = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">x_train = vec.fit_transform(x_train.to_dict(orient=<span class="string">&#x27;record&#x27;</span>))</span><br><span class="line">x_test = vec.transform(x_test.to_dict(orient=<span class="string">&#x27;record&#x27;</span>))</span><br><span class="line">print(vec.feature_names_)</span><br></pre></td></tr></table></figure><pre><code>[&#39;age&#39;, &#39;pclass=1st&#39;, &#39;pclass=2nd&#39;, &#39;pclass=3rd&#39;, &#39;sex=female&#39;, &#39;sex=male&#39;]</code></pre><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">rfc = RandomForestClassifier()</span><br><span class="line">rfc.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,            min_impurity_decrease=0.0, min_impurity_split=None,            min_samples_leaf=1, min_samples_split=2,            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,            oob_score=False, random_state=None, verbose=0,            warm_start=False)</code></pre><h3 id="梯度提升决策树"><a href="#梯度提升决策树" class="headerlink" title="梯度提升决策树"></a>梯度提升决策树</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">gbc = GradientBoostingClassifier()</span><br><span class="line">gbc.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>GradientBoostingClassifier(criterion=&#39;friedman_mse&#39;, init=None,              learning_rate=0.1, loss=&#39;deviance&#39;, max_depth=3,              max_features=None, max_leaf_nodes=None,              min_impurity_decrease=0.0, min_impurity_split=None,              min_samples_leaf=1, min_samples_split=2,              min_weight_fraction_leaf=0.0, n_estimators=100,              presort=&#39;auto&#39;, random_state=None, subsample=1.0, verbose=0,              warm_start=False)</code></pre><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="随机森林-1"><a href="#随机森林-1" class="headerlink" title="随机森林"></a>随机森林</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rfc.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.83282674772036469</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">rfc_pre = rfc.predict(x_test)</span><br><span class="line">print(classification_report(rfc_pre,y_test))</span><br></pre></td></tr></table></figure><pre><code>             precision    recall  f1-score   support          0       0.89      0.84      0.87       211          1       0.74      0.82      0.78       118avg / total       0.84      0.83      0.83       329  </code></pre><h3 id="梯度提升决策树-1"><a href="#梯度提升决策树-1" class="headerlink" title="梯度提升决策树"></a>梯度提升决策树</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gbc.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.82370820668693012</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">print(classification_report(gbc.predict(x_test),y_test))</span><br></pre></td></tr></table></figure><pre><code>             precision    recall  f1-score   support          0       0.92      0.81      0.86       224          1       0.68      0.85      0.75       105avg / total       0.84      0.82      0.83       329</code></pre><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>抽象数据结构与表</title>
      <link href="2017/11/19/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E8%A1%A8/"/>
      <url>2017/11/19/%E6%8A%BD%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="抽象数据结构"><a href="#抽象数据结构" class="headerlink" title="抽象数据结构"></a>抽象数据结构</h1><p>抽象数据结构（ADT）是一些操作的集合，集合了一些必要且重用性高的操作，这些操作在一个项目中只被编写一次。抽象数据结构只定义操作的存在，并不定义操作的实现</p><h1 id="表"><a href="#表" class="headerlink" title="表"></a>表</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>表是一种基础的数据结构，是一系列逻辑上”顺序”的数据（顺序指具有连续的数值索引）。例如$A<em>{0},A</em>{1},A_{2}$就是一个表，数据具有连续索引1,2,3。此外，还有前驱元和后继元的概念：</p><ul><li>前驱元：某个元素之前的元素被称为该元素的前驱元（不定义第一个元素的前驱元）</li><li>后继元：某个元素之后的元素被称为该元素的后继元（不定义最后一个元素的后继元）</li></ul><h2 id="表的实现方法"><a href="#表的实现方法" class="headerlink" title="表的实现方法"></a>表的实现方法</h2><ul><li>数组实现：查找快，插入与删除慢，大小固定，内存中一般连续</li><li>链表实现：查找较慢，插入与删除相对较快，大小可变，内存中一般不连续</li></ul><h2 id="表需要的方法"><a href="#表需要的方法" class="headerlink" title="表需要的方法"></a>表需要的方法</h2><ul><li>is_empty：判断是否为空表</li><li>is_last：判断是否为结尾</li></ul><ul><li>find：根据值获得在表中的节点（find_previous：获得前驱元）</li><li>visit：根据位置获得值（find）</li><li>delete：删除元素</li><li>insert：插入元素</li></ul><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="接口与结构体"><a href="#接口与结构体" class="headerlink" title="接口与结构体"></a>接口与结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//表中数据类型</span></span><br><span class="line"><span class="keyword">type</span> table_data <span class="keyword">struct</span> &#123;</span><br><span class="line">data <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//链表节点类型</span></span><br><span class="line"><span class="keyword">type</span> table_node <span class="keyword">struct</span> &#123;</span><br><span class="line">data table_data</span><br><span class="line">next *table_node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//方法接口</span></span><br><span class="line"><span class="keyword">type</span> table_adt <span class="keyword">interface</span> &#123;</span><br><span class="line">is_empty() <span class="keyword">bool</span></span><br><span class="line">is_last(node table_node) <span class="keyword">bool</span></span><br><span class="line">size() <span class="keyword">int</span></span><br><span class="line">find(data table_data) *table_node</span><br><span class="line">find_previous(data table_data) *table_node</span><br><span class="line">find_last() *table_node</span><br><span class="line">visit(num <span class="keyword">int</span>) *table_node</span><br><span class="line"><span class="built_in">delete</span>(data table_data)</span><br><span class="line">insert(data table_data, previous *table_node)</span><br><span class="line"><span class="built_in">append</span>(data table_data)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//链表结构体</span></span><br><span class="line"><span class="keyword">type</span> link_table <span class="keyword">struct</span> &#123;</span><br><span class="line">head   table_node</span><br><span class="line">length <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="方法的实现"><a href="#方法的实现" class="headerlink" title="方法的实现"></a>方法的实现</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">is_empty</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> table.head.next == <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">is_last</span><span class="params">(node table_node)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> node.next == <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">find</span><span class="params">(data table_data)</span> *<span class="title">table_node</span></span> &#123;</span><br><span class="line">node := table.head.next</span><br><span class="line"><span class="keyword">for</span> (node != <span class="literal">nil</span>) &amp;&amp; (node.data != data) &#123;</span><br><span class="line"><span class="comment">// fmt.Println(node.data, data, (node.data != data))</span></span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">find_previous</span><span class="params">(data table_data)</span> *<span class="title">table_node</span></span> &#123;</span><br><span class="line">node := &amp;table.head</span><br><span class="line"><span class="keyword">for</span> (node.next.data != data) &amp;&amp; (node.next != <span class="literal">nil</span>) &#123;</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">find_last</span><span class="params">()</span> *<span class="title">table_node</span></span> &#123;</span><br><span class="line">node := &amp;table.head</span><br><span class="line"><span class="keyword">for</span> node.next != <span class="literal">nil</span> &#123;</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">visit</span><span class="params">(num <span class="keyword">int</span>)</span> *<span class="title">table_node</span></span> &#123;</span><br><span class="line">node := table.head.next</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; num; i++ &#123;</span><br><span class="line">node = node.next</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> node</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">delete</span><span class="params">(data table_data)</span></span> &#123;</span><br><span class="line">previous := table.find_previous(data)</span><br><span class="line"><span class="keyword">if</span> previous != <span class="literal">nil</span> &#123;</span><br><span class="line">previous.next = previous.next.next</span><br><span class="line">previous.next.next = <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">table.length -= <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">insert</span><span class="params">(data table_data, previous *table_node)</span></span> &#123;</span><br><span class="line">node := &amp;table_node&#123;data, previous.next&#125;</span><br><span class="line">previous.next = node</span><br><span class="line">table.length += <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">append</span><span class="params">(data table_data)</span></span> &#123;</span><br><span class="line">last := table.find_last()</span><br><span class="line">table.insert(data, last)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *link_table)</span> <span class="title">size</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> table.length</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">new_link_table</span><span class="params">()</span> *<span class="title">link_table</span></span> &#123;</span><br><span class="line">head := table_node&#123;table_data&#123;&#125;, <span class="literal">nil</span>&#125;</span><br><span class="line"><span class="keyword">return</span> &amp;link_table&#123;head, <span class="number">0</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="go笔记"><a href="#go笔记" class="headerlink" title="go笔记"></a>go笔记</h3><ul><li>go语言的面向对象使用struct实现，方法和属性分开定义</li><li>方法的定义是<code>func (a *b) name () [return_type] &#123;&#125;</code>其中<code>(a *b)</code>表示该函数是哪个类型的方法，调用过程中，<code>.</code>运算符将运算符前的变量赋给a，类似于Python中的<code>self</code>和C++中的<code>this</code>指针</li><li>接口与C++中接口类似，可用于实现多态，另外如果使用接口访问”对象”，可以保护对象的属性和未在接口中声明的方法，实现类似私有方法的功能</li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>logN复杂度算法与一些示例</title>
      <link href="2017/11/16/logN%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%AE%97%E6%B3%95%E4%B8%8E%E4%B8%80%E4%BA%9B%E7%A4%BA%E4%BE%8B/"/>
      <url>2017/11/16/logN%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%AE%97%E6%B3%95%E4%B8%8E%E4%B8%80%E4%BA%9B%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="logN复杂度估算"><a href="#logN复杂度估算" class="headerlink" title="logN复杂度估算"></a>logN复杂度估算</h1><p>logN复杂度的算法可以认为具有以下特性：</p><blockquote><p>用常数时间将问题的大小削减为某一部分（通常是1/2）</p></blockquote><p>例如分治法求最大子串问题，将一个$O(N^{2})$的问题削减为每个的1/2，每个问题复杂度为$O(N)$（有循环），所以该算法的复杂度估计为$O(NlogN)$</p><h1 id="logN复杂度算法举例"><a href="#logN复杂度算法举例" class="headerlink" title="logN复杂度算法举例"></a>logN复杂度算法举例</h1><h2 id="对分查找"><a href="#对分查找" class="headerlink" title="对分查找"></a>对分查找</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>已知一串整数按顺序排布，寻找某个指定数的下标</p><h3 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h3><p>考虑已经按顺序排列，那么使用二分查找的方法即可。对于For循环内部算法的复杂度是O(1)，且每次循环都将问题缩小一半，所以认为这是一个O(logN)的算法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">binary_search</span><span class="params">(data []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">left, right, mid := <span class="number">0</span>, <span class="built_in">len</span>(data), <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> left != right &#123;</span><br><span class="line">mid = <span class="keyword">int</span>((left + right) / <span class="number">2</span>)</span><br><span class="line"><span class="comment">// fmt.Println(mid)</span></span><br><span class="line"><span class="keyword">if</span> data[mid] == target &#123;</span><br><span class="line"><span class="keyword">return</span> mid</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> data[mid] &gt; target &#123;</span><br><span class="line">right = mid</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">left = mid</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="欧几里德算法"><a href="#欧几里德算法" class="headerlink" title="欧几里德算法"></a>欧几里德算法</h2><p>欧几里得算法是用于取最大公因数的算法（中国古代类似的算法好像是碾转相除法？）。这个算法中，每次循环也是将问题变得更小</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">gcd</span><span class="params">(a, b <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">rem := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> b &gt; <span class="number">0</span> &#123;</span><br><span class="line">rem = a % b</span><br><span class="line">a = b</span><br><span class="line">b = rem</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> a</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="递归求幂"><a href="#递归求幂" class="headerlink" title="递归求幂"></a>递归求幂</h2><p>类似于二分查找，递归求幂的原理是$x^{2n} = x^{n} * x^{n}$相比于普通阶乘，减少了乘法的次数。同时，也是每次循环问题（N）减为原来的一半，也是一个O(logN)复杂度问题</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">pow</span><span class="params">(x, n <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> n == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> n == <span class="number">1</span> &#123;</span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> n%<span class="number">2</span> == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> pow(x*x, n/<span class="number">2</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> pow(x*x, n/<span class="number">2</span>) * x</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法复杂度分析与最大子串问题</title>
      <link href="2017/11/15/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%AD%90%E4%B8%B2%E9%97%AE%E9%A2%98/"/>
      <url>2017/11/15/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%80%E5%A4%A7%E5%AD%90%E4%B8%B2%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="算法复杂度分析"><a href="#算法复杂度分析" class="headerlink" title="算法复杂度分析"></a>算法复杂度分析</h1><h2 id="算法复杂度基本定义"><a href="#算法复杂度基本定义" class="headerlink" title="算法复杂度基本定义"></a>算法复杂度基本定义</h2><p>算法复杂度分析基于以下四条定义：</p><ul><li>如果存在常数c与$n<em>{0}$使$N \geq n</em>{0} $时，有$T(N) \leq cf(N)$，则记 $T(N) = O(f(N))$</li><li>如果存在常数c与$n<em>{0}$使$N \geq n</em>{0} $时，有$T(N) \geq cf(N)$，则记 $T(N) = \Omega(f(N))$</li><li>当且仅当$T(N) = O(f(N))$且$T(N) = \Omega(f(N))$时，记$T(N) = \Theta(f(N))$</li><li>若$T(N) = O(f(N))$且$T(N)  \neq \Theta(f(N))$时，记$T(N) = o(f(N))$</li></ul><p>若使用比较简单（不甚准确）的表达：</p><ul><li>当T(N)增长的比f(N)慢的时候，认为$T(N) = O(f(N))$</li><li>当T(N)增长的比f(N)快的时候，认为$T(N) = \Omega(f(N))$</li><li>当T(N)和f(N)一样快的时候，认为$T(N) = \Theta(f(N))$</li></ul><h2 id="算法复杂度分析运算"><a href="#算法复杂度分析运算" class="headerlink" title="算法复杂度分析运算"></a>算法复杂度分析运算</h2><ul><li>加法：T1(N)=O(f(x))，T2(N)=O(g(x))，则T1(N) + T2(N) = max{O(f(x)),O(g(x))}</li><li>乘法：同上假设，T1(N)<em> T2(N) = O(f(x) </em> g(x))</li></ul><h2 id="算法时间估算"><a href="#算法时间估算" class="headerlink" title="算法时间估算"></a>算法时间估算</h2><p>时间估算中，认为每个操作花费时间为1，跳转，判断等所消耗时间可以忽略，例如</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; N;i++) &#123;</span><br><span class="line">  <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; N;j++) &#123;</span><br><span class="line">    a += i+ j;</span><br><span class="line">  &#125;  </span><br><span class="line">  b += i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>分析以上算法，内循环一次耗时N，外循环一次耗时$N * (N + 1) = N^{2} + N$，时间估算中忽略常数项和低次项，该算法花费时间$O(N^{2})$，由以上可以得出一些结论：</p><ul><li>顺序语句：时间估算为语句中耗时最多的一条</li><li>判断语句：时间估算为不超过所有分支运算时间之和（与选择最耗时的一个分支相同）</li><li>循环语句：时间估算为循环次数的乘积（包括嵌套循环）</li></ul><h1 id="最大子序列问题"><a href="#最大子序列问题" class="headerlink" title="最大子序列问题"></a>最大子序列问题</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>已知一个序列，要求求和最大的连续子序列的和。例如输入-2，11，-4，13，-5，-2，输出20（11-4+13）</p><h2 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h2><h3 id="解法一：真-暴力求解"><a href="#解法一：真-暴力求解" class="headerlink" title="解法一：真.暴力求解"></a>解法一：真.暴力求解</h3><p>考虑最简单直接的解法，计算出以某个数开头的所有子序列和，取出最大的值</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">solution1</span><span class="params">(data []<span class="keyword">int</span>, num <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">max_sum, this_sum := <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; num; i++ &#123;</span><br><span class="line"><span class="keyword">for</span> j := i; j &lt; num; j++ &#123;</span><br><span class="line">this_sum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> k := i; k &lt; j; k++ &#123;</span><br><span class="line">this_sum += data[k]</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> this_sum &gt; max_sum &#123;</span><br><span class="line">max_sum = this_sum</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> max_sum</span><br><span class="line">&#125; <span class="comment">//done: 1.1903458s</span></span><br></pre></td></tr></table></figure><h3 id="解法二：改进-暴力求解"><a href="#解法二：改进-暴力求解" class="headerlink" title="解法二：改进.暴力求解"></a>解法二：改进.暴力求解</h3><p>考虑以上求和的部分，每改一个j（结尾位置）都要重新计算全部子序列和。其实前面的和是被重复计算了，计算下一个子序列和时只需要加上结尾的值就可以了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">solution2</span><span class="params">(data []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">max_sum, this_sum, num := <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(data)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; num; i++ &#123;</span><br><span class="line">this_sum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> j := i; j &lt; num; j++ &#123;</span><br><span class="line">this_sum += data[j]</span><br><span class="line"><span class="keyword">if</span> this_sum &gt; max_sum &#123;</span><br><span class="line">max_sum = this_sum</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> max_sum</span><br><span class="line">&#125; <span class="comment">// done: 1.115286s</span></span><br></pre></td></tr></table></figure><h3 id="解法三：分治法"><a href="#解法三：分治法" class="headerlink" title="解法三：分治法"></a>解法三：分治法</h3><p>分治法解决这个问题的方法是：找出左侧一半的最大子串，找出右侧一半的最大子串，找出跨越左右分界的最大子串（左侧终点确定，右侧起点确定），比较得最大值。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">solution3</span><span class="params">(data []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(data) == <span class="number">1</span> &#123;</span><br><span class="line"><span class="keyword">return</span> data[<span class="number">0</span>]</span><br><span class="line">&#125;</span><br><span class="line">split_num := <span class="keyword">int</span>(<span class="built_in">len</span>(data) / <span class="number">2</span>)</span><br><span class="line"><span class="comment">// fmt.Println(split_num)</span></span><br><span class="line">left_max := solution3(data[:split_num])</span><br><span class="line">right_max := solution3(data[split_num:])</span><br><span class="line"></span><br><span class="line">mid_left_max, mid_right_max := <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">mid_left, mid_right := <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i := split_num; i &gt;= <span class="number">0</span>; i-- &#123;</span><br><span class="line">mid_left += data[i]</span><br><span class="line"><span class="keyword">if</span> mid_left &gt; mid_left_max &#123;</span><br><span class="line">mid_left_max = mid_left</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i := split_num + <span class="number">1</span>; i &lt; <span class="built_in">len</span>(data); i++ &#123;</span><br><span class="line">mid_right += data[i]</span><br><span class="line"><span class="keyword">if</span> mid_right &gt; mid_right_max &#123;</span><br><span class="line">mid_right_max = mid_right</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">mid_max := mid_left_max + mid_right_max</span><br><span class="line"><span class="keyword">if</span> (mid_max &gt; left_max) &amp;&amp; (mid_max &gt; right_max) &#123;</span><br><span class="line"><span class="keyword">return</span> mid_max</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> left_max &gt; right_max &#123;</span><br><span class="line"><span class="keyword">return</span> left_max</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> right_max</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="comment">//done: 1.1223139s</span></span><br></pre></td></tr></table></figure><h3 id="解法四：动态规划-贪心算法"><a href="#解法四：动态规划-贪心算法" class="headerlink" title="解法四：动态规划/贪心算法"></a>解法四：动态规划/贪心算法</h3><p>该算法原理还未理解透彻，正在研究中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">solution4</span><span class="params">(data []<span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">max_sum, this_sum, num := <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(data)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; num; i++ &#123;</span><br><span class="line">this_sum += data[i]</span><br><span class="line"><span class="keyword">if</span> this_sum &lt; <span class="number">0</span> &#123;</span><br><span class="line">this_sum = <span class="number">0</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> this_sum &gt; max_sum &#123;</span><br><span class="line">max_sum = this_sum</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> max_sum</span><br><span class="line">&#125; <span class="comment">//done: 1.1323284s</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 算法学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的决策树分类器</title>
      <link href="2017/11/12/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>2017/11/12/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h1><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>决策树是一种树形结构的机器学习算法，所有的样本起始于根节点，每个具有子节点的父节点都有一个判断，根据判断结果将样本向子节点分流，测试样本从根节点开始向下流动，通过判断最终到达某个没有子节点的叶子节点，这个节点就是该样本所属的类别。<br>例如，判断一个动物是鸭子，狗还是兔子，可以具有以下的决策树：</p><ul><li>判断是否有四条腿<ul><li>没有，是鸭子</li><li>有，判断眼睛颜色<ul><li>红色，是兔子</li><li>非红色，是狗</li></ul></li></ul></li></ul><h2 id="决策树训练算法"><a href="#决策树训练算法" class="headerlink" title="决策树训练算法"></a>决策树训练算法</h2><p>训练决策树时，可以描述如下</p><ol><li>从父节点找到最优划分属性</li><li>根据属性划分出子节点</li><li>若子节点为空/属性相同（无需划分）或样本相等（无法划分），返回，否则返回第一步继续递归划分</li></ol><p>找到最优划分属性时，计算按每个属性划分的信息熵，取信息熵最大的属性为最优划分属性</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="载入数据——泰坦尼克号数据导入"><a href="#载入数据——泰坦尼克号数据导入" class="headerlink" title="载入数据——泰坦尼克号数据导入"></a>载入数据——泰坦尼克号数据导入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">titan = pd.read_csv(<span class="string">&quot;http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt&quot;</span>)</span><br><span class="line">print(titan.head())</span><br></pre></td></tr></table></figure><pre><code>   row.names pclass  survived  \0          1    1st         1   1          2    1st         0   2          3    1st         0   3          4    1st         0   4          5    1st         1                                                 name      age     embarked  \0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   1                      Allison, Miss Helen Loraine   2.0000  Southampton   2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   4                    Allison, Master Hudson Trevor   0.9167  Southampton                            home.dest room      ticket   boat     sex  0                     St Louis, MO  B-5  24160 L221      2  female  1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male  </code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(titan.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 11 columns):row.names    1313 non-null int64pclass       1313 non-null objectsurvived     1313 non-null int64name         1313 non-null objectage          633 non-null float64embarked     821 non-null objecthome.dest    754 non-null objectroom         77 non-null objectticket       69 non-null objectboat         347 non-null objectsex          1313 non-null objectdtypes: float64(1), int64(2), object(8)memory usage: 112.9+ KBNone</code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="选取特征"><a href="#选取特征" class="headerlink" title="选取特征"></a>选取特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = titan[[<span class="string">&quot;pclass&quot;</span>,<span class="string">&quot;age&quot;</span>,<span class="string">&quot;sex&quot;</span>]]</span><br><span class="line">y = titan[<span class="string">&quot;survived&quot;</span>]</span><br><span class="line">print(x.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 3 columns):pclass    1313 non-null objectage       633 non-null float64sex       1313 non-null objectdtypes: float64(1), object(2)memory usage: 30.9+ KBNone</code></pre><h3 id="年龄补全——使用平均值"><a href="#年龄补全——使用平均值" class="headerlink" title="年龄补全——使用平均值"></a>年龄补全——使用平均值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x[<span class="string">&#x27;age&#x27;</span>].fillna(x[<span class="string">&#x27;age&#x27;</span>].mean(),inplace=<span class="literal">True</span>)</span><br><span class="line">print(x.info())</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 1313 entries, 0 to 1312Data columns (total 3 columns):pclass    1313 non-null objectage       1313 non-null float64sex       1313 non-null objectdtypes: float64(1), object(2)memory usage: 30.9+ KBNonec:\users\qiank\appdata\local\programs\python\python35\lib\site-packages\pandas\core\generic.py:3660: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrameSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy  self._update_inplace(new_data)</code></pre><h3 id="数据分割"><a href="#数据分割" class="headerlink" title="数据分割"></a>数据分割</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.25</span>,random_state=<span class="number">1</span>)</span><br><span class="line">print(x_train.shape)</span><br><span class="line">print(x_test.shape)</span><br></pre></td></tr></table></figure><pre><code>(984, 3)(329, 3)</code></pre><h3 id="特征转换"><a href="#特征转换" class="headerlink" title="特征转换"></a>特征转换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">vec = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">x_train = vec.fit_transform(x_train.to_dict(orient=<span class="string">&#x27;record&#x27;</span>))</span><br><span class="line">x_test = vec.transform(x_test.to_dict(orient=<span class="string">&#x27;record&#x27;</span>))</span><br><span class="line">print(vec.feature_names_,<span class="string">&quot;\n&quot;</span>,x_train[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>[&#39;age&#39;, &#39;pclass=1st&#39;, &#39;pclass=2nd&#39;, &#39;pclass=3rd&#39;, &#39;sex=female&#39;, &#39;sex=male&#39;]  [[ 31.19418104   0.           0.           1.           0.           1.        ] [ 31.19418104   0.           0.           1.           0.           1.        ] [ 35.           0.           1.           0.           1.           0.        ] [ 31.           0.           1.           0.           0.           1.        ] [ 26.           0.           0.           1.           0.           1.        ]]</code></pre><h2 id="调用决策树分类器"><a href="#调用决策树分类器" class="headerlink" title="调用决策树分类器"></a>调用决策树分类器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dtc = DecisionTreeClassifier()</span><br><span class="line">dtc.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=None,            max_features=None, max_leaf_nodes=None,            min_impurity_decrease=0.0, min_impurity_split=None,            min_samples_leaf=1, min_samples_split=2,            min_weight_fraction_leaf=0.0, presort=False, random_state=None,            splitter=&#39;best&#39;)</code></pre><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="自带评估"><a href="#自带评估" class="headerlink" title="自带评估"></a>自带评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dtc.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.81155015197568392</code></pre><h3 id="评估器"><a href="#评估器" class="headerlink" title="评估器"></a>评估器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">y_pre = dtc.predict(x_test)</span><br><span class="line">print(classification_report(y_pre,y_test,target_names=[<span class="string">&quot;died&quot;</span>,<span class="string">&quot;survived&quot;</span>]))</span><br></pre></td></tr></table></figure><pre><code>             precision    recall  f1-score   support       died       0.91      0.80      0.85       226   survived       0.66      0.83      0.74       103avg / total       0.83      0.81      0.82       329</code></pre><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的K邻近分类器</title>
      <link href="2017/11/11/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84K%E9%82%BB%E8%BF%91%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>2017/11/11/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84K%E9%82%BB%E8%BF%91%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>KNN（K临近）分类器应该算是概率派的机器学习算法中比较简单的。基本的思想为在预测时，计算输入向量到每个训练样本的欧氏距离（几何距离），选取最近的K个训练样本，K个训练样本中出现最多的类别即预测为输入向量的类别（投票）</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="载入数据集——鸢尾花数据集"><a href="#载入数据集——鸢尾花数据集" class="headerlink" title="载入数据集——鸢尾花数据集"></a>载入数据集——鸢尾花数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">dataset = load_iris()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(dataset.data.shape)</span><br><span class="line">print(dataset.DESCR)</span><br></pre></td></tr></table></figure><pre><code>(150, 4)Iris Plants Database====================Notes-----Data Set Characteristics:    :Number of Instances: 150 (50 in each of three classes)    :Number of Attributes: 4 numeric, predictive attributes and the class    :Attribute Information:        - sepal length in cm        - sepal width in cm        - petal length in cm        - petal width in cm        - class:                - Iris-Setosa                - Iris-Versicolour                - Iris-Virginica    :Summary Statistics:    ============== ==== ==== ======= ===== ====================                    Min  Max   Mean    SD   Class Correlation    ============== ==== ==== ======= ===== ====================    sepal length:   4.3  7.9   5.84   0.83    0.7826    sepal width:    2.0  4.4   3.05   0.43   -0.4194    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)    ============== ==== ==== ======= ===== ====================    :Missing Attribute Values: None    :Class Distribution: 33.3% for each of 3 classes.    :Creator: R.A. Fisher    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)    :Date: July, 1988This is a copy of UCI ML iris datasets.http://archive.ics.uci.edu/ml/datasets/IrisThe famous Iris database, first used by Sir R.A FisherThis is perhaps the best known database to be found in thepattern recognition literature.  Fisher&#39;s paper is a classic in the field andis referenced frequently to this day.  (See Duda &amp; Hart, for example.)  Thedata set contains 3 classes of 50 instances each, where each class refers to atype of iris plant.  One class is linearly separable from the other 2; thelatter are NOT linearly separable from each other.References----------   - Fisher,R.A. &quot;The use of multiple measurements in taxonomic problems&quot;     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to     Mathematical Statistics&quot; (John Wiley, NY, 1950).   - Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis.     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System     Structure and Classification Rule for Recognition in Partially Exposed     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine     Intelligence, Vol. PAMI-2, No. 1, 67-71.   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions     on Information Theory, May 1972, 431-433.   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II     conceptual clustering system finds 3 classes in the data.   - Many, many more ...</code></pre><p>​    </p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="分割数据"><a href="#分割数据" class="headerlink" title="分割数据"></a>分割数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(dataset.data,dataset.target,test_size=<span class="number">0.25</span>,random_state=<span class="number">1</span>)</span><br><span class="line">print(x_train.shape)</span><br><span class="line">print(x_test.shape)</span><br></pre></td></tr></table></figure><pre><code>(112, 4)(38, 4)</code></pre><h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">stantard = StandardScaler()</span><br><span class="line">x_train = stantard.fit_transform(x_train)</span><br><span class="line">x_test = stantard.transform(x_test)</span><br></pre></td></tr></table></figure><h2 id="调用K邻近分类器"><a href="#调用K邻近分类器" class="headerlink" title="调用K邻近分类器"></a>调用K邻近分类器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,           metric_params=None, n_jobs=1, n_neighbors=5, p=2,           weights=&#39;uniform&#39;)</code></pre><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="自带评估"><a href="#自带评估" class="headerlink" title="自带评估"></a>自带评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(knn.score(x_test,y_test))</span><br></pre></td></tr></table></figure><pre><code>0.973684210526</code></pre><h3 id="评估器评估"><a href="#评估器评估" class="headerlink" title="评估器评估"></a>评估器评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">y_pre = knn.predict(x_test)</span><br><span class="line">print(classification_report(y_test,y_pre,target_names=dataset.target_names))</span><br></pre></td></tr></table></figure><pre><code>             precision    recall  f1-score   support     setosa       1.00      1.00      1.00        13 versicolor       1.00      0.94      0.97        16  virginica       0.90      1.00      0.95         9avg / total       0.98      0.97      0.97        38</code></pre><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的朴素贝叶斯分类器</title>
      <link href="2017/11/04/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>2017/11/04/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="理论内容"><a href="#理论内容" class="headerlink" title="理论内容"></a>理论内容</h1><h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p>贝叶斯定理是描述条件概率关系的定律</p><script type="math/tex; mode=display">P(A|B) = \cfrac{P(B|A) * P(A)}{P(B)}</script><h2 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h2><p>朴素贝叶斯分类器是一种基于概率的分类器，我们做以下定义：</p><ul><li>B：具有特征向量B</li><li>A：属于类别A</li></ul><p>有了这个定义，我们解释贝叶斯公式</p><ul><li>P(A|B)：具有特征向量B样本属于A类别的概率（计算目标）</li><li>P(B|A)：在A类别中B向量出现的概率（训练样本中的数据）</li><li>P(A)：A类出现的概率（训练样本中的频率）</li><li>P(B)：B特征向量出现的概率（训练样本中的频率）</li></ul><p>对于朴素贝叶斯分类器，进一步假设特征向量之间无关，那么朴素贝叶斯分类器公式可以如下表示<script type="math/tex">P(A|B) = \cfrac{P(A)\prod P(B_{i} |A)}{P(B)}</script></p><p>以上公式右侧的值都可以在训练样本中算得。进行预测时，分别计算每个类别的概率，取概率最高的一个类别。</p><h2 id="特征向量为连续值的朴素贝叶斯分类器"><a href="#特征向量为连续值的朴素贝叶斯分类器" class="headerlink" title="特征向量为连续值的朴素贝叶斯分类器"></a>特征向量为连续值的朴素贝叶斯分类器</h2><p>对于连续值，有以下两种处理方式</p><ul><li>将连续值按区间离散化</li><li>假设特征向量服从正态分布或其他分布（很强的先验假设），由样本中估计出参数，计算贝叶斯公式时带入概率密度</li></ul><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="导入数据——文本新闻数据"><a href="#导入数据——文本新闻数据" class="headerlink" title="导入数据——文本新闻数据"></a>导入数据——文本新闻数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from sklearn.datasets import fetch_20newsgroups</span></span><br><span class="line"><span class="comment"># news = fetch_20newsgroups(subset=&#x27;all&#x27;)</span></span><br><span class="line"><span class="comment"># print(len(news.data))</span></span><br><span class="line"><span class="comment"># print(news.data[0])</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">train = datasets.load_files(<span class="string">&quot;./20newsbydate/20news-bydate-train&quot;</span>)</span><br><span class="line">test = datasets.load_files(<span class="string">&quot;./20newsbydate/20news-bydate-test&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(train.DESCR)</span><br><span class="line">print(<span class="built_in">len</span>(train.data))</span><br><span class="line">print(train.data[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>None11314b&quot;From: cubbie@garnet.berkeley.edu (                               )\nSubject: Re: Cubs behind Marlins? How?\nArticle-I.D.: agate.1pt592$f9a\nOrganization: University of California, Berkeley\nLines: 12\nNNTP-Posting-Host: garnet.berkeley.edu\n\n\ngajarsky@pilot.njin.net writes:\n\nmorgan and guzman will have era&#39;s 1 run higher than last year, and\n the cubs will be idiots and not pitch harkey as much as hibbard.\n castillo won&#39;t be good (i think he&#39;s a stud pitcher)\n\n       This season so far, Morgan and Guzman helped to lead the Cubs\n       at top in ERA, even better than THE rotation at Atlanta.\n       Cubs ERA at 0.056 while Braves at 0.059. We know it is early\n       in the season, we Cubs fans have learned how to enjoy the\n       short triumph while it is still there.\n&quot;</code></pre><h1 id="处理数据——特征抽取（文字向量化）"><a href="#处理数据——特征抽取（文字向量化）" class="headerlink" title="处理数据——特征抽取（文字向量化）"></a>处理数据——特征抽取（文字向量化）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">vec = CountVectorizer(stop_words=<span class="string">&quot;english&quot;</span>,decode_error=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">train_vec = vec.fit_transform(train.data)</span><br><span class="line">test_vec = vec.transform(test.data)</span><br><span class="line">print(train_vec.shape)</span><br></pre></td></tr></table></figure><pre><code>(11314, 129782)</code></pre><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">bays = MultinomialNB()</span><br><span class="line">bays.fit(train_vec,train.target)</span><br></pre></td></tr></table></figure><pre><code>MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)</code></pre><h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><h2 id="使用自带评估器"><a href="#使用自带评估器" class="headerlink" title="使用自带评估器"></a>使用自带评估器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bays.score(test_vec,test.target)</span><br></pre></td></tr></table></figure><pre><code>0.80244291024960168</code></pre><h2 id="调用评估器"><a href="#调用评估器" class="headerlink" title="调用评估器"></a>调用评估器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">y = bays.predict(test_vec)</span><br><span class="line">print(classification_report(test.target,y,target_names=test.target_names))</span><br></pre></td></tr></table></figure><pre><code>                          precision    recall  f1-score   support             alt.atheism       0.80      0.81      0.80       319           comp.graphics       0.65      0.80      0.72       389 comp.os.ms-windows.misc       0.80      0.04      0.08       394comp.sys.ibm.pc.hardware       0.55      0.80      0.65       392   comp.sys.mac.hardware       0.85      0.79      0.82       385          comp.windows.x       0.69      0.84      0.76       395            misc.forsale       0.89      0.74      0.81       390               rec.autos       0.89      0.92      0.91       396         rec.motorcycles       0.95      0.94      0.95       398      rec.sport.baseball       0.95      0.92      0.93       397        rec.sport.hockey       0.92      0.97      0.94       399               sci.crypt       0.80      0.96      0.87       396         sci.electronics       0.79      0.70      0.74       393                 sci.med       0.88      0.87      0.87       396               sci.space       0.84      0.92      0.88       394  soc.religion.christian       0.81      0.95      0.87       398      talk.politics.guns       0.72      0.93      0.81       364   talk.politics.mideast       0.93      0.94      0.94       376      talk.politics.misc       0.68      0.62      0.65       310      talk.religion.misc       0.88      0.44      0.59       251             avg / total       0.81      0.80      0.78      7532</code></pre>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的线性支持向量机分类器</title>
      <link href="2017/10/28/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>2017/10/28/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h2><p>机器学习的分类器，均可以看成一个或一组超平面，将label不同的数据点在数据空间中分开。对于线性可分问题，属于相同label的数据点在数据空间中可以看成是“类聚”的，即具有相同label的点会聚在一起。这样，分类效果最好的超平面应该满足：对于其分割的两种label，距离最近的两个不同label的数据点距离超平面的距离都足够大，即超平面离两个类聚的空间都足够远。</p><h2 id="支持向量"><a href="#支持向量" class="headerlink" title="支持向量"></a>支持向量</h2><p>对于支持向量机来说，最关心的并不是所有数据的分布情况，而是所谓类聚空间边界的相互位置，这些边界上的数据点，即两个空间间隔最小的两个数据点被称为支持向量，支持向量机分类器就是针对这些点优化的分类器</p><h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>以上的所有说明都是针对线性可分问题的，当处理线性不可分问题的时候，线性分类器就无能为力了。那么需要使用一个叫核函数的东西，将线性不可分问题变成线性可分问题。核函数是一种对应关系，可以将数据映射到更高的维度上去，即认为：在当前维度不可分的问题，到达更高维度的时候有可能变的线性可分。在支持向量机的范畴中，核函数是一种先验，即人工在训练前就指定的。在当前的神经网络算法中，可以将输出层看成线性分类器，将隐藏层看成核函数，这样的视角下神经网络中的核函数是通过数据训练出来的</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="载入手写体数据集"><a href="#载入手写体数据集" class="headerlink" title="载入手写体数据集"></a>载入手写体数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</span><br><span class="line">digits = load_digits()</span><br><span class="line">print(digits.data.shape)</span><br><span class="line">print(<span class="built_in">type</span>(digits),<span class="built_in">type</span>(digits.data))</span><br></pre></td></tr></table></figure><pre><code>(1797, 64)&lt;class &#39;sklearn.utils.Bunch&#39;&gt; &lt;class &#39;numpy.ndarray&#39;&gt;</code></pre><p>使用<code>sklearn.datasets</code>中的<code>load_digits()</code>函数,可以载入8*8的手写数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">dis = digits.data[:<span class="number">9</span>,:]</span><br><span class="line">dis = dis.reshape([-<span class="number">1</span>,<span class="number">8</span>,<span class="number">8</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">    plt.subplot(<span class="number">331</span> + i)</span><br><span class="line">    plt.imshow(dis[i])</span><br><span class="line">plt.show()</span><br><span class="line">print(digits.target[:<span class="number">9</span>])</span><br></pre></td></tr></table></figure><img src="/2017/10/28/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E5%88%86%E7%B1%BB%E5%99%A8/digits_num.png" class=""><pre><code>[0 1 2 3 4 5 6 7 8]</code></pre><p>上面是使用matplotlib打印出的前9个数据的样子，可以发现已经非常不清晰了（顺便提一句MNIST比这个不知道高到那里去了，上神经网络还不是随便98%的准确率）</p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="数据分割：75-训练-25-预测"><a href="#数据分割：75-训练-25-预测" class="headerlink" title="数据分割：75%训练-25%预测"></a>数据分割：75%训练-25%预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(digits.data,digits.target,test_size=<span class="number">0.25</span>,random_state=<span class="number">1</span>)</span><br><span class="line">print(x_train.shape,y_train.shape)</span><br></pre></td></tr></table></figure><pre><code>(1347, 64) (1347,)</code></pre><h3 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">x_train = ss.fit_transform(x_train)</span><br><span class="line">x_test = ss.transform(x_test)</span><br></pre></td></tr></table></figure><h2 id="调用支持向量机分类"><a href="#调用支持向量机分类" class="headerlink" title="调用支持向量机分类"></a>调用支持向量机分类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line">lsvc = LinearSVC()</span><br><span class="line">lsvc.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,     intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,     multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=None, tol=0.0001,     verbose=0)</code></pre><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="使用自带评估工具"><a href="#使用自带评估工具" class="headerlink" title="使用自带评估工具"></a>使用自带评估工具</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(lsvc.score(x_test,y_test))</span><br></pre></td></tr></table></figure><pre><code>0.962222222222</code></pre><h3 id="使用sklearn专用工具"><a href="#使用sklearn专用工具" class="headerlink" title="使用sklearn专用工具"></a>使用sklearn专用工具</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">y_pre = lsvc.predict(x_test)</span><br><span class="line">print(classification_report(y_test,y_pre,target_names=digits.target_names.astype(<span class="built_in">str</span>)))</span><br></pre></td></tr></table></figure><pre><code>             precision    recall  f1-score   support          0       0.98      0.98      0.98        53          1       0.98      0.98      0.98        42          2       1.00      1.00      1.00        41          3       0.98      0.92      0.95        52          4       0.94      1.00      0.97        47          5       0.92      0.92      0.92        39          6       1.00      1.00      1.00        43          7       1.00      0.94      0.97        48          8       0.92      0.95      0.93        37          9       0.90      0.94      0.92        48avg / total       0.96      0.96      0.96       450</code></pre><p>tips：可以发现有意思的一点：数字2和6是机器看来与其他数字最不同的</p>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于sklearn的线性分类器</title>
      <link href="2017/10/21/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/"/>
      <url>2017/10/21/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="导入可能用到的Python库"><a href="#导入可能用到的Python库" class="headerlink" title="导入可能用到的Python库"></a>导入可能用到的Python库</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><ul><li>学习机器学习算法——线性分类器</li><li>使用良性/恶性乳腺癌肿瘤数据集进行预测</li></ul><h1 id="理论学习"><a href="#理论学习" class="headerlink" title="理论学习"></a>理论学习</h1><h2 id="线性分类器"><a href="#线性分类器" class="headerlink" title="线性分类器"></a>线性分类器</h2><p>特征与分类结果存在线性关系的模型为线性分类器，模型通过累积特征和对应权值的方式决策，几何学上可看成一个n维空间中的超平面，学习的过程就是不断调整超平面的位置与倾斜程度，使该超平面可以最完美的将属于不同类别的特征点区分开，公式为：<script type="math/tex">f(w,x,b) = w^{T}x+b</script></p><h2 id="logistic-函数"><a href="#logistic-函数" class="headerlink" title="logistic 函数"></a>logistic 函数</h2><p>线性分类器输出的是一个数，我们希望这个数在区间[0,1]之间，需要一个映射关系，这个映射关系就是logistic函数<script type="math/tex">g(x) = \cfrac{1}{1 + e^{-x}}</script>下面使用numpy和matplot绘制该函数的图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(start=-<span class="number">10</span>,stop=<span class="number">10</span>,num=<span class="number">1000</span>)</span><br><span class="line">y = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2017/10/21/%E5%9F%BA%E4%BA%8Esklearn%E7%9A%84%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/logistics.png" class=""><p>将线性分类器公式带入logistics函数后，可得logistics回归模型<script type="math/tex">f(x,w,b) = \cfrac{1}{1 + e^{-(w^{T}x+b)}}</script></p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>完成了模型的构建之后，需要对算法进行优化已确定最优的W和b参数。这时，需要一个函数用于评价现有参数的质量，这个函数应该满足以下条件</p><ul><li>连续可导（用于基于梯度的优化算法需要连续可导）</li><li>当预测结果越正确时，函数取值越大；预测结果越错误时，函数取值越小（反过来也可）</li></ul><p>对于一个logistics的线性分类器，可以将输出看做取1值的概率，那么，该分类器可以视为一个条件概率$P(y|x)$，其中w与b是分布的参数，于是我们使用最大似然估计的方法确定这个评价函数(其中y是期望输出，即正确值)<script type="math/tex">l(w,b) = \prod ((f(w,b,x))^{y}*(1 - f(w,b,x))^{1 - y})</script></p><ul><li>是否连续可导：是</li><li>当y = 0时，$l(w,b) = 1 - f(w,b,x)$，预测值越接近0，取值越大；y=1时同理</li></ul><p>于是我们只要对$l(w,b)$进行优化，通过梯度优化的方法找到最好的w，b参数即可</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="导入数据——良性-恶性乳腺癌肿瘤数据集"><a href="#导入数据——良性-恶性乳腺癌肿瘤数据集" class="headerlink" title="导入数据——良性/恶性乳腺癌肿瘤数据集"></a>导入数据——良性/恶性乳腺癌肿瘤数据集</h2><h3 id="数据下载"><a href="#数据下载" class="headerlink" title="数据下载"></a>数据下载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">data_url = <span class="string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;</span></span><br><span class="line">data_label = <span class="string">&quot;&quot;&quot; 1. Sample code number            1id number</span></span><br><span class="line"><span class="string">   2. Clump Thickness               1 - 10</span></span><br><span class="line"><span class="string">   3. Uniformity of Cell Size       1 - 10</span></span><br><span class="line"><span class="string">   4. Uniformity of Cell Shape      1 - 10</span></span><br><span class="line"><span class="string">   5. Marginal Adhesion             1 - 10</span></span><br><span class="line"><span class="string">   6. Single Epithelial Cell Size   1 - 10</span></span><br><span class="line"><span class="string">   7. Bare Nuclei                   1 - 10</span></span><br><span class="line"><span class="string">   8. Bland Chromatin               1 - 10</span></span><br><span class="line"><span class="string">   9. Normal Nucleoli               1 - 10</span></span><br><span class="line"><span class="string">  10. Mitoses                       1 - 10</span></span><br><span class="line"><span class="string">  11. Class                         2 for benign, 4 for malignant)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">data_label = [re.sub(<span class="string">r&quot;\s+\d&quot;</span>,<span class="string">&quot;&quot;</span>,x[<span class="number">2</span>:]) <span class="keyword">for</span> x <span class="keyword">in</span> re.findall(<span class="string">r&quot;\. [\w\s]+\d&quot;</span>,data_label)]</span><br><span class="line">print(data_label)</span><br><span class="line">data = pd.read_csv(data_url,names=data_label)</span><br><span class="line">print(data[:<span class="number">5</span>],data.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[&#39;Sample code numberid number&#39;, &#39;Clump Thickness&#39;, &#39;Uniformity of Cell Size&#39;, &#39;Uniformity of Cell Shape&#39;, &#39;Marginal Adhesion&#39;, &#39;Single Epithelial Cell Size&#39;, &#39;Bare Nuclei&#39;, &#39;Bland Chromatin&#39;, &#39;Normal Nucleoli&#39;, &#39;Mitoses&#39;, &#39;Class&#39;]</span><br><span class="line">   Sample code numberid number  Clump Thickness  Uniformity of Cell Size  \</span><br><span class="line">0                      1000025                5                        1   </span><br><span class="line">1                      1002945                5                        4   </span><br><span class="line">2                      1015425                3                        1   </span><br><span class="line">3                      1016277                6                        8   </span><br><span class="line">4                      1017023                4                        1   </span><br><span class="line"></span><br><span class="line">   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \</span><br><span class="line">0                         1                  1                            2   </span><br><span class="line">1                         4                  5                            7   </span><br><span class="line">2                         1                  1                            2   </span><br><span class="line">3                         8                  1                            3   </span><br><span class="line">4                         1                  3                            2   </span><br><span class="line"></span><br><span class="line">  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  </span><br><span class="line">0           1                3                1        1      2  </span><br><span class="line">1          10                3                2        1      2  </span><br><span class="line">2           2                3                1        1      2  </span><br><span class="line">3           4                3                7        1      2  </span><br><span class="line">4           1                3                1        1      2   (699, 11)</span><br></pre></td></tr></table></figure><h3 id="清洗数据（去除有缺失的数据）"><a href="#清洗数据（去除有缺失的数据）" class="headerlink" title="清洗数据（去除有缺失的数据）"></a>清洗数据（去除有缺失的数据）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = data.replace(to_replace=<span class="string">&quot;?&quot;</span>,value=np.nan)</span><br><span class="line">data = data.dropna(how=<span class="string">&#x27;any&#x27;</span>)</span><br><span class="line">print(data.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(683, 11)</span><br></pre></td></tr></table></figure><p>​    </p><h3 id="切分数据集（75-训练-25-测试）"><a href="#切分数据集（75-训练-25-测试）" class="headerlink" title="切分数据集（75%训练-25%测试）"></a>切分数据集（75%训练-25%测试）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(data[data_label[:<span class="number">10</span>]],data[data_label[<span class="number">10</span>]],test_size=<span class="number">0.25</span>,random_state=<span class="number">1</span>)</span><br><span class="line">print(x_train.shape,x_test.shape)</span><br><span class="line">print(y_train.shape,y_test.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(512, 10) (171, 10)</span><br><span class="line">(512,) (171,)</span><br></pre></td></tr></table></figure><p><code>sklearn.cross_validation</code>中的<code>train_test_split()</code>函数用于切分数据集，输入参数为：</p><ul><li>数据</li><li>标签</li><li>test_size：0~1之间，表示测试集占总数据的比例</li><li>random_state：随机种子</li></ul><h3 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">x_train_norm = ss.fit_transform(x_train)</span><br><span class="line">x_test_norm = ss.transform(x_test)</span><br></pre></td></tr></table></figure><ul><li><code>StandardScaler</code>的<code>fit_transform()</code>函数，先计算均值与方差再标准化</li><li><code>StandardScaler</code>的<code>transform()</code>函数，使用<code>fit_transform()</code>计算出的均值方差标准化</li></ul><h2 id="模型建立与训练"><a href="#模型建立与训练" class="headerlink" title="模型建立与训练"></a>模型建立与训练</h2><h3 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h3><h4 id="logistics分类器"><a href="#logistics分类器" class="headerlink" title="logistics分类器"></a>logistics分类器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br></pre></td></tr></table></figure><h4 id="SGD分类器"><a href="#SGD分类器" class="headerlink" title="SGD分类器"></a>SGD分类器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">sgdc = SGDClassifier()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c:\users\qiank\appdata\local\programs\python\python35\lib\site-packages\sklearn\linear_model\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in &lt;class &#39;sklearn.linear_model.stochastic_gradient.SGDClassifier&#39;&gt; in 0.19. If both are left unset, they default to max_iter&#x3D;5 and tol&#x3D;None. If tol is not None, max_iter defaults to max_iter&#x3D;1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.</span><br><span class="line">  &quot;and default tol will be 1e-3.&quot; % type(self), FutureWarning)</span><br></pre></td></tr></table></figure><h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><h4 id="logistics分类器-1"><a href="#logistics分类器-1" class="headerlink" title="logistics分类器"></a>logistics分类器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr.fit(x_train_norm,y_train)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegression(C&#x3D;1.0, class_weight&#x3D;None, dual&#x3D;False, fit_intercept&#x3D;True,</span><br><span class="line">          intercept_scaling&#x3D;1, max_iter&#x3D;100, multi_class&#x3D;&#39;ovr&#39;, n_jobs&#x3D;1,</span><br><span class="line">          penalty&#x3D;&#39;l2&#39;, random_state&#x3D;None, solver&#x3D;&#39;liblinear&#39;, tol&#x3D;0.0001,</span><br><span class="line">          verbose&#x3D;0, warm_start&#x3D;False)</span><br></pre></td></tr></table></figure><h4 id="SGD分类器-1"><a href="#SGD分类器-1" class="headerlink" title="SGD分类器"></a>SGD分类器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sgdc.fit(x_train_norm,y_train)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SGDClassifier(alpha&#x3D;0.0001, average&#x3D;False, class_weight&#x3D;None, epsilon&#x3D;0.1,</span><br><span class="line">       eta0&#x3D;0.0, fit_intercept&#x3D;True, l1_ratio&#x3D;0.15,</span><br><span class="line">       learning_rate&#x3D;&#39;optimal&#39;, loss&#x3D;&#39;hinge&#39;, max_iter&#x3D;5, n_iter&#x3D;None,</span><br><span class="line">       n_jobs&#x3D;1, penalty&#x3D;&#39;l2&#39;, power_t&#x3D;0.5, random_state&#x3D;None,</span><br><span class="line">       shuffle&#x3D;True, tol&#x3D;None, verbose&#x3D;0, warm_start&#x3D;False)</span><br></pre></td></tr></table></figure><h3 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> </span><br></pre></td></tr></table></figure><h4 id="logistics分类器-2"><a href="#logistics分类器-2" class="headerlink" title="logistics分类器"></a>logistics分类器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(lr.score(x_test_norm,y_test))</span><br><span class="line">y_result = lr.predict(x_test_norm)</span><br><span class="line">print(classification_report(y_test,y_result,target_names=[<span class="string">&#x27;Benign&#x27;</span>,<span class="string">&#x27;Malignant&#x27;</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0.988304093567</span><br><span class="line">             precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">     Benign       0.98      1.00      0.99       111</span><br><span class="line">  Malignant       1.00      0.97      0.98        60</span><br><span class="line"></span><br><span class="line">avg &#x2F; total       0.99      0.99      0.99       171</span><br></pre></td></tr></table></figure><p>​    </p><h4 id="SGD分类器-2"><a href="#SGD分类器-2" class="headerlink" title="SGD分类器"></a>SGD分类器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(sgdc.score(x_test_norm,y_test))</span><br><span class="line">y_result = sgdc.predict(x_test_norm)</span><br><span class="line">print(classification_report(y_test,y_result,target_names=[<span class="string">&#x27;Benign&#x27;</span>,<span class="string">&#x27;Malignant&#x27;</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0.970760233918</span><br><span class="line">             precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">     Benign       0.96      1.00      0.98       111</span><br><span class="line">  Malignant       1.00      0.92      0.96        60</span><br><span class="line"></span><br><span class="line">avg &#x2F; total       0.97      0.97      0.97       171</span><br></pre></td></tr></table></figure><p>​    </p><ul><li><code>classification_report()</code>用于测试准确率，精确率和召回率</li><li><code>.score()</code>用于评估本模型的准确率</li></ul>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch构造MLP中的dropout与批标准化</title>
      <link href="2017/10/13/Pytorch%E6%9E%84%E9%80%A0MLP%E4%B8%AD%E7%9A%84dropout%E4%B8%8E%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96/"/>
      <url>2017/10/13/Pytorch%E6%9E%84%E9%80%A0MLP%E4%B8%AD%E7%9A%84dropout%E4%B8%8E%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="MLP中实现dropout，批标准化"><a href="#MLP中实现dropout，批标准化" class="headerlink" title="MLP中实现dropout，批标准化"></a>MLP中实现dropout，批标准化</h1><h2 id="基本网络代码"><a href="#基本网络代码" class="headerlink" title="基本网络代码"></a>基本网络代码</h2><ul><li>三层MLP</li><li>使用MNIST数据集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> pt</span><br><span class="line"><span class="keyword">import</span> torchvision <span class="keyword">as</span> ptv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">train_set = ptv.datasets.MNIST(<span class="string">&quot;../../pytorch_database/mnist/train&quot;</span>,train=<span class="literal">True</span>,transform=ptv.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_set = ptv.datasets.MNIST(<span class="string">&quot;../../pytorch_database/mnist/test&quot;</span>,train=<span class="literal">False</span>,transform=ptv.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">train_dataset = pt.utils.data.DataLoader(train_set,batch_size=<span class="number">100</span>)</span><br><span class="line">test_dataset = pt.utils.data.DataLoader(test_set,batch_size=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">pt.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MLP,self).__init__()</span><br><span class="line">        self.fc1 = pt.nn.Linear(<span class="number">784</span>,<span class="number">512</span>)</span><br><span class="line">        self.fc2 = pt.nn.Linear(<span class="number">512</span>,<span class="number">128</span>)</span><br><span class="line">        self.fc3 = pt.nn.Linear(<span class="number">128</span>,<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,din</span>):</span></span><br><span class="line">        din = din.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        dout = pt.nn.functional.relu(self.fc1(din))</span><br><span class="line">        dout = pt.nn.functional.relu(self.fc2(dout))</span><br><span class="line">        <span class="keyword">return</span> pt.nn.functional.softmax(self.fc3(dout))</span><br><span class="line">model = MLP().cuda()</span><br><span class="line">print(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss func and optim</span></span><br><span class="line">optimizer = pt.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># accuarcy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AccuarcyCompute</span>(<span class="params">pred,label</span>):</span></span><br><span class="line">    pred = pred.cpu().data.numpy()</span><br><span class="line">    label = label.cpu().data.numpy()</span><br><span class="line">    test_np = (np.argmax(pred,<span class="number">1</span>) == label)</span><br><span class="line">    test_np = np.float32(test_np)</span><br><span class="line">    <span class="keyword">return</span> np.mean(test_np)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">    </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">        (inputs,labels) = data</span><br><span class="line">        inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">        labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    </span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">    </span><br><span class="line">        loss = lossfunc(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">    </span><br><span class="line">        optimizer.step()</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(i,<span class="string">&quot;:&quot;</span>,AccuarcyCompute(outputs,labels))</span><br></pre></td></tr></table></figure><pre><code>MLP (  (fc1): Linear (784 -&gt; 512)  (fc2): Linear (512 -&gt; 128)  (fc3): Linear (128 -&gt; 10))0 : 0.1100 : 0.2200 : 0.34300 : 0.17400 : 0.51500 : 0.520 : 0.79100 : 0.77200 : 0.69300 : 0.75400 : 0.85500 : 0.850 : 0.88100 : 0.8200 : 0.76300 : 0.79400 : 0.85500 : 0.850 : 0.89100 : 0.81200 : 0.77300 : 0.82400 : 0.85500 : 0.86</code></pre><h2 id="增加批标准化"><a href="#增加批标准化" class="headerlink" title="增加批标准化"></a>增加批标准化</h2><p>批标准化是添加在激活函数之前，使用标准化的方式将输入处理到一个区域内或者近似平均的分布在一个区域内<br>在pytorch中，使用<code>torch.nn.BatchNorm1/2/3d（）</code>函数表示一个批标准化层，使用方法与其它层类似</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">pt.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MLP,self).__init__()</span><br><span class="line">        self.fc1 = pt.nn.Linear(<span class="number">784</span>,<span class="number">512</span>)</span><br><span class="line">        self.norm1 = pt.nn.BatchNorm1d(<span class="number">512</span>,momentum=<span class="number">0.5</span>)</span><br><span class="line">        self.fc2 = pt.nn.Linear(<span class="number">512</span>,<span class="number">128</span>)</span><br><span class="line">        self.norm2 = pt.nn.BatchNorm2d(<span class="number">128</span>,momentum=<span class="number">0.5</span>)</span><br><span class="line">        self.fc3 = pt.nn.Linear(<span class="number">128</span>,<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,din</span>):</span></span><br><span class="line">        din = din.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        dout = pt.nn.functional.relu(self.norm1(self.fc1(din)))</span><br><span class="line">        dout = pt.nn.functional.relu(self.norm2(self.fc2(dout)))</span><br><span class="line">        <span class="keyword">return</span> pt.nn.functional.softmax(self.fc3(dout))</span><br><span class="line">model_norm = MLP().cuda()</span><br><span class="line">print(model_norm)</span><br><span class="line"></span><br><span class="line">optimizer = pt.optim.SGD(model_norm.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br></pre></td></tr></table></figure><pre><code>MLP (  (fc1): Linear (784 -&gt; 512)  (norm1): BatchNorm1d(512, eps=1e-05, momentum=0.5, affine=True)  (fc2): Linear (512 -&gt; 128)  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.5, affine=True)  (fc3): Linear (128 -&gt; 10))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">    </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">        (inputs,labels) = data</span><br><span class="line">        inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">        labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    </span><br><span class="line">        outputs = model_norm(inputs)</span><br><span class="line">    </span><br><span class="line">        loss = lossfunc(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">    </span><br><span class="line">        optimizer.step()</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            print(i,<span class="string">&quot;:&quot;</span>,AccuarcyCompute(outputs,labels))</span><br></pre></td></tr></table></figure><pre><code>0 : 0.2200 : 0.69400 : 0.890 : 0.96200 : 0.95400 : 0.970 : 0.97200 : 0.96400 : 0.990 : 0.97200 : 0.97400 : 0.990 : 0.97200 : 0.97400 : 0.990 : 0.97200 : 0.98400 : 0.99</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">accuarcy_list = []</span><br><span class="line"><span class="keyword">for</span> i,(inputs,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataset):</span><br><span class="line">    inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">    labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    outputs = model_norm(inputs)</span><br><span class="line">    accuarcy_list.append(AccuarcyCompute(outputs,labels))</span><br><span class="line">print(<span class="built_in">sum</span>(accuarcy_list) / <span class="built_in">len</span>(accuarcy_list))</span><br></pre></td></tr></table></figure><pre><code>0.976300007105</code></pre><p>与不使用批标准化的网络（准确率93%左右）相比，使用批标准化的网络准确率由明显的提高</p><h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><p>dropout是一种常见的防止过拟合的方法，通过将网络中的神经元随机的置0来达到防止过拟合的目的<br>pytorch中使用<code>torch.nn.Dropout()</code>和<code>torch.nn.Dropout2/3d()</code>函数构造，且该层只在训练中起作用，在预测时dropout将不会工作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">pt.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MLP,self).__init__()</span><br><span class="line">        self.fc1 = pt.nn.Linear(<span class="number">784</span>,<span class="number">512</span>)</span><br><span class="line">        self.drop1 = pt.nn.Dropout(<span class="number">0.6</span>)</span><br><span class="line">        self.fc2 = pt.nn.Linear(<span class="number">512</span>,<span class="number">128</span>)</span><br><span class="line">        self.drop2 = pt.nn.Dropout(<span class="number">0.6</span>)</span><br><span class="line">        self.fc3 = pt.nn.Linear(<span class="number">128</span>,<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,din</span>):</span></span><br><span class="line">        din = din.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        dout = pt.nn.functional.relu(self.drop1(self.fc1(din)))</span><br><span class="line">        dout = pt.nn.functional.relu(self.drop2(self.fc2(dout)))</span><br><span class="line">        <span class="keyword">return</span> pt.nn.functional.softmax(self.fc3(dout))</span><br><span class="line">model_drop = MLP().cuda()</span><br><span class="line">print(model_drop)</span><br><span class="line">optimizer = pt.optim.SGD(model_drop.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br></pre></td></tr></table></figure><pre><code>MLP (  (fc1): Linear (784 -&gt; 512)  (drop1): Dropout (p = 0.6)  (fc2): Linear (512 -&gt; 128)  (drop2): Dropout (p = 0.6)  (fc3): Linear (128 -&gt; 10))</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">    </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">        (inputs,labels) = data</span><br><span class="line">        inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">        labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    </span><br><span class="line">        outputs = model_drop(inputs)</span><br><span class="line">    </span><br><span class="line">        loss = lossfunc(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">    </span><br><span class="line">        optimizer.step()</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            print(i,<span class="string">&quot;:&quot;</span>,AccuarcyCompute(outputs,labels))</span><br></pre></td></tr></table></figure><pre><code>0 : 0.11200 : 0.25400 : 0.320 : 0.5200 : 0.51400 : 0.740 : 0.8200 : 0.68400 : 0.80 : 0.86200 : 0.74400 : 0.850 : 0.88200 : 0.78400 : 0.80 : 0.9200 : 0.75400 : 0.83</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">accuarcy_list = []</span><br><span class="line"><span class="keyword">for</span> i,(inputs,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataset):</span><br><span class="line">    inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">    labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    outputs = model_drop(inputs)</span><br><span class="line">    accuarcy_list.append(AccuarcyCompute(outputs,labels))</span><br><span class="line">print(<span class="built_in">sum</span>(accuarcy_list) / <span class="built_in">len</span>(accuarcy_list))</span><br></pre></td></tr></table></figure><pre><code>0.840299996734</code></pre><p>可以看到，dropout对于系统性能的还是有比较大的影响的，对于这种微型网络来说，泛化能力的提升并不明显</p><h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p>当批标准化和dropout同时存在时，这两个层次的相互位置该如何考虑</p><ul><li>-&gt; dropout-&gt;norm-&gt;function?</li><li>-&gt; norm-&gt;dropout-&gt;function?</li></ul>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Pytorch的mlp网络</title>
      <link href="2017/10/04/%E5%9F%BA%E4%BA%8EPytorch%E7%9A%84mlp%E7%BD%91%E7%BB%9C/"/>
      <url>2017/10/04/%E5%9F%BA%E4%BA%8EPytorch%E7%9A%84mlp%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="基于Pytorch的MLP实现"><a href="#基于Pytorch的MLP实现" class="headerlink" title="基于Pytorch的MLP实现"></a>基于Pytorch的MLP实现</h1><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul><li>使用pytorch构建MLP网络</li><li>训练集使用MNIST数据集</li><li>使用GPU加速运算</li><li>要求准确率能达到92%以上</li><li>保存模型<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="数据集：MNIST数据集的载入"><a href="#数据集：MNIST数据集的载入" class="headerlink" title="数据集：MNIST数据集的载入"></a>数据集：MNIST数据集的载入</h3>MNIST数据集是一种常用的数据集，为28*28的手写数字训练集，label使用独热码，在pytorch中，可以使用<code>torchvision.datasets.MNIST()</code>和<code>torch.utils.data.DataLoader（）</code>来导入数据集,其中</li><li><code>torchvision.datasets.MNIST()</code>:用于下载，导入数据集</li><li><code>torch.utils.data.DataLoader（）</code>:用于将数据集整理成batch的形式并转换为可迭代对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> pt</span><br><span class="line"><span class="keyword">import</span> torchvision <span class="keyword">as</span> ptv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_set = ptv.datasets.MNIST(<span class="string">&quot;../../pytorch_database/mnist/train&quot;</span>,train=<span class="literal">True</span>,transform=ptv.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_set = ptv.datasets.MNIST(<span class="string">&quot;../../pytorch_database/mnist/test&quot;</span>,train=<span class="literal">False</span>,transform=ptv.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = pt.utils.data.DataLoader(train_set,batch_size=<span class="number">100</span>)</span><br><span class="line">test_dataset = pt.utils.data.DataLoader(test_set,batch_size=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><h3 id="网络结构构建"><a href="#网络结构构建" class="headerlink" title="网络结构构建"></a>网络结构构建</h3><p>网络使用最简单的MLP模型，使用最简单的线性层即可构建,本次网络一共有3层全连接层，分别为28*28-&gt;512,512-&gt;128,128-&gt;10,除了输出层的激活函数使用softmax以外，其他均采用relu</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">pt.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MLP,self).__init__()</span><br><span class="line">        self.fc1 = pt.nn.Linear(<span class="number">784</span>,<span class="number">512</span>)</span><br><span class="line">        self.fc2 = pt.nn.Linear(<span class="number">512</span>,<span class="number">128</span>)</span><br><span class="line">        self.fc3 = pt.nn.Linear(<span class="number">128</span>,<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,din</span>):</span></span><br><span class="line">        din = din.view(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">        dout = pt.nn.functional.relu(self.fc1(din))</span><br><span class="line">        dout = pt.nn.functional.relu(self.fc2(dout))</span><br><span class="line">        <span class="keyword">return</span> pt.nn.functional.softmax(self.fc3(dout))</span><br><span class="line">model = MLP().cuda()</span><br><span class="line">print(model)</span><br></pre></td></tr></table></figure><pre><code>MLP (  (fc1): Linear (784 -&gt; 512)  (fc2): Linear (512 -&gt; 128)  (fc3): Linear (128 -&gt; 10))</code></pre><h3 id="代价函数，优化器和准确率检测"><a href="#代价函数，优化器和准确率检测" class="headerlink" title="代价函数，优化器和准确率检测"></a>代价函数，优化器和准确率检测</h3><p>代价函数使用交叉熵函数，使用numpy计算准确率（pytorch中也有相关函数），优化器使用最简单的SGD</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss func and optim</span></span><br><span class="line">optimizer = pt.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line">lossfunc = pt.nn.CrossEntropyLoss().cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># accuarcy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">AccuarcyCompute</span>(<span class="params">pred,label</span>):</span></span><br><span class="line">    pred = pred.cpu().data.numpy()</span><br><span class="line">    label = label.cpu().data.numpy()</span><br><span class="line"><span class="comment">#     print(pred.shape(),label.shape())</span></span><br><span class="line">    test_np = (np.argmax(pred,<span class="number">1</span>) == label)</span><br><span class="line">    test_np = np.float32(test_np)</span><br><span class="line">    <span class="keyword">return</span> np.mean(test_np)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test accuarcy</span></span><br><span class="line"><span class="comment"># print(AccuarcyCompute(</span></span><br><span class="line"><span class="comment">#     np.array([[1,10,6],[0,2,5]],dtype=np.float32),</span></span><br><span class="line"><span class="comment">#     np.array([[1,2,8],[1,2,5]],dtype=np.float32)))</span></span><br></pre></td></tr></table></figure><h3 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h3><p>训练网络的步骤分为以下几步：</p><ol><li>初始化，清空网络内上一次训练得到的梯度</li><li>载入数据为Variable，送入网络进行前向传播</li><li>计算代价函数，并进行反向传播计算梯度</li><li>调用优化器进行优化</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">    </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">        (inputs,labels) = data</span><br><span class="line">        inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">        labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    </span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">    </span><br><span class="line">        loss = lossfunc(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">    </span><br><span class="line">        optimizer.step()</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(i,<span class="string">&quot;:&quot;</span>,AccuarcyCompute(outputs,labels))</span><br></pre></td></tr></table></figure><pre><code>0 : 0.9100 : 0.84200 : 0.82300 : 0.88400 : 0.9500 : 0.920 : 0.93100 : 0.91200 : 0.9300 : 0.91400 : 0.9500 : 0.910 : 0.93100 : 0.91200 : 0.94300 : 0.91400 : 0.93500 : 0.920 : 0.96100 : 0.94200 : 0.95300 : 0.91400 : 0.93500 : 0.94</code></pre><h3 id="测试网络"><a href="#测试网络" class="headerlink" title="测试网络"></a>测试网络</h3><p>使用使用测试集训练网络，直接计算结果并将计算准确率即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">accuarcy_list = []</span><br><span class="line"><span class="keyword">for</span> i,(inputs,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataset):</span><br><span class="line">    inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">    labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    accuarcy_list.append(AccuarcyCompute(outputs,labels))</span><br><span class="line">print(<span class="built_in">sum</span>(accuarcy_list) / <span class="built_in">len</span>(accuarcy_list))</span><br></pre></td></tr></table></figure><pre><code>0.936700002551</code></pre><h3 id="保存网络"><a href="#保存网络" class="headerlink" title="保存网络"></a>保存网络</h3><p>pytorch提供了两种保存网络的方法，分别是保存参数和保存模型</p><ul><li>保存参数：仅仅保存网络中的参数，不保存模型，在load的时候要预先定义模型</li><li>保存模型：保存全部参数与模型，load后直接使用</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># only save paramters</span></span><br><span class="line">pt.save(model.state_dict(),<span class="string">&quot;../../pytorch_model/mlp/params/mlp_params.pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save model</span></span><br><span class="line">pt.save(model,<span class="string">&quot;../../pytorch_model/mlp/model/mlp_model.pt&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>/home/sky/virtualpython/pytorch0p2/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn&#39;t retrieve source code for container of type MLP. It won&#39;t be checked for correctness upon loading.  &quot;type &quot; + obj.__name__ + &quot;. It won&#39;t be checked &quot;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">test_save_net = MLP().cuda()</span><br><span class="line">test_save_net.load_state_dict(pt.load(<span class="string">&quot;../../pytorch_model/mlp/params/mlp_params.pt&quot;</span>))</span><br><span class="line">accuarcy_list = []</span><br><span class="line"><span class="keyword">for</span> i,(inputs,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataset):</span><br><span class="line">    inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">    labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    accuarcy_list.append(AccuarcyCompute(outputs,labels))</span><br><span class="line">print(<span class="built_in">sum</span>(accuarcy_list) / <span class="built_in">len</span>(accuarcy_list))</span><br></pre></td></tr></table></figure><pre><code>0.936700002551</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">test_save_model = pt.load(<span class="string">&quot;../../pytorch_model/mlp/model/mlp_model.pt&quot;</span>)</span><br><span class="line">accuarcy_list = []</span><br><span class="line"><span class="keyword">for</span> i,(inputs,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_dataset):</span><br><span class="line">    inputs = pt.autograd.Variable(inputs).cuda()</span><br><span class="line">    labels = pt.autograd.Variable(labels).cuda()</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    accuarcy_list.append(AccuarcyCompute(outputs,labels))</span><br><span class="line">print(<span class="built_in">sum</span>(accuarcy_list) / <span class="built_in">len</span>(accuarcy_list))</span><br></pre></td></tr></table></figure><pre><code>0.936700002551</code></pre><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="Variable转numpy的问题"><a href="#Variable转numpy的问题" class="headerlink" title="Variable转numpy的问题"></a>Variable转numpy的问题</h3><p>Variable目前没查到转为numpy的方法，考虑Variable中的数据保存在一个<code>torch.Tensor</code>中，该Tensor为<code>Variable.data</code>，直接将其转为numpy即可</p><h3 id="GPU产生的转换问题"><a href="#GPU产生的转换问题" class="headerlink" title="GPU产生的转换问题"></a>GPU产生的转换问题</h3><p>GPU上的Tensor不能直接转换为numpy，需要一个在CPU上的副本，因此可以先使用<code>Variable.cpu()</code>创建CPU副本，再使用<code>Variable.data.numpy()</code>方法</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>APB总线协议</title>
      <link href="2017/09/30/APB%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE/"/>
      <url>2017/09/30/APB%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="APB学习笔记"><a href="#APB学习笔记" class="headerlink" title="APB学习笔记"></a>APB学习笔记</h1><h2 id="APB简介"><a href="#APB简介" class="headerlink" title="APB简介"></a>APB简介</h2><blockquote><p>The APB is part of the AMBA 3 protocol family. It provides a low-cost interface that is optimized for minimal power consumption and reduced interface complexity.<br>The APB interfaces to any peripherals that are low-bandwidth and do not require the high performance of a pipelined bus interface. The APB has unpipelined protocol.<br>All signal transitions are only related to the rising edge of the clock to enable the<br>integration of APB peripherals easily into any design flow. Every transfer takes at least<br>two cycles.<br>The APB can interface with the AMBA Advanced High-performance Bus Lite<br>(AHB-Lite) and AMBA Advanced Extensible Interface (AXI). You can use it to provide<br>access to the programmable control registers of peripheral devices.</p></blockquote><p>APB是AMBA总线的组成部分，特点有：</p><ul><li>面向<strong>低功耗，低带宽</strong>应用（当然，性能和传输速度低）</li><li>非流水线设计</li><li>仅依赖时钟上升沿，每次传输最少需要两个时钟周期</li></ul><p>APB可作为AHB-Lite和AXI总线的对外低速接口</p><h2 id="写数据"><a href="#写数据" class="headerlink" title="写数据"></a>写数据</h2><h3 id="非等待模式"><a href="#非等待模式" class="headerlink" title="非等待模式"></a>非等待模式</h3><blockquote><p>The write transfer starts with the address, write data, write signal and select signal all changing after the rising edge of the clock. The first clock cycle of the transfer is called the Setup phase. After the following clock edge the enable signal is asserted, PENABLE, and this indicates that the Access phase is taking place. The address, data and control signals all remain valid throughout the Access phase. The transfer completes at the end of this cycle.</p></blockquote><p>非等待模式认为系统一直都是准备好的，因此不需要关心设备当前状态，非等待模式分为两个部分：</p><ul><li>建立部分：准备好数据（PWDATA），地址（PADDR）和并拉高需要传输信号外设的片选线（PSEL）</li><li>传输部分：拉高使能线（PENABLE），进行传输</li></ul><p>传输完成后，拉低PSEL和PENABLE，完成传输，波形图如下所示</p><img src="/2017/09/30/APB%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE/apb_no_wr.png" class=""><h3 id="等待模式"><a href="#等待模式" class="headerlink" title="等待模式"></a>等待模式</h3><blockquote><p>During an Access phase, when PENABLE is HIGH, the transfer can be extended by driving PREADY LOW.</p></blockquote><p>等待模式引入从机状态信号PREADY，当使能信号PENABLE有效时，传输开始，并持续到PREADY信号拉高。当PREADY信号未被拉高时，所有信号保持不变。其他传输过程与非等待模式相同</p><img src="/2017/09/30/APB%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE/apb_wr.png" class=""><h2 id="读数据"><a href="#读数据" class="headerlink" title="读数据"></a>读数据</h2><h3 id="非等待模式-1"><a href="#非等待模式-1" class="headerlink" title="非等待模式"></a>非等待模式</h3><p>在非等待模式中，认为从机在一个时钟周期内就能送出数据，与写数据相同分为两个模式：</p><ul><li>建立部分：准备好地址（PADDR）和并拉高需要传输信号外设的片选线（PSEL）</li><li>传输部分：拉高使能线（PENABLE），进行传输（在这个时钟沿之前从机要将数据送到数据总线PRDATA上）</li></ul><p>传输完成后，拉低PSEL和PENABLE，完成传输，波形图如下所示</p><img src="/2017/09/30/APB%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE/apb_no_re.png" class=""><h3 id="等待模式-1"><a href="#等待模式-1" class="headerlink" title="等待模式"></a>等待模式</h3><p>等待模式中，从机无法在一个时钟周期内准备好数据，则当数据未准备好时，拉低PREADY信号，传输即被”卡住“，所有由主机控制的信号都不发生变化，直达从机准备好数据，将PREADY拉高，波形如下：</p><img src="/2017/09/30/APB%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE/apb_re.png" class=""><h2 id="错误报告"><a href="#错误报告" class="headerlink" title="错误报告"></a>错误报告</h2><p>当传输发生错误时，从机拉高错误报告信号线PSLVERR，该信号会被APB桥映射到AXI或AMBA总线上，由AXI/AMBA总线的主机进行处理。系统仅关心在APB传输周期最后一个时钟周期的值。</p><p>错误报告信号线PSLVERR在系统中并不是必须的。波形如下</p><img src="/2017/09/30/APB%E6%80%BB%E7%BA%BF%E5%8D%8F%E8%AE%AE/apb_error.png" class=""><h2 id="系统状态转移与信号说明"><a href="#系统状态转移与信号说明" class="headerlink" title="系统状态转移与信号说明"></a>系统状态转移与信号说明</h2><h3 id="系统状态转移"><a href="#系统状态转移" class="headerlink" title="系统状态转移"></a>系统状态转移</h3><p>系统状态图如下：</p><ul><li>IDLE：初始状态，也是等待传输状态。当片选信号PSELx拉高时总线请求通信，进入SETUP状态</li><li>SETUP：建立状态，主从机在该状态准备好所有数据，并进入ACCESS状态</li><li>ACCESS：传输状态，拉高PENABLE信号<ul><li>当PREADY信号拉高，传输完成，根据是否有下一次传输（PSELx是否为高），进入IDLW状态后SETUP状态</li><li>当PREADY信号为低，数据未准备好，在ACCESS状态等待PREADY信号拉高</li></ul></li></ul><h3 id="端口说明"><a href="#端口说明" class="headerlink" title="端口说明"></a>端口说明</h3><div class="table-container"><table><thead><tr><th>信号名</th><th>来源</th><th>说明</th></tr></thead><tbody><tr><td>PCLK</td><td>时钟源</td><td>系统时钟，传输发生在上升沿</td></tr><tr><td>PRESETn</td><td>复位源</td><td>复位信号，低使能</td></tr><tr><td>PADDR</td><td>APB桥</td><td>地址信号，最高可达32位</td></tr><tr><td>PSELx</td><td>APB桥</td><td>片选信号，表示x从机是否被选中</td></tr><tr><td>PENABLE</td><td>APB桥</td><td>使能信号，标记传输使能</td></tr><tr><td>PWRITE</td><td>APB桥</td><td>读/写控制信号，高位写，低为读</td></tr><tr><td>PWDATA</td><td>APB桥</td><td>写数据</td></tr><tr><td>PREADY</td><td>从机</td><td>标记从机是否已将数据发送到总线，高为ready</td></tr><tr><td>PRDATA</td><td>从机</td><td>读数据</td></tr><tr><td>PSLVERR</td><td>从机</td><td>故障信号，高为发生故障</td></tr></tbody></table></div><h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p>如何判定在传输完成后是否有继续传输？</p>]]></content>
      
      
      <categories>
          
          <category> 硬件设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> AMBA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于迭代单元的不恢复余数开方器</title>
      <link href="2017/09/21/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E4%B8%8D%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E5%BC%80%E6%96%B9%E5%99%A8/"/>
      <url>2017/09/21/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E4%B8%8D%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E5%BC%80%E6%96%B9%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="基于迭代单元的不恢复余数开方器"><a href="#基于迭代单元的不恢复余数开方器" class="headerlink" title="基于迭代单元的不恢复余数开方器"></a>基于迭代单元的不恢复余数开方器</h1><h2 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h2><p>与恢复余数开方器类似，不恢复余数开方器也是通过迭代完成运算的，基本算法的伪代码如下所示</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Ra = 被开方数(位宽<span class="number">2</span>W)</span><br><span class="line">Re = 余数(初值为<span class="number">0</span>)</span><br><span class="line">Dout = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i in W -&gt; <span class="number">0</span> &#123;</span><br><span class="line">  <span class="keyword">if</span>(Re &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    Re = &#123;Re,Ra[<span class="number">2</span>i - <span class="number">1</span>],Ra[<span class="number">2</span>i]&#125; - &#123;Dout,<span class="number">2&#x27;b</span>01&#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Re = &#123;Re,Ra[<span class="number">2</span>i - <span class="number">1</span>],Ra[<span class="number">2</span>i]&#125; + &#123;Dout,<span class="number">2&#x27;b</span>11&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  Dout = &#123;Dout,!Re[MSB]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="迭代单元"><a href="#迭代单元" class="headerlink" title="迭代单元"></a>迭代单元</h2><h3 id="基本算法-1"><a href="#基本算法-1" class="headerlink" title="基本算法"></a>基本算法</h3><p>迭代单元的基本算法即基本算法中for循环包裹的部分：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">input Re = 上一余数</span><br><span class="line">input Dout = 上一结果</span><br><span class="line"><span class="keyword">if</span>(Re &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    Re = &#123;Re,Ra[<span class="number">2</span>i - <span class="number">1</span>],Ra[<span class="number">2</span>i]&#125; - &#123;Dout,<span class="number">2&#x27;b</span>01&#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Re = &#123;Re,Ra[<span class="number">2</span>i - <span class="number">1</span>],Ra[<span class="number">2</span>i]&#125; + &#123;Dout,<span class="number">2&#x27;b</span>11&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  Dout = &#123;Dout,!Re[MSB]&#125;</span><br><span class="line">output 本次余数 = Re</span><br><span class="line">output 本次结果 = Dout</span><br></pre></td></tr></table></figure><h3 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> norestore_square_cell #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>,</span><br><span class="line"><span class="keyword">parameter</span> STEP = <span class="number">0</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]radicand,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]last_dout,</span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]remainder_din,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]this_dout,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]remainder_dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]target_data = &#123;remainder_din[<span class="number">2</span> * WIDTH],remainder_din[<span class="number">2</span> * WIDTH - <span class="number">3</span>:<span class="number">0</span>],radicand[<span class="number">2</span> * STEP +:<span class="number">2</span>]&#125;;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]pos_data = &#123;last_dout,<span class="number">2&#x27;b01</span>&#125;;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]neg_data = &#123;last_dout,<span class="number">2&#x27;b11</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]pos_final_data = target_data - pos_data;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]neg_final_data = target_data + neg_data;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]final_data = (remainder_din[<span class="number">2</span> * WIDTH])?neg_final_data:pos_final_data;</span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">&#123;this_dout,remainder_dout&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder_dout &lt;= final_data;</span><br><span class="line">this_dout &lt;= &#123;last_dout[WIDTH - <span class="number">2</span>:<span class="number">0</span>],~final_data[<span class="number">2</span> * WIDTH]&#125;;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h2 id="顶层模块"><a href="#顶层模块" class="headerlink" title="顶层模块"></a>顶层模块</h2><p>顶层模块根据位宽参数生成多级迭代单元完成算法</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> square_extractor #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]radicand,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout</span><br><span class="line"><span class="comment">// output [2 * WIDTH - 1:0]remainder</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">genvar</span> i;</span><br><span class="line"><span class="keyword">generate</span></span><br><span class="line"><span class="keyword">for</span> (i = WIDTH - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i = i - <span class="number">1</span>) <span class="keyword">begin</span>:square</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]remainder_dout,remainder_din;</span><br><span class="line"><span class="keyword">wire</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]this_dout,last_dout;</span><br><span class="line"><span class="keyword">if</span>(i == WIDTH - <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> remainder_din = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">assign</span> last_dout = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> remainder_din = square[i + <span class="number">1</span>]<span class="variable">.remainder_dout</span>;</span><br><span class="line"><span class="keyword">assign</span> last_dout = square[i + <span class="number">1</span>]<span class="variable">.this_dout</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">norestore_square_cell #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH),</span><br><span class="line"><span class="variable">.STEP</span>(i)</span><br><span class="line">) u_square_cell (</span><br><span class="line"><span class="variable">.clk</span>(clk),    <span class="comment">// Clock</span></span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="variable">.radicand</span>(radicand),</span><br><span class="line"><span class="variable">.last_dout</span>(last_dout),</span><br><span class="line"><span class="variable">.remainder_din</span>(remainder_din),</span><br><span class="line"></span><br><span class="line"><span class="variable">.this_dout</span>(this_dout),</span><br><span class="line"><span class="variable">.remainder_dout</span>(remainder_dout)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">endgenerate</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> dout = square[<span class="number">0</span>]<span class="variable">.this_dout</span>;</span><br><span class="line"><span class="comment">// assign remainder = square[0].remainder_dout;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h2 id="TestBench"><a href="#TestBench" class="headerlink" title="TestBench"></a>TestBench</h2><p>由于本算法<strong>无法获得正确余数</strong>，在验证时，计算输出数据<code>dout</code>的平方和输出数据加1<code>dout + 1</code>的平方，若输入在这两个数之间的区域，判定结果正确</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> tb_square (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> clk;    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">logic</span> rst_n;  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]radicand;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout;</span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder;</span><br><span class="line"></span><br><span class="line">square_extractor #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH)</span><br><span class="line">) dut (</span><br><span class="line"><span class="variable">.clk</span>(clk),    <span class="comment">// Clock</span></span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="variable">.radicand</span>(radicand),</span><br><span class="line"></span><br><span class="line"><span class="variable">.dout</span>(dout)</span><br><span class="line"><span class="comment">// .remainder(remainder)</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">clk = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">#<span class="number">50</span> clk = ~clk;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line">#<span class="number">5</span> rst_n = <span class="number">1&#x27;b0</span>;</span><br><span class="line">#<span class="number">10</span> rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]act;</span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout_ex;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">radicand = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">radicand = (<span class="number">2</span> * WIDTH)&#x27;($urandom_range(<span class="number">0</span>,<span class="number">2</span> ** (<span class="number">2</span> * WIDTH)));</span><br><span class="line"><span class="keyword">repeat</span>(<span class="number">4</span> * WIDTH) <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">dout_ex = &#x27;&#123;dout&#125;;</span><br><span class="line"><span class="keyword">if</span>(((dout_ex + <span class="number">1</span>) ** <span class="number">2</span> &gt; radicand) &amp;&amp; (dout_ex ** <span class="number">2</span> &lt;= radicand)) <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;successfully&quot;</span>);</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;failed&quot;</span>);</span><br><span class="line"><span class="built_in">$stop</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于迭代单元的恢复余数开方器</title>
      <link href="2017/09/19/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E5%BC%80%E6%96%B9%E5%99%A8/"/>
      <url>2017/09/19/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E5%BC%80%E6%96%B9%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="基于迭代单元的恢复余数开方器"><a href="#基于迭代单元的恢复余数开方器" class="headerlink" title="基于迭代单元的恢复余数开方器"></a>基于迭代单元的恢复余数开方器</h1><h2 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h2><p>该开方器的算法与“手算”（以前并不知道开方还有这种手算的方法）算法相似，使用迭代解决，文字描述如下</p><ol><li>将0为余数的初值<code>a</code>，0作为结果初值<code>b</code></li><li>将被开方数前两位<code>&#123;I(2m + 1),I(2m)&#125;</code>取出，与01比较大小。若前两位大，则<code>&#123;I(2m + 1),I(2m)&#125; - 01</code>为输出余数（<code>a(m)</code>），输出结果1(<code>b(m)</code>)，否则<code>&#123;I(2m + 1),I(2m)&#125;</code>为输出余数（<code>a(m)</code>），输出结果0（<code>b(m)</code>）</li><li>将被开方数的从高位数第3,4位<code>&#123;I(2m - 1),I(2m - 2)&#125;</code>取出，比较<code>&#123;a(m),I(2m - 1),I(2m - 2)&#125;</code>和<code>&#123;b(m),2&#39;b01&#125;</code>的大小，若前一项大，则输出余数<code>a(m - 1)</code>为前一项减后一项，输出结果<code>b(m - 1)</code>为<code>&#123;b(m),1&#125;</code>;否则，输出余数为前一项（直接输出），输出结果<code>b(m - 1)</code>为<code>&#123;b(m),0&#125;</code></li><li>…</li><li>直到计算完被开方数结束</li></ol><h2 id="迭代单元"><a href="#迭代单元" class="headerlink" title="迭代单元"></a>迭代单元</h2><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>迭代单元的算法比较简单，描述如下：</p><ol><li>组合输入余数和当前开方数的两位<code>&#123;b,I(i),I(i - 1)&#125;</code>，组合输入结果和01为<code>&#123;a,2&#39;b01&#125;</code></li><li>比较大小，若组合余数大则输出余数为组合余数减去组合结果，输出结果<code>&#123;a,1&#125;</code>；否则余数输出组合余数，结果输出<code>&#123;a,0&#125;</code></li></ol><h3 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> square_cell #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>,</span><br><span class="line"><span class="keyword">parameter</span> STEP = <span class="number">0</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]radicand,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]last_dout,</span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder_din,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]this_dout,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder_dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]target_data = &#123;remainder_din[<span class="number">2</span> * WIDTH - <span class="number">3</span>:<span class="number">0</span>],radicand[<span class="number">2</span> * STEP +:<span class="number">2</span>]&#125;;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]try_data = &#123;last_dout,<span class="number">2&#x27;b01</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">&#123;this_dout,remainder_dout&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(target_data &gt;= try_data) <span class="keyword">begin</span></span><br><span class="line">this_dout &lt;= &#123;last_dout[WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b1</span>&#125;;</span><br><span class="line">remainder_dout &lt;= target_data - try_data;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">this_dout &lt;= &#123;last_dout[WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b0</span>&#125;;</span><br><span class="line">remainder_dout &lt;= target_data;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h2 id="顶层与Testbench"><a href="#顶层与Testbench" class="headerlink" title="顶层与Testbench"></a>顶层与Testbench</h2><h3 id="顶层单元"><a href="#顶层单元" class="headerlink" title="顶层单元"></a>顶层单元</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> square_extractor #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]radicand,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout,</span><br><span class="line"><span class="keyword">output</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">genvar</span> i;</span><br><span class="line"><span class="keyword">generate</span></span><br><span class="line"><span class="keyword">for</span> (i = WIDTH - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i = i - <span class="number">1</span>) <span class="keyword">begin</span>:square</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder_dout,remainder_din;</span><br><span class="line"><span class="keyword">wire</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]this_dout,last_dout;</span><br><span class="line"><span class="keyword">if</span>(i == WIDTH - <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> remainder_din = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">assign</span> last_dout = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> remainder_din = square[i + <span class="number">1</span>]<span class="variable">.remainder_dout</span>;</span><br><span class="line"><span class="keyword">assign</span> last_dout = square[i + <span class="number">1</span>]<span class="variable">.this_dout</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">square_cell #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH),</span><br><span class="line"><span class="variable">.STEP</span>(i)</span><br><span class="line">) u_square_cell (</span><br><span class="line"><span class="variable">.clk</span>(clk),    <span class="comment">// Clock</span></span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="variable">.radicand</span>(radicand),</span><br><span class="line"><span class="variable">.last_dout</span>(last_dout),</span><br><span class="line"><span class="variable">.remainder_din</span>(remainder_din),</span><br><span class="line"></span><br><span class="line"><span class="variable">.this_dout</span>(this_dout),</span><br><span class="line"><span class="variable">.remainder_dout</span>(remainder_dout)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">endgenerate</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> dout = square[<span class="number">0</span>]<span class="variable">.this_dout</span>;</span><br><span class="line"><span class="keyword">assign</span> remainder = square[<span class="number">0</span>]<span class="variable">.remainder_dout</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h3 id="TestBench"><a href="#TestBench" class="headerlink" title="TestBench"></a>TestBench</h3><p>Testbench输入随机的输入后，等待完成，完成后取结果和余数看是否能恢复出正确的输入</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> tb_square (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> clk;    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">logic</span> rst_n;  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]radicand;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout;</span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder;</span><br><span class="line"></span><br><span class="line">square_extractor #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH)</span><br><span class="line">) dut (</span><br><span class="line"><span class="variable">.clk</span>(clk),    <span class="comment">// Clock</span></span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="variable">.radicand</span>(radicand),</span><br><span class="line"></span><br><span class="line"><span class="variable">.dout</span>(dout),</span><br><span class="line"><span class="variable">.remainder</span>(remainder)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">clk = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">#<span class="number">50</span> clk = ~clk;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line">#<span class="number">5</span> rst_n = <span class="number">1&#x27;b0</span>;</span><br><span class="line">#<span class="number">10</span> rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]act;</span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout_ex;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">radicand = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">radicand = (<span class="number">2</span> * WIDTH)&#x27;($urandom_range(<span class="number">0</span>,<span class="number">2</span> ** (<span class="number">2</span> * WIDTH)));</span><br><span class="line"><span class="keyword">repeat</span>(<span class="number">4</span> * WIDTH) <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">dout_ex = &#x27;&#123;dout&#125;;</span><br><span class="line">act = dout_ex * dout_ex + remainder;</span><br><span class="line"><span class="keyword">if</span>(act != radicand) <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$stop</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于迭代单元的除法器</title>
      <link href="2017/09/17/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E9%99%A4%E6%B3%95%E5%99%A8/"/>
      <url>2017/09/17/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E9%99%A4%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="基于迭代单元的除法器"><a href="#基于迭代单元的除法器" class="headerlink" title="基于迭代单元的除法器"></a>基于迭代单元的除法器</h1><h2 id="迭代单元"><a href="#迭代单元" class="headerlink" title="迭代单元"></a>迭代单元</h2><p>数字信号处理中，有大量的算法是基于迭代算法，即下一次的运算需要上一次运算的结果，将运算部分固化为迭代单元可以将数据处理和流程控制区分，更容易做出时序和面积优化更好的硬件描述，这次将基于迭代单元构造恢复余数和不恢复余数除法器</p><h2 id="恢复余数除法器"><a href="#恢复余数除法器" class="headerlink" title="恢复余数除法器"></a>恢复余数除法器</h2><h3 id="迭代单元-1"><a href="#迭代单元-1" class="headerlink" title="迭代单元"></a>迭代单元</h3><h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><ol><li>将除数移位i位</li><li>判断位移后的除数与余数大小</li><li>若位移除数大于余数，则余数输出当前余数，结果输出0；否则输出余数减位移除数，结果输出1</li></ol><img src="/2017/09/17/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E9%99%A4%E6%B3%95%E5%99%A8/restore.jpg" class=""><h4 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> restore_cell #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>,</span><br><span class="line"><span class="keyword">parameter</span> STEP = <span class="number">1</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,</span><br><span class="line"><span class="keyword">input</span> rst_n,</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [WIDTH * <span class="number">3</span> - <span class="number">1</span>:<span class="number">0</span>]remainder_din,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH * <span class="number">3</span> - <span class="number">1</span>:<span class="number">0</span>]remainder_dout,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> quotient</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">wire</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]divisor_exd = &#x27;&#123;divisor&#125;;</span><br><span class="line"><span class="keyword">wire</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]sub = &#123;<span class="number">1&#x27;b0</span>,remainder_din&#125; - (divisor_exd &lt;&lt; STEP);</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">&#123;remainder_dout,quotient&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(sub[WIDTH * <span class="number">3</span>] == <span class="number">1&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">remainder_dout = sub;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder_dout = remainder_din;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">quotient = ~(sub[<span class="number">3</span> * WIDTH]);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h3 id="顶层模块"><a href="#顶层模块" class="headerlink" title="顶层模块"></a>顶层模块</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> restore_cell_divider #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dividend,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout,</span><br><span class="line"><span class="keyword">output</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">genvar</span> i;</span><br><span class="line"><span class="keyword">generate</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">2</span> * WIDTH - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i = i - <span class="number">1</span>) <span class="keyword">begin</span>:restore</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]last_remaider;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]this_remaider;</span><br><span class="line"><span class="keyword">if</span>(i == <span class="number">2</span> * WIDTH - <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> last_remaider = &#x27;&#123;dividend&#125;;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> last_remaider = restore[i + <span class="number">1</span>]<span class="variable">.this_remaider</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">restore_cell #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH),</span><br><span class="line"><span class="variable">.STEP</span>(i)</span><br><span class="line">) u_restore_cell (</span><br><span class="line"><span class="variable">.clk</span>(clk),</span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),</span><br><span class="line"></span><br><span class="line"><span class="variable">.remainder_din</span>(last_remaider),</span><br><span class="line"><span class="variable">.divisor</span>(divisor),</span><br><span class="line"></span><br><span class="line"><span class="variable">.remainder_dout</span>(this_remaider),</span><br><span class="line"><span class="variable">.quotient</span>(dout[i])</span><br><span class="line">);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">endgenerate</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> remainder = restore[<span class="number">0</span>]<span class="variable">.this_remaider</span>[WIDTH - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h2 id="不恢复余数除法器"><a href="#不恢复余数除法器" class="headerlink" title="不恢复余数除法器"></a>不恢复余数除法器</h2><h3 id="迭代单元-2"><a href="#迭代单元-2" class="headerlink" title="迭代单元"></a>迭代单元</h3><h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4><ol><li>将除数移位i位</li><li>若余数大于0，余数输出余数减移位除数；否则余数输出余数加移位除数。结果输出余数符号位取反</li></ol><img src="/2017/09/17/%E5%9F%BA%E4%BA%8E%E8%BF%AD%E4%BB%A3%E5%8D%95%E5%85%83%E7%9A%84%E9%99%A4%E6%B3%95%E5%99%A8/norestore.jpg" class=""><h4 id="RTL代码-1"><a href="#RTL代码-1" class="headerlink" title="RTL代码"></a>RTL代码</h4><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> norestore_cell #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>,</span><br><span class="line"><span class="keyword">parameter</span> STEP = <span class="number">1</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,</span><br><span class="line"><span class="keyword">input</span> rst_n,</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]remainder_din,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]remainder_dout,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> quotient</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">wire</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]divisor_exd = &#x27;&#123;divisor&#125;;</span><br><span class="line"><span class="keyword">wire</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]divisor_move = divisor_exd &lt;&lt; STEP;</span><br><span class="line"><span class="keyword">wire</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]sub = remainder_din - divisor_move;</span><br><span class="line"><span class="keyword">wire</span> [WIDTH * <span class="number">3</span>:<span class="number">0</span>]add = remainder_din + divisor_move;</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">&#123;remainder_dout,quotient&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(remainder_din[<span class="number">3</span> * WIDTH] == <span class="number">&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">remainder_dout = sub;</span><br><span class="line">quotient = ~(sub[<span class="number">3</span> * WIDTH]);</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder_dout = add;</span><br><span class="line">quotient = ~(add[<span class="number">3</span> * WIDTH]);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h3 id="顶层模块-1"><a href="#顶层模块-1" class="headerlink" title="顶层模块"></a>顶层模块</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> norestore_cell_divider #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dividend,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">genvar</span> i;</span><br><span class="line"><span class="keyword">generate</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">2</span> * WIDTH - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i = i - <span class="number">1</span>) <span class="keyword">begin</span>:restore</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">3</span> * WIDTH:<span class="number">0</span>]last_remaider;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">3</span> * WIDTH:<span class="number">0</span>]this_remaider;</span><br><span class="line"><span class="keyword">if</span>(i == <span class="number">2</span> * WIDTH - <span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> last_remaider = &#x27;&#123;dividend&#125;;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">assign</span> last_remaider = restore[i + <span class="number">1</span>]<span class="variable">.this_remaider</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">norestore_cell #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH),</span><br><span class="line"><span class="variable">.STEP</span>(i)</span><br><span class="line">) u_restore_cell (</span><br><span class="line"><span class="variable">.clk</span>(clk),</span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),</span><br><span class="line"></span><br><span class="line"><span class="variable">.remainder_din</span>(last_remaider),</span><br><span class="line"><span class="variable">.divisor</span>(divisor),</span><br><span class="line"></span><br><span class="line"><span class="variable">.remainder_dout</span>(this_remaider),</span><br><span class="line"><span class="variable">.quotient</span>(dout[i])</span><br><span class="line">);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">endgenerate</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">3</span> * WIDTH:<span class="number">0</span>]remainder_final = restore[<span class="number">0</span>]<span class="variable">.this_remaider</span>;</span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(remainder_final[<span class="number">3</span> * WIDTH] == <span class="number">1&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">remainder = remainder_final[WIDTH - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder = remainder_final[WIDTH - <span class="number">1</span>:<span class="number">0</span>] + divisor;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p>需要注意的是，不恢复余数除法器最后需要调整余数为正</p>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不恢复余数除法器</title>
      <link href="2017/09/13/%E4%B8%8D%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E9%99%A4%E6%B3%95%E5%99%A8/"/>
      <url>2017/09/13/%E4%B8%8D%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E9%99%A4%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="不恢复余数除法器"><a href="#不恢复余数除法器" class="headerlink" title="不恢复余数除法器"></a>不恢复余数除法器</h2><h3 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h3><p>不恢复余数除法器的基本算法来自于恢复余数除法器，区别在于当余数变负时不停下恢复余数而是继续运行迭代，并在迭代中加上移位后除数而不是减去移位后除数，基本算法如下所示</p><ol><li>将除数向左移位到恰好大于被除数</li><li>若余数为正：余数减去移位后除数；若余数为负：余数加上移位后除数；</li><li>若现余数为正，该位结果为1，否则为0，将除数向右移位一位</li><li>重复2,3，知道移位后除数小于原除数</li></ol><h3 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> norestore_divider #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [WIDTH * <span class="number">2</span> - <span class="number">1</span>:<span class="number">0</span>]dividend,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor,</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> din_valid,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span>[<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout,</span><br><span class="line"><span class="keyword">output</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">// parameter JUDGE = 2 ** (2 * WIDTH);</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]remainder_r;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor_move;</span><br><span class="line"><span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor_lock;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]judge;</span><br><span class="line"><span class="keyword">always</span> @ (*) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(remainder_r[<span class="number">2</span> * WIDTH] == <span class="number">1&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">judge = remainder_r - divisor_move;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">judge = remainder_r + divisor_move;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">&#123;remainder_r,divisor_lock,divisor_move,dout&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(din_valid == <span class="number">1&#x27;b1</span>) <span class="keyword">begin</span><span class="comment">//lock input data</span></span><br><span class="line">remainder_r[WIDTH * <span class="number">2</span> - <span class="number">1</span>:<span class="number">0</span>] &lt;= dividend;</span><br><span class="line">remainder_r[<span class="number">2</span> * WIDTH] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">divisor_move[<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">2</span> * WIDTH] &lt;= divisor;</span><br><span class="line">divisor_move[<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">divisor_lock &lt;= divisor;</span><br><span class="line">dout &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>((divisor_move &gt; &#x27;&#123;remainder_r&#125;) &amp;&amp; (dout == <span class="number">&#x27;b0</span>)) <span class="keyword">begin</span></span><br><span class="line">         <span class="comment">//开始运算条件</span></span><br><span class="line">remainder_r &lt;= remainder_r;</span><br><span class="line">dout &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">divisor_move &lt;= divisor_move &gt;&gt; <span class="number">1</span>;</span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(divisor_move &gt;= &#x27;&#123;divisor_lock&#125;) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(remainder_r[<span class="number">2</span> * WIDTH] == <span class="number">1&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">remainder_r &lt;= judge;</span><br><span class="line"><span class="keyword">if</span>(judge[<span class="number">2</span> * WIDTH] == <span class="number">&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b1</span>&#125;;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b0</span>&#125;;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder_r &lt;= judge;</span><br><span class="line"><span class="keyword">if</span>(judge[<span class="number">2</span> * WIDTH] == <span class="number">&#x27;b0</span>) <span class="keyword">begin</span></span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b1</span>&#125;;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b0</span>&#125;;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">divisor_move &lt;= divisor_move &gt;&gt; <span class="number">1</span>;</span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(remainder_r[<span class="number">2</span> * WIDTH - <span class="number">1</span>] == <span class="number">1&#x27;b1</span>) <span class="keyword">begin</span></span><br><span class="line">         <span class="comment">//调整余数</span></span><br><span class="line">remainder_r &lt;= remainder_r + divisor_lock;</span><br><span class="line">dout &lt;= dout;</span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line">divisor_move &lt;= divisor_move;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder_r &lt;= remainder_r;</span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line">divisor_move &lt;= divisor_move;</span><br><span class="line">dout &lt;= dout;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> remainder = remainder_r[WIDTH - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h3 id="测试平台"><a href="#测试平台" class="headerlink" title="测试平台"></a>测试平台</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> tb_divider (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> clk;    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">logic</span> rst_n;  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dividend;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> din_valid;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder;</span><br><span class="line"></span><br><span class="line">norestore_divider #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH)</span><br><span class="line">) dut (</span><br><span class="line"><span class="variable">.clk</span>(clk),    <span class="comment">// Clock</span></span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="variable">.dividend</span>(dividend),</span><br><span class="line"><span class="variable">.divisor</span>(divisor),</span><br><span class="line"></span><br><span class="line"><span class="variable">.din_valid</span>(din_valid),</span><br><span class="line"></span><br><span class="line"><span class="variable">.dout</span>(dout),</span><br><span class="line"><span class="variable">.remainder</span>(remainder)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">clk = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">#<span class="number">50</span> clk = ~clk;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"># <span class="number">5</span> rst_n = <span class="number">&#x27;b0</span>;</span><br><span class="line">#<span class="number">10</span> rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout_exp;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder_exp;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">&#123;dividend,divisor,din_valid&#125; = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">dividend = (<span class="number">2</span> * WIDTH)&#x27;($urandom_range(<span class="number">0</span>,<span class="number">2</span> ** (<span class="number">2</span> * WIDTH)));</span><br><span class="line">divisor = (WIDTH)&#x27;($urandom_range(<span class="number">1</span>,<span class="number">2</span> ** WIDTH - <span class="number">1</span>));</span><br><span class="line">din_valid = <span class="number">1&#x27;b1</span>;</span><br><span class="line"></span><br><span class="line">remainder_exp = dividend % divisor;</span><br><span class="line">dout_exp = (dividend - remainder_exp) / divisor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">repeat</span>(<span class="number">5</span> * WIDTH) <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">din_valid = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span>((remainder == remainder_exp) &amp;&amp; (dout_exp == dout)) <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;successfully&quot;</span>);</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;failed&quot;</span>);</span><br><span class="line"><span class="built_in">$stop</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>selenium初探</title>
      <link href="2017/09/11/selenium%E5%88%9D%E6%8E%A2/"/>
      <url>2017/09/11/selenium%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="selenium初探"><a href="#selenium初探" class="headerlink" title="selenium初探"></a>selenium初探</h1><h2 id="selenium简介与安装"><a href="#selenium简介与安装" class="headerlink" title="selenium简介与安装"></a>selenium简介与安装</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>selenium是一个网站的自动化测试库，但由于其具有大量的自动化库而且可以调用浏览器，常常被用于爬虫技术。也正是因为其是调用浏览器的，这几乎成了一个无解的爬虫。在神经网络领域需要大量的数据集，爬虫是一种快速获得数据的方法，这也正是我学习这个库的动机</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><h4 id="selenium安装"><a href="#selenium安装" class="headerlink" title="selenium安装"></a>selenium安装</h4><p>使用<code>pip install -U selenium</code>即可</p><h4 id="Diver安装"><a href="#Diver安装" class="headerlink" title="Diver安装"></a>Diver安装</h4><p>selenium要调用各种浏览器需要对应的浏览器driver，我将使用chrome测试，测试成功后转为无界面的PhontomJS。使用Chrome需要将对应的driver下载后复制到Python的安装文件夹下，使用PhontomJS则直接将.exe文件复制到Python安装文件夹下即可</p><h2 id="selenium基本操作"><a href="#selenium基本操作" class="headerlink" title="selenium基本操作"></a>selenium基本操作</h2><h3 id="浏览器操作"><a href="#浏览器操作" class="headerlink" title="浏览器操作"></a>浏览器操作</h3><h4 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br></pre></td></tr></table></figure><h4 id="打开浏览器"><a href="#打开浏览器" class="headerlink" title="打开浏览器"></a>打开浏览器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver = webdriver.PhantomJS() <span class="comment">#打开PhantomJS浏览器</span></span><br><span class="line">driver = webdriver.Chrome() <span class="comment">#打开Chrome浏览器</span></span><br></pre></td></tr></table></figure><h4 id="访问网页"><a href="#访问网页" class="headerlink" title="访问网页"></a>访问网页</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">driver.get(url)</span><br></pre></td></tr></table></figure><p>访问网址为url的网站，若使用Chrome将看到打开的浏览器跳转到指定的url</p><h3 id="交互操作"><a href="#交互操作" class="headerlink" title="交互操作"></a>交互操作</h3><h4 id="获得表单元素"><a href="#获得表单元素" class="headerlink" title="获得表单元素"></a>获得表单元素</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name_field = driver.find_element_by_id(<span class="string">&quot;username&quot;</span>)</span><br><span class="line">submit_button = driver.find_element_by_tag_name(<span class="string">&quot;button&quot;</span>)</span><br><span class="line">submit_button = driver.find_elements_by_link_text(<span class="string">&quot;教务系统&quot;</span>)</span><br></pre></td></tr></table></figure><p>根据元素id，类型和超链接名称获取元素，除了以上的方法，还有</p><ul><li>find_element_by_id</li><li>find_element_by_name</li><li>find_element_by_xpath</li><li>find_element_by_link_text</li><li>find_element_by_partial_link_text</li><li>find_element_by_tag_name</li><li>find_element_by_class_name</li><li>find_element_by_css_selector</li></ul><p>还有获取多个元素的方法：</p><ul><li>find_elements_by_name</li><li>find_elements_by_xpath</li><li>find_elements_by_link_text</li><li>find_elements_by_partial_link_text</li><li>find_elements_by_tag_name</li><li>find_elements_by_class_name</li><li>find_elements_by_css_selector</li></ul><h4 id="输入表单数据"><a href="#输入表单数据" class="headerlink" title="输入表单数据"></a>输入表单数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">name_field = driver.find_element_by_id(<span class="string">&#x27;loginName&#x27;</span>)</span><br><span class="line">name_field.send_keys(<span class="string">&#x27;...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>获取元素后使用<code>send_keys()</code>方法输入数据</p><h4 id="点击按钮或超链接"><a href="#点击按钮或超链接" class="headerlink" title="点击按钮或超链接"></a>点击按钮或超链接</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">submit_button = driver.find_element_by_id(<span class="string">&#x27;loginAction&#x27;</span>)</span><br><span class="line">submit_button.click()</span><br></pre></td></tr></table></figure><p>获取元素后使用<code>click()</code>方法点击按钮</p>]]></content>
      
      
      <categories>
          
          <category> Python应用手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>恢复余数除法器</title>
      <link href="2017/09/09/%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E9%99%A4%E6%B3%95%E5%99%A8/"/>
      <url>2017/09/09/%E6%81%A2%E5%A4%8D%E4%BD%99%E6%95%B0%E9%99%A4%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="恢复余数除法器"><a href="#恢复余数除法器" class="headerlink" title="恢复余数除法器"></a>恢复余数除法器</h2><h3 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h3><p>恢复余数除法器是一种常用的除法器，过程与手算除法的方法很类似，过程为</p><ol><li>将除数向左位移直到比被除数大</li><li>执行被除数减除数操作，得余数，并将商向左移位1位，空位补1</li><li>若余数大于0，除数向右移位1位。如余数小于0，余数加当前除数，商最后一位置0，除数向右移位1位</li><li>重复到2，只到除数比最初的除数小</li></ol><h3 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h3><p>RTL代码就是使用了大量的<code>if</code>语句完成了以上的算法描述，其中</p><ul><li>为了使移位后的除数确保大于被除数，直接将除数放到一个位宽WIDTH*3的寄存器的前WIDTH位</li><li><code>divisor_move &gt;= &#39;&#123;divisor_lock&#125;</code>用于当移位除数小于原除数时停止</li><li><code>(divisor_move &gt; &#39;&#123;remainder_r&#125;) &amp;&amp; (dout == &#39;b0)</code>用于当出现第一个1时才开始保存结果</li></ul><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> restore_divider #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [WIDTH * <span class="number">2</span> - <span class="number">1</span>:<span class="number">0</span>]dividend,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor,</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> din_valid,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout,</span><br><span class="line"><span class="keyword">output</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">2</span> * WIDTH:<span class="number">0</span>]remainder_r;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor_move;</span><br><span class="line"><span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor_lock;</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">      <span class="comment">//初始化</span></span><br><span class="line">&#123;remainder_r,divisor_lock,divisor_move,dout&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(din_valid == <span class="number">1&#x27;b1</span>) <span class="keyword">begin</span></span><br><span class="line">          <span class="comment">//锁存输入，3倍WIDTH的宽度用于保证移位后的除数大于被除数</span></span><br><span class="line">remainder_r[WIDTH * <span class="number">2</span> - <span class="number">1</span>:<span class="number">0</span>] &lt;= dividend;</span><br><span class="line">remainder_r[<span class="number">2</span> * WIDTH] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">divisor_move[<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">2</span> * WIDTH] &lt;= divisor;</span><br><span class="line">divisor_move[<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">divisor_lock &lt;= divisor;</span><br><span class="line">dout &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>((divisor_move &gt; &#x27;&#123;remainder_r&#125;) &amp;&amp; (dout == <span class="number">&#x27;b0</span>)) <span class="keyword">begin</span></span><br><span class="line"><span class="comment">//开始条件</span></span><br><span class="line">           remainder_r &lt;= remainder_r;</span><br><span class="line">dout &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">divisor_move &lt;= divisor_move &gt;&gt; <span class="number">1</span>;</span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(divisor_move &gt;= &#x27;&#123;divisor_lock&#125;) <span class="keyword">begin</span></span><br><span class="line">          <span class="keyword">if</span>(remainder_r[<span class="number">2</span> * WIDTH] == <span class="number">1&#x27;b0</span>) <span class="keyword">begin</span> <span class="comment">//执行减法</span></span><br><span class="line">remainder_r &lt;= remainder_r - divisor_move;</span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b1</span>&#125;;</span><br><span class="line"><span class="comment">// divisor_move &lt;= divisor_move &gt;&gt; 1;</span></span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line"><span class="keyword">if</span>(remainder_r &gt;= divisor_move) <span class="keyword">begin</span></span><br><span class="line">divisor_move &lt;= divisor_move &gt;&gt; <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">divisor_move &lt;= divisor_move;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span><span class="comment">//恢复余数</span></span><br><span class="line">remainder_r &lt;= remainder_r + divisor_move;</span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">1</span>],<span class="number">1&#x27;b0</span>&#125;;</span><br><span class="line">divisor_move &lt;= divisor_move &gt;&gt; <span class="number">1</span>;</span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder_r &lt;= remainder_r;</span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line">divisor_move &lt;= divisor_move;</span><br><span class="line">dout &lt;= dout;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> remainder = remainder_r[WIDTH - <span class="number">1</span>:<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h3 id="测试平台"><a href="#测试平台" class="headerlink" title="测试平台"></a>测试平台</h3><p>测试平台复用了shiftsub除法器的平台，增加了“遇错停止”的功能</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> tb_divider (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> clk;    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">logic</span> rst_n;  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dividend;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> din_valid;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder;</span><br><span class="line"></span><br><span class="line">restore_divider #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH)</span><br><span class="line">) dut (</span><br><span class="line"><span class="variable">.clk</span>(clk),    <span class="comment">// Clock</span></span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="variable">.dividend</span>(dividend),</span><br><span class="line"><span class="variable">.divisor</span>(divisor),</span><br><span class="line"></span><br><span class="line"><span class="variable">.din_valid</span>(din_valid),</span><br><span class="line"></span><br><span class="line"><span class="variable">.dout</span>(dout),</span><br><span class="line"><span class="variable">.remainder</span>(remainder)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">clk = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">#<span class="number">50</span> clk = ~clk;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"># <span class="number">5</span> rst_n = <span class="number">&#x27;b0</span>;</span><br><span class="line">#<span class="number">10</span> rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout_exp;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder_exp;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">&#123;dividend,divisor,din_valid&#125; = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">dividend = (<span class="number">2</span> * WIDTH)&#x27;($urandom_range(<span class="number">0</span>,<span class="number">2</span> ** (<span class="number">2</span> * WIDTH)));</span><br><span class="line">divisor = (WIDTH)&#x27;($urandom_range(<span class="number">1</span>,<span class="number">2</span> ** WIDTH - <span class="number">1</span>));</span><br><span class="line">din_valid = <span class="number">1&#x27;b1</span>;</span><br><span class="line"></span><br><span class="line">remainder_exp = dividend % divisor;</span><br><span class="line">dout_exp = (dividend - remainder_exp) / divisor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">repeat</span>(<span class="number">5</span> * WIDTH) <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">din_valid = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span>((remainder == remainder_exp) &amp;&amp; (dout_exp == dout)) <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;successfully&quot;</span>);</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;failed&quot;</span>);</span><br><span class="line"><span class="built_in">$stop</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>移位相减除法器</title>
      <link href="2017/09/06/%E7%A7%BB%E4%BD%8D%E7%9B%B8%E5%87%8F%E9%99%A4%E6%B3%95%E5%99%A8/"/>
      <url>2017/09/06/%E7%A7%BB%E4%BD%8D%E7%9B%B8%E5%87%8F%E9%99%A4%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="移位相减除法器"><a href="#移位相减除法器" class="headerlink" title="移位相减除法器"></a>移位相减除法器</h2><h3 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h3><p>与使用移位相加实现加法一样，移位减法可以实现除法，基本算法如下描述</p><ol><li>将除数向左移位直到比被除数大</li><li>使用移位后的除数与被除数比较，若除数大，则商向左移位1位后末尾补0；若除数小，则被除数累减除数，商向左移位1位后末尾补1</li><li>除数向右移位1位，重复2，知道除数小于原除数</li></ol><h3 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h3><p>移位相减算法比较简单，一个Verilog模块即可描述</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> shiftsub_divider #(</span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span></span><br><span class="line">)(</span><br><span class="line"><span class="keyword">input</span> clk,    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">input</span> rst_n,  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dividend,</span><br><span class="line"><span class="keyword">input</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor,</span><br><span class="line"></span><br><span class="line"><span class="keyword">input</span> din_valid,</span><br><span class="line"></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>定义端口，其中<code>remainder</code>前<code>WIDTH</code>位均为0，可以不连接</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor_lock;</span><br><span class="line"><span class="keyword">reg</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor_ref;</span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">&#123;divisor_lock,divisor_ref&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(din_valid == <span class="number">1&#x27;b1</span>) <span class="keyword">begin</span></span><br><span class="line">divisor_lock[<span class="number">3</span> * WIDTH - <span class="number">1</span>:<span class="number">2</span> * WIDTH] &lt;= divisor;</span><br><span class="line">divisor_lock[WIDTH - <span class="number">1</span>:<span class="number">0</span>] &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line">divisor_ref &lt;= divisor;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(divisor_lock &gt;= &#x27;&#123;divisor_ref&#125;) <span class="keyword">begin</span></span><br><span class="line">divisor_lock &lt;= divisor_lock &gt;&gt; <span class="number">1</span>;</span><br><span class="line">divisor_ref &lt;= divisor_ref;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">divisor_lock &lt;= divisor_lock;</span><br><span class="line">divisor_ref &lt;= divisor_ref;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><code>divisor_lock</code>为移位后的除数，宽度为<code>3 * WIDTH</code>是为了确保移位后的除数比被除数大。<code>divisor_ref</code>保存最初始除数的值，<code>divisor_lock &gt;= &#39;&#123;divisor_ref&#125;</code>为终止条件</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">negedge</span> rst_n) <span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(~rst_n) <span class="keyword">begin</span></span><br><span class="line">&#123;remainder,dout&#125; &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(din_valid == <span class="number">1&#x27;b1</span>) <span class="keyword">begin</span></span><br><span class="line">remainder &lt;= dividend;</span><br><span class="line">dout &lt;= <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>((dout == <span class="number">&#x27;b0</span>) &amp;&amp; (remainder &lt; divisor_lock)) <span class="keyword">begin</span></span><br><span class="line">remainder &lt;= remainder;</span><br><span class="line">dout &lt;= dout;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">if</span>(divisor_lock &gt;= &#x27;&#123;divisor_ref&#125;)<span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span>(remainder &gt;= divisor_lock) <span class="keyword">begin</span></span><br><span class="line">remainder &lt;= remainder - divisor_lock;</span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b1</span>&#125;;</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">remainder &lt;= remainder;</span><br><span class="line">dout &lt;= &#123;dout[<span class="number">2</span> * WIDTH - <span class="number">2</span>:<span class="number">0</span>],<span class="number">1&#x27;b0</span>&#125;;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line">&#123;remainder,dout&#125; &lt;= &#123;remainder,dout&#125;;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p>执行移位相减，其中<code>(dout == &#39;b0) &amp;&amp; (remainder &lt; divisor_lock)</code>是为了从除数恰好小于被除数时开始运算</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>测试方法为随机产生数据，再使用Verilog自带的<code>/</code>和<code>%</code>运算符获取期待值后再与真实结果比较</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> tb_divider (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">parameter</span> WIDTH = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> clk;    <span class="comment">// Clock</span></span><br><span class="line"><span class="keyword">logic</span> rst_n;  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dividend;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]divisor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> din_valid;</span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout;</span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder;</span><br><span class="line"></span><br><span class="line">shiftsub_divider #(</span><br><span class="line"><span class="variable">.WIDTH</span>(WIDTH)</span><br><span class="line">) dut (</span><br><span class="line"><span class="variable">.clk</span>(clk),    <span class="comment">// Clock</span></span><br><span class="line"><span class="variable">.rst_n</span>(rst_n),  <span class="comment">// Asynchronous reset active low</span></span><br><span class="line"></span><br><span class="line"><span class="variable">.dividend</span>(dividend),</span><br><span class="line"><span class="variable">.divisor</span>(divisor),</span><br><span class="line"></span><br><span class="line"><span class="variable">.din_valid</span>(din_valid),</span><br><span class="line"></span><br><span class="line"><span class="variable">.dout</span>(dout),</span><br><span class="line"><span class="variable">.remainder</span>(remainder)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">//产生时钟信号</span></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">clk = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">#<span class="number">50</span> clk = ~clk;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//产生复位信号</span></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"># <span class="number">5</span> rst_n = <span class="number">&#x27;b0</span>;</span><br><span class="line">#<span class="number">10</span> rst_n = <span class="number">1&#x27;b1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">logic</span> [<span class="number">2</span> * WIDTH - <span class="number">1</span>:<span class="number">0</span>]dout_exp;</span><br><span class="line"><span class="keyword">logic</span> [WIDTH - <span class="number">1</span>:<span class="number">0</span>]remainder_exp;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">  <span class="comment">//初始化</span></span><br><span class="line">&#123;dividend,divisor,din_valid&#125; = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">forever</span> <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">      <span class="comment">//产生随机输入并启动</span></span><br><span class="line">dividend = (<span class="number">2</span> * WIDTH)&#x27;($urandom_range(<span class="number">0</span>,<span class="number">2</span> ** (<span class="number">2</span> * WIDTH)));</span><br><span class="line">divisor = (WIDTH)&#x27;($urandom_range(<span class="number">1</span>,<span class="number">2</span> ** WIDTH - <span class="number">1</span>));</span><br><span class="line">din_valid = <span class="number">1&#x27;b1</span>;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//计算期待结果</span></span><br><span class="line">remainder_exp = dividend % divisor;</span><br><span class="line">dout_exp = (dividend - remainder_exp) / divisor;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//等待运算结果</span></span><br><span class="line"><span class="keyword">repeat</span>(<span class="number">4</span> * WIDTH) <span class="keyword">begin</span></span><br><span class="line">@(<span class="keyword">negedge</span> clk);</span><br><span class="line">din_valid = <span class="number">&#x27;b0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment">//期待结果与真实结果比较</span></span><br><span class="line"><span class="keyword">if</span>((remainder == remainder_exp) &amp;&amp; (dout_exp == dout)) <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;successfully&quot;</span>);</span><br><span class="line"><span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span></span><br><span class="line"><span class="built_in">$display</span>(<span class="string">&quot;failed&quot;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python驱动树莓派SPI接口</title>
      <link href="2017/09/06/Python%E9%A9%B1%E5%8A%A8%E6%A0%91%E8%8E%93%E6%B4%BESPI%E6%8E%A5%E5%8F%A3/"/>
      <url>2017/09/06/Python%E9%A9%B1%E5%8A%A8%E6%A0%91%E8%8E%93%E6%B4%BESPI%E6%8E%A5%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>进行IC测试，需要使用SPI输入数据并采集数据，考虑使用树莓派可以直接将数据采集和数据处理结合成一体，避免易出错的数据采集部分（单片机或FPGA实现）</p><h1 id="树莓派SPI接口"><a href="#树莓派SPI接口" class="headerlink" title="树莓派SPI接口"></a>树莓派SPI接口</h1><h3 id="物理接口"><a href="#物理接口" class="headerlink" title="物理接口"></a>物理接口</h3><p>由上图中可以看出，树莓派的19,21,23构成了一个SPI接口，片选信号使用GPIO控制，本次并不使用自动的片选信号。速度方面，树莓派的接口有以下速度可以选择</p><div class="table-container"><table><thead><tr><th>速度</th><th>值 </th></tr></thead><tbody><tr><td>125.0 MHz</td><td>125000000</td></tr><tr><td>62.5 MHz</td><td>62500000</td></tr><tr><td>31.2 MHz</td><td>31200000</td></tr><tr><td>15.6 MHz</td><td>15600000</td></tr><tr><td>7.8 MHz</td><td>7800000</td></tr><tr><td>3.9 MHz</td><td>3900000</td></tr><tr><td>1953 kHz</td><td>1953000</td></tr><tr><td>976 kHz</td><td>976000</td></tr><tr><td>488 kHz</td><td>488000</td></tr><tr><td>244 kHz</td><td>244000</td></tr><tr><td>122 kHz</td><td>122000</td></tr><tr><td>61 kHz</td><td>61000</td></tr><tr><td>30.5 kHz</td><td>30500</td></tr><tr><td>15.2 kHz</td><td>15200</td></tr><tr><td>7629 Hz</td><td>7629</td></tr></tbody></table></div><h3 id="开启SPI接口"><a href="#开启SPI接口" class="headerlink" title="开启SPI接口"></a>开启SPI接口</h3><p>使用<code>sudo raspi-config</code>命令进入配置选项后选择SPI接口，打开后重启即可</p><h1 id="Python驱动"><a href="#Python驱动" class="headerlink" title="Python驱动"></a>Python驱动</h1><p>Python使用<code>spidev</code>库驱动SPI</p><h3 id="启动并配置SPI接口"><a href="#启动并配置SPI接口" class="headerlink" title="启动并配置SPI接口"></a>启动并配置SPI接口</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spi &#x3D; spidev.SpiDev()</span><br><span class="line">spi.open(0, 0)</span><br><span class="line">spi.max_speed_hz &#x3D; 15600000</span><br></pre></td></tr></table></figure><h3 id="发送数据"><a href="#发送数据" class="headerlink" title="发送数据"></a>发送数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def write_pot(input):</span><br><span class="line">    msb &#x3D; input &gt;&gt; 8</span><br><span class="line">    lsb &#x3D; input &amp; 0xFF</span><br><span class="line">    spi.xfer([msb, lsb])</span><br></pre></td></tr></table></figure><h1 id="故障排除"><a href="#故障排除" class="headerlink" title="故障排除"></a>故障排除</h1><h3 id="MOSI工作不正常"><a href="#MOSI工作不正常" class="headerlink" title="MOSI工作不正常"></a>MOSI工作不正常</h3><p>问题描述：使用逻辑分析仪测试输出，发现有SCK信号和CS信号，MOSI信号一直为高<br>解决方法：使用<code>raspi-config</code>关闭SPI后重启，再打开SPI，重启，故障排除（重启debug大法）</p><h1 id="参考教程"><a href="#参考教程" class="headerlink" title="参考教程"></a>参考教程</h1><p><a href="https://pypi.python.org/pypi/spidev/3.1">python-spidev网站</a><br><a href="http://www.takaitra.com/posts/492">Controlling an SPI device with the Raspberry Pi</a></p>]]></content>
      
      
      <categories>
          
          <category> Python应用手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python解决大规模二进制数据错位</title>
      <link href="2017/09/06/Python%E8%A7%A3%E5%86%B3%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E6%8D%AE%E9%94%99%E4%BD%8D/"/>
      <url>2017/09/06/Python%E8%A7%A3%E5%86%B3%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E6%8D%AE%E9%94%99%E4%BD%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>有一些二进制数据，每八位按顺序存为一个十进制数保存成CSV文件，每行为一个二进数数据，每个单元格均为一个十进制数。若数据为<code>0000 0001 1000 0000</code>，在CSV的一行中则存为<code>1,128\n</code>。<br>现发现存储错位，需要将每个数据整体向左移位2位并保存成以上描述的格式</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><ul><li>将每个行数据读出并将每个十进制转换为8位二进制数的<strong>字符串</strong>(同时使用切片去除开头的二进制数标识)</li><li>将字符串整体连接起来，切去开头两个0并在结尾连接一个<code>00</code></li><li>重新将字符串切片，并转换<h1 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 读取数据</span><br><span class="line"> with open(&quot;.&#x2F;ramdata_brockenline.csv&quot;) as file_point:</span><br><span class="line">     content_list &#x3D; [x.split(&quot;,&quot;) for x in file_point.read().split(&quot;\n&quot;)]</span><br><span class="line"></span><br><span class="line"> input_data &#x3D; []</span><br><span class="line"> for content in content_list[:-1]:</span><br><span class="line">     # 转换为字符串并进行移位</span><br><span class="line">     int_list &#x3D; &quot;&quot;.join([bin(int(x))[2:].zfill(8)</span><br><span class="line">                         for x in content[1:]])[2:] + &quot;00&quot;</span><br><span class="line">     # 切片</span><br><span class="line">     bin_list &#x3D; [int(int_list[i: i + 8], 2) for i in range(0, len(int_list), 8)]</span><br><span class="line">     input_data.append([content[0], bin_list])</span><br><span class="line"> </span><br><span class="line"> # 打印出结果</span><br><span class="line"> for x in input_data:</span><br><span class="line">     print(x)</span><br><span class="line"> print(len(input_data))</span><br></pre></td></tr></table></figure><h1 id="最终代码"><a href="#最终代码" class="headerlink" title="最终代码"></a>最终代码</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">class InputCSVHandle(object):</span><br><span class="line">    &quot;&quot;&quot;docstring for InputCSVHandle&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, FilePath):</span><br><span class="line">        super(InputCSVHandle, self).__init__()</span><br><span class="line">        self.FilePath &#x3D; FilePath</span><br><span class="line">        self.InputData &#x3D; self.InputHanlde(self.CSVReader())</span><br><span class="line"></span><br><span class="line">    def CSVReader(self):</span><br><span class="line">        with open(self.FilePath, &quot;r&quot;) as file_point:</span><br><span class="line">            return [x.split(&quot;,&quot;)</span><br><span class="line">                    for x in file_point.read().split(&quot;\n&quot;)]</span><br><span class="line"></span><br><span class="line">    def InputHanlde(self, content_list):</span><br><span class="line">        input_data &#x3D; []</span><br><span class="line">        for content in content_list[:-1]:</span><br><span class="line">            int_list &#x3D; &quot;&quot;.join([bin(int(x))[2:].zfill(8)</span><br><span class="line">                                for x in content[1:]])[2:] + &quot;00&quot;</span><br><span class="line">            bin_list &#x3D; [int(int_list[i: i + 8], 2)</span><br><span class="line">                        for i in range(0, len(int_list), 8)]</span><br><span class="line">            input_data.append([content[0], bin_list])</span><br><span class="line">        return input_data</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    test &#x3D; InputCSVHandle(&quot;.&#x2F;ramdata_brockenline.csv&quot;)</span><br><span class="line">    print(test.InputData)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Python应用手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch60分钟教程学习笔记</title>
      <link href="2017/09/06/PyTorch60%E5%88%86%E9%92%9F%E6%95%99%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>2017/09/06/PyTorch60%E5%88%86%E9%92%9F%E6%95%99%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><p>tensor是的含义是张量，简单的理解可以将其当成三维矩阵，pytorch中的张量是对数据的一种封装，也是数据结构中最核心的部分之一。对于pytorch中的张量，数组可能是更好的理解方法。</p><h3 id="Tensor的定义"><a href="#Tensor的定义" class="headerlink" title="Tensor的定义"></a>Tensor的定义</h3><ul><li>直接定义矩阵，使用<code>torch.Tensor(shape)</code>方法定义未初始化的张量，使用<code>torch.rand(shape)</code>或<code>torch.randn(shape)</code>定义随机张量<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import torch as pt</span><br><span class="line">x &#x3D; pt.Tensor(2,4)</span><br><span class="line">print(x)</span><br><span class="line"># 1.00000e-23 *</span><br><span class="line">#  0.0000  0.0000  1.2028  0.0000</span><br><span class="line">#  0.0000  0.0000  1.1517  0.0000</span><br><span class="line"># [torch.FloatTensor of size 2x4]</span><br><span class="line">x &#x3D; pt.rand(5,3)</span><br><span class="line"># 0.7609  0.5925  0.5840</span><br><span class="line"># 0.1949  0.6366  0.3763</span><br><span class="line"># 0.1802  0.8529  0.9373</span><br><span class="line"># 0.6013  0.9685  0.9945</span><br><span class="line"># 0.6555  0.1740  0.9884</span><br><span class="line"># [torch.FloatTensor of size 5x3]</span><br><span class="line">print(x,x.size()[0])</span><br><span class="line"># 5</span><br><span class="line">y &#x3D; pt.rand(5,3)</span><br></pre></td></tr></table></figure></li><li>从numpy 中定义tensor，使用<code>torch.from_numpy(ndarray)</code>的方法，需要注意的是，这种情况下numpy矩阵和tensor会“绑定”，即修改任何一个的值，另一个的值也会发生变化<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; np.ones(5)</span><br><span class="line">b &#x3D; pt.from_numpy(a)</span><br><span class="line">print(a,b)</span><br><span class="line">#[ 1.  1.  1.  1.  1.] </span><br><span class="line"> #1</span><br><span class="line"> #1</span><br><span class="line"> #1</span><br><span class="line"> #1</span><br><span class="line"> #1</span><br><span class="line">#[torch.DoubleTensor of size 5]</span><br></pre></td></tr></table></figure><h3 id="Tensor的基本操作"><a href="#Tensor的基本操作" class="headerlink" title="Tensor的基本操作"></a>Tensor的基本操作</h3>Tensor和numpy中的ndarray相似，可以完成加减乘除等运算，常见的操作方法通常为<code>Tensor.操作(参数)</code>或<code>torch.操作(参数,out=输出tensor)</code>，以加法为例<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">result &#x3D; pt.Tensor(5,3)</span><br><span class="line">test &#x3D; pt.add(x,y,out&#x3D;result)</span><br><span class="line"># print(result,test)</span><br><span class="line"></span><br><span class="line">y.add_(x)</span><br></pre></td></tr></table></figure>两种方法<code>test = pt.add(x,y,out=result)</code>和<code>y.add_(x)</code>都是相加，前者是相加后将结果交给一个新的Tensor<code>result</code>，而后者可以理解为<code>y</code>自加<code>x</code><br>Tensor还可以转换为numpy的对象ndarray，可以使用<code>Tensor.numpy()</code>获得与<code>Tensor</code>绑定的ndarray对象，修改Tensor时，ndarray对象也发生变化<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; pt.ones(5)</span><br><span class="line">b &#x3D; a.numpy()</span><br><span class="line"># print(a,b)</span><br><span class="line">a.add_(1)</span><br><span class="line"># print(a,b)</span><br></pre></td></tr></table></figure><h3 id="使用GPU加速"><a href="#使用GPU加速" class="headerlink" title="使用GPU加速"></a>使用GPU加速</h3>使用<code>Tensor = Tensor.cuda()</code>的方法可以讲<code>Tensor</code>放到GPU上，通常的运算不支持从CPU到GPU的变换，因此若要在GPU上进行网络运算，网络声明完成后也要调用网络和输入的<code>.cuda()</code>方法将网络和输入放在GPU上<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a,b &#x3D; pt.Tensor(2,2),pt.Tensor(2,2)</span><br><span class="line">a &#x3D; a.cuda()</span><br><span class="line">b &#x3D; b.cuda()</span><br></pre></td></tr></table></figure><h2 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h2><h3 id="Variable正向传播"><a href="#Variable正向传播" class="headerlink" title="Variable正向传播"></a>Variable正向传播</h3>Variable与TensorFlow中的Variable一样，是构建神经网络和训练的核心类，使用Variable可以构建计算图，并在图中计算结果（正向传播）和微分（反向传播），Variable的一些运算符重载过，因此可以直接使用<code>+-*/</code>运算符<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; Variable(pt.ones(2,2),requires_grad&#x3D;True)</span><br><span class="line">y &#x3D; x + 2</span><br><span class="line">z &#x3D; y * y * 3</span><br><span class="line">out &#x3D; z.mean()</span><br><span class="line"># Variable containing:</span><br><span class="line">#27</span><br><span class="line">#[torch.FloatTensor of size 1]</span><br></pre></td></tr></table></figure><h3 id="Variable反向传播"><a href="#Variable反向传播" class="headerlink" title="Variable反向传播"></a>Variable反向传播</h3>以上构建了一个计算图并计算了<code>out</code>的值，完成前向传播，使用<code>out.backward()</code>可以执行反向传播，就是计算微分。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">out.backward()</span><br><span class="line">print(x.grad)</span><br><span class="line">#Variable containing:</span><br><span class="line"># 4.5000  4.5000</span><br><span class="line"># 4.5000  4.5000</span><br><span class="line">#[torch.FloatTensor of size 2x2]</span><br></pre></td></tr></table></figure><h1 id="网络构建"><a href="#网络构建" class="headerlink" title="网络构建"></a>网络构建</h1><h2 id="网络结构构建"><a href="#网络结构构建" class="headerlink" title="网络结构构建"></a>网络结构构建</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class Net(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;docstring for Net&quot;&quot;&quot;</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 &#x3D; nn.Conv2d(1,6,5)# input channel,6 output channel,5x5</span><br><span class="line">        self.conv2 &#x3D; nn.Conv2d(6,16,5)</span><br><span class="line">        self.fc1 &#x3D; nn.Linear(16*5*5,120)#input 16*5*5,output120</span><br><span class="line">        self.fc2 &#x3D; nn.Linear(120, 84)</span><br><span class="line">        self.fc3 &#x3D; nn.Linear(84, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        x &#x3D; F.max_pool2d(F.relu(self.conv1(x)),(2,2)) #input,poolcore shape</span><br><span class="line">        x &#x3D; F.max_pool2d(F.relu(self.conv2(x)), 2) #(2,2) &#x3D;&gt; 2 because 2&#x3D;2</span><br><span class="line">        x &#x3D; x.view(-1, self.num_flat_features(x)) #reshape</span><br><span class="line">        x &#x3D; F.relu(self.fc1(x))</span><br><span class="line">        x &#x3D; F.relu(self.fc2(x))</span><br><span class="line">        x &#x3D; self.fc3(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">    def num_flat_features(self,x):</span><br><span class="line">        size &#x3D; x.size()[1:] #remove batch size</span><br><span class="line">        num_f &#x3D; 1</span><br><span class="line">        for s in size:</span><br><span class="line">            num_f *&#x3D; s</span><br><span class="line">        return num_f</span><br></pre></td></tr></table></figure>以上为构建一个简单的CNN的例子，其中</li><li><code>nn</code>来自<code>import torch.nn as nn</code>这其中封装各种各样的网络层</li><li><code>F</code>来自<code>import torch.nn.functional as F</code>，这其中封装了各种各样的神经网络需要使用的函数</li></ul><p>在网络结构中</p><ul><li><code>nn.Linear(input_size,output_size)</code>为线性连接层，为MLP的线性部分<br>-<code>nn.Conv2d(input_channel,output_channel,shape)</code>表示卷积核</li></ul><p>函数中</p><ul><li><code>F.max_pool2d(input,core_shape)</code>为池化层</li><li><code>F.relu(input)</code>为ReLu激活函数</li></ul><p>另外，<code>Variable.view()</code>为变形函数，其中的<code>-1</code>表示不关心batch，而函数<code>self.num_flat_features(x)</code>是为了获得<code>x</code>的元素数量，这一步直接将<code>x</code>拍扁成向量</p><h2 id="网络的前向传播"><a href="#网络的前向传播" class="headerlink" title="网络的前向传播"></a>网络的前向传播</h2><p>定义网络后（以上的类）后，声明后可以直接调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net &#x3D; Net().cuda()</span><br><span class="line">print(net)</span><br><span class="line">#Net (</span><br><span class="line"># (conv1): Conv2d(1, 6, kernel_size&#x3D;(5, 5), #stride&#x3D;(1, 1))</span><br><span class="line"># (conv2): Conv2d(6, 16, kernel_size&#x3D;(5, 5), #stride&#x3D;(1, 1))</span><br><span class="line"># (fc1): Linear (400 -&gt; 120)</span><br><span class="line"># (fc2): Linear (120 -&gt; 84)</span><br><span class="line"># (fc3): Linear (84 -&gt; 10)</span><br><span class="line">#)</span><br></pre></td></tr></table></figure><br>其中<code>.cuda()</code>是将整个网络放到GPU上，如果直接使用<code>net = Net()</code>网络位置在CPU上，将无法使用GPU加速。<br>定义网络后，直接传入输入即可完成前向传播<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad() # Zero the gradient buffers of all parameters </span><br><span class="line"></span><br><span class="line">inputdata &#x3D; Variable(pt.randn(1,1,32,32)) #?(1,1,32,32) nSamples x nChannels x Height x Width</span><br><span class="line">inputdata &#x3D; inputdata.cuda()</span><br><span class="line"># 1-batch 1-input channel 32,32</span><br><span class="line"># print(inputdata)</span><br><span class="line"># print(inputdata.unsqueeze(0)) #[torch.FloatTensor of size 1x1x1x32x32]</span><br><span class="line">out &#x3D; net(inputdata)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><br>其中<code>net.zero_grad()</code>是为了清除梯度，起类似于初始化的作用。pytorch要求数据与网络的位置相同，因此若是网络声明在GPU上，数据也必须要GPU上加速。</p><h3 id="网络的反向传播（权值更新）"><a href="#网络的反向传播（权值更新）" class="headerlink" title="网络的反向传播（权值更新）"></a>网络的反向传播（权值更新）</h3><p>网络的反向传播可以直接使用预先定义的代价函数的<code>.backward()</code>方法实现<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()</span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure><br>在更新权值的时候，可以手动指定更新的方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for f in net.parameters():</span><br><span class="line">    f.data.sub_(f.grad.data * 0.01)</span><br></pre></td></tr></table></figure><br>其中：</p><ul><li>net.parameters()是个生成器，可以遍历net中的所有参数</li><li>f.grad.data为输出（代价函数）到这一参数的梯度</li></ul><p>除了手动制定，也可以从<code>import torch.optim as optim</code>中调用优化器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">optimizer &#x3D; optim.SGD(net.parameters(),lr&#x3D;0.01)</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">out &#x3D; net(inputdata)</span><br><span class="line">loss &#x3D; criterion(out,target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure><br>其中<code>criterion()</code>为代价函数，<code>loss</code>为代价函数的输出值，<code>optimizer.step()</code>为调用一次优化</p><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>代价函数表示当前结果距离期望输出的“距离”，<code>torch.nn</code>封装了一些代价函数，可以在训练的时候直接调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">target &#x3D; Variable(pt.arange(1,11)).cuda()</span><br><span class="line"># print(target)</span><br><span class="line">criterion &#x3D; nn.MSELoss().cuda()</span><br><span class="line">loss &#x3D; criterion(out,target) #out shape &#x3D; 1*10 target shape &#x3D; 10</span><br></pre></td></tr></table></figure><br>这里调用的代价函数是<code>MSELoss()</code>平方平均函数</p><h1 id="分类网络搭建，训练与测试"><a href="#分类网络搭建，训练与测试" class="headerlink" title="分类网络搭建，训练与测试"></a>分类网络搭建，训练与测试</h1><h2 id="分类网络数据准备"><a href="#分类网络数据准备" class="headerlink" title="分类网络数据准备"></a>分类网络数据准备</h2><p>教程提供的范例的训练集是CIFAR10数据集，该数据集提供了10种不同类型的图片，引入代码如下图<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transform &#x3D; transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])</span><br><span class="line"></span><br><span class="line">trainset &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&#39;.&#x2F;data&#39;, train&#x3D;True,</span><br><span class="line">                                        download&#x3D;True, transform&#x3D;transform)</span><br><span class="line">trainloader &#x3D; torch.utils.data.DataLoader(trainset, batch_size&#x3D;4,</span><br><span class="line">                                          shuffle&#x3D;True, num_workers&#x3D;2)</span><br><span class="line"></span><br><span class="line">testset &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&#39;.&#x2F;data&#39;, train&#x3D;False,</span><br><span class="line">                                       download&#x3D;True, transform&#x3D;transform)</span><br><span class="line">testloader &#x3D; torch.utils.data.DataLoader(testset, batch_size&#x3D;4,</span><br><span class="line">                                         shuffle&#x3D;False, num_workers&#x3D;2)</span><br><span class="line"></span><br><span class="line">classes &#x3D; (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;,</span><br><span class="line">           &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)</span><br></pre></td></tr></table></figure><br>这部分仅仅是下载并提供数据集，不必深究，需要注意的是从<code>testloader</code>中获得数据即可</p><h2 id="分类网络搭建"><a href="#分类网络搭建" class="headerlink" title="分类网络搭建"></a>分类网络搭建</h2><p>分类网络搭建使用两层conv+pool后接3层mlp层的结构，是个基本的卷积神经网络，构建类如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">class Net(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;docstring for Net&quot;&quot;&quot;</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 &#x3D; nn.Conv2d(3,6,5)</span><br><span class="line">        self.pool &#x3D; nn.MaxPool2d(2,2)</span><br><span class="line">        self.conv2 &#x3D; nn.Conv2d(6,16,5)</span><br><span class="line">        self.fc1 &#x3D; nn.Linear(16*5*5,120)</span><br><span class="line">        self.fc2 &#x3D; nn.Linear(120,84)        </span><br><span class="line">        self.fc3 &#x3D; nn.Linear(84, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        x &#x3D; self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x &#x3D; self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x &#x3D; x.view(-1,16*5*5)</span><br><span class="line">        x &#x3D; F.relu(self.fc1(x))</span><br><span class="line">        x &#x3D; F.relu(self.fc2(x))</span><br><span class="line">        x &#x3D; self.fc3(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">net &#x3D; Net().cuda()</span><br></pre></td></tr></table></figure><br>这里将组件的定义放在了构造函数中，而将网络前馈部分放在了单独的<code>forward()</code>函数中。另外，使用<code>net = Net().cuda()</code>将网络放在了GPU上</p><h2 id="分类网络的训练"><a href="#分类网络的训练" class="headerlink" title="分类网络的训练"></a>分类网络的训练</h2><p>分类网络的训练需要定义优化器和代价函数，剩下的就是将数据丢进神经网络中了，代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">criterion &#x3D; nn.CrossEntropyLoss()</span><br><span class="line">#声明使用交叉熵函数作为代价函数</span><br><span class="line">optimizer &#x3D; optim.SGD(net.parameters(),lr&#x3D;0.001,momentum&#x3D;0.9)</span><br><span class="line">#声明使用学习率0.001的SGD优化器</span><br><span class="line"></span><br><span class="line">for epoch in range(2):</span><br><span class="line">    running_loss &#x3D; 0</span><br><span class="line">    for i,data in enumerate(trainloader,0):</span><br><span class="line">        inputs,labels &#x3D; data</span><br><span class="line">        inputs,labels &#x3D; Variable(inputs).cuda(),Variable(labels).cuda()</span><br><span class="line">        #获得数据并将其放在GPU上</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        #初始化梯度</span><br><span class="line"></span><br><span class="line">        outputs &#x3D; net(inputs)</span><br><span class="line">        #前馈</span><br><span class="line">        loss &#x3D; criterion(outputs,labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        #反馈计算梯度并更新权值</span><br><span class="line"></span><br><span class="line">        running_loss +&#x3D; loss.data[0]</span><br><span class="line">        if i % 200 &#x3D;&#x3D; 0:</span><br><span class="line">            print(&#39;[%d, %5d] loss: %.3f&#39; %</span><br><span class="line">                  (epoch + 1, i + 1, running_loss &#x2F; 2000))</span><br><span class="line">            running_loss &#x3D; 0</span><br><span class="line">            #打印平均代价函数值</span><br><span class="line">print(&#39;Finished Training&#39;)</span><br></pre></td></tr></table></figure><br>总结一下，该部分代码总共做了以下几件事</p><ul><li>定义优化器与代价函数</li><li>执行网络训练</li></ul><p>执行网络训练部分，每次迭代包括以下操作</p><ol><li>获取batch数据并将其放在GPU上<br>2.初始化梯度<br>3.执行前馈计算代价函数<br>4.执行反馈计算梯度并更新权值</li></ol><h2 id="分类网络的测试"><a href="#分类网络的测试" class="headerlink" title="分类网络的测试"></a>分类网络的测试</h2><p>网络测试部分就是将所有的训练数据再投入网络中训练一次，看真实结果与预测结果是否相同，代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">corret,total &#x3D; 0,0</span><br><span class="line">for images,labels in testloader:</span><br><span class="line">    images &#x3D; images.cuda()</span><br><span class="line">    labels &#x3D; labels.cuda()</span><br><span class="line">    outputs &#x3D; net(Variable(images))</span><br><span class="line">    _,predicted &#x3D; torch.max(outputs.data,1)</span><br><span class="line">    total +&#x3D; labels.size(0)</span><br><span class="line">    corret +&#x3D; (predicted &#x3D;&#x3D; labels).sum()</span><br><span class="line"></span><br><span class="line">print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (</span><br><span class="line">    100 * corret &#x2F; total))</span><br></pre></td></tr></table></figure><br>前馈得到预测结果后，使用<code>_,predicted = torch.max(outputs.data,1)</code>在第一维看取出最大的数（丢弃）和最大数的位置（保留）后再与label相比即可进行测试</p>]]></content>
      
      
      <categories>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ROM乘法器</title>
      <link href="2017/09/06/ROM%E4%B9%98%E6%B3%95%E5%99%A8/"/>
      <url>2017/09/06/ROM%E4%B9%98%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h1><p>ROM乘法器的算法比较简单，即使用一个ROM保存乘法的结果，在需要运算的时候直接到相应的地址去查表即可。例如计算两个4位二进制数的乘法<code>a*b</code>，那么需要一个八位输入八位输出的ROM存储计算结果即可，其地址与存储数据的关系为：地址<code>&#123;a,b&#125;</code>（位拼接）存储a*b（例如地址为<code>8&#39;b00010010</code>存储的结果就是<code>0001*0001=8&#39;b00000010</code>）<br>这种情况下使用的ROM比较大，所以在时序要求不严格的时候可以用时钟换面积，例如对于8位<em>8位的ROM乘法器，我们将其拆成乘数1高4位，低4位和乘数2高4位低4位两两相乘。高四位和高四位相乘后结果向左位移4位，高四位和低四位相乘结果往左移2位，低四位和低四位相乘结果不变累加（就是手算乘法常用的套路）可得在四个（最少）时钟周期后得到结果，使用的ROM可由16\</em>16降到4*4</p><h1 id="单个ROM乘法器"><a href="#单个ROM乘法器" class="headerlink" title="单个ROM乘法器"></a>单个ROM乘法器</h1><h2 id="Python生成器"><a href="#Python生成器" class="headerlink" title="Python生成器"></a>Python生成器</h2><p>单个ROM在Verilog中可以使用case语句模拟，手写这种重复化很高的case语句无疑是一种效率很低的方法，本次使用Python语句生成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">class ROMGenerator(object):</span><br><span class="line">    &quot;&quot;&quot;docstring for ROMGenerator&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, Width):</span><br><span class="line">        super(ROMGenerator, self).__init__()</span><br><span class="line">        self.Width &#x3D; Width</span><br><span class="line"></span><br><span class="line">    def GeneratorROM(self, FileName):</span><br><span class="line">        RomContent &#x3D; [&quot;&quot;&quot;</span><br><span class="line">module ROM_%s (</span><br><span class="line">    input [%s:0]addr,</span><br><span class="line">    output reg [%s:0]dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">always @(*) begin</span><br><span class="line">    case(addr)\</span><br><span class="line">&quot;&quot;&quot; % (self.Width, self.Width * 2 - 1, self.Width * 2 - 1)]</span><br><span class="line">        for i in range(2 ** self.Width):</span><br><span class="line">            for j in range(2 ** self.Width):</span><br><span class="line">                RomContent.append(</span><br><span class="line">                    &quot;\t\t%s\&#39;d%s:dout &#x3D; %s\&#39;d%s;&quot; %</span><br><span class="line">                    (2 * self.Width, i * (2 ** self.Width) + j,</span><br><span class="line">                        2 * self.Width, i * j))</span><br><span class="line">        RomContent.append(&quot;&quot;&quot;\t\tdefault:dout &#x3D; \&#39;b0;</span><br><span class="line">    endcase</span><br><span class="line">end</span><br><span class="line">endmodule</span><br><span class="line">&quot;&quot;&quot;)</span><br><span class="line">        with open(&quot;.&#x2F;%s.v&quot; % FileName, &quot;w&quot;) as filepoint:</span><br><span class="line">            filepoint.write(&quot;\n&quot;.join(RomContent))</span><br><span class="line">        return &quot;\n&quot;.join(RomContent)</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    test &#x3D; ROMGenerator(4)</span><br><span class="line">    print(test.GeneratorROM(&quot;ROM_4&quot;))</span><br></pre></td></tr></table></figure><br>代码很简单，除了开头和结尾以外，就是对于批量化生成需要的<code>\t\t%s\&#39;d%s:dout = %s\&#39;d%s;</code></p><h2 id="测试平台"><a href="#测试平台" class="headerlink" title="测试平台"></a>测试平台</h2><p>测试时使用SystemVerilog编写的测试平台，使用<code>*</code>运算符和自己的模块的输出相比较<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">module mult_tb (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">parameter WIDTH &#x3D; 4;</span><br><span class="line"></span><br><span class="line">logic clk,rst_n;</span><br><span class="line">logic [WIDTH - 1:0]multiplier1;</span><br><span class="line">logic [WIDTH - 1:0]multiplier2;</span><br><span class="line"></span><br><span class="line">logic [2 * WIDTH - 1:0]product;</span><br><span class="line"></span><br><span class="line">ROM_4 dut(</span><br><span class="line">    .addr(&#123;multiplier1,multiplier2&#125;),</span><br><span class="line">    .dout(product)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">clk &#x3D; 1&#39;b0;</span><br><span class="line">forever begin</span><br><span class="line">#50 clk &#x3D; ~clk;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">rst_n &#x3D; 1&#39;b1;</span><br><span class="line">#5 rst_n &#x3D; 1&#39;b0;</span><br><span class="line">#10 rst_n &#x3D; 1&#39;b1;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">&#123;multiplier1,multiplier2&#125; &#x3D; &#39;b0;</span><br><span class="line">repeat(100) begin</span><br><span class="line">@(negedge clk);</span><br><span class="line">multiplier1 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">multiplier2 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">end</span><br><span class="line">$stop();</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">logic [2 * WIDTH - 1:0]exp;</span><br><span class="line">initial begin</span><br><span class="line">exp &#x3D; &#39;b0;</span><br><span class="line">forever begin</span><br><span class="line">@(posedge clk);</span><br><span class="line">exp &#x3D; multiplier1 * multiplier2;</span><br><span class="line">if(exp &#x3D;&#x3D; product) begin</span><br><span class="line">$display(&quot;successful&quot;);</span><br><span class="line">end else begin</span><br><span class="line">$display(&quot;fail&quot;);</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure></p><h1 id="分时复用ROM乘法器"><a href="#分时复用ROM乘法器" class="headerlink" title="分时复用ROM乘法器"></a>分时复用ROM乘法器</h1><h2 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h2><h3 id="核心部分"><a href="#核心部分" class="headerlink" title="核心部分"></a>核心部分</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">module serial_multrom_mult_core #(</span><br><span class="line">parameter HALF_WIDTH &#x3D; 4</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">input [2 * HALF_WIDTH - 1:0]mult1,mult2,</span><br><span class="line"></span><br><span class="line">input start,</span><br><span class="line">input [2 * HALF_WIDTH - 1:0]rom_dout,</span><br><span class="line">output reg [2 * HALF_WIDTH - 1:0]rom_address,</span><br><span class="line">output reg [4 * HALF_WIDTH - 1:0]dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">parameter INIT &#x3D; 1&#39;b0,</span><br><span class="line">      WORK &#x3D; 1&#39;b1;</span><br><span class="line">reg mode;</span><br><span class="line">reg [1:0]counte_4_decay2;</span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">mode &lt;&#x3D; 1&#39;b0;</span><br><span class="line">end else begin</span><br><span class="line">case (mode)</span><br><span class="line">INIT:begin</span><br><span class="line">if(start &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">mode &lt;&#x3D; WORK;</span><br><span class="line">end else begin</span><br><span class="line">mode &lt;&#x3D; INIT;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">WORK:begin</span><br><span class="line">if(counte_4_decay2 &#x3D;&#x3D; 2&#39;d3) begin</span><br><span class="line">mode &lt;&#x3D; INIT;</span><br><span class="line">end else begin</span><br><span class="line">mode &lt;&#x3D; WORK;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">default:mode &lt;&#x3D; INIT;</span><br><span class="line">endcase</span><br><span class="line">end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>到这里是一个状态机的状态部分，开始信号有效时状态变为<code>WORK</code>，运算结束状态变为<code>INIT</code>。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">reg [1:0]counte_4;</span><br><span class="line">always @(posedge clk or negedge rst_n) begin : proc_counte_4</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">counte_4 &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if(mode &#x3D;&#x3D; WORK)begin</span><br><span class="line">counte_4 &lt;&#x3D; counte_4 + 1&#39;b1;</span><br><span class="line">end else begin</span><br><span class="line">counte_4 &lt;&#x3D; &#39;b0;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">reg [2 * HALF_WIDTH - 1:0]mult1_lock,mult2_lock;</span><br><span class="line">always @(posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">&#123;mult1_lock,mult2_lock&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if(start &#x3D;&#x3D; 1&#39;b1)begin</span><br><span class="line">&#123;mult1_lock,mult2_lock&#125; &lt;&#x3D; &#123;mult1,mult2&#125;;</span><br><span class="line">end else begin</span><br><span class="line">&#123;mult1_lock,mult2_lock&#125; &lt;&#x3D; &#123;mult1_lock,mult2_lock&#125;;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">reg [1:0]counte_4_decay;</span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">&#123;rom_address,counte_4_decay&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if(start &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">&#123;rom_address,counte_4_decay&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else begin</span><br><span class="line">case (counte_4)</span><br><span class="line">2&#39;d0:rom_address &lt;&#x3D; &#123;mult1_lock[HALF_WIDTH - 1:0],mult2_lock[HALF_WIDTH - 1:0]&#125;;</span><br><span class="line">2&#39;d1:rom_address &lt;&#x3D; &#123;mult1_lock[2 * HALF_WIDTH - 1:HALF_WIDTH],mult2_lock[HALF_WIDTH - 1:0]&#125;;</span><br><span class="line">2&#39;d2:rom_address &lt;&#x3D; &#123;mult1_lock[HALF_WIDTH - 1:0],mult2_lock[2 * HALF_WIDTH - 1:HALF_WIDTH]&#125;;</span><br><span class="line">2&#39;d3:rom_address &lt;&#x3D; &#123;mult1_lock[2 * HALF_WIDTH - 1:HALF_WIDTH],mult2_lock[2 * HALF_WIDTH - 1:HALF_WIDTH]&#125;;</span><br><span class="line">default:rom_address &lt;&#x3D; &#39;b0;</span><br><span class="line">endcase</span><br><span class="line">counte_4_decay &lt;&#x3D; counte_4;</span><br><span class="line">end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><br>以上是输入控制部分，将乘数1高四位低四位，乘数2高四位低四位位拼接后送入ROM，获取乘积<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">wire [4 * HALF_WIDTH - 1:0]rom_dout_ex &#x3D; &#39;&#123;rom_dout&#125;;</span><br><span class="line">reg [4 * HALF_WIDTH - 1:0]rom_dout_lock;</span><br><span class="line"></span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">&#123;rom_dout_lock,counte_4_decay2&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if(start &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">&#123;rom_dout_lock,counte_4_decay2&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else begin</span><br><span class="line">case (counte_4_decay)</span><br><span class="line">2&#39;d0:rom_dout_lock &lt;&#x3D; rom_dout_ex;</span><br><span class="line">2&#39;d1:rom_dout_lock &lt;&#x3D; rom_dout_ex &lt;&lt; HALF_WIDTH;</span><br><span class="line">2&#39;d2:rom_dout_lock &lt;&#x3D; rom_dout_ex &lt;&lt; HALF_WIDTH;</span><br><span class="line">2&#39;d3:rom_dout_lock &lt;&#x3D; rom_dout_ex &lt;&lt; (2 * HALF_WIDTH);</span><br><span class="line">default:rom_dout_lock &lt;&#x3D; &#39;b0;</span><br><span class="line">endcase</span><br><span class="line">counte_4_decay2 &lt;&#x3D; counte_4_decay;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">dout &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if(mode &#x3D;&#x3D; WORK) begin</span><br><span class="line">dout &lt;&#x3D; dout + rom_dout_lock;</span><br><span class="line">end else if(start &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">dout &lt;&#x3D; &#39;b0;</span><br><span class="line">end else begin</span><br><span class="line">dout &lt;&#x3D; dout;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure><br>从ROM获取数据后按乘数组成位移相应位数后累加</p><h3 id="顶层部分"><a href="#顶层部分" class="headerlink" title="顶层部分"></a>顶层部分</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">module serial_multrom_mult_top #(</span><br><span class="line">parameter HALF_WIDTH &#x3D; 2</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">input start,</span><br><span class="line">input [2 * HALF_WIDTH - 1:0]mult1,mult2,</span><br><span class="line">output [4 * HALF_WIDTH - 1:0]dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">wire [2 * HALF_WIDTH - 1:0]rom_dout;</span><br><span class="line">wire [2 * HALF_WIDTH - 1:0]rom_address;</span><br><span class="line">serial_multrom_mult_core #(</span><br><span class="line">.HALF_WIDTH(HALF_WIDTH)</span><br><span class="line">) u_serial_multrom_mult_core (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">.mult1(mult1),</span><br><span class="line">.mult2(mult2),</span><br><span class="line"></span><br><span class="line">.start(start),</span><br><span class="line">.rom_dout(rom_dout),</span><br><span class="line">.rom_address(rom_address),</span><br><span class="line">.dout(dout)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">ROM_4 u_ROM_4(</span><br><span class="line">    .addr(rom_address),</span><br><span class="line">    .dout(rom_dout)</span><br><span class="line">);</span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure><h2 id="Testbench"><a href="#Testbench" class="headerlink" title="Testbench"></a>Testbench</h2><p>testbench由单个ROM的Testbench加入时钟和开始信号等改进而来<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">&#96;timescale 1ns&#x2F;1ps</span><br><span class="line">module mult_tb (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">parameter HALF_WIDTH &#x3D; 4;</span><br><span class="line">parameter WIDTH &#x3D; HALF_WIDTH * 2;</span><br><span class="line"></span><br><span class="line">logic clk,rst_n;</span><br><span class="line">logic start;</span><br><span class="line">logic [WIDTH - 1:0]multiplier1;</span><br><span class="line">logic [WIDTH - 1:0]multiplier2;</span><br><span class="line"></span><br><span class="line">logic [2 * WIDTH - 1:0]product;</span><br><span class="line"></span><br><span class="line">serial_multrom_mult_top #(</span><br><span class="line">.HALF_WIDTH(HALF_WIDTH)</span><br><span class="line">) dut (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">.start(start),</span><br><span class="line">.mult1(multiplier1),</span><br><span class="line">.mult2(multiplier2),</span><br><span class="line">.dout(product)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">clk &#x3D; 1&#39;b0;</span><br><span class="line">forever begin</span><br><span class="line">#50 clk &#x3D; ~clk;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">rst_n &#x3D; 1&#39;b1;</span><br><span class="line">#5 rst_n &#x3D; 1&#39;b0;</span><br><span class="line">#10 rst_n &#x3D; 1&#39;b1;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">logic [2 * WIDTH - 1:0]exp;</span><br><span class="line">initial begin</span><br><span class="line">&#123;multiplier1,multiplier2&#125; &#x3D; &#39;b0;</span><br><span class="line">repeat(100) begin</span><br><span class="line">@(negedge clk);</span><br><span class="line">start &#x3D; 1&#39;b1;</span><br><span class="line">multiplier1 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">multiplier2 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">exp &#x3D; multiplier1 * multiplier2;</span><br><span class="line">repeat(12) begin</span><br><span class="line">@(negedge clk);</span><br><span class="line">start &#x3D; &#39;b0;</span><br><span class="line">end</span><br><span class="line">if(product &#x3D;&#x3D; exp) begin</span><br><span class="line">$display(&quot;successful&quot;);</span><br><span class="line">end else begin</span><br><span class="line">$display(&quot;fail&quot;);</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">$stop();</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure><br>需要注意的是，使用modelsim仿真的时候出现错误代码<code>211</code>，这是关闭波形优化功能即可正常仿真</p>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>全并行流水移位相加乘法器</title>
      <link href="2017/09/06/%E5%85%A8%E5%B9%B6%E8%A1%8C%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%A7%BB%E4%BD%8D%E7%9B%B8%E5%8A%A0%E4%B9%98%E6%B3%95%E5%99%A8/"/>
      <url>2017/09/06/%E5%85%A8%E5%B9%B6%E8%A1%8C%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%A7%BB%E4%BD%8D%E7%9B%B8%E5%8A%A0%E4%B9%98%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h2><p>与分时复用的移位相加类似，取消分时复用，使用面积换时间，使用流水线设计，流水线填满后可以一个时钟周期计算出一个结果</p><ul><li>分别计算乘数的移位结果，并与被乘数对应位相与</li><li>使用加法树将结果相加</li></ul><h2 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h2><h3 id="移位部分"><a href="#移位部分" class="headerlink" title="移位部分"></a>移位部分</h3><p>固定移位单元代码如下，当被乘数第n位为1时，输出乘数移位向左移位n位的结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">module shift_unit # (</span><br><span class="line">parameter WIDTH &#x3D; 4,</span><br><span class="line">parameter SHIFT_NUM &#x3D; 0</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line">input shift_valid,</span><br><span class="line">input shift_mask,</span><br><span class="line">input [WIDTH - 1:0]shift_din,</span><br><span class="line"></span><br><span class="line">output reg [2 * WIDTH - 1:0]shift_dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">wire [2 * WIDTH - 1:0]shift_din_ext;</span><br><span class="line">assign shift_din_ext &#x3D; &#123;(WIDTH)&#39;(0),shift_din&#125;;</span><br><span class="line"></span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">shift_dout &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if((shift_valid &#x3D;&#x3D; 1&#39;b1) &amp;&amp; (shift_mask &#x3D;&#x3D; 1&#39;b1)) begin</span><br><span class="line">shift_dout &lt;&#x3D; shift_din_ext &lt;&lt; SHIFT_NUM;</span><br><span class="line">end else begin</span><br><span class="line">shift_dout &lt;&#x3D; &#39;b0;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure><br>移位器代码如下，使用生成语句生成位宽个移位器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">module parallel_shifter # (</span><br><span class="line">parameter WIDTH &#x3D; 4</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">input mult_valid,</span><br><span class="line">input [WIDTH - 1:0]mult1,mult2,</span><br><span class="line"></span><br><span class="line">output [(WIDTH ** 2) * 2 - 1:0]shift_dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">genvar a;</span><br><span class="line">generate</span><br><span class="line">for (a &#x3D; 0; a &lt; WIDTH; a &#x3D; a + 1) begin:shifter_layer</span><br><span class="line">shift_unit # (</span><br><span class="line">.WIDTH(WIDTH),</span><br><span class="line">.SHIFT_NUM(a)</span><br><span class="line">) u_shift_unit (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line">.shift_valid(mult_valid),</span><br><span class="line">.shift_mask(mult2[a]),</span><br><span class="line">.shift_din(mult1),</span><br><span class="line"></span><br><span class="line">.shift_dout(shift_dout[a * 2 * WIDTH +: 2 * WIDTH])</span><br><span class="line">);</span><br><span class="line">end</span><br><span class="line">endgenerate</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure></p><h3 id="加法部分"><a href="#加法部分" class="headerlink" title="加法部分"></a>加法部分</h3><p>加法部分使用加法树，可以实现流水线操作，以下为加法数单层代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">module adder_layer # (</span><br><span class="line">parameter ADDER_NUM &#x3D; 4,</span><br><span class="line">parameter ADDER_WIDTH &#x3D; 8</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line">input [ADDER_NUM * ADDER_WIDTH * 2 - 1:0]adder_din,</span><br><span class="line"></span><br><span class="line">output [ADDER_NUM * (ADDER_WIDTH + 1) - 1:0]adder_dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">genvar i;</span><br><span class="line">generate</span><br><span class="line">for(i &#x3D; 0;i &lt; ADDER_NUM;i &#x3D; i + 1) begin:adder_layer_gen</span><br><span class="line">wire [ADDER_WIDTH - 1:0]add1 &#x3D; adder_din[2 * i * ADDER_WIDTH +: ADDER_WIDTH];</span><br><span class="line">wire [ADDER_WIDTH - 1:0]add2 &#x3D; adder_din[(2 * i + 1) * ADDER_WIDTH +: ADDER_WIDTH];</span><br><span class="line">wire [ADDER_WIDTH:0]sum &#x3D; add1 + add2;</span><br><span class="line">reg [ADDER_WIDTH:0]sum_reg;</span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">sum_reg &lt;&#x3D; &#39;b0;</span><br><span class="line">end else begin</span><br><span class="line">sum_reg &lt;&#x3D; sum;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">assign adder_dout[i * (ADDER_WIDTH + 1) +: ADDER_WIDTH + 1] &#x3D; sum_reg;</span><br><span class="line">end</span><br><span class="line">endgenerate</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure><br>以下为加法树代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">module adder_tree # (</span><br><span class="line">parameter LAYER_NUM &#x3D; 4,</span><br><span class="line">parameter MIN_ADDER_WIDTH &#x3D; 8</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">input [(2 ** LAYER_NUM) * MIN_ADDER_WIDTH - 1:0]adder_din,</span><br><span class="line">output [LAYER_NUM + MIN_ADDER_WIDTH - 1:0]adder_dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">genvar i;</span><br><span class="line">generate</span><br><span class="line">for(i &#x3D; LAYER_NUM;i &gt; 0;i &#x3D; i - 1)begin:adder_layer_def</span><br><span class="line">wire [(2 ** i) * (MIN_ADDER_WIDTH + LAYER_NUM - i) - 1:0]layer_din;</span><br><span class="line">wire [2 ** (i - 1) * (MIN_ADDER_WIDTH + LAYER_NUM - i + 1) - 1:0]layer_dout;</span><br><span class="line">if(i &#x3D;&#x3D; LAYER_NUM) begin</span><br><span class="line">assign layer_din &#x3D; adder_din;</span><br><span class="line">end else begin</span><br><span class="line">assign layer_din &#x3D; adder_layer_def[i + 1].layer_dout;</span><br><span class="line">end</span><br><span class="line">adder_layer #  (</span><br><span class="line">.ADDER_NUM(2 ** (i - 1)),</span><br><span class="line">.ADDER_WIDTH(MIN_ADDER_WIDTH + LAYER_NUM - i)</span><br><span class="line">) u_adder_layer (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line">.adder_din(layer_din),</span><br><span class="line">.adder_dout(layer_dout)</span><br><span class="line">);</span><br><span class="line">end</span><br><span class="line">endgenerate</span><br><span class="line"></span><br><span class="line">assign adder_dout &#x3D; adder_layer_def[1].layer_dout;</span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure></p><h3 id="顶层"><a href="#顶层" class="headerlink" title="顶层"></a>顶层</h3><p>顶层组合了加法器和移位器，代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">module shift_adder # (</span><br><span class="line">parameter LOG2_WIDTH &#x3D; 2</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">input [2 ** LOG2_WIDTH - 1:0]mult1,mult2,</span><br><span class="line">input din_valid,</span><br><span class="line"></span><br><span class="line">output [(2 ** LOG2_WIDTH) * 2 - 1:0]dout</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">parameter WIDTH &#x3D; 2 ** LOG2_WIDTH;</span><br><span class="line"></span><br><span class="line">wire [(WIDTH ** 2) * 2 - 1:0]shift_dout;</span><br><span class="line">parallel_shifter # (</span><br><span class="line">.WIDTH(WIDTH)</span><br><span class="line">) u_parallel_shifter (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">.mult_valid(din_valid),</span><br><span class="line">.mult1(mult1),</span><br><span class="line">.mult2(mult2),</span><br><span class="line"></span><br><span class="line">.shift_dout(shift_dout)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">wire [LOG2_WIDTH + 2 * WIDTH:0]adder_dout;</span><br><span class="line">adder_tree # (</span><br><span class="line">.LAYER_NUM(LOG2_WIDTH),</span><br><span class="line">.MIN_ADDER_WIDTH(2 * WIDTH)</span><br><span class="line">) u_adder_tree (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">.adder_din(shift_dout),</span><br><span class="line">.adder_dout(adder_dout)</span><br><span class="line">);</span><br><span class="line">assign dout &#x3D; adder_dout[WIDTH * 2 - 1:0];</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>测试平台使用sv语法完成，因该乘法器完成一次运算的时间固定因此无输出有效信号，找到固定延迟后与使用<code>*</code>计算出的结果比较即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">module mult_tb (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">parameter LOG2_WIDTH &#x3D; 2;</span><br><span class="line">parameter WIDTH &#x3D; 2 ** LOG2_WIDTH;</span><br><span class="line"></span><br><span class="line">logic clk,rst_n;</span><br><span class="line">logic multiplier_valid;</span><br><span class="line">logic [WIDTH - 1:0]multiplier1;</span><br><span class="line">logic [WIDTH - 1:0]multiplier2;</span><br><span class="line"></span><br><span class="line">logic [2 * WIDTH - 1:0]product;</span><br><span class="line"></span><br><span class="line">shift_adder # (</span><br><span class="line">.LOG2_WIDTH(LOG2_WIDTH)</span><br><span class="line">) dut (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">.mult1(multiplier1),</span><br><span class="line">.mult2(multiplier2),</span><br><span class="line">.din_valid(multiplier_valid),</span><br><span class="line"></span><br><span class="line">.dout(product)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">clk &#x3D; 1&#39;b0;</span><br><span class="line">forever begin</span><br><span class="line"># 50 clk &#x3D; ~clk;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">rst_n &#x3D; 1&#39;b1;</span><br><span class="line"># 5 rst_n &#x3D; 1&#39;b0;</span><br><span class="line"># 10 rst_n &#x3D; 1&#39;b1;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">&#123;multiplier_valid,multiplier1,multiplier2&#125; &#x3D; &#39;b0;</span><br><span class="line">repeat(100) begin</span><br><span class="line">@(negedge clk);</span><br><span class="line">multiplier1 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">multiplier2 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">multiplier_valid &#x3D; 1&#39;b1;</span><br><span class="line">end</span><br><span class="line">$stop();</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">reg [WIDTH - 1:0]mult11,mult12,mult13;</span><br><span class="line">reg [WIDTH - 1:0]mult21,mult22,mult23;</span><br><span class="line">reg [2 * WIDTH - 1:0]exp;</span><br><span class="line"></span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">&#123;mult11,mult12,mult13,mult21,mult22,mult23&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else begin</span><br><span class="line">mult13 &lt;&#x3D; mult12;</span><br><span class="line">mult12 &lt;&#x3D; mult11;</span><br><span class="line">mult11 &lt;&#x3D; multiplier1;</span><br><span class="line"></span><br><span class="line">mult23 &lt;&#x3D; mult22;</span><br><span class="line">mult22 &lt;&#x3D; mult21;</span><br><span class="line">mult21 &lt;&#x3D; multiplier2;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">exp &#x3D; &#39;b0;</span><br><span class="line">forever begin</span><br><span class="line">@(negedge clk);</span><br><span class="line">exp &#x3D; mult13 * mult23;</span><br><span class="line">if(exp &#x3D;&#x3D; product) begin</span><br><span class="line">$display(&quot;successful&quot;);</span><br><span class="line">end else begin</span><br><span class="line">$display(&quot;fail&quot;);</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分时复用的移位相加乘法器</title>
      <link href="2017/09/06/%E5%88%86%E6%97%B6%E5%A4%8D%E7%94%A8%E7%9A%84%E7%A7%BB%E4%BD%8D%E7%9B%B8%E5%8A%A0%E4%B9%98%E6%B3%95%E5%99%A8/"/>
      <url>2017/09/06/%E5%88%86%E6%97%B6%E5%A4%8D%E7%94%A8%E7%9A%84%E7%A7%BB%E4%BD%8D%E7%9B%B8%E5%8A%A0%E4%B9%98%E6%B3%95%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="基本算法"><a href="#基本算法" class="headerlink" title="基本算法"></a>基本算法</h2><p>移位相加即是日常我们使用的手算算法，移位相加的描述如下</p><ul><li>设置积的初值为0</li><li>若乘数的最低位为0，则积不变，否则累加被乘数</li><li>若乘数的第一位为0，则积不变，否则累加向左移位一位的被乘数</li><li>…</li><li>若乘数的第n位（最高位）为0，则积不变，否则累加向左移位n位的被乘数<h2 id="RTL代码"><a href="#RTL代码" class="headerlink" title="RTL代码"></a>RTL代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">module serial_shiftadder_multipcation #  (</span><br><span class="line">parameter WIDTH &#x3D; 4</span><br><span class="line">)(</span><br><span class="line">input clk,    &#x2F;&#x2F; Clock</span><br><span class="line">input rst_n,  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">input multiplier_valid,</span><br><span class="line">input [WIDTH - 1:0]multiplier1,</span><br><span class="line">input [WIDTH - 1:0]multiplier2,</span><br><span class="line"></span><br><span class="line">output reg product_valid,</span><br><span class="line">output reg [2 * WIDTH - 1:0]product</span><br><span class="line">);</span><br></pre></td></tr></table></figure>接口定义部分，采用参数化设计，WIDTH为乘数/被乘数的位宽，multiplier_valid拉高时表示输入有效，并开始计算。product_valid被拉高时表示计算完成，当前的输出是有效的<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*****************buffer and shift*******************&#x2F;</span><br><span class="line">reg [WIDTH - 1:0]min_mult;</span><br><span class="line">reg [2 * WIDTH - 1:0]max_mult;</span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">&#123;max_mult,min_mult&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if(multiplier_valid &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">if(multiplier1 &gt; multiplier2) begin</span><br><span class="line">max_mult &lt;&#x3D; &#39;&#123;multiplier1&#125;;</span><br><span class="line">min_mult &lt;&#x3D; multiplier2;</span><br><span class="line">end else begin</span><br><span class="line">max_mult &lt;&#x3D; &#39;&#123;multiplier2&#125;;</span><br><span class="line">min_mult &lt;&#x3D; multiplier1;</span><br><span class="line">end</span><br><span class="line">end else if(min_mult !&#x3D; &#39;b0) begin</span><br><span class="line">max_mult &lt;&#x3D; max_mult &lt;&lt; 1;</span><br><span class="line">min_mult &lt;&#x3D; min_mult &gt;&gt; 1;</span><br><span class="line">end else begin</span><br><span class="line">max_mult &lt;&#x3D; max_mult;</span><br><span class="line">min_mult &lt;&#x3D; min_mult;</span><br><span class="line">end</span><br><span class="line">end</span><br></pre></td></tr></table></figure>移位部分，有输入时比较两个输入的大小，使用小的数控制迭代数量，减小时间消耗。若较小的乘数不为0，则将较大的数向左移位，较小的的数向右位移。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;******************adder********************&#x2F;</span><br><span class="line">always @ (posedge clk or negedge rst_n) begin</span><br><span class="line">if(~rst_n) begin</span><br><span class="line">&#123;product_valid,product&#125; &lt;&#x3D; &#39;b0;</span><br><span class="line">end else if(min_mult[0] &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">product &lt;&#x3D; product + max_mult;</span><br><span class="line">product_valid &lt;&#x3D; 1&#39;b0;</span><br><span class="line">end else if(min_mult !&#x3D; &#39;b0) begin</span><br><span class="line">product &lt;&#x3D; product;</span><br><span class="line">product_valid &lt;&#x3D; 1&#39;b0;</span><br><span class="line">end else if(multiplier_valid &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">product &lt;&#x3D; &#39;b0;</span><br><span class="line">product_valid &lt;&#x3D; 1&#39;b0;</span><br><span class="line">end else begin</span><br><span class="line">product &lt;&#x3D; product;</span><br><span class="line">product_valid &lt;&#x3D; 1&#39;b1;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure>累加部分，若较小的乘数最低位为0，保持积不变，否则累加当前的大乘数，当小乘数为0是，表示运算已经结束，输出有效拉高。<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2>使用自动化测试，使用高层次方法计算积，再与输出比较看是否相等<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">module mult_tb (</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">parameter WIDTH &#x3D; 4;</span><br><span class="line"></span><br><span class="line">logic clk,rst_n;</span><br><span class="line">logic multiplier_valid;</span><br><span class="line">logic [WIDTH - 1:0]multiplier1;</span><br><span class="line">logic [WIDTH - 1:0]multiplier2;</span><br><span class="line"></span><br><span class="line">logic product_valid;</span><br><span class="line">logic [2 * WIDTH - 1:0]product;</span><br><span class="line"></span><br><span class="line">serial_shiftadder_multipcation #  (</span><br><span class="line">.WIDTH(WIDTH)</span><br><span class="line">) dut (</span><br><span class="line">.clk(clk),    &#x2F;&#x2F; Clock</span><br><span class="line">.rst_n(rst_n),  &#x2F;&#x2F; Asynchronous reset active low</span><br><span class="line"></span><br><span class="line">.multiplier_valid(multiplier_valid),</span><br><span class="line">.multiplier1(multiplier1),</span><br><span class="line">.multiplier2(multiplier2),</span><br><span class="line"></span><br><span class="line">.product_valid(product_valid),</span><br><span class="line">.product(product)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">clk &#x3D; 1&#39;b0;</span><br><span class="line">forever begin</span><br><span class="line"># 50 clk &#x3D; ~clk;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">rst_n &#x3D; 1&#39;b1;</span><br><span class="line"># 5 rst_n &#x3D; 1&#39;b0;</span><br><span class="line"># 10 rst_n &#x3D; 1&#39;b1;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">initial begin</span><br><span class="line">&#123;multiplier_valid,multiplier1,multiplier2&#125; &#x3D; &#39;b0;</span><br><span class="line">forever begin</span><br><span class="line">@(negedge clk);</span><br><span class="line">if(product_valid &#x3D;&#x3D; 1&#39;b1) begin</span><br><span class="line">multiplier1 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">multiplier2 &#x3D; (WIDTH)&#39;($urandom_range(0,2 ** WIDTH));</span><br><span class="line">multiplier_valid &#x3D; 1&#39;b1;</span><br><span class="line">end else begin</span><br><span class="line">multiplier_valid &#x3D; 1&#39;b0;</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">logic [2 * WIDTH - 1:0]exp;</span><br><span class="line">initial begin</span><br><span class="line">forever begin</span><br><span class="line">@(posedge product_valid);</span><br><span class="line">exp &#x3D; multiplier1 * multiplier2;</span><br><span class="line">if(exp &#x3D;&#x3D; product) begin</span><br><span class="line">$display(&quot;successfully, mult1&#x3D;%d mult2&#x3D;%d product&#x3D;%d&quot;,multiplier1,multiplier2,product);</span><br><span class="line">end else begin</span><br><span class="line">$display(&quot;failed,mult1&#x3D;%d mult2&#x3D;%d product&#x3D;%d exp&#x3D;%d&quot;,multiplier1,multiplier2,product,exp);</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">endmodule</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Verilog巩固手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 数字信号处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于OpenCv-Python的视频组合</title>
      <link href="2017/09/06/%E5%9F%BA%E4%BA%8EOpenCv-Python%E7%9A%84%E8%A7%86%E9%A2%91%E7%BB%84%E5%90%88/"/>
      <url>2017/09/06/%E5%9F%BA%E4%BA%8EOpenCv-Python%E7%9A%84%E8%A7%86%E9%A2%91%E7%BB%84%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h2 id="step0：概述"><a href="#step0：概述" class="headerlink" title="step0：概述"></a>step0：概述</h2><ul><li>动机：手头有数个20秒左右的短视频（守望先锋最佳镜头），期望能组合成一个长视频</li></ul><ul><li>技术路线：opencv+python（opencv在Python中的封装库是cv2，依赖于numpy）<h2 id="step1：打开并显示视频"><a href="#step1：打开并显示视频" class="headerlink" title="step1：打开并显示视频"></a>step1：打开并显示视频</h2>要组合视频，首先需要打开视频并获取每一帧的图像，在opencv中可以使用<code>VideoCapture</code>这个类来打开视频，打开的视频也存在于这个类中，使用<code>.read()</code>方法也可以获得每一帧的图像，该方法的用法类似于生成器，每调用一次都会返回下一帧的图像。其中<code>.waitKey()</code>方法是延迟并获取键盘输入，传入参数是延迟时间数，单位是1/60s且必须是整数，因为原视频是60帧，所以间隔为1时是常速播放<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">capture &#x3D; cv2.VideoCapture(</span><br><span class="line">    &quot;..&#x2F;leviathan&#39;s highlight_17-08-16_00-52-33.mp4&quot;)</span><br><span class="line">if capture.isOpened():</span><br><span class="line">    while True:</span><br><span class="line">        ret, prev &#x3D; capture.read()</span><br><span class="line">        if ret is True:</span><br><span class="line">            cv2.imshow(&quot;&quot;, prev)</span><br><span class="line">        else:</span><br><span class="line">            break</span><br><span class="line">        cv2.waitKey(1)</span><br></pre></td></tr></table></figure>玩过守望先锋的小伙伴应该知道，那个最佳镜头的最后会一段浮现守望先锋logo的部分，我们需要切掉这一部分，方法是只截取前17.5秒的视频，因为不知道是否有24帧的视频，所以要先获得帧率再截取前17.5*fps的视频，现在的代码是<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">capture &#x3D; cv2.VideoCapture(</span><br><span class="line">    &quot;..&#x2F;leviathan&#39;s highlight_17-08-16_00-52-33.mp4&quot;)</span><br><span class="line">print(capture.get(cv2.CAP_PROP_FRAME_WIDTH))</span><br><span class="line">print(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))</span><br><span class="line">fps &#x3D; capture.get(cv2.CAP_PROP_FPS)</span><br><span class="line">if capture.isOpened():</span><br><span class="line">    i &#x3D; 0</span><br><span class="line">    while i &lt; fps * 17.5:</span><br><span class="line">        i +&#x3D; 1</span><br><span class="line">        ret, prev &#x3D; capture.read()</span><br><span class="line">        if ret is True:</span><br><span class="line">            cv2.imshow(&quot;&quot;, prev)</span><br><span class="line">        else:</span><br><span class="line">            break</span><br><span class="line">        cv2.waitKey(1)</span><br></pre></td></tr></table></figure>顺便还看了下幕布的尺寸为1920*1080<br>参考<a href="http://blog.csdn.net/u010167269/article/details/53303340">python tools：计算视频的 FPS，以及总帧数</a><h2 id="step2打开并显示一堆视频"><a href="#step2打开并显示一堆视频" class="headerlink" title="step2打开并显示一堆视频"></a>step2打开并显示一堆视频</h2>因为视频一共有20个左右，所以可以使用<code>os</code>模块中的<code>listdir()</code>获取所有文件，并筛选带<code>.mp4</code>后缀的视频文件。这样获取的list是完全按顺序排列的，我们还可以使用<code>random.shuffle()</code>方法打乱整个视频列表<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mp4list &#x3D; [x for x in os.listdir(&quot;..&#x2F;&quot;) if x[-4:] &#x3D;&#x3D; &quot;.mp4&quot;]</span><br><span class="line">random.shuffle(mp4list)</span><br></pre></td></tr></table></figure>于是遍历整个列表看所有视频了<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">mp4list &#x3D; [x for x in os.listdir(&quot;..&#x2F;&quot;) if x[-4:] &#x3D;&#x3D; &quot;.mp4&quot;]</span><br><span class="line">random.shuffle(mp4list)</span><br><span class="line">print(mp4list)</span><br><span class="line">for mp4file in mp4list:</span><br><span class="line">    capture &#x3D; cv2.VideoCapture(&quot;..&#x2F;%s&quot; % mp4file)</span><br><span class="line">    fps &#x3D; capture.get(cv2.CAP_PROP_FPS)</span><br><span class="line">    print(fps)</span><br><span class="line">    if fps !&#x3D; 60:</span><br><span class="line">        jump &#x3D; 20</span><br><span class="line">    else:</span><br><span class="line">        jump &#x3D; 1</span><br><span class="line">    if capture.isOpened():</span><br><span class="line">        i &#x3D; 0</span><br><span class="line">        while i &lt; fps * 1:</span><br><span class="line">            i +&#x3D; 1</span><br><span class="line">            ret, prev &#x3D; capture.read()</span><br><span class="line">            if ret is True:</span><br><span class="line">                cv2.imshow(&quot;&quot;, prev)</span><br><span class="line">            else:</span><br><span class="line">                break</span><br><span class="line">            cv2.waitKey(jump)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><h2 id="step3：保存为一个大视频"><a href="#step3：保存为一个大视频" class="headerlink" title="step3：保存为一个大视频"></a>step3：保存为一个大视频</h2>保存视频首先需要创建一个视频容器，可以使用<code>cv2.VideoWriter</code>，输入参数为路径，压缩方式，帧率，幕布大小，随后使用该对象的<code>write()</code>方法即可写入一帧，写入完成后，使用<code>release()</code>方法释放容器并保存，若在次之前程序中断，那视频文件会是损坏状态，于是程序是这样的<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line">VideoWriter &#x3D; cv2.VideoWriter(</span><br><span class="line">    &quot;.&#x2F;overwatch.avi&quot;,</span><br><span class="line">    cv2.VideoWriter_fourcc(&#39;X&#39;, &#39;V&#39;, &#39;I&#39;, &#39;D&#39;), 60,</span><br><span class="line">    (1920, 1080))</span><br><span class="line"></span><br><span class="line">mp4list &#x3D; [x for x in os.listdir(&quot;..&#x2F;&quot;) if x[-4:] &#x3D;&#x3D; &quot;.mp4&quot;]</span><br><span class="line">random.shuffle(mp4list)</span><br><span class="line">print(mp4list)</span><br><span class="line">for mp4file in mp4list:</span><br><span class="line">    print(mp4file)</span><br><span class="line">    capture &#x3D; cv2.VideoCapture(&quot;..&#x2F;%s&quot; % mp4file)</span><br><span class="line">    fps &#x3D; capture.get(cv2.CAP_PROP_FPS)</span><br><span class="line">    if capture.isOpened():</span><br><span class="line">        i &#x3D; 0</span><br><span class="line">        while i &lt; fps * 17.5:</span><br><span class="line">            i +&#x3D; 1</span><br><span class="line">            ret, prev &#x3D; capture.read()</span><br><span class="line">            if ret is True:</span><br><span class="line">                if fps &#x3D;&#x3D; 60:</span><br><span class="line">                    VideoWriter.write(prev)</span><br><span class="line">                else:</span><br><span class="line">                    VideoWriter.write(prev)</span><br><span class="line">                    VideoWriter.write(prev)</span><br><span class="line">            else:</span><br><span class="line">                break</span><br><span class="line">VideoWriter.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>其中为了补偿30帧左右的视频，非60帧图片一帧写入两次</li></ul>]]></content>
      
      
      <categories>
          
          <category> Python应用手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Python的运动计费管理系统</title>
      <link href="2017/09/06/%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E8%BF%90%E5%8A%A8%E8%AE%A1%E8%B4%B9%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/"/>
      <url>2017/09/06/%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E8%BF%90%E5%8A%A8%E8%AE%A1%E8%B4%B9%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h1><p>  小伙伴们最近迷恋上羽毛球，组织了个小群，办了公用的运动卡用于开场，考虑不是每次活动都是全员参与，需要一个计费的系统来计算每个人需要交的费用。商讨后决定采用“预充-扣费”的方式，则需要一个系统进行计费和扣费。</p><h1 id="技术路线规划"><a href="#技术路线规划" class="headerlink" title="技术路线规划"></a>技术路线规划</h1><div class="table-container"><table><thead><tr><th>模块名</th><th>语言</th><th>备注</th></tr></thead><tbody><tr><td>管理核心</td><td>Python</td><td>使用JSON存储信息</td></tr><tr><td>Web后端</td><td>Python</td><td>Flask框架</td></tr><tr><td>Web前端</td><td>HTML</td><td>Jinja框架渲染</td></tr></tbody></table></div><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h3 id="核心模块——用户状态管理"><a href="#核心模块——用户状态管理" class="headerlink" title="核心模块——用户状态管理"></a>核心模块——用户状态管理</h3><p>该部分是整个计费系统的核心，用于管理每个用户的余额。使用一个类表示用户，需要的属性为</p><ul><li>状态列表（用户名，ID，使用次数，余额）</li></ul><p>需要的方法有：</p><ul><li>创建用户（创建新的JSON文件）</li><li>读取用户状态（从已有的JSON文件中）</li><li>扣费（使用次数增加1，余额减小）</li><li>充值（余额增加）</li><li>保存状态（将现有的状态写入JSON文件）</li></ul><p>代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#  -*- coding: utf-8 -*-</span><br><span class="line">import json</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class UserHanlde(object):</span><br><span class="line">    &quot;&quot;&quot;docstring for UserHanlde&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, UserID, UserName&#x3D;&quot;&quot;):</span><br><span class="line">        super(UserHanlde, self).__init__()</span><br><span class="line">        if self.UserExsist(UserID):</span><br><span class="line">            self.UserInfo &#x3D; self.LoadUserInfo(UserID)</span><br><span class="line">        else:</span><br><span class="line">            self.UserInfo &#x3D; self.CreateNewUser(UserName, UserID)</span><br></pre></td></tr></table></figure><br>构造函数，若该用户ID存在则读取状态，否则创建<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def UserExsist(self, UserID):</span><br><span class="line">    return os.path.exists(&quot;.&#x2F;Users&#x2F;%s.json&quot; % UserID)</span><br></pre></td></tr></table></figure><br>判断该ID的JSON文件是否存在<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def CreateNewUser(self, UserName, UserID):</span><br><span class="line">    UserInfo &#x3D; &#123;</span><br><span class="line">        &quot;name&quot;: UserName,</span><br><span class="line">        &quot;id&quot;: UserID,</span><br><span class="line">        &quot;num&quot;: 0,</span><br><span class="line">        &quot;balance&quot;: 50</span><br><span class="line">    &#125;</span><br><span class="line">    with open(&quot;.&#x2F;Users&#x2F;%s.json&quot; % UserID, &quot;w&quot;) as jsonfile:</span><br><span class="line">        json.dump(UserInfo, jsonfile, ensure_ascii&#x3D;False, indent&#x3D;4)</span><br><span class="line">    return UserInfo</span><br></pre></td></tr></table></figure><br> 创建新用户，将初始余额设为50并保存JSON文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def LoadUserInfo(self, UserID):</span><br><span class="line">    with open(&quot;.&#x2F;Users&#x2F;%s.json&quot; % UserID, &quot;r&quot;) as jsonfile:</span><br><span class="line">        return json.load(jsonfile)</span><br></pre></td></tr></table></figure><br>从JSON文件中载入用户状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def PlayOneTime(self, Pay):</span><br><span class="line">    self.UserInfo[&quot;num&quot;] +&#x3D; 1</span><br><span class="line">    self.UserInfo[&quot;balance&quot;] &#x3D; self.UserInfo[&quot;balance&quot;] - Pay</span><br></pre></td></tr></table></figure><br>扣费，扣除指定的费用并在将扣费次数+1<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def Recharge(self, Pay):</span><br><span class="line">    self.UserInfo[&quot;balance&quot;] +&#x3D; Pay</span><br></pre></td></tr></table></figure><br>充值，费用加上指定值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def DeleteUser(self):</span><br><span class="line">    os.remove(&quot;.&#x2F;Users&#x2F;%s.json&quot; % self.UserInfo[&quot;id&quot;])</span><br></pre></td></tr></table></figure><br>删除用户，删除指定的JSON文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def SaveInfo(self):</span><br><span class="line">    with open(&quot;.&#x2F;Users&#x2F;%s.json&quot; % self.UserInfo[&quot;id&quot;], &quot;w&quot;) as jsonfile:</span><br><span class="line">        json.dump(self.UserInfo, jsonfile, ensure_ascii&#x3D;False, indent&#x3D;4)</span><br></pre></td></tr></table></figure><br>保存状态，将当前状态写入对应的JSON文件</p><h3 id="Web后端"><a href="#Web后端" class="headerlink" title="Web后端"></a>Web后端</h3><p>web后端使用Python的Flask框架构造，代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from flask import Flask, render_template, request</span><br><span class="line">from UserHanlde import UserHanlde</span><br><span class="line">import os</span><br><span class="line">app &#x3D; Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def GetUserIDList():</span><br><span class="line">    return [x[:-5] for x in os.listdir(&quot;.&#x2F;Users&quot;) if &quot;.json&quot; in x]</span><br><span class="line"></span><br><span class="line">def GetUserInfoList():</span><br><span class="line">    UserInfoList &#x3D; dict()</span><br><span class="line">    for UserID in GetUserIDList():</span><br><span class="line">        UserData &#x3D; UserHanlde(UserID)</span><br><span class="line">        UserInfoList[UserID] &#x3D; UserData.UserInfo</span><br><span class="line">    return UserInfoList</span><br></pre></td></tr></table></figure><br>常用部分的封装:</p><ul><li><code>GetUserIDList()</code>：返回已经存在的用户ID列表</li><li><code>GetUserInfoList()</code>：返回已经存在的用户状态列表<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">@app.route(&quot;&#x2F;index&quot;)</span><br><span class="line">def ViewInfo():</span><br><span class="line">    return render_template(&quot;index.html&quot;, user_list&#x3D;GetUserInfoList())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&quot;&#x2F;recharge&quot;)</span><br><span class="line">def GetReChargeInfo():</span><br><span class="line">    return render_template(&quot;recharge.html&quot;, user_list&#x3D;GetUserInfoList())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&quot;&#x2F;recharge_handle&quot;, methods&#x3D;[&quot;GET&quot;, &quot;POST&quot;])</span><br><span class="line">def Recharge():</span><br><span class="line">    UserID &#x3D; request.values.get(&quot;id&quot;)</span><br><span class="line">    UserRecharge &#x3D; request.values.get(&quot;pay&quot;)</span><br><span class="line">    if UserRecharge.isdigit() is True:</span><br><span class="line">        UserHanlder &#x3D; UserHanlde(UserID)</span><br><span class="line">        UserHanlder.Recharge(int(UserRecharge))</span><br><span class="line">        UserHanlder.SaveInfo()</span><br><span class="line">        return render_template(&quot;back.html&quot;)</span><br><span class="line">    else:</span><br><span class="line">        return &quot;fail&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&quot;&#x2F;register&quot;)</span><br><span class="line">def GetRegisterInfo():</span><br><span class="line">    return render_template(&quot;register.html&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&quot;&#x2F;register_handle&quot;, methods&#x3D;[&quot;GET&quot;, &quot;POST&quot;])</span><br><span class="line">def Register():</span><br><span class="line">    UserID &#x3D; request.values.get(&quot;id&quot;)</span><br><span class="line">    UserName &#x3D; request.values.get(&quot;name&quot;)</span><br><span class="line">    UserHanlder &#x3D; UserHanlde(UserID, UserName&#x3D;UserName)</span><br><span class="line">    return render_template(&quot;back.html&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&quot;&#x2F;pay&quot;)</span><br><span class="line">def GetPayName():</span><br><span class="line">    return render_template(&quot;pay.html&quot;, user_list&#x3D;GetUserInfoList())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&quot;&#x2F;pay_handle&quot;, methods&#x3D;[&quot;GET&quot;, &quot;POST&quot;])</span><br><span class="line">def Pay():</span><br><span class="line">    UserIDList &#x3D; request.values.getlist(&quot;vehicle&quot;)</span><br><span class="line">    UserIDPay &#x3D; request.values.get(&quot;pay&quot;)</span><br><span class="line">    if UserIDPay.isdigit() is True:</span><br><span class="line">        PayNum &#x3D; int(UserIDPay) &#x2F; len(UserIDList)</span><br><span class="line">        for UserID in UserIDList:</span><br><span class="line">            UserHanlder &#x3D; UserHanlde(UserID)</span><br><span class="line">            UserHanlder.PlayOneTime(PayNum)</span><br><span class="line">            UserHanlder.SaveInfo()</span><br><span class="line">        return render_template(&quot;back.html&quot;)</span><br><span class="line">    else:</span><br><span class="line">        return &quot;fail&quot;</span><br></pre></td></tr></table></figure>路由部分</li><li><code>/index</code>：主页，包括导航和状态显示，所有用户的消费次数和余额将在这里显示</li><li><code>/recharge</code>和<code>/recharge_handle</code>：充值页面， <code>/recharge</code>为操作页面，用户在这里填写表单数据，随后表单数据被提交到<code>/recharge_handle</code>处理充值业务</li><li><code>/register</code>和<code>/register_handle</code>：注册页面，与<code>/recharge</code>和<code>/recharge_handle</code>关系相同</li><li><code>/pay</code>和<code>/pay_handle</code>：扣费页面，与<code>/recharge</code>和<code>/recharge_handle</code>关系相同<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app.run(host&#x3D;&quot;0.0.0.0&quot;)</span><br></pre></td></tr></table></figure>运行，监听所有IP，这样在局域网就可以访问了<h3 id="Web前端"><a href="#Web前端" class="headerlink" title="Web前端"></a>Web前端</h3>Web使用HTML代码提供GUI，使用Jinja框架分离数据与模板</li><li>index界面<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;index&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&lt;h1&gt;羽毛球运动管理系统&lt;&#x2F;h1&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&lt;table border&#x3D;&quot;1&quot;&gt;</span><br><span class="line">&lt;thead&gt;</span><br><span class="line">&lt;tr&gt;</span><br><span class="line">&lt;th&gt;用户&lt;&#x2F;th&gt;</span><br><span class="line">&lt;th&gt;次数&lt;&#x2F;th&gt;</span><br><span class="line">&lt;th&gt;余额&lt;&#x2F;th&gt;</span><br><span class="line">&lt;&#x2F;tr&gt;</span><br><span class="line">&lt;&#x2F;thead&gt;</span><br><span class="line">&lt;tbody&gt;</span><br><span class="line">&#123;% for user_id in user_list -%&#125;</span><br><span class="line">&lt;tr&gt;</span><br><span class="line">&lt;td&gt;&#123;&#123;user_list[user_id][&quot;name&quot;]&#125;&#125;&lt;&#x2F;td&gt;</span><br><span class="line">&lt;td&gt;&#123;&#123;user_list[user_id][&quot;num&quot;]&#125;&#125;&lt;&#x2F;td&gt;</span><br><span class="line">&lt;td&gt;&#123;&#123;user_list[user_id][&quot;balance&quot;]&#125;&#125;&lt;&#x2F;td&gt;</span><br><span class="line">&lt;&#x2F;tr&gt;</span><br><span class="line">&#123;%- endfor %&#125;</span><br><span class="line">&lt;&#x2F;tbody&gt;</span><br><span class="line">&lt;&#x2F;table&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure>用户状态显示，使用for循环生成表格<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;register&quot;&gt;register&lt;&#x2F;a&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;recharge&quot;&gt;recharge&lt;&#x2F;a&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;pay&quot;&gt;pay&lt;&#x2F;a&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>超链接部分，用于导航</li><li>register界面<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;register&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;羽毛球运动管理系统--注册&lt;&#x2F;h1&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&lt;form action&#x3D;&quot;register_handle&quot; method&#x3D;&quot;post&quot; accept-charset&#x3D;&quot;utf-8&quot;&gt;</span><br><span class="line">name&lt;input type&#x3D;&quot;text&quot; name&#x3D;&quot;name&quot;&gt;</span><br><span class="line">id&lt;input type&#x3D;&quot;text&quot; name&#x3D;&quot;id&quot;&gt;</span><br><span class="line">&lt;input type&#x3D;&quot;submit&quot; name&#x3D;&quot;Submit&quot;&gt;</span><br><span class="line">&lt;&#x2F;form&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;&#x2F;index&quot;&gt;back to index&lt;&#x2F;a&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>使用两个文本输入框表单输入用户名与用户ID</li><li>recharge界面<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;recharge&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&lt;h1&gt;羽毛球运动管理系统--充值&lt;&#x2F;h1&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&lt;form action&#x3D;&quot;recharge_handle&quot; method&#x3D;&quot;post&quot; accept-charset&#x3D;&quot;utf-8&quot;&gt;</span><br><span class="line">&lt;select name&#x3D;&quot;id&quot;&gt;</span><br><span class="line">&#123;% for userid in user_list -%&#125;</span><br><span class="line">&lt;option value&#x3D;&quot;&#123;&#123;userid&#125;&#125;&quot;&gt;&#123;&#123;user_list[userid][&quot;name&quot;]&#125;&#125;&lt;&#x2F;option&gt;</span><br><span class="line">&#123;%- endfor %&#125;</span><br><span class="line">&lt;&#x2F;select&gt;</span><br><span class="line">recharge￥&lt;input type&#x3D;&quot;text&quot; name&#x3D;&quot;pay&quot;&gt;</span><br><span class="line">&lt;input type&#x3D;&quot;submit&quot; name&#x3D;&quot;Submit&quot;&gt;</span><br><span class="line">&lt;&#x2F;form&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;&#x2F;index&quot;&gt;back to index&lt;&#x2F;a&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>使用下拉菜单提供可供选择的用户名，文本输入充值金额</li><li>pay界面<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;pay&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;羽毛球运动管理系统--消费&lt;&#x2F;h1&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&lt;form action&#x3D;&quot;pay_handle&quot; method&#x3D;&quot;post&quot; accept-charset&#x3D;&quot;utf-8&quot;&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">&#123;%for userid in user_list%&#125;</span><br><span class="line">&lt;input type&#x3D;&quot;checkbox&quot; name&#x3D;&quot;vehicle&quot; value&#x3D;&quot;&#123;&#123;userid&#125;&#125;&quot;&gt;&#123;&#123;user_list[userid][&quot;name&quot;]&#125;&#125;&lt;br&gt;</span><br><span class="line">&#123;% endfor %&#125;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">pay￥&lt;input type&#x3D;&quot;text&quot; name&#x3D;&quot;pay&quot;&gt;</span><br><span class="line">&lt;input type&#x3D;&quot;submit&quot; name&#x3D;&quot;Submit&quot;&gt;</span><br><span class="line">&lt;&#x2F;form&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;&#x2F;index&quot;&gt;back to index&lt;&#x2F;a&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>使用复选框列出所有用户提供选择，文本输入总输入金额，复选框这种表单数据在后端使用<code>request.values.getlist(&quot;name&quot;)</code>获取为一个列表</li><li>back界面<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;back&lt;&#x2F;title&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;a href&#x3D;&quot;&#x2F;index&quot;&gt;back to index&lt;&#x2F;a&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure>用户完成充值/注册/消费时用于返回主页</li></ul>]]></content>
      
      
      <categories>
          
          <category> Python应用手记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Python的Rosenblatt感知机模型</title>
      <link href="2017/09/06/%E5%9F%BA%E4%BA%8EPython%E7%9A%84Rosenblatt%E6%84%9F%E7%9F%A5%E5%99%A8%E6%A8%A1%E5%9E%8B/"/>
      <url>2017/09/06/%E5%9F%BA%E4%BA%8EPython%E7%9A%84Rosenblatt%E6%84%9F%E7%9F%A5%E5%99%A8%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Rosenblatt感知器"><a href="#Rosenblatt感知器" class="headerlink" title="Rosenblatt感知器"></a>Rosenblatt感知器</h1><p>Rosenblatt感知器是一种最简单的感知器模型，即输出值为输入与对应权值相乘后取和再累加并加上偏置后通过符号函数的结果，即：<code>Output = sgn(w0 * x0 + w1 * x1 + ... + wn * xn + bias)</code>。<br>训练时，使用有监督学习，当输出值与真实值不同时，对应的weight与该次输入数据与真实值和学习率的乘积相加，或可以描述为<code>weight += input * (d - o) * n</code>其中，input为输入值，d为真实值，o为输出值，n为学习率</p><h1 id="Python实现"><a href="#Python实现" class="headerlink" title="Python实现"></a>Python实现</h1><h3 id="Rosenblatt神经元的实现"><a href="#Rosenblatt神经元的实现" class="headerlink" title="Rosenblatt神经元的实现"></a>Rosenblatt神经元的实现</h3><p>通过Rosenblatt感知器的数学模型，可以很简单的使用<code>numpy</code>库实现感知机功能<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Rosenblatt(object):</span><br><span class="line">    &quot;&quot;&quot;docstring for Rosenblatt&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, InputNum):</span><br><span class="line">        super(Rosenblatt, self).__init__()</span><br><span class="line">        self.Weight &#x3D; np.zeros([InputNum + 1, 1])</span><br><span class="line">        self.TrainRaito &#x3D; 1</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F;激活函数（符号函数）</span><br><span class="line">    def ActivitionFunction(self, InputData):</span><br><span class="line">        #  print(InputData, np.zeros(InputData.shape))</span><br><span class="line">        #  print((InputData &gt; np.zeros(InputData.shape)).all())</span><br><span class="line">        if (InputData &gt; np.zeros(InputData.shape)).all() &#x3D;&#x3D; True:</span><br><span class="line">            #  print(&quot;1&quot;)</span><br><span class="line">            return 1</span><br><span class="line">        else:</span><br><span class="line">            #  print(&quot;-1&quot;)</span><br><span class="line">            return -1</span><br></pre></td></tr></table></figure></p><ul><li><code>(InputData &gt; np.zeros(InputData.shape)).all()</code>表示当<code>InputData</code>中的每一个元素都大于0时，返回<code>True</code>，与此相似的还有<code>.any()</code>，只要有一个元素满足即返回<code>True</code></li><li>需要注意的是这里的<code>==</code>不可改为<code>is</code>，否则会出现奇怪的情况<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;前馈传播</span><br><span class="line">def Feedforward(self, InputData):</span><br><span class="line">    return self.ActivitionFunction(</span><br><span class="line">        np.matmul(self.Weight.T, np.hstack((np.ones([1, 1]), InputData)).T))</span><br></pre></td></tr></table></figure></li><li>这里的<code>.T</code>表示矩阵的转置，注意二维矩阵转置才是符合要求的，一维矩阵的转置行为有点奇怪。</li><li><code>np.hstack((a,b))</code>函数表示在第0维上垛堞<code>a</code>和<code>b</code>矩阵<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;训练</span><br><span class="line">def TrainOneStep(self, InputData, RightResult):</span><br><span class="line">    Result &#x3D; self.Feedforward(InputData)</span><br><span class="line">    if Result !&#x3D; RightResult:</span><br><span class="line">        self.ChangeWeight(InputData, RightResult, Result)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;修改权值</span><br><span class="line">def ChangeWeight(self, InputData, RightResult, Result):</span><br><span class="line">    #  print(self.TrainRaito *</span><br><span class="line">    #        (RightResult - Result))</span><br><span class="line">    self.Weight +&#x3D; self.TrainRaito * \</span><br><span class="line">        (RightResult - Result) * np.hstack((np.ones([1, 1]), InputData)).T</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置学习率</span><br><span class="line">def SetTrainRatio(self, Ratio):</span><br><span class="line">    self.TrainRaito &#x3D; Ratio</span><br></pre></td></tr></table></figure><h3 id="双月数据集"><a href="#双月数据集" class="headerlink" title="双月数据集"></a>双月数据集</h3>本次测试使用的是双月数据集，如下图所示：</li></ul><p>该数据集是一个线性不可分的数据集，上方的半月的真实值为1，下方的半月真实值为-1，该数据集生成代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">import random</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class SemicircleGenerator(object):</span><br><span class="line">    &quot;&quot;&quot;docstring for SemicircleGenerator&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, StartLocation, RadiusList, Orientation):</span><br><span class="line">        super(SemicircleGenerator, self).__init__()</span><br><span class="line">        self.StartLocation &#x3D; StartLocation</span><br><span class="line">        self.MaxRadius &#x3D; max(RadiusList)</span><br><span class="line">        self.MinRadius &#x3D; min(RadiusList)</span><br><span class="line">        self.Orientation &#x3D; Orientation</span><br></pre></td></tr></table></figure><br>构造函数确定了单月的信息：</p><ul><li><code>StartLocation</code>是一个坐标list，表示月原点（圆心）的位置</li><li><code>RadiusList</code>是一个存储了大圈的半径和小圈的半径list</li><li><code>Orientation</code>表示月的朝向，<code>+</code>表示向上，<code>-</code>表示向下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def Gen_SemicircleData(self, BatchSize):</span><br><span class="line">    for _ in range(BatchSize):</span><br><span class="line">        Radius &#x3D; random.uniform(self.MinRadius, self.MaxRadius)</span><br><span class="line">        BiasX &#x3D; random.uniform(- Radius, Radius)</span><br><span class="line">        BiasY &#x3D; math.sqrt(Radius * Radius - BiasX * BiasX)</span><br><span class="line">        if self.Orientation &#x3D;&#x3D; &quot;+&quot;:</span><br><span class="line">            yield [BiasX + self.StartLocation[0], BiasY</span><br><span class="line">                   + self.StartLocation[1]]</span><br><span class="line">        else:</span><br><span class="line">            yield [self.StartLocation[0] - BiasX,</span><br><span class="line">                   self.StartLocation[1] - BiasY]</span><br></pre></td></tr></table></figure><code>Gen_SemicircleData()</code>是一个生成器，用于生成指定数量的单月形状内的点，过程是首先使用<code>random.uniform()</code>生成一个半径范围内的随机半径，再生成一个正负半径内的随机x偏移量，通过勾股定理计算出y的偏移量，即可以生成一个落在单月形状内的随机点，再根据朝向生成这个点的绝对坐标使用<code>yield</code>返回</li></ul><h3 id="Rosenblatt训练与测试环境"><a href="#Rosenblatt训练与测试环境" class="headerlink" title="Rosenblatt训练与测试环境"></a>Rosenblatt训练与测试环境</h3><p>通过调用Rosenblatt和数据集代码生成训练和测试环境，并使用<code>matplotlib</code>绘图实现可视化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from Rosenblatt import Rosenblatt</span><br><span class="line">from SemicircleGenerator import SemicircleGenerator</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">neural &#x3D; Rosenblatt(2)</span><br><span class="line">dataset1 &#x3D; SemicircleGenerator([0, 0], [4, 6], &quot;+&quot;)</span><br><span class="line">dataset2 &#x3D; SemicircleGenerator([7, -2], [4, 6], &quot;-&quot;)</span><br><span class="line">testdata_x, testdata_y &#x3D; [], []</span><br></pre></td></tr></table></figure><br>首先建立神经元和数据集<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for data in dataset1.Gen_SemicircleData(1000):</span><br><span class="line">    neural.TrainOneStep(np.array([data]), 1)</span><br><span class="line">    testdata_x.append(data[0])</span><br><span class="line">    testdata_y.append(data[1])</span><br><span class="line">for data in dataset2.Gen_SemicircleData(1000):</span><br><span class="line">    neural.TrainOneStep(np.array([data]), -1)</span><br><span class="line">    testdata_x.append(data[0])</span><br><span class="line">    testdata_y.append(data[1])</span><br></pre></td></tr></table></figure><br>再分别使用数据集进行训练，并保存训练数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(neural.Weight)</span><br><span class="line">x_data, y_data &#x3D; [-6, 13], []</span><br><span class="line">print(neural.Weight[1][0])</span><br><span class="line">for i in x_data:</span><br><span class="line">    y_data.append(- (neural.Weight[0][0] + i *</span><br><span class="line">                     neural.Weight[1][0]) &#x2F; (neural.Weight[2][0]))</span><br></pre></td></tr></table></figure><br>通过训练得到的数据得出结果直线<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x_data, y_data, color&#x3D;&quot;red&quot;)</span><br><span class="line">plt.scatter(testdata_x, testdata_y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br>使用<code>matplotlib</code>绘图，<code>plt.plot()</code>用于绘制折线图，颜色配置可以参考<a href="http://www.cnblogs.com/darkknightzh/p/6117528.html">这里</a>，<code>plt.scatter()</code>用于绘制散点图，<code>plt.show()</code>显示已经绘制的图像，更多<code>matplotlib</code>绘图可以参考<a href="http://www.jianshu.com/p/ee8bb1bd0019">这里</a>和<a href="http://blog.topspeedsnail.com/archives/819">这里</a></p><h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>生成的图像如下：</p><p>红线代表感知器的学习结果，可以看到很好的划分出了两个半月之间的界限</p>]]></content>
      
      
      <categories>
          
          <category> 传统机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NeuralNetwork </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript入门笔记6</title>
      <link href="2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B06/"/>
      <url>2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B06/</url>
      
        <content type="html"><![CDATA[<h1 id="标准对象"><a href="#标准对象" class="headerlink" title="标准对象"></a>标准对象</h1><h3 id="正则对象"><a href="#正则对象" class="headerlink" title="正则对象"></a>正则对象</h3><p>正则表达式是一种处理文本信息的神器，在JavaScript中可以方便的使用正则对象对文本进行处理。JavaScript中声明正则对象可以使用<code>var name = /.../</code>和<code>var name = new RegExp(&quot;...&quot;)</code>，第二种方法个人是不推荐的，要处理一系列的文本转义，正则表达式定以后可以使用<code>.test()</code>方法检验是否有匹配和<code>.exec()</code>方法分组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">var re_test &#x3D; &#x2F;\w+@\w+\.\w+&#x2F;</span><br><span class="line">console.log(re_test) &#x2F;&#x2F;&#x2F;\w+@\w+\.\w+&#x2F;</span><br><span class="line">console.log(re_test.test(&quot;avbd@163.com&quot;)) &#x2F;&#x2F;true</span><br><span class="line">console.log(re_test.test(&quot;adfasd&quot;)) &#x2F;&#x2F;false</span><br><span class="line"></span><br><span class="line">var group_test &#x3D; &#x2F;(\w+)@(\w+)\.\w+&#x2F;</span><br><span class="line">console.log(group_test.exec(&quot;avbd@163.com&quot;)) </span><br><span class="line">&#x2F;&#x2F;[ &#39;avbd@163.com&#39;, &#39;avbd&#39;, &#39;163&#39;, index: 0, input: &#39;avbd@163.com&#39; ]</span><br></pre></td></tr></table></figure><br>另外，在正则结尾后的<code>/</code>处可以加一些参数，比如加g就是启用全局匹配，调用<code>.exec()</code>会像迭代器一样逐个返回匹配到的值。当匹配完所有值后将返回<code>null</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">var global_test &#x3D; &#x2F;\w+&#x2F;g</span><br><span class="line">console.log(global_test.exec(&quot;avbd@163.com&quot;))</span><br><span class="line">&#x2F;&#x2F;[ &#39;avbd&#39;, index: 0, input: &#39;avbd@163.com&#39; ]</span><br><span class="line">console.log(global_test.exec(&quot;avbd@163.com&quot;))</span><br><span class="line">&#x2F;&#x2F;[ &#39;163&#39;, index: 5, input: &#39;avbd@163.com&#39; ]</span><br><span class="line">console.log(global_test.exec(&quot;avbd@163.com&quot;))</span><br><span class="line">&#x2F;&#x2F;[ &#39;com&#39;, index: 9, input: &#39;avbd@163.com&#39; ]</span><br><span class="line">console.log(global_test.exec(&quot;avbd@163.com&quot;))</span><br><span class="line">&#x2F;&#x2F;null</span><br></pre></td></tr></table></figure></p><h3 id="JSON对象"><a href="#JSON对象" class="headerlink" title="JSON对象"></a>JSON对象</h3><p>json是一种超轻量级的数据传递格式，脱胎于JavaScript的对象，将按JSON格式完成的对象序列化成文本便可以在网络中传输，接收到文本后反序列化即可获得原数据<br>序列化使用<code>JSON.stringify()</code>方法，第一个参数为要序列化的object，第二个参数可以是一个列表，描述哪些属性被序列化（默认全部序列化），也可以是一个输入参数为<code>(key,value)</code>的函数，被序列化的内容是<code>key:value+</code>，<code>value+</code>是该函数的返回值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">var json_test &#x3D; &#123;</span><br><span class="line">name:&quot;qian&quot;,</span><br><span class="line">age:20,</span><br><span class="line">skill:&quot;python&quot;</span><br><span class="line">&#125;</span><br><span class="line">json_string &#x3D; JSON.stringify(json_test)</span><br><span class="line">console.log(typeof(json_string),json_string)</span><br><span class="line">&#x2F;&#x2F;string &#123;&quot;name&quot;:&quot;qian&quot;,&quot;age&quot;:20,&quot;skill&quot;:&quot;python&quot;&#125;</span><br><span class="line">console.log(JSON.stringify(json_test,[&quot;name&quot;,&quot;age&quot;]))</span><br><span class="line">&#x2F;&#x2F;&#123;&quot;name&quot;:&quot;qian&quot;,&quot;age&quot;:20&#125;</span><br><span class="line">console.log(JSON.stringify(json_test, function(key,value) &#123;</span><br><span class="line">if (key &#x3D;&#x3D; &quot;age&quot;) &#123;</span><br><span class="line">return value - 1</span><br><span class="line">&#125; else &#123;</span><br><span class="line">return value</span><br><span class="line">&#125;</span><br><span class="line">&#125;)) &#x2F;&#x2F;&#123;&quot;name&quot;:&quot;qian&quot;,&quot;age&quot;:19,&quot;skill&quot;:&quot;python&quot;&#125;</span><br></pre></td></tr></table></figure><br>反序列化使用<code>JSON.parse()</code>方法，输入参数为JSON文本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">json_return &#x3D; JSON.parse(json_string)</span><br><span class="line">console.log(typeof(json_return),json_return)</span><br></pre></td></tr></table></figure></p><h1 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h1><h3 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h3><p>面向对象编程是目前编程语言的潮流，JavaScript的面向对象编程方法基于原型链而与C++和python的class-object方法不同。JavaScript可以通过一个对象创立另一个对象，或者通过构造函数创建变量<br>通过某个对象创建对象时，使用<code>Object.create()</code>方法，传入一个对象可依据传入的对象创建出一个平级的对象（而不是继承的），但是创建出的对象没有任何属性，仅保留了方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">test &#x3D; &#123;</span><br><span class="line">name:&quot;javascript&quot;,</span><br><span class="line">time:0,</span><br><span class="line">use:function ()&#123;</span><br><span class="line">this.time ++</span><br><span class="line">return this.time</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var python &#x3D; Object.create(test)</span><br><span class="line">console.log(python) &#x2F;&#x2F;&#123;&#125;</span><br><span class="line">python.name &#x3D; &quot;python&quot;</span><br><span class="line">python.time &#x3D; 1</span><br><span class="line">console.log(python.use()) &#x2F;&#x2F;2</span><br></pre></td></tr></table></figure><br>另一种可以通过构造函数来创建对象，使用一个内部使用了<code>this</code>的函数并在函数内声明各种属性和方法，使用<code>new function</code>的方法调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">function createobject(name) &#123;</span><br><span class="line">this.name &#x3D; name</span><br><span class="line">this.time &#x3D; 0</span><br><span class="line">this.use &#x3D; function () &#123;</span><br><span class="line">this.time ++</span><br><span class="line">return this.time</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">var golang &#x3D; new createobject(&quot;golang&quot;) </span><br><span class="line">console.log(golang) &#x2F;&#x2F;createobject &#123; name: &#39;golang&#39;, time: 0, use: [Function] &#125;</span><br><span class="line">console.log(golang.use()) &#x2F;&#x2F;1</span><br></pre></td></tr></table></figure></p><h3 id="原型继承"><a href="#原型继承" class="headerlink" title="原型继承"></a>原型继承</h3><p>个人认为JavaScript最有意思的一点就是其原型继承的继承机制，由于JavaScript中没有类，因此继承是由对象到对象的。每个对象都有原型<code>.prototype</code>，该原型可以简单的和<code>class</code>类比，一个对象是由原型创建的，那么将一个对象的原型指向另一个对象就可以说是继承了。<br>但是如果使用直接使用<code>.prototype = objectname</code>的话，在子对象中添加方法的时候方法就会被添加到父对象中从而修改父类，这是不希望看到的，于是可以指定一个空的且与父对象原型相同的对象（父对象平级的空对象，将其<code>prototype</code>指向父对象的<code>prototype</code>），于是这个对象就具备了父对象的所有方法，但是属性仍是空的。<br>为了继承属性，需要在子对象的构造函数里使用<code>parentobject.call(this,...)</code>的方法。<code>call</code>将父对象的构造函数中的所有方法和对象的<code>this</code>改为指向子对象，于是父对象的方法和属性被子对象继承且原型链正确，子对象新的方法被定义在那个空对象中，不会改变父对象。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">function createobject(name) &#123;</span><br><span class="line">this.x &#x3D; name</span><br><span class="line">this.time &#x3D; 0</span><br><span class="line">this.use &#x3D; function () &#123;</span><br><span class="line">this.time ++</span><br><span class="line">return this.time</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">var golang &#x3D; new createobject(&quot;golang&quot;)</span><br><span class="line">console.log(golang) &#x2F;&#x2F;createobject &#123; x: &#39;golang&#39;, time: 0, use: [Function] &#125;</span><br><span class="line"></span><br><span class="line">function inherit(parent,child) &#123;</span><br><span class="line">function F() &#123;</span><br><span class="line">&#125;</span><br><span class="line">F.prototype &#x3D; parent</span><br><span class="line">child.prototype &#x3D; F</span><br><span class="line">child.prototype.constructor &#x3D; child</span><br><span class="line">&#125;</span><br><span class="line">function inherit_test(name) &#123;</span><br><span class="line">createobject.call(this,name)</span><br><span class="line">&#125;</span><br><span class="line">inherit(createobject,inherit_test)</span><br><span class="line">test_object &#x3D; new inherit_test(&quot;a&quot;)</span><br><span class="line">console.log(test_object) &#x2F;&#x2F;inherit_test &#123; x: &#39;a&#39;, time: 0, use: [Function] &#125;</span><br></pre></td></tr></table></figure><br>以上的例子中，<code>F()</code>是空对象的构造方法，函数<code>inherit(parent,child)</code>封装了继承的原型链修改部分，子对象构造函数<code>inherit_test(name)</code>中的<code>createobject.call(this,name)</code>则拉取了父对象的所有方法和属性</p><h3 id="类继承"><a href="#类继承" class="headerlink" title="类继承"></a>类继承</h3><p>没有类这一概念可以说是JavaScript的缺点，因为原型继承大大复杂了继承的实现成本，对对象本身的操作却没有数量级的提升，于是在新的JavaScript语法中，<code>class</code>被引进<br>类的声明使用<code>class 类名 &#123;方法&#125;</code>，有一个特殊的方法叫<code>constructor()</code>，这是类的构造函数，和Python的<code>__init__</code>类似，属性可以在该方法中使用<code>this.属性名 = 值</code>声明。调用类生成对象时与使用构造函数生成类一样，使用<code>var var_name = new class_name</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class TestClass &#123;</span><br><span class="line">constructor(name) &#123;</span><br><span class="line">this.name &#x3D; name</span><br><span class="line">this.usetime &#x3D; 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">useonetime() &#123;</span><br><span class="line">this.usetime ++</span><br><span class="line">console.log(this.usetime)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">var a &#x3D; new TestClass(&quot;javascript&quot;)</span><br><span class="line">console.log(a) &#x2F;&#x2F;TestClass &#123; name: &#39;javascript&#39;, usetime: 0 &#125;</span><br><span class="line">a.useonetime() &#x2F;&#x2F;1</span><br></pre></td></tr></table></figure><br>类的引入方便了继承的实现，在class中实现继承只需要两个操作</p><ul><li>在声明类时使用<code>class 类名 extends 父类名 &#123;&#125;</code>即可</li><li>在构造函数中使用<code>super()</code>调用父类的构造函数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class TestIherit extends TestClass &#123;</span><br><span class="line">constructor(name,data) &#123;</span><br><span class="line">super(name)</span><br><span class="line">this.data &#x3D; data</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">reportdata () &#123;</span><br><span class="line">console.log(this.data)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">var b &#x3D; new TestIherit(&quot;python&quot;,10)</span><br><span class="line">console.log(b)</span><br><span class="line">&#x2F;&#x2F;TestIherit &#123; name: &#39;python&#39;, usetime: 0, data: 10 &#125;</span><br><span class="line">b.useonetime() &#x2F;&#x2F;1</span><br><span class="line">b.reportdata() &#x2F;&#x2F;10</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> JavaScript学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript入门笔记5</title>
      <link href="2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B05/"/>
      <url>2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B05/</url>
      
        <content type="html"><![CDATA[<h1 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h1><blockquote><p>函数就是最基本的一种代码抽象的方式</p><h3 id="函数的声明与调用"><a href="#函数的声明与调用" class="headerlink" title="函数的声明与调用"></a>函数的声明与调用</h3><p>JavaScript中声明函数的方法有两种</p><ul><li>声明一个有名称的函数，使用类似C语言的<code>function name(arguments) &#123;&#125;</code></li><li>声明一个匿名函数，再将该函数赋值给一个变量，使用<code>var i = function (arguments) &#123;&#125;;</code><br>函数的调用方法与C和Python都很相似，使用<code>name(arguments)</code>的方式调用<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">function add(a,b) &#123;</span><br><span class="line">return a + b</span><br><span class="line">&#125;</span><br><span class="line">console.log(add(4,8)) &#x2F;&#x2F;12</span><br><span class="line"></span><br><span class="line">var add &#x3D; function(a,b) &#123;</span><br><span class="line">return a + b</span><br><span class="line">&#125;</span><br><span class="line">console.log(add(4,9)) &#x2F;&#x2F;13</span><br></pre></td></tr></table></figure><h3 id="函数的参数"><a href="#函数的参数" class="headerlink" title="函数的参数"></a>函数的参数</h3>JavaScript中的参数传递方式很灵活，可以使用<code>arguments</code>和<code>rest</code>关键字获取动态数量的参数</li><li><code>arguments</code>关键字指向所有<strong>传入的参数</strong>，<code>arguments</code>是一个对象，不能使用<code>for of</code>循环，且<code>arguments</code>的每个元素都是<code>string</code>类型<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">function sum(a) &#123;</span><br><span class="line">var s &#x3D; 0</span><br><span class="line">for (var i in arguments) &#123;</span><br><span class="line">s +&#x3D; i</span><br><span class="line">console.log(typeof(i))</span><br><span class="line">&#125;</span><br><span class="line">return s</span><br><span class="line">&#125;</span><br><span class="line">data &#x3D; sum(1,2,3,4)</span><br><span class="line">console.log(data)</span><br><span class="line">&#x2F;*</span><br><span class="line">string</span><br><span class="line">string</span><br><span class="line">string</span><br><span class="line">string</span><br><span class="line">00123</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure></li><li><code>rest</code>关键字指向<strong>剩余的参数</strong>，在已经申明的参数后添加<code>...rest</code>，在函数中可已使用<code>rest</code>参数获取被声明参数以外的参数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">function test_rest(a,b,...rest) &#123;</span><br><span class="line">console.log(&quot;a &#x3D;&quot;,a)</span><br><span class="line">console.log(&quot;b &#x3D;&quot;,b)</span><br><span class="line">console.log(rest)</span><br><span class="line">&#125;</span><br><span class="line">test_rest(1,2,3,4,5)</span><br><span class="line">&#x2F;*</span><br><span class="line">a &#x3D; 1</span><br><span class="line">b &#x3D; 2</span><br><span class="line">[ 3, 4, 5 ]</span><br><span class="line"> *&#x2F;</span><br><span class="line">test_rest()</span><br><span class="line">&#x2F;*</span><br><span class="line">a &#x3D; undefined</span><br><span class="line">b &#x3D; undefined</span><br><span class="line">[]</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure><h3 id="函数与变量作用域"><a href="#函数与变量作用域" class="headerlink" title="函数与变量作用域"></a>函数与变量作用域</h3>函数内的变量作用域是函数的<code>&#123;&#125;</code>内，但在使用其他的带<code>&#123;&#125;</code>的语句中的<code>var</code>声明的变量作用域并不是在<code>&#123;&#125;</code>内而是函数内，使用<code>let</code>可声明语法块级<code>&#123;&#125;</code>作用域的变量。同时，<code>const</code>声明的常量作用也是语法块级的<code>&#123;&#125;</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">function print_list(a) &#123;</span><br><span class="line">for (var i in a)&#123; &#x2F;&#x2F;变量声明在for循环内，但是由于使用var声明，作用域为函数print_list</span><br><span class="line">var c &#x3D; i</span><br><span class="line">console.log(i)</span><br><span class="line">&#x2F;*</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line"> *&#x2F;</span><br><span class="line">&#125;</span><br><span class="line">console.log(i) &#x2F;&#x2F;3</span><br><span class="line">console.log(c) &#x2F;&#x2F;3</span><br><span class="line">&#125;</span><br><span class="line">print_list([1,2,3,4])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">function print_list2(a) &#123;</span><br><span class="line">for (let i in a)&#123; &#x2F;&#x2F;使用let声明的变量作用域为当前的for循环</span><br><span class="line">var c &#x3D; i</span><br><span class="line">console.log(i)</span><br><span class="line">&#x2F;*</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line"> *&#x2F;</span><br><span class="line">&#125;</span><br><span class="line">console.log(c) &#x2F;&#x2F;3</span><br><span class="line">console.log(i) &#x2F;&#x2F;ReferenceError: i is not defined</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F; print_list2([1,2,3,4])</span><br><span class="line"></span><br><span class="line">function print_list3(a) &#123;</span><br><span class="line">for (let i of a) &#123;</span><br><span class="line">const c &#x3D; 0 &#x2F;&#x2F;const声明的常量作用域为当前for循环</span><br><span class="line">console.log(i)</span><br><span class="line">&#x2F;*</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line"> *&#x2F;</span><br><span class="line">&#125;</span><br><span class="line">console.log(c) &#x2F;&#x2F;ReferenceError: c is not defined</span><br><span class="line">&#125;</span><br><span class="line">print_list3([1,2])</span><br></pre></td></tr></table></figure>函数中搜索变量的方式是先从当前作用域中搜索，若未找到，则向更高层的作用域搜索，因此，当函数内的变量名和全局变量冲突时，优先使用局部变量。全局变量绑定在<code>window</code>上，可以使用<code>window.变量名</code>直接访问。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data &#x3D; 10</span><br><span class="line">function test_window() &#123;</span><br><span class="line">var data &#x3D; 5</span><br><span class="line">console.log(data) &#x2F;&#x2F;5</span><br><span class="line">&#125;</span><br><span class="line">test_window()</span><br></pre></td></tr></table></figure>另外，JavaScript还用变量定义前提的机制<br>JavaScript的函数定义有个特点，它会先扫描整个函数体的语句，把所有申明的变量“提升”到函数顶部，由于JavaScript的这一怪异的“特性”，我们在函数内部定义变量时，请严格遵守“在函数内部首先申明所有变量”这一规则。最常见的做法是用一个<code>var</code>申明函数内部用到的所有变量</li></ul></blockquote><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>被绑定在对象里的函数称为方法，在该函数中可以使用<code>this</code>关键字访问本对象的属性和方法，调用的使用使用<code>对象名.方法名()</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">var test &#x3D; &#123;</span><br><span class="line">name:&quot;a&quot;,</span><br><span class="line">age:10,</span><br><span class="line">count:0,</span><br><span class="line">ageadd:function () &#123;</span><br><span class="line">this.age +&#x3D; 1</span><br><span class="line">return this.age</span><br><span class="line">&#125;,</span><br><span class="line">changename:function (new_name) &#123;</span><br><span class="line">this.name +&#x3D; new_name</span><br><span class="line">return this.name</span><br><span class="line">&#125;,</span><br><span class="line">test_d:function () &#123;</span><br><span class="line">this.count +&#x3D; 1</span><br><span class="line">return this.ageadd.apply(test)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">console.log(test.name,test.age) &#x2F;&#x2F;a 10</span><br><span class="line">test.ageadd()</span><br><span class="line">console.log(test.name,test.age) &#x2F;&#x2F;a 11</span><br></pre></td></tr></table></figure><br>需要说明的<code>this</code>关键字，该关键字仅在使用<code>对象名.方法名()</code>的方式调用的时候是指向该对象的，若不是使用这种方法调用，可以使用<code>.apply(object,[arguments])</code>或<code>.call(object,arguments)</code>的方式使<code>this</code>指向对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func_test &#x3D; test.ageadd</span><br><span class="line">console.log(func_test()) &#x2F;&#x2F;NaN</span><br><span class="line">console.log(func_test.apply(test)) &#x2F;&#x2F;12</span><br><span class="line"></span><br><span class="line">changename_test &#x3D; test.changename</span><br><span class="line">console.log(changename_test(&quot;x&quot;)) &#x2F;&#x2F;undefinedx</span><br><span class="line">console.log(changename_test.apply(test,[&quot;x&quot;])) &#x2F;&#x2F;ax</span><br><span class="line">console.log(changename_test.call(test,&quot;x&quot;)) &#x2F;&#x2F;axx</span><br></pre></td></tr></table></figure></p><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>装饰器是一种动态修改函数功能的方法，该函数中的<code>test_d()</code>函数就是一个装饰器，动态修改了<code>ageadd()</code>功能，增加了计数的功能<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">var test &#x3D; &#123;</span><br><span class="line">name:&quot;a&quot;,</span><br><span class="line">age:10,</span><br><span class="line">count:0,</span><br><span class="line">ageadd:function () &#123;</span><br><span class="line">this.age +&#x3D; 1</span><br><span class="line">return this.age</span><br><span class="line">&#125;,</span><br><span class="line">changename:function (new_name) &#123;</span><br><span class="line">this.name +&#x3D; new_name</span><br><span class="line">return this.name</span><br><span class="line">&#125;,</span><br><span class="line">test_d:function () &#123;</span><br><span class="line">this.count +&#x3D; 1</span><br><span class="line">return this.ageadd.apply(test)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">console.log(test.count,test.age) &#x2F;&#x2F;0 12</span><br><span class="line">c &#x3D; test.test_d()</span><br><span class="line">console.log(test.count,test.age) &#x2F;&#x2F;1 13</span><br></pre></td></tr></table></figure></p><h3 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h3><p>高阶函数就是传入函数作为参数的函数，类似于C语言中传入函数指针。如以下的例子<code>test_adfunc()</code>，就是传入了一个平方的函数作为参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">function test_adfunc(f,...rest) &#123;</span><br><span class="line">for (let i in rest) &#123;</span><br><span class="line">console.log(f(i))</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">test_adfunc(function (x) &#123;</span><br><span class="line">return x * x</span><br><span class="line">&#125;,1,2,3,4)</span><br><span class="line">&#x2F;*</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">4</span><br><span class="line">9</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure><br>常见的高阶函数包括：</p><ul><li><code>map()</code>函数：将一个列表（也可能是其他数据结构）中的所有属性使用传入的函数处理并返回处理完后的列表，原列表不变<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var test_list &#x3D; [1,2,3,4,5]</span><br><span class="line">console.log(test_list.map(function (x)&#123;</span><br><span class="line">return x * 2</span><br><span class="line">&#125;)) &#x2F;&#x2F;[ 2, 4, 6, 8, 10 ]</span><br><span class="line">console.log(test_list) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br></pre></td></tr></table></figure></li><li><code>reduce()</code>函数：用于迭代处理，输入有两个值，分别是上一次该函数运行的结果和本次输入的属性，同样原列表不变<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_list) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br><span class="line">console.log(test_list.reduce(function (x,y) &#123;</span><br><span class="line">return x + y</span><br><span class="line">&#125;)) &#x2F;&#x2F;15</span><br><span class="line">console.log(test_list) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br></pre></td></tr></table></figure></li><li><code>filter()</code>函数：用于筛选，返回值为<code>True</code>时保留，返回<code>False</code>时删除，同样不改变原列表<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_list) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br><span class="line">console.log(test_list.filter(function (x) &#123;</span><br><span class="line">return x % 2 &#x3D;&#x3D; 0</span><br><span class="line">&#125;)) &#x2F;&#x2F;[ 2, 4 ]</span><br><span class="line">console.log(test_list) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br></pre></td></tr></table></figure></li><li><code>sort()</code>函数：用于排序，默认都转换为<code>string</code>后按ASCII码排序，可传入一个函数说明大小关系<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_list) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br><span class="line">console.log(test_list.sort(function (x,y) &#123;</span><br><span class="line">if(x &gt; y) &#123;</span><br><span class="line">return -1</span><br><span class="line">&#125; else &#123;</span><br><span class="line">return 1</span><br><span class="line">&#125;</span><br><span class="line">&#125;)) &#x2F;&#x2F;[ 5, 4, 3, 2, 1 ]</span><br><span class="line">console.log(test_list) &#x2F;&#x2F;[ 5, 4, 3, 2, 1 ]</span><br></pre></td></tr></table></figure><h3 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h3>闭包对我个人来说是一个全新的概念，在学习Python的时候就放弃了这一部分的学习。闭包通俗的来说就是在函数内定义的函数可以访问到外面那个函数里的变量，个人感觉主要作用是基于一个模板（内部函数）定值函数和封装私有变量。闭包的使用很简单，就是在定义函数内的函数的时候直接使用外部函数的变量即可<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">function counte(start) &#123;</span><br><span class="line">init &#x3D; start</span><br><span class="line">return function () &#123;</span><br><span class="line">init ++</span><br><span class="line">return init</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">a &#x3D; counte(10)</span><br><span class="line">console.log(a()) &#x2F;&#x2F;11</span><br><span class="line">console.log(a()) &#x2F;&#x2F;12</span><br><span class="line">console.log(a()) &#x2F;&#x2F;13</span><br></pre></td></tr></table></figure>这个例子中的<code>init</code>变量就类似于一个类的私有变量一样，不能由外部操作，仅能通过返回的函数操作。<br>需要注意的时候，使用闭包的时候要避免使用循环的变量（值自己发生变化的变量），否则可能发生一些奇怪的事情<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">function test_closure2() &#123;</span><br><span class="line">    var arr &#x3D; [];</span><br><span class="line">    for (var i&#x3D;1; i&lt;&#x3D;3; i++) &#123;</span><br><span class="line">        arr.push(function () &#123;</span><br><span class="line">            return i * i;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    return arr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var results &#x3D; test_closure2();</span><br><span class="line">console.log(results[0]()); &#x2F;&#x2F; 16</span><br><span class="line">console.log(results[1]()); &#x2F;&#x2F; 16</span><br><span class="line">console.log(results[2]()); &#x2F;&#x2F; 16</span><br></pre></td></tr></table></figure>这个例子调用了循环变量，产生这种结果的原因是在<code>var results = test_closure2();</code>中函数已经被完全执行，在后面调用的时候<code>i</code>已经为<code>4</code>了，要解决这个问题，第一种方法是再声明一个立即执行且输入<code>i</code>为参数的函数，返回一个函数，被返回的函数调用的是立即执行的函数的变量，<code>(function ()) ()</code>的语法可以声明一个立即执行的匿名函数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">function test_closure3() &#123;</span><br><span class="line">var arr &#x3D; []</span><br><span class="line">for (var i &#x3D; 1; i &lt;&#x3D; 3; i++) &#123;</span><br><span class="line">arr.push((function (n) &#123;</span><br><span class="line">return function () &#123;</span><br><span class="line">return n * n</span><br><span class="line">&#125;</span><br><span class="line">&#125;)(i))</span><br><span class="line">&#125;</span><br><span class="line">return arr</span><br><span class="line">&#125;</span><br><span class="line">results &#x3D; test_closure3()</span><br><span class="line">console.log(results[0]()) &#x2F;&#x2F;1</span><br><span class="line">console.log(results[1]()) &#x2F;&#x2F;4</span><br><span class="line">console.log(results[2]()) &#x2F;&#x2F;9</span><br></pre></td></tr></table></figure>第二种方法比较奇怪，将<code>var i</code>改为<code>let i</code>即可，原因不明<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">function test_closure(start) &#123;</span><br><span class="line">var arr &#x3D; []</span><br><span class="line">for(let i &#x3D; start;i &lt; start + 3;i++) &#123;</span><br><span class="line">arr.push(function () &#123;</span><br><span class="line">return i * i</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br><span class="line">return arr</span><br><span class="line">&#125;</span><br><span class="line">var b &#x3D; test_closure(2)</span><br><span class="line">console.log(b[0]()) &#x2F;&#x2F;4</span><br><span class="line">console.log(b[1]()) &#x2F;&#x2F;9</span><br><span class="line">console.log(b[2]()) &#x2F;&#x2F;16</span><br></pre></td></tr></table></figure><h3 id="箭头函数"><a href="#箭头函数" class="headerlink" title="箭头函数"></a>箭头函数</h3>箭头函数是一种特殊的匿名函数，相对于普通的匿名函数最大的优势在于修复了<code>this</code>指针乱飞的问题，调用箭头函数的时候<code>this</code>指向调用它的对象<br>只有一句的箭头函数可用<code>(arguments) =&gt; (func)</code>定义，不需要<code>&#123;&#125;</code>和<code>return</code>，若是多语句的箭头函数，需要使用<code>(arguments) =&gt; &#123;&#125;</code>定义，最后需要<code>return</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">var test_arrow &#x3D; (x) &#x3D;&gt; (x*x)</span><br><span class="line">console.log(test_arrow(6)) &#x2F;&#x2F;36</span><br><span class="line"></span><br><span class="line">var test_arrow2 &#x3D; (x) &#x3D;&gt; &#123;</span><br><span class="line">if(x &#x3D;&#x3D; 0) &#123;</span><br><span class="line">return true</span><br><span class="line">&#125; else &#123;</span><br><span class="line">return false</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">console.log(test_arrow2(2)) &#x2F;&#x2F;false</span><br></pre></td></tr></table></figure>同时，多输入函数也可以使用箭头函数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">var test_arrow3 &#x3D; (x,y) &#x3D;&gt; &#123;</span><br><span class="line">console.log(&quot;x &#x3D;&quot;,x)</span><br><span class="line">console.log(&quot;y &#x3D;&quot;,y)</span><br><span class="line">&#125;</span><br><span class="line">test_arrow3(2,3)</span><br><span class="line">&#x2F;*</span><br><span class="line">x &#x3D; 2</span><br><span class="line">y &#x3D; 3</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure>箭头函数修复了<code>this</code>的问题<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">test_noarrow_ob &#x3D; &#123;</span><br><span class="line">data:10,</span><br><span class="line">handle:function() &#123;</span><br><span class="line">y &#x3D; function () &#123;</span><br><span class="line">this.data ++</span><br><span class="line">return this.data</span><br><span class="line">&#125;</span><br><span class="line">return y</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">console.log(test_noarrow_ob.handle()()) &#x2F;&#x2F;NaN</span><br><span class="line"></span><br><span class="line">test_arrow_ob &#x3D; &#123;</span><br><span class="line">data:10,</span><br><span class="line">handle:function() &#123;</span><br><span class="line">y &#x3D; () &#x3D;&gt; &#123;</span><br><span class="line">this.data ++</span><br><span class="line">return this.data</span><br><span class="line">&#125;</span><br><span class="line">return y</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">console.log(test_arrow_ob.handle()()) &#x2F;&#x2F;11</span><br></pre></td></tr></table></figure><h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3>这里的生成器与Python中的生成器完全相同，使用<code>function* ()</code>声明函数，使用<code>yield</code>返回值并继续迭代，使用<code>return</code>返回值并停止迭代<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">function* test_gen(a) &#123;</span><br><span class="line">for(let i &#x3D; 0; i &lt; a; i++)&#123;</span><br><span class="line">yield i</span><br><span class="line">&#125;</span><br><span class="line">return a &#x2F;&#x2F;to generate done:true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>使用生成器时，不建议的方法是使用<code>.next()</code>方法，该方法返回一个Object，分别是值和是否继续迭代<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; test_gen(3)</span><br><span class="line">console.log(typeof(x)) &#x2F;&#x2F;object</span><br><span class="line">console.log(x.next())  &#x2F;&#x2F;&#123; value: 0, done: false &#125;</span><br><span class="line">console.log(x.next())  &#x2F;&#x2F;&#123; value: 1, done: false &#125;</span><br><span class="line">console.log(x.next())  &#x2F;&#x2F;&#123; value: 2, done: false &#125;</span><br><span class="line">console.log(x.next())  &#x2F;&#x2F;&#123; value: 3, done: true &#125;</span><br></pre></td></tr></table></figure>另一种方法是建议的，使用<code>for of</code>循环直接迭代，与python中的<code>for</code>相同<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for (let i of test_gen(3)) &#123;</span><br><span class="line">console.log(i)</span><br><span class="line">&#x2F;*</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line"> *&#x2F;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> JavaScript学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript入门笔记4</title>
      <link href="2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B04/"/>
      <url>2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B04/</url>
      
        <content type="html"><![CDATA[<h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><h3 id="Map的定义"><a href="#Map的定义" class="headerlink" title="Map的定义"></a>Map的定义</h3><blockquote><p>Map是一组键值对的结构，具有极快的查找速度。</p></blockquote><p>Map是JavaScript中更像字典的一种数据结构，使用<code>new Map()</code>定义，可选的在定义中传入使用二维数组存储的键值对，即<code>new Map([...,[key,value],...])</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">var black_map &#x3D; new Map()</span><br><span class="line">console.log(black_map) &#x2F;&#x2F;Map &#123;&#125;</span><br><span class="line">var test_map &#x3D; new Map([[&quot;javascript&quot;,0],[&quot;python&quot;,1],[&quot;verilog&quot;,3]])</span><br><span class="line">console.log(test_map) &#x2F;&#x2F;Map &#123; &#39;javascript&#39; &#x3D;&gt; 0, &#39;python&#39; &#x3D;&gt; 1, &#39;verilog&#39; &#x3D;&gt; 3 &#125;</span><br></pre></td></tr></table></figure></p><h3 id="Map的访问"><a href="#Map的访问" class="headerlink" title="Map的访问"></a>Map的访问</h3><ul><li>使用<code>Map.has(key)</code>可以确定当前Map中是否有键为<code>key</code>的键值对，若有返回<code>true</code>，否则返回<code>false</code></li><li>使用<code>Map.get(key)</code>可以获得键为<code>key</code>的值，若无该键返回<code>undefined</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_map) &#x2F;&#x2F;Map &#123; &#39;javascript&#39; &#x3D;&gt; 0, &#39;python&#39; &#x3D;&gt; 1, &#39;verilog&#39; &#x3D;&gt; 3 &#125;</span><br><span class="line">console.log(test_map.has(&quot;python&quot;)) &#x2F;&#x2F;true</span><br><span class="line">console.log(test_map.get(&quot;python&quot;)) &#x2F;&#x2F;1</span><br><span class="line">console.log(test_map.has(&quot;java&quot;)) &#x2F;&#x2F;false</span><br><span class="line">console.log(test_map.get(&quot;java&quot;)) &#x2F;&#x2F;undefined</span><br></pre></td></tr></table></figure><h3 id="Map的修改"><a href="#Map的修改" class="headerlink" title="Map的修改"></a>Map的修改</h3></li><li>使用<code>Map.set(key,value)</code>的方法可以在Map中添加<code>key:value</code>键值对</li><li>使用<code>Map.delete(key)</code>的方法可以在Map中删除键为<code>key</code>的键值对<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_map) &#x2F;&#x2F;Map &#123; &#39;javascript&#39; &#x3D;&gt; 0, &#39;python&#39; &#x3D;&gt; 1, &#39;verilog&#39; &#x3D;&gt; 3 &#125;</span><br><span class="line">test_map.set(&quot;java&quot;,0)</span><br><span class="line">console.log(test_map) &#x2F;&#x2F;Map &#123; &#39;javascript&#39; &#x3D;&gt; 0, &#39;python&#39; &#x3D;&gt; 1, &#39;verilog&#39; &#x3D;&gt; 3, &#39;java&#39; &#x3D;&gt; 0 &#125;</span><br><span class="line">test_map.delete(&quot;java&quot;)</span><br><span class="line">console.log(test_map) &#x2F;&#x2F;Map &#123; &#39;javascript&#39; &#x3D;&gt; 0, &#39;python&#39; &#x3D;&gt; 1, &#39;verilog&#39; &#x3D;&gt; 3 &#125;</span><br></pre></td></tr></table></figure><h1 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h1><h3 id="Set的创建"><a href="#Set的创建" class="headerlink" title="Set的创建"></a>Set的创建</h3>set是一种类似于集合的数据结构，每个值不可重复，也可以视为没有value的Map，创建Set使用<code>new Set()</code>创建空Set或<code>new Set([key1,key2,...])</code>基于list创建Set<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">var black_set &#x3D; new Set()</span><br><span class="line">console.log(black_set) &#x2F;&#x2F;Set &#123;&#125;</span><br><span class="line">var test_set &#x3D; new Set([&quot;java&quot;, &quot;verilog&quot;, &quot;python&quot;])</span><br><span class="line">console.log(test_set)  &#x2F;&#x2F;Set &#123; &#39;java&#39;, &#39;verilog&#39;, &#39;python&#39; &#125;</span><br></pre></td></tr></table></figure><h3 id="Set的操作"><a href="#Set的操作" class="headerlink" title="Set的操作"></a>Set的操作</h3></li><li><code>Set.has(key)</code>方法可以判断是否存在<code>key</code>，存在返回<code>true</code>，不存在返回<code>false</code></li><li><code>Set.add(key)</code>方法可以添加<code>key</code>键，重复添加无效果且不报错</li><li><code>Set.delete(key)</code>方法删除<code>key</code>键，若<code>key</code>不存在，无效果，不报错<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_set)  &#x2F;&#x2F;Set &#123; &#39;java&#39;, &#39;verilog&#39;, &#39;python&#39; &#125;</span><br><span class="line">console.log(test_set.has(&quot;java&quot;)) &#x2F;&#x2F;true</span><br><span class="line">console.log(test_set.has(&quot;perl&quot;)) &#x2F;&#x2F;false</span><br><span class="line">test_set.add(&quot;perl&quot;)</span><br><span class="line">console.log(test_set) &#x2F;&#x2F;Set &#123; &#39;java&#39;, &#39;verilog&#39;, &#39;python&#39;, &#39;perl&#39; &#125;</span><br><span class="line">test_set.delete(&quot;perl&quot;)</span><br><span class="line">console.log(test_set) &#x2F;&#x2F;Set &#123; &#39;java&#39;, &#39;verilog&#39;, &#39;python&#39; &#125;</span><br></pre></td></tr></table></figure><h1 id="Iterable"><a href="#Iterable" class="headerlink" title="Iterable"></a>Iterable</h1><h3 id="iterable概述"><a href="#iterable概述" class="headerlink" title="iterable概述"></a>iterable概述</h3>iterable是JavaScript中新增的一种语法，使用Python的方式去理解就是迭代器。<code>Array</code>，<code>Map</code>和<code>Set</code>均属于iterable，对象不属于iterable。<br>iterable可以使用<code>for of</code>循环遍历所有的值，<code>for of</code>和<code>for in</code>的区别在于<code>for of</code>遍历的集合本身，而<code>for in</code>遍历的是一个对象的所有属性。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">var a &#x3D; [1,2,3,4]</span><br><span class="line">a.name &#x3D; &quot;test&quot;</span><br><span class="line"></span><br><span class="line">for (var i in a) &#123;</span><br><span class="line">console.log(i)</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">name</span><br><span class="line"> *&#x2F;</span><br><span class="line"></span><br><span class="line">for (var i of a) &#123;</span><br><span class="line">console.log(i)</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure><h3 id="Map和Set"><a href="#Map和Set" class="headerlink" title="Map和Set"></a>Map和Set</h3>对于<code>Map</code>和<code>Set</code>，<code>for of</code>循环的分别是<code>[key,value]</code>和<code>key</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">var b &#x3D; new Map([[&quot;a&quot;,0],[&quot;b&quot;,1],[&quot;c&quot;,2]])</span><br><span class="line">for (var i of b) &#123;</span><br><span class="line">console.log(i)</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line">[ &#39;a&#39;, 0 ]</span><br><span class="line">[ &#39;b&#39;, 1 ]</span><br><span class="line">[ &#39;c&#39;, 2 ]</span><br><span class="line"> *&#x2F;</span><br><span class="line"></span><br><span class="line">var c &#x3D; new Set([&quot;a&quot;,&quot;b&quot;,&quot;c&quot;])</span><br><span class="line">for (var i of c) &#123;</span><br><span class="line">console.log(i)</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line">c</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure><h3 id="forEach方法"><a href="#forEach方法" class="headerlink" title="forEach方法"></a>forEach方法</h3><code>forEach()</code>是iterable的一种方法，是一个高阶函数，传入一个函数，迭代的执行传入函数的操作，即对每个元素进行传入函数的操作<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a.forEach(function (element, index, array) &#123;</span><br><span class="line">console.log(element,index,array)</span><br><span class="line">&#125;)</span><br><span class="line">&#x2F;*</span><br><span class="line">1 0 [ 1, 2, 3, 4, name: &#39;test&#39; ]</span><br><span class="line">2 1 [ 1, 2, 3, 4, name: &#39;test&#39; ]</span><br><span class="line">3 2 [ 1, 2, 3, 4, name: &#39;test&#39; ]</span><br><span class="line">4 3 [ 1, 2, 3, 4, name: &#39;test&#39; ]</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> JavaScript学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript入门笔记3</title>
      <link href="2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B03/"/>
      <url>2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B03/</url>
      
        <content type="html"><![CDATA[<h1 id="条件控制语句"><a href="#条件控制语句" class="headerlink" title="条件控制语句"></a>条件控制语句</h1><p>条件控制使用<code>if...else if...else</code>语句控制，该语句的使用与C语言几乎完全相同<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">var i &#x3D; 10;</span><br><span class="line">if (i &lt; 11) &#123;</span><br><span class="line">console.log(&quot;python&quot;);</span><br><span class="line">&#125; else if(i &gt; 13)&#123;</span><br><span class="line">console.log(&quot;C++&quot;);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">console.log(&quot;javascript&quot;);</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;python</span><br></pre></td></tr></table></figure><br>当然，<code>else if</code>和<code>else</code>都不是必须的</p><h1 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h1><h3 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h3><p>JavaScript的for循环也与C语言的循环很像（用法几乎相同）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sum &#x3D; 0;</span><br><span class="line">for(var i &#x3D; 0;i &lt; 10; i++) &#123;</span><br><span class="line">sum &#x3D; sum + i;</span><br><span class="line">&#125;</span><br><span class="line">console.log(sum) &#x2F;&#x2F;45</span><br></pre></td></tr></table></figure></p><h3 id="for-in循环"><a href="#for-in循环" class="headerlink" title="for in循环"></a>for in循环</h3><p><code>for in</code> 循环是for循环的一种变种，可以将一个对象或者数组的所有值循环出来，与Python的for循环相似，需要注意的是，<code>for in</code>循环的结果是被循环的数据类型的<code>key</code>而不是<code>value</code>，对于list来说就是索引值而不是存储的值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">test_ob &#x3D; &#123;</span><br><span class="line">name:&quot;go&quot;,</span><br><span class="line">age:10,</span><br><span class="line">data:12</span><br><span class="line">&#125;</span><br><span class="line">for (var i in test_ob) &#123;</span><br><span class="line">console.log(i,test_ob[i])</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line">name go</span><br><span class="line">age 10</span><br><span class="line">data 12</span><br><span class="line"> *&#x2F;</span><br><span class="line">test_list &#x3D; [1,2,3,4]</span><br><span class="line">for (var i in test_list) &#123;</span><br><span class="line">console.log(i)</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure></p><h3 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h3><p><code>while</code>循环与C语言while循环很像，为一种条件循环语句，当条件满足的时候循环，否则跳出继续执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">var a &#x3D; 5</span><br><span class="line">while (a &gt;&#x3D; 2) &#123;</span><br><span class="line">console.log(a)</span><br><span class="line">a --</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line">5</span><br><span class="line">4</span><br><span class="line">3</span><br><span class="line">2</span><br><span class="line"> *&#x2F;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> JavaScript学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript入门笔记2</title>
      <link href="2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B02/"/>
      <url>2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B02/</url>
      
        <content type="html"><![CDATA[<h1 id="字符串相关"><a href="#字符串相关" class="headerlink" title="字符串相关"></a>字符串相关</h1><h3 id="字符串基础"><a href="#字符串基础" class="headerlink" title="字符串基础"></a>字符串基础</h3><p>字符串历来是各种编程语言坑最多的地方（个人认为），不同软件语言在字符串上的操作的差别比软件语言和硬件描述语言的差距都大（一样是个人认为）<br>JavaScript的字符串在描述上与Python类似，使用<code>&quot;&quot;</code>和<code>&#39;&#39;</code>标识，多行字符串使用<code>`` </code>标识，同样，字符串是<strong>不可变对象</strong>，即一旦确定就不可改变</p><h3 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h3><p>需要强调的是，字符串操作均是返回一个新的字符串，原字符串并不会改变</p><ul><li>获取指定位置字符：使用数组下标的方式获得</li><li>大小写转换：全部变为大写使用<code>toUpperCase()</code>，全部使用小写使用<code>toLowerCase()</code></li><li>查找子串位置：<code>indexOf()</code>返回子串的开头位置，没有查找到返回-1</li><li>返回指定子串：<code>substring()</code>传入子串开头结尾的位置返回子串<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">var test_string &#x3D; &quot;hello JavaScript&quot;</span><br><span class="line">console.log(test_string)</span><br><span class="line">console.log(test_string[6])</span><br><span class="line">&#x2F;&#x2F; J</span><br><span class="line"></span><br><span class="line">test_string[2] &#x3D; &quot;x&quot;</span><br><span class="line">console.log(test_string)</span><br><span class="line">&#x2F;&#x2F; hello JavaScript</span><br><span class="line"></span><br><span class="line">console.log(test_string.toUpperCase())</span><br><span class="line">&#x2F;&#x2F; HELLO JAVASCRIPT</span><br><span class="line">console.log(test_string.toLowerCase())</span><br><span class="line">&#x2F;&#x2F; hello javascript</span><br><span class="line">console.log(test_string.substring(2,7))</span><br><span class="line">&#x2F;&#x2F; llo J</span><br><span class="line">console.log(test_string.indexOf(&quot;Script&quot;))</span><br><span class="line">&#x2F;&#x2F; 10</span><br></pre></td></tr></table></figure><h3 id="“模板字符串”"><a href="#“模板字符串”" class="headerlink" title="“模板字符串”"></a>“模板字符串”</h3></li><li>使用<code>+</code>可以将多个变量或字符串连接</li><li><code>$&#123;&#125;</code>可以在字符串中直接显示变量，使用这种方法的字符串需要使用<code>`` </code>包裹<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var test_string2 &#x3D; &quot;hi&quot;;</span><br><span class="line">var test_string3 &#x3D; &quot;nice to meet you&quot;</span><br><span class="line">console.log(test_string + test_string2 + test_string3)</span><br><span class="line">&#x2F;&#x2F; hello JavaScripthinice to meet you</span><br><span class="line">console.log(&#96;$&#123;test_string&#125;,$&#123;test_string2&#125;,$&#123;test_string3&#125;&#96;)</span><br><span class="line">&#x2F;&#x2F; hello JavaScript,hi,nice to meet you</span><br></pre></td></tr></table></figure><h1 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h1><h3 id="列表基础"><a href="#列表基础" class="headerlink" title="列表基础"></a>列表基础</h3>JavaScript的列表与Python的列表相似，应该大部分动态语言的列表都是这个样子：索引自由，切片自由，不绑定数据类型。与Python不同的是JavaScript列表更加“自由”：</li><li>可以直接修改列表的length属性修改列表长度，不足位用undefined补齐<blockquote><p>大多数其他编程语言不允许直接改变数组的大小，越界访问索引会报错。然而，JavaScript的Array却不会有任何错误。在编写代码时，不建议直接修改Array的大小，访问索引时要确保索引不会越界。</p></blockquote></li><li>赋值超出列表长度修改列表长度，不足位用<code>empty items</code>补齐<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">var testlist &#x3D; [1,2,&quot;d&quot;]</span><br><span class="line">console.log(testlist)</span><br><span class="line">&#x2F;&#x2F; [ 1, 2, &#39;d&#39; ]</span><br><span class="line">console.log(testlist.length)</span><br><span class="line">&#x2F;&#x2F; 3</span><br><span class="line">testlist[6] &#x3D; &quot;c&quot;</span><br><span class="line">console.log(testlist)</span><br><span class="line">&#x2F;&#x2F; [ 1, 2, &#39;d&#39;, &lt;3 empty items&gt;, &#39;c&#39; ]</span><br><span class="line">testlist.length &#x3D; 4</span><br><span class="line">console.log(testlist)</span><br><span class="line">&#x2F;&#x2F; [ 1, 2, &#39;d&#39;, &lt;1 empty item&gt; ]</span><br><span class="line">testlist.length &#x3D; 8</span><br><span class="line">console.log(testlist)</span><br><span class="line">&#x2F;&#x2F; [ 1, 2, &#39;d&#39;, &lt;5 empty items&gt; ]</span><br></pre></td></tr></table></figure><h3 id="列表操作"><a href="#列表操作" class="headerlink" title="列表操作"></a>列表操作</h3></li><li>查找：<code>indexOf()</code>查找元素的索引，若未查到则返回-1<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">console.log(testlist) &#x2F;&#x2F;[ 6, 5, 3, 2, 1 ]</span><br><span class="line">console.log(testlist.indexOf(3)) &#x2F;&#x2F;2</span><br><span class="line">console.log(testlist.indexOf(&quot;a&quot;)) &#x2F;&#x2F;-1</span><br></pre></td></tr></table></figure></li><li>切片：<code>slice()</code>方法，第一个参数是开始索引，第二个参数是结束索引<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var testlist &#x3D; [1,2,3,4,5]</span><br><span class="line">console.log(testlist.slice(1,3)) &#x2F;&#x2F; [ 2, 3 ]</span><br></pre></td></tr></table></figure></li><li>结尾处修改：<code>pop()</code>方法<code>push()</code>，分别在结尾处删除和添加元素<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">testlist.push(&quot;a&quot;)</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 1, 2, 3, 4, 5, &#39;a&#39; ]</span><br><span class="line">console.log(testlist.pop()) &#x2F;&#x2F;a</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br></pre></td></tr></table></figure></li><li>开头处修改：<code>shift()</code>和<code>unshift()</code>，分别在开头出删除和添加元素<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">testlist.unshift(&quot;a&quot;)</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ &#39;a&#39;, 1, 2, 3, 4, 5 ]</span><br><span class="line">console.log(testlist.shift()) &#x2F;&#x2F;a</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br></pre></td></tr></table></figure></li><li>任意修改：<code>splice()</code>是在指定位置（第一个参数）删除指定个（第二个参数）元素，再从该位置添加元素（剩余参数）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">console.log(testlist) &#x2F;&#x2F;[ 1, 2, 3, 4, 5 ]</span><br><span class="line">testlist.splice(1,3,&quot;a&quot;,&quot;b&quot;)</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 1, &#39;a&#39;, &#39;b&#39;, 5 ]</span><br></pre></td></tr></table></figure></li><li>顺序修改：<code>sort()</code>和 <code>reverse()</code>函数，分别为排序和反转函数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var testlist &#x3D; [3,2,6,5,1]</span><br><span class="line">testlist.sort()</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 1, 2, 3, 5, 6 ]</span><br><span class="line">testlist.reverse()</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 6, 5, 3, 2, 1 ]</span><br></pre></td></tr></table></figure></li><li>连接：<code>()</code>与<code>()</code>，分别是连接成列表和字符串，这两个函数并不改变原列表，而是将结果通过返回值返回<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(testlist) &#x2F;&#x2F;[ 6, 5, 3, 2, 1 ]</span><br><span class="line">console.log(testlist.concat(8,9,10)) &#x2F;&#x2F;[ 6, 5, 3, 2, 1, 8, 9, 10 ]</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 6, 5, 3, 2, 1 ]</span><br><span class="line">console.log(testlist.join(&quot;-&quot;)) &#x2F;&#x2F;6-5-3-2-1</span><br><span class="line">console.log(testlist) &#x2F;&#x2F;[ 6, 5, 3, 2, 1 ]</span><br></pre></td></tr></table></figure><h1 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h1><h3 id="对象概述"><a href="#对象概述" class="headerlink" title="对象概述"></a>对象概述</h3><blockquote><p>JavaScript的对象是一种无序的集合数据类型，它由若干键值对组成。</p></blockquote></li></ul><p>由此可以看出，JavaScript中的对象类似于Python中的字典，是键-值对的集合，同时也是<strong>无序</strong>的，也就是说每次遍历的时候顺序可能有所不同<br>对象的声明和Python中的字典非常相似，使用<code>&#123;&#125;</code>括起来的一些<code>key:value</code>对<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var test_ob &#x3D; &#123;</span><br><span class="line">name:&quot;javascript&quot;,</span><br><span class="line">data:10,</span><br><span class="line">&quot;ob-test&quot;:true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>若键的名称为一般的变量名，则可以不使用<code>&quot;&quot;</code>包裹，在访问的时候可同时使用<code>.key</code>和<code>[&quot;key&quot;]</code>的方式访问。若使用的键名称使用了变量名以外的命名，则只能使用<code>[&quot;key&quot;]</code>的方式访问<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_ob) &#x2F;&#x2F;&#123; name: &#39;javascript&#39;, data: 10, &#39;ob-test&#39;: true &#125;</span><br><span class="line">console.log(test_ob.name) &#x2F;&#x2F;javascript</span><br><span class="line">console.log(test_ob[&quot;name&quot;]) &#x2F;&#x2F;javascript</span><br><span class="line">console.log(test_ob[&quot;ob-test&quot;]) &#x2F;&#x2F;true</span><br><span class="line">console.log(test_ob.x) &#x2F;&#x2F;undefined</span><br></pre></td></tr></table></figure><br>同时，若是访问了不存在的键，JavaScript并不会报错，而是返回<code>undefined</code></p><h3 id="对象键-值对动态改变"><a href="#对象键-值对动态改变" class="headerlink" title="对象键-值对动态改变"></a>对象键-值对动态改变</h3><p>与一般的动态语言相似，JavaScript对象的键值对可以动态增加和删除</p><ul><li>对一个不存在的键值复制可增加该键值对</li><li>使用<code>delete</code>可以删除一个键值对<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_ob) &#x2F;&#x2F;&#123; name: &#39;javascript&#39;, data: 10, &#39;ob-test&#39;: true &#125;</span><br><span class="line">test_ob.a &#x3D; 12</span><br><span class="line">console.log(test_ob) &#x2F;&#x2F;&#123; name: &#39;javascript&#39;, data: 10, &#39;ob-test&#39;: true, a: 12 &#125;</span><br><span class="line">delete test_ob.a</span><br><span class="line">console.log(test_ob) &#x2F;&#x2F;&#123; name: &#39;javascript&#39;, data: 10, &#39;ob-test&#39;: true &#125;</span><br></pre></td></tr></table></figure><h3 id="对象键存在性查询"><a href="#对象键存在性查询" class="headerlink" title="对象键存在性查询"></a>对象键存在性查询</h3>要查询一个键存不存在，除了直接访问以外，还有<code>in</code>和<code>hasOwnProperty</code>两种方法</li><li><code>in</code> 可以查询该键是否存在于这个对象中，并不关心是否是继承得来的</li><li><code>hasOwnProperty</code> 查询该键是否属于这个对象且不是继承得来的<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">console.log(test_ob) &#x2F;&#x2F;&#123; name: &#39;javascript&#39;, data: 10, &#39;ob-test&#39;: true &#125;</span><br><span class="line">console.log(&quot;a&quot; in test_ob) &#x2F;&#x2F;false</span><br><span class="line">console.log(&quot;name&quot; in test_ob) &#x2F;&#x2F;true</span><br><span class="line">console.log(test_ob.hasOwnProperty(&quot;a&quot;)) &#x2F;&#x2F;false</span><br><span class="line">console.log(test_ob.hasOwnProperty(&quot;name&quot;)) &#x2F;&#x2F;true</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> JavaScript学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript入门笔记1</title>
      <link href="2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B01/"/>
      <url>2017/09/06/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B01/</url>
      
        <content type="html"><![CDATA[<h1 id="JavaScript概述"><a href="#JavaScript概述" class="headerlink" title="JavaScript概述"></a>JavaScript概述</h1><h2 id="JavaScript学习目标"><a href="#JavaScript学习目标" class="headerlink" title="JavaScript学习目标"></a>JavaScript学习目标</h2><ul><li>目标水平：入门级别（会使用JavaScript，不求精通）</li><li>当前水平：Python，C与C++编程基础，无Java编程基础，主业为数字IC前端设计与验证</li><li>选用教程：<a href="https://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000">廖雪峰JavaScript教程</a><h2 id="JavaScript简介"><a href="#JavaScript简介" class="headerlink" title="JavaScript简介"></a>JavaScript简介</h2>我经常讲JavaScript戏称为雷峰塔，与Java这个雷锋并没有什么关系，是一款常用与Web编程的脚本语言。<blockquote><p>为什么起名叫JavaScript？原因是当时Java语言非常红火，所以网景公司希望借Java的名气来推广，但事实上JavaScript除了语法上有点像Java，其他部分基本上没啥关系。</p></blockquote></li></ul><p>一般的浏览器即可支持JavaScript的运行，最早这个语言适用于给网页添加一些动态的动画交互之类的东西，后来这个语言逐渐发展到现在node.js已经打通了后端，这个语言也变成了一个全能型脚本语言，至于作为一个数字IC硬件工程师要学习这个…主要是接触一下web编程，然后就是</p><blockquote><p>简单粗暴的回答就是：因为你没有选择。在Web世界里，只有JavaScript能跨平台、跨浏览器驱动网页，与用户交互。</p></blockquote><h2 id="JavaScript开发环境搭建"><a href="#JavaScript开发环境搭建" class="headerlink" title="JavaScript开发环境搭建"></a>JavaScript开发环境搭建</h2><p>简单的JavaScript脚本使用浏览器即可运行，不需要搭建环境，不过还是选择了个Node.js的环境吧，毕竟还是比较适应，这个直接下载安装即可，教程可以<a href="https://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000/00143450141843488beddae2a1044cab5acb5125baf0882000">点这里</a>，如果想要搭建一个机遇Sublime的环境可以参照<a href="http://www.cnblogs.com/bluesky4485/p/3928364.html">这个</a></p><h1 id="JavaScript基本语法"><a href="#JavaScript基本语法" class="headerlink" title="JavaScript基本语法"></a>JavaScript基本语法</h1><h3 id="结尾的分号"><a href="#结尾的分号" class="headerlink" title="结尾的分号"></a>结尾的分号</h3><p>JavaScript比较奇特的一点就是虽然并不要求在结尾添加分号;，但是浏览器执行引擎会在语句结尾自动添加;，这种行为可能会导致语义异常</p><blockquote><p>注意：让JavaScript引擎自动加分号在某些情况下会改变程序的语义，导致运行结果与期望不一致。在本教程中，我们不会省略;，所有语句都会添加;。</p><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><p>JavaScript的注释与C和Verilog相同，使用<code>//</code>和<code>/*...*/</code>分别实现行注释和块注释</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="基本数据结构"><a href="#基本数据结构" class="headerlink" title="基本数据结构"></a>基本数据结构</h3><p>JavaScript常用的有Number，字符串和布尔值三种基本数据结构</p><ul><li>Number：数字，不区分浮点数与定点数，特殊的值为NaN和Infinity，分别表示无法计算的数和超过范围的数，其中NaN与任何数均不相等，包括NaN</li><li>字符串：使用<code>&quot; &quot;</code>或<code>&#39; &#39;</code>包裹的内容，与Python字符串相似</li><li>布尔值：仅可取True和False，与其他语言的布尔值相似<br>另外，还有些需要注意的<br>由于JavaScript这个设计缺陷，不要使用<code>==</code>比较，始终坚持使用<code>===</code>比较。</li></ul></blockquote><p>这是由于<code>==</code>是将数据类型转换为一致后再进行比较，而<code>===</code>的比较包括数据类型的比较</p><blockquote><p>唯一能判断NaN的方法是通过isNaN()函数</p></blockquote><h3 id="数组与对象"><a href="#数组与对象" class="headerlink" title="数组与对象"></a>数组与对象</h3><p>数组就是一组数的集合，使用[]定义，和Python数组类似<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">var test &#x3D; [1,2,&quot;test&quot;]</span><br><span class="line">console.log(test[0])</span><br><span class="line">console.log(test[1])</span><br><span class="line">console.log(test[2])</span><br></pre></td></tr></table></figure><br>字典是键-值的对应，类似于Python的字典<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var test_dict &#x3D; &#123;</span><br><span class="line">&quot;a&quot;:1,</span><br><span class="line">&quot;b&quot;:&quot;data&quot;</span><br><span class="line">&#125;</span><br><span class="line">console.log(test_dict[&quot;a&quot;])</span><br><span class="line">console.log(test_dict[&quot;b&quot;])</span><br></pre></td></tr></table></figure></p><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>JavaScript的变量就是标准的动态语言变量，不绑定数据结构，但是最好在使用前使用var声明，否则会被视为全局变量产生不必要的麻烦。有趣的是变量名允许使用<code>$</code>字符和中文</p><blockquote><p>变量名也可以用中文，但是，请不要给自己找麻烦。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JavaScript学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
